"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","ExpirationDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1217559","CGV: Small: Making Sense out of Large Graphs - Bridging HCI with Data Mining","IIS","INFO INTEGRATION & INFORMATICS, GRAPHICS & VISUALIZATION","09/15/2012","07/31/2014","Christos Faloutsos","PA","Carnegie-Mellon University","Continuing grant","Maria Zemankova","08/31/2015","$528,578.00","Duen Horng Chau, Aniket Kittur","christos@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, 7453","7364, 7453, 7923, 9251","$0.00","The goal of this research project is to help people make sense of large graphs, ranging from social networks to network traffic. The approach consists of combining two complementary fields that have historically had little interaction -- data mining and human-computer interaction -- to develop interactive algorithms and interfaces that help users gain insights from graphs with hundreds of thousands of nodes and edges. The goal of the project is to develop mixed-initative machine learning, visualization, and interaction techniques in which computers do what they are best at (sifting through huge volumes of data and spotting outliers) while humans do what they are best at (recognizing patterns, testing hypotheses, and inducing schemas). This research addresses two classes of tasks: first, attention routing -- using machine learning to direct an analyst's attention to interesting nodes or subgraphs that do not conform to normal behavior. Second, sensemaking -- helping analysts build in-depth representations and mental models of a specific areas or aspects of a graph. Evaluation of the tools will involve both controlled laboratory studies as well as long-term field deployments.<br/><br/>As large graphs appear in many settings -- national security, intrusion detection, business intelligence (recommendation systems, fraud detection), biology (gene regulation), and academia (scientific literature) -- the potential benefits of new tools for making sense of graphs is far reaching. Project results, including open-source software and annotated data sets, will be disseminated via the project web site (http://kittur.org/large_graphs.html) and incorporated into educational activities."
"1117015","RI: Small: Automatic Speech Recognition of Unconventionally-Vocalized Speech","IIS","ROBUST INTELLIGENCE","09/01/2011","04/08/2013","Daniel Ellis","NY","Columbia University","Continuing grant","Tatiana D. Korelsky","08/31/2015","$457,999.00","","dpwe@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7495, 7923, 9251","$0.00","Despite great advances in computer recognition of conventional speech, automatic recognizers have enormous trouble with speech that deviates from speech norms in pitch range, speaking style, and timing.<br/>Unconventional speech includes the ""motherese"" used to speak to young children, certain kinds of dysarthric speech, and singing. Current speech recognizers draw their power from statistical models of very large collections of real speech, but the corollary of this power is that speech that differs from this norm cannot be handled nearly so well.<br/><br/>The goal of this project is to create a speech recognition system able to handle a broad range of non-canonical speaking and voicing styles. As a motivating basis, we will target the transcription of singing.<br/>Sung speech poses a number of significant challenges with implications in broader speech scenarios: In comparison with conventional speech, the speech timing is highly distorted; the pitch level, range, and dynamics are very different; and there are frequently simultaneous sound sources (i.e., accompanying instruments) whose signals must be distinguished from the voice.<br/><br/>The approach is to make a best-effort separation of the voice, e.g., by closely filtering the predominant pitch in a mixed signal. This candidate voice is then transformed and normalized to resemble conventional speech: The pitch harmonics are interpolated to achieve a more pitch-invariant spectrum, and the time axis is warped to achieve a more uniform rate of change (eliding over sustained, unchanging sounds). Then, a conventional speech recognizer is adapted to recognize this normalized speech. To train the recognizer for the target domain, a substantial collection of music audio is manually aligned with phoneme-level transcriptions of the singing. This corpus will be freely available to other researchers in music and non-canonical speech.<br/><br/>This work will develop techniques to make current speech recognition applicable to a much broader range of speech material and speakers."
"1116076","RI: Small: Emotional Speech Production: Analysis, Modeling and Synthesis","IIS","ROBUST INTELLIGENCE","08/01/2011","07/29/2011","Sungbok Lee","CA","University of Southern California","Standard Grant","Tatiana D. Korelsky","07/31/2015","$450,000.00","Shrikanth Narayanan","sungbokl@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7923","$0.00","Encoding of emotions in speech is achieved by vocal modulations that require an intricate control of human voicing and vocal tract articulation. The aim of this research is to identify and model articulatory processes for emotional speech production based on advanced speech production data acquisition technologies including Electromagnetic articulography (EMA) and a real-time Magnetic resonance imaging (rt-MRI). The research focuses on directly measuring and modeling articulatory kinematics and their interplay with prosodic modulation of pitch, loudness and segmental durations in speech emotion expression in order to understand the emotional speech production strategies across emotion types as well as across speakers. The validity of the emotional speech production models is verified by using a software articulatory synthesizer in an analysis-by-synthesis fashion. Theoretical implications of the findings are interpreted in relation to the Hyper and Hypo theory and the Converter/Distributor (C/D) model of speech production.<br/><br/>Detailed knowledge on the effects of emotion on the human speech articulatory and prosodic patterning has transformative potential in developing improved speech processing technologies for emotional speech recognition and synthesis that are critical for the development of natural and robust man-machine interfaces. This goal also critically includes informing quantitative assessment of expressive speech to characterize atypical or distressed vocal behavior in diverse populations, for instance, children with Autism Spectrum Disorder (ASD). Finally, a natural by-product of this research effort is the unique articulatory database that will be shared freely with the community for further expansion of the knowledge of human speech production."
"1117247","III: Small: Genome Assembly Using Sparse Sequence Information","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","09/09/2011","Mihai Pop","MD","University of Maryland College Park","Standard Grant","Sylvia J. Spengler","08/31/2015","$492,809.00","David Schwartz","mpop@umiacs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923","$0.00","Rapid advances in DNA sequencing technologies are providing scientists with the ability to rapidly and cost-effectively decode the genomes of organisms. Current technologies, however, can only reconstruct a fragmented picture of a genome's chromosomes. Stitching the resulting fragments together into a complete genome currently requires costly and time-intensive laboratory experiments. The goal of this proposal is to develop new computational approaches that combine sequencing data with the data generated by modern high-throughput mapping technologies in order to enable the automated reconstruction of much larger genomic segments, up to whole chromosomes, than currently possible. The proposed research will be closely integrated with educational activities at the University of Maryland, College Park through the mentoring of undergraduate and graduate students and of a postdoctoral fellow. <br/><br/>Despite tremendous advances over the past 20+ years, both in sequencing technologies, and in computational algorithms for genome assembly, the genomes of the majority of organisms cannot be completely reconstructed through fully-automated processes. The best sequencing technologies can only ""read"" up to a few 1000s of letters yet most organisms contain millions to billions of letters in their genomes. At the same time, genome assembly is a difficult computational problem and even the best assembly software can only generate fragmented reconstructions of the genomes being sequenced, primarily due to repetitive sequences found in the genomes of most organisms. The full completion of highly-repetitive genomes requires time- and labor-intensive processes that often last multiple years. High-throughput optical mapping technologies provide a promising source of information that could be used to disambiguate genomic repeats and automatically reconstruct much larger segments of an organism's genome than possible through the sole use of current sequencing data. Optical mapping data describe the relative placement of multiple genomic landmarks (e.g. restriction enzyme recognition sites) along large stretches of a genome, spanning hundreds of thousands of letters and even whole chromosomes. To date, however, there is no algorithmic framework that allows the incorporation of this rich source of information in the assembly process. Specifically, genome assembly can be formulated as a graph traversal problem, finding a path through a complex graph that satisfies the constraints imposed by the data provided to the assembler. Optical mapping data encode a new type of constraint on the possible traversals of a graph, potentially leading to a more complete reconstruction of genomes. <br/><br/>The main goal of this proposal is to develop an algorithmic framework and associated software tools, that enable the use of optical mapping and optical sequencing data during the assembly process. It is important to note that constrained graph traversal problems are generally computationally intractable. We propose several heuristic traversals algorithms that can use optical mapping information and are likely to perform well in practice. In addition, computational analyses will be used to determine the combination of parameters for the mapping experiment that generate data that is most informative for the assembly process. These computational predictions will be validated in an experimental setting.<br/><br/>In addition to the main research objective, this proposal will directly contribute to the education of future generations of scientists, both through the mentoring of graduate students and post-doctoral fellows, and through the continuation of a summer research internship for undergraduate and highschool students. The software developed in this proposal, as well as the scientific publications arising from this work, will be freely and broadly disseminated through open licensing."
"1409639","CHS: Medium: Adapting to Affect in Multimodal Dialogue-Rich Interaction with Middle School Students","IIS","Cyber-Human Systems, Cyberlearning&FutureLearn Tech","08/01/2014","08/01/2014","James Lester","NC","North Carolina State University","Continuing grant","Anthony Hornof","07/31/2017","$489,443.00","Kristy Boyer, Bradford Mott, Eric Wiebe","lester@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367, 8020","7367, 7924, 8045","$0.00","Affect, or emotion, profoundly shapes human experience. It influences how we perform tasks, how we build relationships with one another, and how we navigate the complexities of our daily lives. Affect is shaped and influenced by communication with other humans, experiences with the natural world, and interactions with machines. Affect plays a particularly prominent role in learning. During learning, a recurring subset of the broad range of human emotions such as confusion, frustration, boredom, anxiety, engagement, surprise, and delight appear regularly. Different emotions are best responded to in different ways. For example, task-based feedback and guidance is a helpful response to emotions of confusion and frustration, while empathetic feedback is more helpful for emotions of anger or excitement. Prior research has not answered the question of how affective adaptation can maximize the benefit to students as they interact with interactive computer-based learning environments. And yet the investigators on this project are now well positioned to address a central, unanswered question of how learning environments can adaptively respond to students' affect to create the most effective, engaging learning experiences while simultaneously promoting improved attitudes toward learning.<br/><br/>The project will provide important societal benefits by generating theoretical and practical advances across multiple disciplines. The project will lead to a deeper understanding of affect-rich learning; a set of broadly applicable affect adaptation principles; and a computational model of affective adaptation and dialogue that will be incorporated into a learning environment for science learning. The resulting affect-modeling technologies can serve as a foundation for the next generation of adaptive educational software that will promote learning through affect-rich adaptation. This will be broadly useful throughout education. The project will address issues of diversity by partnering with the highly diverse Dunn Middle School and Harnett Central Middle School, and through ongoing collaboration with the STARS Alliance for Broadening Participation in Computing. To ensure societal impact, the results will be disseminated to the public through middle school outreach programs, and to the scientific community through publication at scientific venues.<br/><br/>The three major scientific goals of the project are to: (1) Capture rich multimodal data of students' affective experiences while interacting with a fully instrumented learning environment with spoken dialogue. Observational studies will be conducted by having middle school students interact with an existing learning environment for science education called ""Crystal Island."" Crystal Island was developed by the investigators on this project and has already been used by thousands of students in middle school classrooms to learn microbiology, but it does not currently support rich multimodal interaction or natural language dialogue. Crystal Island will be fully instrumented to collect rich, multimodal data including speech, facial expression, gaze, posture, skin conductance response, heart rate, and problem-solving actions. (2) Design, develop, and refine an affect-understanding model that integrates students' natural language, nonverbal behavior, physiological response, and task-action phenomena into a rich multi-dimensional stream of affective data. By utilizing this data collected from the observational studies, an affect-understanding model will be constructed using machine learned including hidden Markov modeling. This will be the first affect-understanding model for learning environments that integrates the full complement of affect signals of spoken language (including prosody, syntax, and semantics), nonverbal behavior (including gaze and posture), physiological data (including skin conductance response and heart rate), and task actions (including navigation and manipulation actions in the learning environment). (3) Design, develop, and refine an integrated affect and dialogue management model that adaptively responds to students' affective states in the course of their learning interactions. By utilizing the learning-interaction data collected in the observational studies, a Partially Observable Markov Decision Process (POMDP) affect adaptation policy will be acquired with reinforcement learning, integrating affect and dialogue management. The resulting adaptation policy will govern both when and how the system responds to students' affect as they solve problems. The computer-based mentor will provide problem-solving advice, encouragement, empathetic responses, and other support as is needed to improve the educational experience and outcome."
"1408924","III: Medium: Collaborative Research: Collective Opinion Fraud Detection: Identifying and Integrating Cues from Language, Behavior, and Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","08/01/2014","Christos Faloutsos","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","08/31/2018","$299,908.00","","christos@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7364, 7924","$0.00","Given user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake. It is well known that a large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services. What is more, opinion fraud is prevalent; while credit card fraud is as rare as 0.2% or less, it is estimated that 20-30% of the reviews on well-known service sites could be fake. This poses a serious risk to businesses and the public, from investing on a low-quality product to consulting an incompetent doctor for diagnosis and treatment. Like other kinds of fraud, opinion fraud is a serious legal offense. In fact, it is currently being recognized as a serious issue in law enforcement by policymakers. Thus solving this problem is of great importance to businesses and the general public alike. Accurately spotting opinion fraud will enable site owners to provide trustworthy content, maintain the integrity of their service, and protect the online citizens from unfair (or potentially harmful) products and services. Businesses will also benefit from reviews with reliable feedback. Honest businesses will be indirectly rewarded, as it will no longer be easy for unscrupulous businesses to benefit from fake reviews. The research outcomes will thus contribute significantly to the healthy growth of the Internet commerce. Educational activities include incorporating research findings in graduate level courses, educating public on fraudulent behavior and misinformation, and providing publicly available educational materials including lectures and manuscripts.<br/><br/>Given the critical issues of opinion fraud in online communities, how can one identify fake reviews and attribute responsible culprits behind them? By conjoining expertise of the PIs over various modalities of deception footprints ranging over language, user behavior, and relational information, this project presents a research program that will result in much needed solutions to this emergent, prevalent, and socially impactful problem. The ultimate goal is to create a unified detection framework via synergistic integration of multiple information sources; from linguistics, user behavior, and network effects, to obtain the best of all worlds. The main idea is to formulate the problem as a relational inference task on composite heterogeneous networks, providing a principled, extensible approach that can blend and reinforce all the above cues towards effective and robust detection of fraud. From a scientific point of view, the research brings together three disciplines: natural language analysis, behavioral modeling, and graph mining. The outcome is a suite of novel, principled, and scalable techniques and models that will enhance our understanding of the creation and dissemination of opinion fraud and misinformation in general at a large scale. The PIs will collaborate with industry partners such as Yelp, Google, and Amazon, directly solicit online fake reviews, and conduct well-designed user studies for testing and validation of their techniques. The project web site (http://www.cs.stonybrook.edu/~leman/PROJECTS/OPINION_FRAUD/) provides additional information and will include open-source software and datasets."
"1423515","RI: Small: Algorithms for accelerating optimization in deep learning","IIS","ROBUST INTELLIGENCE","08/01/2014","08/01/2014","Miguel Carreira-Perpinan","CA","University of California - Merced","Standard Grant","Todd Leen","07/31/2017","$449,999.00","","mcarreira-perpinan@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2092284318","CSE","7495","7495, 7923","$0.00","Intelligent processing of complex signals such as images or sound is often performed by a parameterized, nested hierarchy of simple nonlinear processing layers, as in a deep neural net, an object recognition cascade or a speech front-end. Joint estimation of the parameters of all the layers and selection of an optimal architecture is a difficult nonconvex optimization problem, difficult to parallelize, and requiring significant human expert effort, which leads to suboptimal systems in practice. This research will develop a new, general mathematical strategy to learn the parameters and, to some extent, the architecture of nested systems, called the method of auxiliary coordinates (MAC). MAC has provable convergence, is easy to implement reusing existing algorithms for single layers, applies even when parameter derivatives are not available, easily makes use of parallel architectures, and often provides reasonable models within a few iterations. The PI's research and teaching will introduce undergraduate students to the design of nested machine learning systems, and provide computer science graduate students with skills in optimization, in support of specific areas (machine learning, computer vision/speech, etc.). The PI will broadly disseminate the results of the research by publishing papers in optimization, machine learning, computer vision and speech. The PI will make Matlab and C/C++ code available for the algorithms developed and use it as teaching aid in his courses on optimization and machine learning. The PI will strive to involve a diverse population of students in the research.<br/><br/>MAC could drastically facilitate, by reducing runtime and human effort, the practical design and estimation of complex models currently being developed in data-rich disciplines such as machine learning, computer vision and speech, but also in other areas of engineering and science. It could also obviate the construction of hand-crafted features in trees and other classifiers. It may bring a wide-ranging and timely benefit to society given that serial computation is reaching a plateau and cloud computing is becoming a commodity, and intelligent data processing is finding its way into mainstream devices (phones, cameras, etc.), thanks to increases in computational power and data availability. The research will develop MAC along two aims. Optimization: The PI will explore different ways to define auxiliary coordinates; different algorithms to solve the MAC-constrained problem; and efficient W and Z steps. The PI will also investigate the convergence properties of these approaches and their ability to be parallelized. Machine learning: The PI will apply MAC-based optimization to several existing and new nested models: deep neural nets; best-subset feature selection; learning features for decision trees; dictionary and classifier learning; parametric embeddings; learning hash functions; distal learning; model adaptation; and others. The evaluation plan includes standard benchmarks and articulatory speech modeling tasks. The research is interdisciplinary and potentially transformative: it opens many opportunities for research in optimization and machine learning, promoting thinking in terms of MAC formulations when designing learning systems, and could replace or complement the backpropagation algorithm in learning nested systems both in the serial and parallel settings. The models developed for articulatory speech will also improve our understanding of speech production."
"1420159","CHS: Small: Direct physical grasping, manipulation, and tooling of simulated objects","IIS","Cyber-Human Systems","08/01/2014","07/31/2014","Robert St. Amant","NC","North Carolina State University","Standard Grant","Anthony Hornof","07/31/2017","$496,858.00","Christopher Healey","stamant@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","7367, 7923","$0.00","This project will develop and evaluate an approach to physical grasping, manipulating, and applying tools to simulated objects, and a means of exploring of three-dimensional information. The project is founded on the concept of tool use, in which handheld tool objects are used to modify the properties or appearance of target objects. The project integrates a wide range of findings in human-computer interaction and visualization, from bimanual and tangible user interfaces to augmented reality. At the core of this research endeavor is a desktop augmented reality system with a stereoscopic or monoscopic display, a haptic pointing device, and a camera focused on the user's hands. In one hand the user holds a physical wireframe cube that contains virtual objects, and in the other hand the pointing device, its tip visually augmented to show its function, which will relate to one of several possible tools, including: (a) a probe for pointing at, selecting, and moving objects, (b) a magnifying or semantic lens for filtering, recoding, and elaborating information, and (c) a cutting plane that shows slices or projection views. On the display, users watch the immediate, direct effects of their actions with the tools on the simulated object. The system will support visualization with fluid and natural interaction techniques, improving the ability of users to explore and understand 3D objects to some extent as if they were holding the objects in their hands. The project will provide societal benefits by generating theoretical and practical advances across multiple disciplines, such as a deeper understanding of the psychological theory and computer algorithms that are needed to give a person a seamless impression that he or she is manipulating an object that appears to be physically in front of the person, but which is only there virtually. It should be relatively straightforward to transition the practical outcome of this work to low-cost hardware components such as head-mounted 3D displays, such that the project could ultimately provide everyday users with a means of directly creating and modifying objects that they have in mind for 3D printing. University students will help to develop and evaluate the system, thus exposing these students to a new and potentially transformative approach to augmenting a simulated space with physical tools, and thus providing a larger population of students with opportunities for exciting hands-on computer science learning. Orthopedic surgeons have been recruited to assist in exploring the use of the system for preoperative surgical planning such as by permitting the exploration of complex 3D bone structures.<br/><br/>Development and evaluation of the novel interaction techniques in this hands-on augmented reality system will lead to a better understanding of how performance may be improved in data exploration with augmented tool use. The research will investigate: the spatial collocation of user actions and system effects; physical constraints between the hands, objects, and the environment; and a greater role for proprioception. Experimental results will give insight into questions that cross the boundaries between relatively disparate areas of research in HCI and visualization, specifically the potential benefits of proprioception in bimanual tasks, the extent to which mechanical constraints and stabilization can improve performance in precise interaction tasks, and how these factors may compensate for the visual errors associated with presenting 3D information on a stereo or monoscopic display. The research will extend beyond the laboratory to a real and important medical domain, which will help validate our work in practice."
"1344291","INSPIRE Track I: Distributed Sensing Collective to Capture 3D Soundscapes","CNS","SPECIAL PROJECTS - CISE, COMPUTER SYSTEMS, INFO INTEGRATION & INFORMATICS, IIS SPECIAL PROJECTS, CYBER-PHYSICAL SYSTEMS (CPS), DES AUTO FOR MICRO & NANO SYST, INSPIRE","10/01/2013","08/01/2014","Curt Schurgers","CA","University of California-San Diego","Continuing grant","M. Mimi McClure","09/30/2017","$1,009,748.00","Ana Sirovic, Jules Jaffe, Ryan Kastner, Brice Semmens","schurgersc@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","1714, 7354, 7364, 7484, 7918, 7945, 8078","8653, 9178, 9251","$0.00","This INSPIRE award is partially funded by the Cyber-Physical Systems Program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, the Information and Intelligent Systems Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering, the Computer Systems Research Program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, and the Software and Hardware Foundations Program in the Division of Computing and Communications Foundations in the Directorate for Computer and Information Science and Engineering.<br/><br/>Sound plays a vital role in the ocean ecosystem as many organisms rely on acoustics for navigation, communication, detecting predators, and finding food. Therefore, the 3D underwater soundscape, i.e., the combination of sounds present in the immersive underwater environment, is of extreme importance to understand and protect underwater ecosystems. This project is creating a transformative distributed ocean observing system for studying the underwater soundscape at revolutionary spatial (~100 meters) and temporal (~100 seconds) resolutions that is also able to simultaneously resolve small-scale ocean current flow. These breakthroughs are achieved using a distributed collective of small hydrophone-equipped subsurface floats, which utilize group management techniques and sensor fusion to understand the ocean soundscape in a Lagrangian manner. The ability to record soundscapes provides a novel sensing technology to understand the effects of sound on marine ecosystems and the role that sound plays for species development. Experiments off the coast of San Diego, CA, and a research campaign in the Cayman Islands provide concrete scientific studies that are tightly interwoven with the engineering research.<br/><br/>Oceans are drivers of global climate, are home to some of the most important and diverse ecosystems, and represent a substantial contribution to the world's economy as a major source of food and employment. The technological and scientific advances in this project provide crucial tools to understand natural ocean resources, by studying soundscapes at spatio-temporal scales that were heretofore extremely burdensome and expensive to obtain."
"1016909","III: Small: Collaborative Research: Mining Information Propagation on the Web","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/31/2010","Jurij Leskovec","CA","Stanford University","Standard Grant","Sylvia J. Spengler","08/31/2015","$419,211.00","","jure@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7364","7923","$0.00","Real-time information is a fundamental emerging issue in the creation<br/>and management of Web content. Increasingly, rather than consulting<br/>relatively static sources that are indexed on a periodic basis,<br/>people refer to information on news sites, blogs, social-networking<br/>sites, and Twitter feeds that change dynamically and spread rapidly.<br/>This project will study how information content varies over time, how<br/>it is transmitted through underlying social networks, and how its<br/>recipients assemble it into larger units. The project will explore<br/>new techniques for addressing these issues, based on novel methods<br/>for tracking, analyzing, and presenting information that evolves and<br/>spreads rapidly over time. The resulting approach aims to transform<br/>important aspects of the ways in which real-time information on the<br/>Web is handled.<br/><br/>First the fundamental units of information that spread through the<br/>underlying information networks will be identified. From a set of<br/>nearly 1 billion news media articles and blog posts (approx. 6TB of<br/>data), and a collection of 500 million tweets from Twitter, small<br/>(generally textual) units of information will be identified that<br/>remain relatively stable as they spread through the Web. The<br/>temporal variation within these basic units will be analyzed and<br/>modeled. This modeling will include connections with biological<br/>models of epidemics, as well as new frameworks that exploit the<br/>fundamental differences between biological and social contagion.<br/>Finally, the temporal variation will be related to network-level<br/>models for the diffusion of this information. Generally, the actual<br/>networks on which real-time information spreads cannot be directly<br/>observed, nor can the influence of any particular node in the network<br/>be directly measured. Therefore, the project will develop machine-<br/>learning techniques that infer these hidden networks and unobserved<br/>levels of influence.<br/><br/>For more information see the project web site at:<br/>http://snap.stanford.edu/proj/mipro"
"0954570","CAREER:Deciphering the Neural Code From Perception To Cognition","BCS","COGNEURO, ROBUST INTELLIGENCE","05/15/2010","08/14/2013","Gabriel Kreiman","MA","Children's Hospital Corporation","Continuing grant","Alumit Ishai","04/30/2015","$503,398.00","","gabriel.kreiman@tch.harvard.edu","300 LONGWOOD AVENUE","BOSTON","MA","021155737","6179192729","SBE","1699, 7495","0000, 1045, 1187, OTHR","$0.00","Human beings can recognize objects in a highly selective, robust and fast manner. One of the remarkable properties of our recognition machinery is the possibility to selectively recognize objects even after transformations such as rotation, translation, scaling, occlusion and clutter. How the human brain accomplishes recognition is not well understood. More is known about processing of sensory information from receptors to the initial stages in cortex than about the subsequent transformation of perceptual data into cognition. In parallel, over the last decades, major progress has been made in building ever more accurate and sophisticated computers and devices to capture sensory information but progress has been slower in terms of developing algorithms and hardware to automatically interpret the sensory data. With support from the National Science Foundation, Dr. Gabriel Krieman is undertaking research whose aim is to elucidate the computational steps and algorithms implemented by the cerebral cortex to transform incoming inputs into cognitive functions and behavior. The research focuses on one particular aspect of cognitive experience, the neuronal mechanisms and circuits that underlie visual processing. While vision is only one of many aspects of cognition, lessons learnt from studying visual cortex can also eventually help describe other aspects of cortical function and can pave the way for research on other challenging aspects of cognition. To investigate visual cognition, Dr. Kreiman takes advantage of a rare opportunity to both stimulate and record electrical activity at high spatial and temporal resolution directly from the human brain in epilepsy patients. The study investigates tasks where visual cognition is dissociated from the incoming sensory processing in order to isolate the cognitive operations involved in recognition. The discoveries about the function of biological neural circuits will be applied to develop biophysically-inspired robust machine vision algorithms. <br/><br/>Visual recognition is essential for most everyday tasks including navigating, reading, and identifying objects, faces and emotions. By furthering our understanding of the transformation of perceptual information into cognition, the study is contributing to two broad goals: (1) Helping to alleviate the challenging conditions that involve cognitive disorders through the development of brain-machine interfaces; and (2) Applying knowledge about neuronal circuits to develop computational algorithms to extract cognitive information from sensory data. Building a fast, robust and reliable artificial vision system would have profound repercussions in many areas of science and engineering including pattern recognition, surveillance and security, automatic navigation, clinical image analysis and others. These scientific and engineering advances could in turn translate into important real-world applications of interest for industrial partnerships. Dr. Kreiman pursues these goals by studying the best possible system that can solve visual recognition challenges, the human brain. Understanding the visual system relies on many skills ranging from computer science to engineering to physics to neuroscience to psychology. The project serves well to train a generation of multidisciplinary students who can build on the fundamental science knowledge and apply this knowledge to challenging biological problems."
"0930731","Facility Support: OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","EAR","INSTRUMENTATION & FACILITIES, CI REUSE, INFO INTEGRATION & INFORMATICS, EarthCube","09/15/2009","01/15/2014","Chaitanya Baru","CA","University of California-San Diego","Continuing grant","Russell C. Kelz","08/31/2014","$1,517,073.00","","baru@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","1580, 6892, 7364, 8074","0000, 7433, OTHR","$0.00","0930731<br/>Baru<br/><br/>This collaborative grant to the San Diego Supercomputer Center and Arizona State University (PI: Arrowsmith/EAR-0930643) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http://www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products. The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF/Information Technology Research and EAR/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project. That portal currently hosts and distributes a limited number of data sets acquired through the NSF/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research. This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g., NCALM, USGS, regional consortia, states, etc.) to link to their data archives and/or to host and distribute their data and processing software algorithms through a freely accessible web-interface. High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures. Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense. Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets. These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate. OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal."
"1230493","Collaborative Research: Understanding the Rules for Human Rhythmic Motor Coordination","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/15/2012","07/31/2014","Noah Cowan","MD","Johns Hopkins University","Continuing grant","Betty H. Tuller","07/31/2015","$237,699.00","","ncowan@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","SBE","7252, 7495","7252, 7298, 7956, 9251, 8605","$0.00","Walking for a healthy adult seems easy. However, underlying this apparent simplicity our nervous system is performing a task of astounding complexity. Using sensory information about the body's movement, the nervous system coordinates the activation of dozens of muscles so that we stably and efficiently move through our environment. For example, if our nervous system senses that our foot will strike the ground too soon, it will adjust muscle activations so we do not stumble and fall. In this project, an interdisciplinary team of investigators aims to uncover the rules the nervous system uses to make such adjustments. Using a general computational and theoretical framework taken from engineering (used to understand, for example, the rhythmic control of the angle of attack of rotating helicopter blades), the method depends on gently perturbing a person's senses and body in various ways and observing how the nervous system adjusts muscle activations in response. The investigators will first test their methods on a simpler type of rhythmic movement, repetitive hitting of a virtual ball with a paddle, then extend the findings to coordination during walking. <br/><br/>By constructing a general approach to understanding the control of rhythmic movements, including swimming in fish, flying in insects and birds, and walking in people and robots, the investigators may provide a foundation for understanding how control breaks down for people with neurological conditions such as stroke and incomplete spinal cord injury. This has the potential to advance neuromuscular rehabilitation and the design of assistive devices. <br/><br/>[Co-funded by CISE and SBE]"
"0844639","Maintaining U.S. Leadership in Engineering and Science","ENG","OFFICE OF MULTIDISCIPLINARY AC, IGERT FULL PROPOSALS, ENGINEERING EDUCATION, SPECIAL STUDIES AND ANALYSES, INTERFAC PROCESSES & THERMODYN, Manufacturing Machines & Equip, BIOTECH, BIOCHEM & BIOMASS ENG, GRANT OPP FOR ACAD LIA W/INDUS, ELECT, PHOTONICS, & MAG DEVICE, MECHANICS OF MATERIALS, MATERIALS AND SURFACE ENG, NANOSCALE: SCIENCE & ENGIN CTR, ELECTRONIC/PHOTONIC MATERIALS, NANOMANUFACTURING, Gen & Age Rel Disabilities Eng, BIOMEDICAL ENGINEERING, CROSS-EF ACTIVITIES, Cyber-Human Systems, DYNAMICAL SYSTEMS, ROBUST INTELLIGENCE, SCIENCE, TECH & SOCIETY, Engy, Pwr, Ctrl, Ntwks (EPCN), EFRI RESEARCH PROJECTS, ENVIRONMENTAL SUSTAINABILITY, ENERGY FOR SUSTAINABILITY, ENG NNI SPECIAL STUDIES, SOFTWARE & HARDWARE FOUNDATION, DES AUTO FOR MICRO & NANO SYST, UNDISTRIBUTED PANEL/IPA FUNDS, , , , , , , , ","10/01/2009","07/31/2014","Robert Shelton","PA","World Technology Evaluation Center, Inc.","Cooperative Agreement","Deborah B. Young","09/30/2015","$5,692,458.00","","shelton@wtec.org","1653 Lititz Pike 417","Lancaster","PA","176016507","7172997130","ENG","1253, 1335, 1340, 1385, 1414, 1468, 1491, 1504, 1517, 1630, 1633, 1675, 1775, 1788, 5342, 5345, 7275, 7367, 7478, 7495, 7603, 7607, 7633, 7643, 7644, 7681, 7798, 7945, 9199, J217, J427, k669, L128, l165, l224, m145, M187","0000, 7237, 7367, 7556, 7945, OTHR","$0.00","This project provides for international technology assessments and related planning workshop support. WTEC and its predecessors have conducted over 60 such technology assessments since 1989. The objectives include seeking technologies to transfer to the U.S., evaluating the position of U.S. science and technology with respect to leading competitors, and seeking opportunities for international cooperation in research. <br/><br/>The project provides for four or more additional international studies and reporting of the results, plus one or more workshops in area related to international technology assessments. <br/><br/>Results will be disseminated at workshops including copies of visual aids distributed in hardcopy and posted on the Web, final reports from each study tour of academic quality in hardcopy, CD, and Web media, plus at least one synthesis report on cross-cutting findings. A blog on international S&T policy will be published to report progress."
"1139161","Collaborative Research: Socially Assistive Robots","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","04/01/2012","07/31/2014","Pamela Hinds","CA","Stanford University","Continuing grant","Ephraim P. Glinert","03/31/2017","$650,000.00","Daniel Schwartz","phinds@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","1640, 7495","1640, 7723","$0.00","Socially Assistive Robots<br/>Lead PI/Institution: Brian Scassellati, Yale University<br/>This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits. The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians. For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone. In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population. This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does. <br/>To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year. <br/>This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.<br/>For more information visit www.yale.edu/SAR"
"1162095","RI: Medium: Automated Calibration of Ultrasound for Image-Guided Surgical Procedures","IIS","ROBUST INTELLIGENCE","07/01/2012","07/31/2014","Gregory Chirikjian","MD","Johns Hopkins University","Continuing grant","Satyandra Gupta","06/30/2016","$760,662.00","Emad Boctor","gregc@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7924","$0.00","This project, developing advanced mathematical and computational methods for the online calibration of ultrasound probes that takes into account a probabilistic version of the well-known AX = XB sensor-calibration problem that has been overlooked in the robotics and computer vision literature, will advance current capabilities in computer-integrated surgical interventions, leading to lower radiation exposure to patients and better outcomes for minimally-invasive surgery.<br/><br/>Ultrasound has many benefits for minimally-invasive surgical procedures, including cost, ease-of-use, and patient/doctor radiation exposure. But ultrasound images are fuzzy and require extensive training for proper use during surgical procedures. As a result, outcomes are heavily dependent on an individual surgeon's skill with the device. <br/><br/>Broader Impacts: Beyond the potential benefits to surgical procedures, the Laboratory for Computational Sensing and Robotics (LCSR) at JHU has an established summer program for visiting undergraduate students that will facilitate involvement of undergraduates in the proposed research. In addition, the PI continues to mentor high school students from Baltimore Polytechnic High School through research experiences both during the academic year and the summer. The hands-on and visual nature of ultrasound image acquisition together with the mathematical problems of registration and calibration make this an ideal project to introduce students to the importance of mathematics."
"1111654","RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","IIS","ROBUST INTELLIGENCE","09/01/2011","07/31/2014","Michael Lewicki","OH","Case Western Reserve University","Continuing grant","Kenneth C. Whang","08/31/2015","$815,889.00","","michael.lewicki@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7495","7925","$0.00","How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br/><br/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br/><br/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing."
"1422696","CHS: Small: Context-aware mobile systems to facilitate synergistic face-to-face interactions","IIS","Cyber-Human Systems","08/01/2014","07/31/2014","Quentin Jones","NJ","New Jersey Institute of Technology","Standard Grant","Kevin Crowston","07/31/2017","$499,544.00","Starr Roxanne Hiltz","qjones@njit.edu","323 DOCTOR MARTIN LUTHER","Newark","NJ","071021982","9735965275","CSE","7367","7367, 7923","$0.00","Cyber-Human Systems hold the promise of seamless mobile social navigation, where people on the move are able to make connections to the right people at the right place and the right time. Chance encounters, the unintended meeting between people unfamiliar with each other, are rare but powerful incidents that offer people an opportunity to develop new social ties. Building new social ties and thus increasing social capital is important because individuals embedded in richly connected social environments are, for example, better able to handle personal setbacks, such as financial failures and illness, and to provide social support for others. While we often are surrounded by potential new friends it is problematic to identify who they are and how to connect with them. Context-aware systems have the potential to mediate such chance encounters and, hence, transform the way we make new social ties. The goal of this project is to understand the dynamics of chance encounters and to develop, deploy and test mechanisms for systems that can facilitate such chance encounters leading to new social ties.<br/><br/>The project has two phases. In the first, the investigators will conduct a prospective cohort study (n=500), in which two cohorts of freshmen students will be followed over 18 months, exploring both the extent of changes in their social networks that are the result of chance encounters and how formation of new ties might be enhanced by a context-aware system. A combination of ethnographic and experience sampling studies will provide insights into the dynamics of chance encounters and the contextual variables that influence people's motivations for meeting others when on-the-go, such as the nature of place; number of people nearby (social context); the individual user context, e.g., current activity (cognitive context); the nature of the relationship between two potentially matched people, e.g., shared attributes (relational context), and privacy concerns. The second phase involves design research to generate innovative mechanisms and designs for systems that will be validated in field use. Findings from these studies will identify ways that contextual data can identify opportunities for chance encounters and support serendipitous introductions, fulfilling the CHS missions of creating systems that enhance human capabilities and advance society's cohesiveness."
"1449209","SAVI: Collaborative Research: Fostering New Collaborations in Open Online Community Data Research: Prototyping an Open Collaboration Data Factory","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, Science Across Virtual Instits","08/01/2014","07/31/2014","Sean Goggins","MO","University of Missouri-Columbia","Standard Grant","Kevin Crowston","07/31/2016","$194,949.00","","gogginss@missouri.edu","310 JESSE HALL","COLUMBIA","MO","652111230","5738827560","CSE","1640, 7367, 8077","5914, 5918, 5936, 5937, 5946, 5948, 7916, 8058, 9150","$0.00","Open online communities (OOC), such as Wikipedia or free and open source software (FOSS) development projects, have emerged as significant drivers of innovation, economic activity and social well-being. OOCs play important roles in a wide variety of areas, such as software development, knowledge management, education, health and scientific discovery. With support from both American and international funding agencies, scholars from diverse disciplines, including computer science, sociology, mathematics, economics, physics, anthropology, organization science and communications, have been studying OOCs to build disciplinary understanding. However, differences in data and method impede the development of coherent understandings across disciplines. The study of OOCs is nascent, and as yet not much attention has been paid to the development of principles and systems for sharing data and detailed methodological approaches. These gaps limit scientific progress around OOCs even as they are increasing in importance for organizing and accomplishing work. The goal of this Science Across Virtual Institutes (SAVI) project is to build an international inter-disciplinary community of scholars who can collaborate to overcome disciplinary differences in research aims, data and method. The supported collaboration will enable synthesis of OOC research, which in turn will increase the coherence of scientific and public knowledge across disciplines that study OOCs, making OCCs more productive and effective. <br/><br/>The project design is based on the principle that research collaborations among scholars from multiple disciplines are more likely to develop from actively engaging potential collaborators in a shared activity, rather than simply getting them together in a room to talk. Accordingly, the project will involve participants in a series of working groups, workshops and hackathons focused on the activity of specifying, designing and prototyping an ?Open Collaboration Data Factory? (OCDF). The long-term vision for the OCDF includes a common set of easily accessible and replicable research datasets, and tools and processes that support research addressing the challenges of OOC systems, such as workflow tools to encourage creation of high-quality datasets; practice guidelines to facilitate consistent application of common research methods; documented research and resource exemplars to support coherent mapping of theory, data-based measures and available analytic tools; and ethical and privacy guidelines for processing OOC data. The SAVI funds will support coordination work, meetings and collocated prototyping among OOC researchers from diverse disciplines in the USA and Europe to build community through taking the initial steps towards this vision. The project will also include an initial phase inventorying research communities and research questions to in order to identify, characterize and annotate available datasets and software tools and identify strategies for increasing compatibility between them. All products and outcomes of the project will be made available under open licenses to further promote the reproducibility of studies and methods.<br/><br/>This is designated as a Science Across Virtual Institutes (SAVI) award and is co-funded by NSF's Office of International and Integrative Activities."
"1449188","SAVI: Collaborative Research: Fostering New Collaborations in Open Online Community Data Research: Prototyping an Open Collaboration Data Factory","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, Science Across Virtual Instits","08/01/2014","07/31/2014","Susan Winter","MD","University of Maryland College Park","Standard Grant","Kevin Crowston","07/31/2016","$104,996.00","Katherine Shilton, Brian Butler","sjwinter@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","1640, 7367, 8077","5914, 5918, 5936, 5937, 5946, 5948, 7916, 8058","$0.00","Open online communities (OOC), such as Wikipedia or free and open source software (FOSS) development projects, have emerged as significant drivers of innovation, economic activity and social well-being. OOCs play important roles in a wide variety of areas, such as software development, knowledge management, education, health and scientific discovery. With support from both American and international funding agencies, scholars from diverse disciplines, including computer science, sociology, mathematics, economics, physics, anthropology, organization science and communications, have been studying OOCs to build disciplinary understanding. However, differences in data and method impede the development of coherent understandings across disciplines. The study of OOCs is nascent, and as yet not much attention has been paid to the development of principles and systems for sharing data and detailed methodological approaches. These gaps limit scientific progress around OOCs even as they are increasing in importance for organizing and accomplishing work. The goal of this Science Across Virtual Institutes (SAVI) project is to build an international inter-disciplinary community of scholars who can collaborate to overcome disciplinary differences in research aims, data and method. The supported collaboration will enable synthesis of OOC research, which in turn will increase the coherence of scientific and public knowledge across disciplines that study OOCs, making OCCs more productive and effective. <br/><br/>The project design is based on the principle that research collaborations among scholars from multiple disciplines are more likely to develop from actively engaging potential collaborators in a shared activity, rather than simply getting them together in a room to talk. Accordingly, the project will involve participants in a series of working groups, workshops and hackathons focused on the activity of specifying, designing and prototyping an ?Open Collaboration Data Factory? (OCDF). The long-term vision for the OCDF includes a common set of easily accessible and replicable research datasets, and tools and processes that support research addressing the challenges of OOC systems, such as workflow tools to encourage creation of high-quality datasets; practice guidelines to facilitate consistent application of common research methods; documented research and resource exemplars to support coherent mapping of theory, data-based measures and available analytic tools; and ethical and privacy guidelines for processing OOC data. The SAVI funds will support coordination work, meetings and collocated prototyping among OOC researchers from diverse disciplines in the USA and Europe to build community through taking the initial steps towards this vision. The project will also include an initial phase inventorying research communities and research questions to in order to identify, characterize and annotate available datasets and software tools and identify strategies for increasing compatibility between them. All products and outcomes of the project will be made available under open licenses to further promote the reproducibility of studies and methods.<br/><br/>This is designated as a Science Across Virtual Institutes (SAVI) award and is co-funded by NSF's Office of International and Integrative Activities."
"1410004","CHS: Medium: Collaborative Research: Responsive Generation of Intrinsically Motivating Scenarios","IIS","Cyber-Human Systems","09/01/2014","07/30/2014","Jill Denner","CA","ETR Associates","Standard Grant","William Bainbridge","08/31/2017","$321,100.00","","jilld@etr.org","4 Carbonero Way","Scotts Valley","CA","950664200","8314384060","CSE","7367","7367, 7924","$0.00","This project will develop advanced methods for automatically generating scenarios that are intrinsically motivating, responsive to the user's behavior, and potentially beneficial in many spheres of the economy and culture. As numerous existing communication media are merging, computer-based narratives have become increasingly complex, significant, and influential. However, at present they are inflexible and ignore the characteristics and goals of the individual user. For many of our most pressing societal needs - from more effective education to addressing climatology challenges - a key component of any approach is motivation. Intrinsic motivation, which involves performing an activity because it is inherently interesting, is often associated with deep learning and creativity. This project employs an approach that combines types of reasoning drawn from computational creativity and logic programming to meet this challenge.<br/><br/>The research will demonstrate the first successful scenario generator, dynamically combining narrative and simulated action, and showing that generation can be guided by domain models, laying the foundation for projects to leverage generated scenarios for intrinsically motivating learning and other activities. In so doing, it will execute a novel evaluation plan that will produce a more refined understanding of the relationship between intrinsic motivation and learning, including the interrelated categories of engagement, agency, and valuation of outcomes by comparing player experience of integrated scenario systems with and without allowing the user's choices to influence the challenges and narrative. It is hoped that this research will demonstrate the utility of heterogeneous architectures for enabling previously-impossible experiences for users in a wide range of interactive experiences. A specific focus is creation of a computer-based educational experience focused on meteorological shifts, made possible by this project's technical advances and informed by its findings related to user motivation and learning.<br/><br/>While the research community has had some success in generating both narrative and simulated action, generating both together presents novel research questions. Further, to meet social needs, this generation must be capable of being guided by pedagogical and other explicitly-represented goals. This research seeks to achieve two fundamental advances. First, the project will demonstrate a successful scenario generator, showing that generation can be guided by domain models, which will enable future projects to leverage generated scenarios for intrinsically motivating learning and other activities. Second, user studies will support the first empirically grounded understanding of the effects of narrative and action responsiveness and variation on user experience, particularly engagement, motivation, and learning. By demonstrating successful scenario generation, this project will turn attention to the scenario as a potential fundamental unit for educational software, with the potential to reach underrepresented groups and produce significant economic benefit."
"1407927","III: Medium: Collaborative Research: Collective Opinion Fraud Detection: Identifying and Integrating Cues from Language, Behavior, and Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","08/01/2014","Bing Liu","IL","University of Illinois at Chicago","Standard Grant","Maria Zemankova","08/31/2018","$299,994.00","","liub@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364","7364, 7924","$0.00","Given user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake. It is well known that a large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services. What is more, opinion fraud is prevalent; while credit card fraud is as rare as 0.2% or less, it is estimated that 20-30% of the reviews on well-known service sites could be fake. This poses a serious risk to businesses and the public, from investing on a low-quality product to consulting an incompetent doctor for diagnosis and treatment. Like other kinds of fraud, opinion fraud is a serious legal offense. In fact, it is currently being recognized as a serious issue in law enforcement by policymakers. Thus solving this problem is of great importance to businesses and the general public alike. Accurately spotting opinion fraud will enable site owners to provide trustworthy content, maintain the integrity of their service, and protect the online citizens from unfair (or potentially harmful) products and services. Businesses will also benefit from reviews with reliable feedback. Honest businesses will be indirectly rewarded, as it will no longer be easy for unscrupulous businesses to benefit from fake reviews. The research outcomes will thus contribute significantly to the healthy growth of the Internet commerce. Educational activities include incorporating research findings in graduate level courses, educating public on fraudulent behavior and misinformation, and providing publicly available educational materials including lectures and manuscripts.<br/><br/>Given the critical issues of opinion fraud in online communities, how can one identify fake reviews and attribute responsible culprits behind them? By conjoining expertise of the PIs over various modalities of deception footprints ranging over language, user behavior, and relational information, this project presents a research program that will result in much needed solutions to this emergent, prevalent, and socially impactful problem. The ultimate goal is to create a unified detection framework via synergistic integration of multiple information sources; from linguistics, user behavior, and network effects, to obtain the best of all worlds. The main idea is to formulate the problem as a relational inference task on composite heterogeneous networks, providing a principled, extensible approach that can blend and reinforce all the above cues towards effective and robust detection of fraud. From a scientific point of view, the research brings together three disciplines: natural language analysis, behavioral modeling, and graph mining. The outcome is a suite of novel, principled, and scalable techniques and models that will enhance our understanding of the creation and dissemination of opinion fraud and misinformation in general at a large scale. The PIs will collaborate with industry partners such as Yelp, Google, and Amazon, directly solicit online fake reviews, and conduct well-designed user studies for testing and validation of their techniques. The project web site (http://www.cs.stonybrook.edu/~leman/PROJECTS/OPINION_FRAUD/) provides additional information and will include open-source software and datasets."
"1350573","CAREER: A Visual Analysis Approach to Space-Time Data Exploration","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/31/2014","Ross Maciejewski","AZ","Arizona State University","Standard Grant","Maria Zemankova","07/31/2019","$434,764.00","","rmacieje@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","1045, 7364, 7453","$0.00","From smart phones to fitness trackers to sensor enabled buildings, data is currently being collected at an unprecedented rate. Now, more than ever, data exists that can be used to gain insight into how policy decisions can impact our daily lives. For example, one can imagine using data to help predict where crime may occur next or inform decisions on police resource allocations or diet and activity patterns could be used to provide recommendations for improving an individual's overall health and well-being. Underlying all of this data are measurements with respect to space and time. However, finding relationships within datasets and accurately representing these relationships to inform policy changes is a challenging problem. This research addresses fundamental questions of how we can effectively explore such space-time data in order to enhance knowledge discovery and dissemination. This research both extends traditional visual representations and develops novel views for showing how correlations, clusters and other various spatial dynamics change over time. Broader impacts of the research program include: (1) enhanced infrastructure for research and education in the form of new visual analytics algorithms and open source software; (2) broad dissemination of visual analysis methods across various domains including geography, urban planning, and public health; and (3) impacts on society including the dissemination of novel tools and methods for improved public health and safety. The primary educational goals of this CAREER project are to increase students' access to crucial but highly unavailable visual analytic technologies and to broaden participation in data science and engineering. Toward those ends, the Visual Analytics Education program will engage broad student populations (undergraduate and graduate) through innovative curricula focusing on visual data analysis and the core technologies that drive the research program (visual analytics tools). By focusing on those technologies and their synergy in the research program, the education program directly integrates the proposed research with education. The programs will benefit multiple groups (researchers, patients, students, underrepresented groups) and institutions (academia, industry, healthcare, education) both locally and globally.<br/><br/>For spatial data, the translation of such data into a visual form allows users to quickly see patterns, explore summaries and relate domain knowledge about underlying geographical phenomena that would not be apparent in tabular form. However, several critical challenges arise when visualizing and exploring these large spatiotemporal datasets. While, the underlying geographical component of the data lends itself well to univariate visualization in the form of traditional cartographic representations (e.g., choropleth, isopleth, dasymetric maps), as the data becomes multivariate, cartographic representations become more complex. Multivariate color maps, textures, small multiples and 3D views have been employed as means of increasing the amount of information that can be conveyed when plotting spatial data to a map. However, each of these methods has their own limitations. Multivariate color maps and textures result in cognitive overload where much time is spent trying to separate data elements in the visual channel. In 3D, occlusion and clutter remain fundamental challenges for effective visual data understanding. Utilizing small multiples can help in side-by-side comparison, but their scalability is limited by the available screen space and the cognitive overhead associated with pairwise comparisons. Instead of being confined to the original spatiotemporal domain, this proposal seeks to both extend traditional visual representations and develop novel views for showing how correlations, clusters and other various spatial dynamics change over time. Underlying these novel views is also the need for visual representations in which the manipulation of the representation is directly tied to the underlying computational analytics. Specifically, this research focuses on datasets from urban planning, geography, public health and crime to address: (1) the extraction of semi-supervised templates for spatial and temporal aggregation; (2) the development of interaction techniques for visual steering and classification of spatiotemporal data; (3) the integration of multiple families of anomaly detection algorithms and information theoretic methods for semi-supervised anomaly detection, and; (4) novel algorithms for the extraction of flow fields from spatiotemporal data. Additional information can be found at the project website (http://vader.lab.asu.edu/Space-TimeVA) including open source software, course learning modules and podcasts."
"1330937","Workshop: How the Brain Accommodates Variability in Linguistic Representations; July, 2013 - University of Michigan","BCS","LINGUISTICS, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","07/01/2013","06/19/2013","T. Florian Jaeger","NY","University of Rochester","Standard Grant","William J. Badecker","12/31/2014","$11,903.00","Victor Ferreira","fjaeger@bcs.rochester.edu","518 HYLAN, RIVER CAMPUSBOX 27014","ROCHESTER","NY","146270140","5852754031","SBE","1311, 7252, 7495","1311, 7252, 7495, 7556","$0.00","When we listen, we rapidly and reliably decode speakers' intentions and we mostly do so independently of whom were are talking to. Yet, anyone who has interacted with an automated speech recognition system (e.g., while booking a flight) is painfully aware that speech recognition is a computationally hard problem: although we hardly ever become aware of it, the physical signal corresponding to, for example, one speaker's ""b"" can be identical to another speaker's ""p"", making it hard for computers to distinguish between them. How then does the human brain accomplish this task with such apparent ease? <br/><br/>This NSF funded workshop brings together researchers from computer sciences, linguistics, and the cognitive sciences to discuss and investigate how the brain achieves robust language understanding despite variability. The invited speakers are internationally-known experts. Representatives from both industry and academia will present on the state of the art in automated speech recognition, implicit learning during language understanding, and the neural systems underlying speech perception. The workshop will take place in conjunction with the 2013 Linguistic Society of America's Summer Institute--the largest international linguistics summer school--and will thereby provide training to a large number of young language researchers."
"1353418","EAGER: Collaborative Research: Establishing Trustworthy-Citizen-Created Data for Disaster Response and Humanitarian Action","IIS","Cyber-Human Systems","09/01/2013","09/04/2013","Cornelia Caragea","TX","University of North Texas","Standard Grant","Kevin Crowston","08/31/2015","$74,999.00","","ccaragea@unt.edu","1155 Union Circle #305250","DENTON","TX","762035017","9405653940","CSE","7367","7367, 7916","$0.00","Often referred to as microblogging, the practice of average citizens reporting on activities ""on-the-ground"" during a disaster is increasingly common. The contents of these message are potentially valuable to responder organizations and victims, but their volume makes it difficult to separate valuable messages from the stream. This project will examine microblogged messages sent during disasters to determine what aspects of the messages (individually and collectively) indicate that they are relevant, verifiable and actionable. Factors to be considered include the content of the messages, the identity of the sender and the overall pattern and spread of messages. The identified factors will then be used to instruct crowdsourced workers who will label messages to create a large corpus of labelled messages. <br/><br/>The project is important because microblogging data are seen as increasingly important: they are ubiquitous, rapid and accessible, and they are believed to empower average citizens to become more situationally aware during disasters and to coordinate to help themselves. The result of the project, if it is successful, will be evidence that it is possible to identify relevant, verifiable and actionable messages from a stream of microblogged messages and identification of the evidentiary factors. A further outcome will be a disaster-related, labeled dataset of messages, which will be useful to researchers, e.g., those seeking to automatically classify information within a microblogged data stream."
"1017190","HCC: Small: Collaborative Research: Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children","IIS","Cyber-Human Systems","09/01/2010","08/19/2010","Yang Liu","TX","University of Texas at Dallas","Standard Grant","Ephraim P. Glinert","08/31/2015","$195,726.00","","yangl@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7367","7923, 9102, 9150","$0.00","It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development. Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds. Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills. These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions. Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced. Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones. At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children. With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts. Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country). Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities. Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children. <br/><br/>Broader Impacts: This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date. Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general. Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains. In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used."
"1266162","I/UCRC: New Site of I/UCRC Safety, Security, and Rescue Research Center","IIP","INDUSTRY/UNIV COOP RES CENTERS, Cyber-Human Systems","06/01/2013","07/31/2014","Jing Xiao","NC","University of North Carolina at Charlotte","Continuing grant","Lawrence A. Hornak","05/31/2018","$160,000.00","Srinivas Akella","xiao@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","ENG","5761, 7367","5761, 8039","$0.00","The University of North Carolina at Charlotte's site for the Safety, Security and Rescue Research I/UCRC intends to contribute to the mission of the existing center to conduct integrative, multi-disciplinary research in autonomous systems to improve homeland security and emergency response. The site plans to extend the scope of SSR to healthcare, energy, material handling, and manufacturing, by focusing on human safety, injury prevention, and patient care. The new SSR I/UCRC site intends to address areas including autonomous and guided robot actions for both sensing and manipulation under high-level human control, multi-agent, integration of real-time multi-modal sensory data, secure real-time computational analysis of safety critical SSR scenarios.<br/><br/><br/>SSR Technologies are having world-wide impact in both the private and government sector. Moreover, application of these technologies is having impact that touches individual citizens. The University of North Carolina at Charlotte's Site of the SSR I/UCRC intends to extend the research outcomes it brings to the center to a new set of industries both regionally and nationally not currently represented in the center drawing upon complementary research domains. The site intends to leverage its I/UCRC site and strong NSF-funded programs on broadening participation in computing (e.g., the STARS Alliance) and REU Site by providing opportunities to engage undergraduate students from underrepresented groups and encourage them to enter graduate study."
"1117178","RI: Small: Collaborative Research: Adaptive Sampling with Robots for Marine Observations","IIS","ROBUST INTELLIGENCE","09/01/2011","06/19/2013","Daniela Rus","MA","Massachusetts Institute of Technology","Continuing grant","Satyandra Gupta","08/31/2015","$250,000.00","","rus@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7923","$0.00","This project develops (1) develops hardware platforms for persistent underwater observations, (2) develops adaptive sampling algorithms, (3) develops efficient data storage and access algorithms for sensor networks with slow broadcast rates, and (4) supports investigation of specific important environmental issues such as the interaction of rainfall events through the landscape to deliver sediment and nutrients to the near-shore and lagoon, ultimately affecting the coral reef. Specifically, the project contributes a new class of modular underwater robots and systems with increased agility in motion and effective data collection and retrieval and a science-base for coordinating underwater robots and sensors to provide a provably-correct foundation for applications to marine observations. Novel decentralized algorithms coordinate a group of robots and sensors for three related problems: sensor placement, event detection and tracking, and adaptive sampling, along with a unified framework for analyzing the stability and convergence of these algorithms.<br/><br/>Persistent underwater monitoring is deployable in any coastal environment and provides automation for collecting data in support of many environmental hypotheses. The same capabilities can also be used in the context of coastal and harbor protection operation, locating underwater mines and identifying intrusion. The underwater technology enables an unprecedented level of automation for environmental monitoring in water. The project impacts education through instructional and outreach activities aimed at developing and sharing a new curriculum that brings robotics technology together with marine biology through application, workshops, and tools. The project contributes designs and software for affordable and usable underwater robot and sensor platforms."
"1111125","HCC: Large: Collaborative Research: Human-Robot Dialog for Collaborative Navigation Tasks","IIS","INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","08/15/2011","04/11/2012","Holly Yanco","MA","University of Massachusetts Lowell","Standard Grant","Ephraim P. Glinert","07/31/2015","$416,903.00","","holly@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7364, 7367","7364, 7367, 7925, 9251","$0.00","This research involves collaboration among investigators at three institutions. The PIs anticipate a future in which humans and intelligent robots will collaborate on shared tasks. To achieve this vision, a robot must have sufficiently rich knowledge of the task domain and that knowledge must be usable in ways that support effective communication between a human and the robot. Navigational space is one of the few task domains where the structure of the knowledge is sufficiently well understood for a physically-embodied robot agent to be a useful collaborator, meeting genuine human needs. In this project, the PIs will develop and evaluate an intelligent robot capable of being genuinely useful to a human, and capable of natural dialog with a human about their shared task.<br/><br/>The Hybrid Spatial Semantic Hierarchy (HSSH) is a human-inspired multi-ontology representation for knowledge of navigational space. The spatial representations in the HSSH provide for efficient incremental learning, graceful degradation under resource limitations, and natural interfaces for different kinds of human-robot interactions. Speech is a natural though demanding way to use natural language to communicate with a robot. To maintain real-time performance, natural language understanding must be organized to minimize the amount of backtracking from early conclusions in light of later information. This project will answer three scientific questions.<br/><br/>(1) Can the HSSH framework, extended with real-time computer vision, express the kinds of knowledge of natural human environments that are relevant to navigation tasks? <br/>(2) Can the HSSH representation support effective natural language communication in the spatial navigation domain? <br/>3) Can we develop effective human-robot interaction that meets the needs of a person and improves the performance of the system?<br/><br/>To these ends, the PIs will perform this research with two different kinds of navigational robots, each learning from its travel experiences and building an increasingly sophisticated cognitive map: an intelligent robotic wheelchair which carries its human driver to desired destinations, and a telepresence robot that transmits its perceptions to a remote human driver as it navigates within an environment so the driver can achieve virtual presence and communicate with others remotely. To inform the design process, the PIs will conduct focus groups with potential users. They will also evaluate their implemented systems throughout the process, creating an iterative design-test cycle.<br/><br/>Broader Impacts: To be successful, an intelligent robot must not only be able to perceive the world, represent what it learns, make useful inferences and plans, and act effectively. It must also be able to communicate effectively with other agents, and particularly with people. This confluence among grounded knowledge representation, situated natural language understanding, and human-robot interaction is intellectually fundamental, and is the focus of this research. Since the domain of spatial knowledge is foundational for virtually all aspects of human knowledge, project outcomes will have broad applicability. This work will create technologies for mobility assistance for people with disabilities in perception (blindness or low vision), cognition (developmental delay or dementia), or general frailty (old age). It will also support telepresence applications such as telecommuting, telemedicine and search and rescue. The project includes outreach to K-12 and community college students, K-12 teachers, and the public in a number of venues."
"1116221","RI: Small: Collaborative Research:Adaptive Sampling with Robots for Marine Observations","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","09/01/2011","07/23/2011","Carrick Detweiler","NE","University of Nebraska-Lincoln","Standard Grant","Satyandra Gupta","08/31/2015","$249,971.00","","carrick@cse.unl.edu","2200 Vine St, 151 Whittier","LINCOLN","NE","685830861","4024723171","CSE","7495, 9150","7923, 9150","$0.00","This project develops (1) develops hardware platforms for persistent underwater observations, (2) develops adaptive sampling algorithms, (3) develops efficient data storage and access algorithms for sensor networks with slow broadcast rates, and (4) supports investigation of specific important environmental issues such as the interaction of rainfall events through the landscape to deliver sediment and nutrients to the near-shore and lagoon, ultimately affecting the coral reef. Specifically, the project contributes a new class of modular underwater robots and systems with increased agility in motion and effective data collection and retrieval and a science-base for coordinating underwater robots and sensors to provide a provably-correct foundation for applications to marine observations. Novel decentralized algorithms coordinate a group of robots and sensors for three related problems: sensor placement, event detection and tracking, and adaptive sampling, along with a unified framework for analyzing the stability and convergence of these algorithms.<br/><br/>Persistent underwater monitoring is deployable in any coastal environment and provides automation for collecting data in support of many environmental hypotheses. The same capabilities can also be used in the context of coastal and harbor protection operation, locating underwater mines and identifying intrusion. The underwater technology enables an unprecedented level of automation for environmental monitoring in water. The project impacts education through instructional and outreach activities aimed at developing and sharing a new curriculum that brings robotics technology together with marine biology through application, workshops, and tools. The project contributes designs and software for affordable and usable underwater robot and sensor platforms."
"1116988","HCC: Small: Collaborative Research: The Influence of Self-Avatars on Perception and Action in Virtual Worlds","IIS","Cyber-Human Systems","09/01/2011","08/27/2011","Robert Bodenheimer","TN","Vanderbilt University","Standard Grant","William Bainbridge","08/31/2015","$250,000.00","","bobbyb@vuse.vanderbilt.edu","Office of Sponsored Programs","NASHVILLE","TN","372407830","6158756070","CSE","7367","7367, 7453, 7923, 9150","$0.00","The objective of this research is to enable more effective design and use of virtual worlds. The pervasiveness of visually-oriented online and interactive digital media allows people to represent themselves increasingly through surrogates in virtual worlds. These digital personae are called ""avatars,"" and when they closely represent the user, ""self-avatars."" Self-avatars enable forms of learning, interaction, and skill development that can increase a user's effectiveness in a virtual world. This project will explore how self-avatars play a significant role through three key components of perception and action: the relationship between action and the perception of space and objects, active acquisition of spatial memory, and the planning and execution of actions themselves. <br/><br/>This research will consider three properties of self-avatars themselves, each likely to have an effect across a broad range of situations: (1) the virtual perspective from which the avatar is seen, (2) the nature of the coupling between user size and motion and avatar size and motion, and (3) the naturalness of the interface system by which the user controls the avatar. The work builds on a growing body of knowledge about the role of body ownership in perceptual and cognitive tasks. This framework provides a theory in which to ground the research, a body of empirical knowledge about perception and action in the real world, and established methodologies that can be used for assessing the results of the research. The ability to utilize work from cognitive and perceptual science to solve a problem in computer graphics and user interaction is a major strength of the research. <br/><br/>Virtual environments are important in many domains, including architecture, education, medicine, simulation, training, and visualization. The core impact of this research is to enable self-avatars to enhance user experience in virtual environments, which are a major category of computer simulations. A broad impact of this project is that enhancing the user experience will lead to more capable applications of virtual environments in the aforementioned domains. This research will also have utility in entertainment systems, the dominant environments for avatars. It advances discovery and understanding while training students in cross-disciplinary research methods in an innovative intellectual environment. The interdisciplinary nature of the research and its consequent applications, together with the close integration of two research groups, will aid in bringing new students to computer science, beyond the students traditionally attracted to that field."
"1409287","III: Medium: Collaborative Research: Closing the User-Model Loop for Understanding Topics in Large Document Collections","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/30/2014","Jordan Boyd-Graber","MD","University of Maryland College Park","Continuing grant","Maria Zemankova","07/31/2018","$168,398.00","Leah Findlater","jbg@umiacs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7364, 7924","$0.00","Individuals and organizations must cope with massive amounts of unstructured text information: individuals sifting through a lifetime of e-mail and documents, journalists understanding the activities of government organizations, companies reacting to what people say about them online, or scholars making sense of digitized documents from the ancient world. This project's research goal is to bring together two previously disconnected components of how users understand this deluge of data: algorithms to sift through the data and interfaces to communicate the results of the algorithms. This project will allow users to provide feedback to algorithms that were typically employed on a ""take it or leave it"" basis: if the algorithm makes a mistake or misunderstands the data, users can correct the problem using an intuitive user interface and improve the underlying analysis. This project will jointly improve both the algorithms and the interfaces, leading to deeper understanding of, faster introduction to, and greater trust in the algorithms we rely on to understand massive textual datasets. The resulting source code and functional demos will be broadly disseminated, and tutorials will be shared online and in person in educational efforts and to aid the adoption of the methodologies.<br/><br/>This project enables computer algorithms and humans to apply their respective strengths and collaborate in managing and making sense of large volumes of textual data. It ""closes the loop"" in novel ways to connect users with a class of big data analysis algorithms called topic models. This connection is made through interfaces that empower the user to change the underlying models by refining the number and granularity of topics, adding or removing words considered by the model, and adding constraints on what words appear together in topics. The underlying model also enables new visualizations in the form of a Metadata Map that uses active learning to focus users' limited attention on the most important documents in a collection. Users annotate documents with useful meta-data and thereby further improve the quality of the discovered topics. The project includes evaluations of these methods through careful user studies and in-depth case studies to demonstrate that topics are more coherent, users can more quickly provide annotations, users trust the underlying algorithms more, and users can more effectively build an understanding of their textual data. The project web site (http://nlp.cs.byu.edu/closing-the-loop) will include pointers to the project Git repositories for source code, project demos, tutorials, and publications communicating experimental results."
"1423189","CHS: Small: Looking Across the Uncanny Valley: Procedural and Data-Driven Methods for Gaze Modeling","IIS","Cyber-Human Systems","08/01/2014","07/31/2014","Sophie Joerg","SC","Clemson University","Continuing grant","Ephraim P. Glinert","07/31/2017","$177,609.00","Andrew Duchowski","sjoerg@clemson.edu","300 BRACKETT HALL","CLEMSON","SC","296340001","8646562424","CSE","7367","7367, 7923, 9150","$0.00","Eye movements play a key role in human communication, yet they remain a significant stumbling block for humanoid animation. Computer generated avatars currently lack realistic gaze, which subconsciously distracts viewers and thereby detracts from the usefulness of the many applications that employ these graphical actors (e.g., educational / tutoring / training systems that incorporate animated agents), a perceptual issue that has been dubbed the ""uncanny valley."" This project represents a collaboration between two investigators with complementary skills who will tackle the problem by developing a holistic model of gaze dynamics for avatars, which combines detailed real-world measurements (with the aid of binocular eye-tracking) and signal analysis of both eye motions and the periocular skin region around the eyes, to generate improved synthetic eye movement animations. Project activities will include creation of a database of gaze motions, perceptual experiments to improve our understanding of the saliency of different components of human gaze (eyeball rotation, vergence, jitter, periocular skin motion) and their signal properties in physical space, and the implementation of exemplary tasks (such as reading and conversations) along with a software tool which will enable animators to more easily design convincing gaze in frequently encountered situations. The PI intends to open-source the software to be developed in this research. <br/><br/>The gaze model under development by the PI differs from previous approaches in the following ways. First, while others have modeled cyclopean avatar gaze few have accessed the steadily growing eye tracking literature for inclusion of binocular eye movement. The PI argues that binocular eye tracking in three-dimensional physical space allows estimation of where the subject is fixating in depth and, consequently, recording, analysis, and modeling of gaze vergence, which will yield more believable characters. Second, the proposed model provides a component of subtle gaze jitter, which is critical for dynamic realism as the eyes are never perfectly still. Third, the description of the rotations of the eyes is mathematically concise, follows physiological laws, and is easy to implement. Finally, the proposed modeling effort includes perceptual studies designed to investigate the influence of each model component and to optimize the parameters of the resulting complete model. The procedural model is two-staged and reminiscent of the functionality of human vision: a bottom-up stage of eye rotation, which will be used to represent gaze when selecting a series of look points, followed by a top-down stage of gaze orientation dependent on a given task. Building a perceptual science underlying gaze modeling will foster the believability of synthetic actors, and will more broadly impact diverse areas such as social robotics where realistic gaze simulation is crucial for creating likable robots."
"1409739","III: Medium: Collaborative Research: Closing the User-Model Loop for Understanding Topics in Large Document Collections","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/30/2014","Eric Ringger","UT","Brigham Young University","Continuing grant","Maria Zemankova","07/31/2018","$267,176.00","Kevin Seppi","ringger@cs.byu.edu","A-285 ASB","Provo","UT","846021231","8014226177","CSE","7364","7364, 7924, 9150","$0.00","Individuals and organizations must cope with massive amounts of unstructured text information: individuals sifting through a lifetime of e-mail and documents, journalists understanding the activities of government organizations, companies reacting to what people say about them online, or scholars making sense of digitized documents from the ancient world. This project's research goal is to bring together two previously disconnected components of how users understand this deluge of data: algorithms to sift through the data and interfaces to communicate the results of the algorithms. This project will allow users to provide feedback to algorithms that were typically employed on a ""take it or leave it"" basis: if the algorithm makes a mistake or misunderstands the data, users can correct the problem using an intuitive user interface and improve the underlying analysis. This project will jointly improve both the algorithms and the interfaces, leading to deeper understanding of, faster introduction to, and greater trust in the algorithms we rely on to understand massive textual datasets. The resulting source code and functional demos will be broadly disseminated, and tutorials will be shared online and in person in educational efforts and to aid the adoption of the methodologies.<br/><br/>This project enables computer algorithms and humans to apply their respective strengths and collaborate in managing and making sense of large volumes of textual data. It ""closes the loop"" in novel ways to connect users with a class of big data analysis algorithms called topic models. This connection is made through interfaces that empower the user to change the underlying models by refining the number and granularity of topics, adding or removing words considered by the model, and adding constraints on what words appear together in topics. The underlying model also enables new visualizations in the form of a Metadata Map that uses active learning to focus users' limited attention on the most important documents in a collection. Users annotate documents with useful meta-data and thereby further improve the quality of the discovered topics. The project includes evaluations of these methods through careful user studies and in-depth case studies to demonstrate that topics are more coherent, users can more quickly provide annotations, users trust the underlying algorithms more, and users can more effectively build an understanding of their textual data. The project web site (http://nlp.cs.byu.edu/closing-the-loop) will include pointers to the project Git repositories for source code, project demos, tutorials, and publications communicating experimental results."
"1409992","CHS: Medium: Collaborative Research: Responsive Generation of Intrinsically Motivating Scenarios","IIS","Cyber-Human Systems","09/01/2014","07/30/2014","Michael Mateas","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","08/31/2017","$857,000.00","Arnav Jhala, Noah Wardrip-Fruin","michaelm@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","7367, 7924","$0.00","This project will develop advanced methods for automatically generating scenarios that are intrinsically motivating, responsive to the user's behavior, and potentially beneficial in many spheres of the economy and culture. As numerous existing communication media are merging, computer-based narratives have become increasingly complex, significant, and influential. However, at present they are inflexible and ignore the characteristics and goals of the individual user. For many of our most pressing societal needs - from more effective education to addressing climatology challenges - a key component of any approach is motivation. Intrinsic motivation, which involves performing an activity because it is inherently interesting, is often associated with deep learning and creativity. This project employs an approach that combines types of reasoning drawn from computational creativity and logic programming to meet this challenge.<br/><br/>The research will demonstrate the first successful scenario generator, dynamically combining narrative and simulated action, and showing that generation can be guided by domain models, laying the foundation for projects to leverage generated scenarios for intrinsically motivating learning and other activities. In so doing, it will execute a novel evaluation plan that will produce a more refined understanding of the relationship between intrinsic motivation and learning, including the interrelated categories of engagement, agency, and valuation of outcomes by comparing player experience of integrated scenario systems with and without allowing the user's choices to influence the challenges and narrative. It is hoped that this research will demonstrate the utility of heterogeneous architectures for enabling previously-impossible experiences for users in a wide range of interactive experiences. A specific focus is creation of a computer-based educational experience focused on meteorological shifts, made possible by this project's technical advances and informed by its findings related to user motivation and learning.<br/><br/>While the research community has had some success in generating both narrative and simulated action, generating both together presents novel research questions. Further, to meet social needs, this generation must be capable of being guided by pedagogical and other explicitly-represented goals. This research seeks to achieve two fundamental advances. First, the project will demonstrate a successful scenario generator, showing that generation can be guided by domain models, which will enable future projects to leverage generated scenarios for intrinsically motivating learning and other activities. Second, user studies will support the first empirically grounded understanding of the effects of narrative and action responsiveness and variation on user experience, particularly engagement, motivation, and learning. By demonstrating successful scenario generation, this project will turn attention to the scenario as a potential fundamental unit for educational software, with the potential to reach underrepresented groups and produce significant economic benefit."
"1423002","III: Small: Information Chain Support for Disaster Mitigation, Preparedness, Response and Recovery","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","08/01/2014","Hui Fang","DE","University of Delaware","Standard Grant","James French","07/31/2017","$500,000.00","Patricia Young, James Kendra, Xiaoming Li","hfang@ece.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7364","7364, 7923, 9150","$0.00","When disasters strike, an urgent task for decision makers and the general public is to consolidate scattered, probably chaotic and incomplete information and then to plan the next step. The information needed to reach a decision or develop a policy is very likely not provided by a single document or a single piece of text, but resides in multiple sources. In other words, a document might be complemented or further elaborated upon by other documents, and all of them, only as a whole, provide a complete and satisfying answer. This project will create a new information chain of support for emergency management. InfoChain is expected to significantly improve the way policy/decision makers, disaster researchers and the general public search emergency-related information by automatically connecting the dots in information. All research results gleaned from this project will be disseminated to the research community through publications, tutorials and open-source software. Data collections will be available for other researchers to use in evaluating their own approaches. <br/><br/>Today's search engines, or more general Information Retrieval (IR) systems are designed for simple information needs that can be satisfied by one document. Documents are ranked independently with regard to their relevance scores to a query. A single document is expected to cover all the query concepts. Unfortunately, this assumption offers little help for connecting different pieces of relevant information, which is crucial to emergency management. The key novelty of this project is the capability to search document tuples, a group of documents that collectively satisfy an information need. Tuple-based retrieval models and result organization that define collective relevance of a document tuple with respect to an information need will help users efficiently examine search results. The document tuple is a more natural and desirable retrieval unit for complicated information needs, and its incorporation into IR retrieval models for emergency management leaps over the single-document-oriented IR practices and is the first such effort. For further information see the project web site at: http://www.eecis.udel.edu/~hfang/infochain.html"
"1420971","CHS: Small: Robust Interactive Audio Source Separation","IIS","Cyber-Human Systems","10/01/2014","08/01/2014","Bryan Pardo","IL","Northwestern University","Standard Grant","Anthony Hornof","09/30/2017","$498,736.00","","pardo@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7923","$0.00","Algorithms to separate audio sources have many potential uses such as to extract important audio data from historic recordings or to help people with hearing impairments select what to amplify and what to suppress in their hearing aids. Computer processing of audio content can potentially be used to isolate the sound sources of interest and to improve the audio clarity any time that the content exhibits interference from multiple sound sources, such as to extract a single voice of interest from a room full of voices. However, current sound source identification and separation methods are only reliable when there is a single predominant sound. This project will develop the science and technology that is needed to more easily isolate a single sound source from audio content with multiple competing sources, and that is needed to build interactive computer systems that will guide users though an interactive source separation process, to permit the separation and recombining of sound sources in a manner that is beyond the reach of existing audio software. The outcomes of the project will improve the possibility of speech recognition in environments with multiple talkers, will be useful for many scientific inquiries such as in biodiversity monitoring through the automated analysis of field recordings, and will be broadly useful any time that manual tagging of audio data is not practical.<br/><br/>While many computational auditory scene analysis algorithms have been proposed to separate audio scenes into individual sources, current methods are brittle and difficult to use and as a result have not been broadly adopted by potential users. The methods are brittle in that each algorithm relies on a single cue to separate sources and if the cue is not reliable then the method fails. The methods are difficult to use because the algorithms cannot predict which audio scenes any specific algorithm is likely to work on, and so the user does not know which method to apply in any given case. They are also difficult to use because their control parameters are hard to understand for users who lack expertise in signal processing. This project will research how to integrate multiple source separation algorithms into a single framework, and how to improve the ease of use by exploring interfaces that permit users to interactively define what they wish to isolate in audio scenes, and that permit systems to provide users with guidance on selecting a tool and setting the necessary parameters. The project will produce an open-source audio source separation tool that embodies these scientific research outcomes."
"1425337","CHS: Small: Non-visual Access to Graphical Information Using a Vibro-Audio Display","IIS","Cyber-Human Systems","09/01/2014","07/31/2014","Nicholas Giudice","ME","University of Maine","Continuing grant","Ephraim P. Glinert","08/31/2017","$177,568.00","","nicholas.giudice@maine.edu","5717 Corbett Hall","ORONO","ME","044695717","2075811484","CSE","7367","7367, 7923, 9150","$0.00","Vision impairment is estimated by the World Health Organization as effecting 12 million people in the United States and as many as 285 million people worldwide, and these numbers are projected to double by 2030 due to the aging of our population. Lack of access to non-textual material such as graphs and maps is a major impediment for the blind, because the ability to apprehend and accurately interpret such information is critical for success in the classroom and in the workplace, as well as for independent travel. The inability to exploit this information helps explain why only about 11% of blind or low-vision persons have a bachelor's degree, why only 25% of blind people are employed, and why almost 70% of blind individuals do not navigate independently outside of their home. A major step toward improving these numbers, as well as the overall quality of life for members of the blind and low-vision community, would be to solve the longstanding challenge of affording low-cost and effective access to key graphical material.<br/><br/>The PI's goal in this project is to develop and evaluate a highly intuitive tool for doing just that. To this end, he will explore a multimodal combination of vibro-tactile, audio, and kinesthetic cues that can be generated by modern touchscreen tablets (especially smartphones), to convey useful visual information in real-time. Benefits of this approach include portability, affordability, and flexibility of use for multiple critical and common applications such as those enumerated above. The PI argues that considering these design factors from the outset, in conjunction with principled empirical investigations to evaluate and enhance information perceptibility interleaved with frequent prototype testing and iterative refinement, with tight involvement of members of the target population in all phases of the research, will ensure that project outcomes significantly reduce the graphical information gap between blind persons and their sighted peers. The research will make important contributions to our understanding of how blind and low-vision individuals process non-visual information, which is essential for rendering perceptually salient multimodal graphics, and will also help establish best practices both for rendering these graphics using a vibro-audio interface implemented on touchscreen enabled devices, as well as for similar future specialized interface development efforts."
"1408287","III: Medium: Collaborative Research: Collective Opinion Fraud Detection: Identifying and Integrating Cues from Language, Behavior, and Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","08/01/2014","Leman Akoglu","NY","SUNY at Stony Brook","Standard Grant","Maria Zemankova","08/31/2018","$600,000.00","Yejin Choi","leman@cs.stonybrook.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7364","7364, 7924","$0.00","Given user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake. It is well known that a large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services. What is more, opinion fraud is prevalent; while credit card fraud is as rare as 0.2% or less, it is estimated that 20-30% of the reviews on well-known service sites could be fake. This poses a serious risk to businesses and the public, from investing on a low-quality product to consulting an incompetent doctor for diagnosis and treatment. Like other kinds of fraud, opinion fraud is a serious legal offense. In fact, it is currently being recognized as a serious issue in law enforcement by policymakers. Thus solving this problem is of great importance to businesses and the general public alike. Accurately spotting opinion fraud will enable site owners to provide trustworthy content, maintain the integrity of their service, and protect the online citizens from unfair (or potentially harmful) products and services. Businesses will also benefit from reviews with reliable feedback. Honest businesses will be indirectly rewarded, as it will no longer be easy for unscrupulous businesses to benefit from fake reviews. The research outcomes will thus contribute significantly to the healthy growth of the Internet commerce. Educational activities include incorporating research findings in graduate level courses, educating public on fraudulent behavior and misinformation, and providing publicly available educational materials including lectures and manuscripts.<br/><br/>Given the critical issues of opinion fraud in online communities, how can one identify fake reviews and attribute responsible culprits behind them? By conjoining expertise of the PIs over various modalities of deception footprints ranging over language, user behavior, and relational information, this project presents a research program that will result in much needed solutions to this emergent, prevalent, and socially impactful problem. The ultimate goal is to create a unified detection framework via synergistic integration of multiple information sources; from linguistics, user behavior, and network effects, to obtain the best of all worlds. The main idea is to formulate the problem as a relational inference task on composite heterogeneous networks, providing a principled, extensible approach that can blend and reinforce all the above cues towards effective and robust detection of fraud. From a scientific point of view, the research brings together three disciplines: natural language analysis, behavioral modeling, and graph mining. The outcome is a suite of novel, principled, and scalable techniques and models that will enhance our understanding of the creation and dissemination of opinion fraud and misinformation in general at a large scale. The PIs will collaborate with industry partners such as Yelp, Google, and Amazon, directly solicit online fake reviews, and conduct well-designed user studies for testing and validation of their techniques. The project web site (http://www.cs.stonybrook.edu/~leman/PROJECTS/OPINION_FRAUD/) provides additional information and will include open-source software and datasets."
"1349355","Workshop: Robot Planning in the Real World: Research Challenges and Opportunities","IIS","ROBUST INTELLIGENCE","08/15/2013","08/06/2013","Ron Alterovitz","NC","University of North Carolina at Chapel Hill","Standard Grant","Jeffrey Trinkle","07/31/2015","$48,058.00","Sven Koenig, Maxim Likhachev","ron@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","7495, 7556","$0.00","Planning is one of the key technologies in robotics. Yet, robots are deployed in only a small number of niche areas, and most deployed robots have very minimal planning capability. This workshop discusses how the field of robot planning should progress to make robots deployable more widely, performing more novel tasks and relying less on human supervision. It brings together researchers from robotics, artificial intelligence, and related research disciplines to discuss the state of the art in planning, its use in various robotic applications and current research challenges. By studying planning research across different applications, analyzing planning challenges as part of complete robot architectures, and discussing the interaction of planning with other robot modules (such as perception, control, and user interfaces), the workshop participants will gain new insights into how planning can help robots become more robust and efficient. The workshop consists of invited talks, breakout sessions, panels and a final discussion aiming to converge on the roadmap for the field of robot planning that will be summarized in a report. The report and all presentations will be posted on the workshop website. The workshop is expected to stimulate future research towards robot planning in the real world and have strong potential to enable advances in all areas of robotics, from home assistance to medicine to exploration to manufacturing."
"1344250","INSPIRE Track 1: Collaborative Research: Transforming Remotely-conducted Research through Ethnography, Education and Rapidly-Evolving Technologies","OCE","OCE, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE, INSPIRE","09/01/2013","08/01/2014","Chris German","MA","Woods Hole Oceanographic Institution","Continuing grant","Brian Midson","08/31/2016","$800,000.00","","cgerman@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082892462","GEO","6899, 7484, 7495, 8078","8653","$0.00","This INSPIRE award is partially funded by the Oceanographic Centers and Facilities Program in the Division of Ocean Sciences in the Directorate for Geosciences, the Transforming Undergraduate Education in STEM Program in the Division of Undergraduate Education in the Directorate for Education and Human Resources, and the Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering.<br/><br/>This project is aimed at expanding the ways scientists conduct field work from oceanographic research platforms. To do so, the team will assemble a cohort of 12 undergraduate students who will be involved in a telepresence-based research cruise, whose mission is to investigate greenhouse gas exhalation from the seafloor. The students will be active in all phases of the planning, execution and conclusion of the project. The students will be mentored by the PIs as well as a group of early-career scientists. <br/><br/>In addition to the ocean science objectives, the PIs will conduct an evaluation of the effectiveness of the activity for recruiting and entraining undergraduate students in STEM. They will also assess the impact the experience has on the learning experience of the students. They will also improve the capability of researchers to utilize increasingly advanced robotic systems for this activity, and in the future. <br/><br/>Another important aspect of the project is integrating an ethnography component, defined as the study of the practices through which a community makes meaning. The PIs will compare ship-based versus telepresence interactions, paying attention to where conflicts arise and how they are resolved. They will evaluate the cultural processes involved in human-machine interactions for this activity. They will assist in developing the best practices for this approach to science and help communicate the outcomes broadly."
"1029549","Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","09/01/2010","07/31/2014","Anind Dey","PA","Carnegie-Mellon University","Continuing grant","Ephraim P. Glinert","08/31/2015","$1,531,518.00","Yaser Sheikh, Takeo Kanade","anind@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 7367","1640, 7367, 7723, 7969, 9218, 9251, HPCC","$0.00","Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br/>Communicative Behavior<br/>Lead PI/Institution: James M. Rehg, Georgia Institute of Technology<br/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles."
"1423273","CHS: Small: Toward a New Generation of Untethered Magnetic Haptic Interfaces","IIS","Cyber-Human Systems","08/01/2014","07/29/2014","Jake Abbott","UT","University of Utah","Continuing grant","Anthony Hornof","07/31/2017","$191,993.00","","jake.abbott@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7367","7367, 7923, 9150","$0.00","This project will advance the science and technology of magnetic-levitation-based haptic interfaces by developing an untethered hand-held interface in which magnetic forces are applied to a freely moving tool rather than a handle that is physically attached to a larger device. The project will extend force-feedback devices into a new wave of development that incorporates free mobility. Current haptic devices use mechanically linkages to impart forces and torques to the user. These new untethered devices will use projected magnetic fields and an externally tracked tool so that the user is freed from any physical linkage. The project will contribute to the development of new microsurgical systems that can be used to train and evaluate novice surgeons prior to conducting surgery on actual patients.<br/><br/>This project will investigate a new type of magnetic haptic interface, an untethered magnetic interface that renders force/torque to a permanent magnet attached to a stylus by using electromagnets that project their magnetic fields into free space. The position and orientation of the permanent magnet must be tracked to provide feedback for the device to work as a haptic interface. Unlike Lorentz-force interfaces, which must encase a portion of the stylus, the project will produce an untethered interface in which the stylus can be completely removed from the electromagnet system, thus eliminating the physical linkage between the haptic stylus and the rest of the system, and reducing stylus inertia to only that of the stylus itself. The project has three goals: (1) To develop the analytical relationships that will govern untethered magnetic haptic interfaces. Many of the existing basic principles for haptic devices will need to be reconsidered, such the fundamental trade-offs among workspace size, stylus inertia, maximum force/torque generation, maximum stable surface stiffness, and sampling update rate. (2) To adapt high-speed image-processing techniques to track the six degrees of freedom of movement that are possible in an untethered manual tool. (3) To realize a prototype magnetic haptic interface that is optimized for simulating cataract surgery."
"1450545","EAGER: A Method to Retrieve Non-Textual Data from Widespread Repositories","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, NSF Public Access Initiative","08/01/2014","07/29/2014","Eduard Hovy","PA","Carnegie-Mellon University","Standard Grant","Sylvia J. Spengler","07/31/2015","$300,000.00","Jamie Callan","hovy@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 7364, 7414","7364, 7916, 1640","$0.00","As the results of scholarly research in data-rich sciences, the growth of non-textual data, for example, numerical data, continues to expand. This work explores through a prototype whether alternatives can be found to large centralized repositories of non-textual data that are easy to use, universal and low cost. The idea is to be able to access non-textual information as easily and readily as documents without laborious additional work. The automatic creation of a number of indices would provide a mechanism to facilitate indexing and retrieval, such as done by internet search giants for text. If successful, it will be easy to post numerical data and and have it be available via standard web search engines as easily as textual information is today. <br/><br/>The team will build a system using a wide variety of data sources and objects from a range of disciplines, and then design representations that specify the characteristics of non-textual data, including numerical data. Next they will develop enhanced indexing capabilities to handle queries in an extended search engine and procures to annotate the data by each type. After developing a query and interaction interface for developers and pilot users, they will test the viability of the approach and the effectiveness for creating descriptive additions for various types of data."
"1451465","EAGER: Towards the New Making Renaissance: Tools for Creative Making","IIS","Cyber-Human Systems","08/01/2014","07/29/2014","Eric Paulos","CA","University of California-Berkeley","Standard Grant","Kevin Crowston","07/31/2015","$175,000.00","","paulos@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367","7367, 7916","$0.00","The emerging ubiquity of low cost digital fabrication technologies such as 3D printing and laser cutting tools coupled with the popularity of local and online making communities such as Tech Shops, Maker Spaces, Fab Labs, Esty, Thingiverse, and Ponoko, have empowered individuals and groups to participate in the creative act of making in new and remarkable ways. This ""maker movement"" as it is often called, is radically transformative, affecting education, manufacturing, healthcare, and the economy. However, the creative design tools and mechanisms for knowledge capture and sharing lag behind. This project will develop new software tools for promoting creative and rapid design exploration using digital fabrication equipment as well as a novel sensor for capturing and identifying workshop activities for learning and tutorial creation. The software and hardware approaches proposed will broaden participation by a new community of non-engineers, enabling everyday individuals to not just easily enter the emerging world of digital fabrication but to be leading participants in this important technological and cultural phenomenon.<br/><br/>This project includes a set of focused studies and the design of several new physical interactive technologies for capturing and expressing a broad range of physical making and prototyping activities. Specifically, it involves building and evaluating two technologies: first, MetaMorphe, a web-based system to enable more rapid and dynamic design exploration of 3D physical designs for digital fabrication, and second, FabSense, a ring-worn wireless inertial sensor for capturing and identifying a user's activities scoped within the landscape of making with workshop hand tools. While this proposal plans to provide significant functionality in these system, it also argues for an increased foregrounding of the creative process, an improved inclusion of everyday tools, and a capturing of the analog experience of making."
"1344361","EAGER: Exploratory Research on Harnessing Human Manipulation","IIS","ROBUST INTELLIGENCE","08/15/2013","08/15/2013","Matthew Mason","PA","Carnegie-Mellon University","Standard Grant","Satyandra Gupta","07/31/2015","$99,999.00","Nancy Pollard","matt.mason@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7916","$0.00","This project is exploring the use of crowd-sourcing, or citizen science, to produce a large database of analyzed human manipulation video. Every human is an expert on human manipulation. Harnessing this expertise has the potential to radically transform our knowledge of manipulation. A large analyzed video database directly serves several important goals of robotics, including autonomous robotic manipulation and recognition of human behavior. This new approach is in its earliest stages. The project goals are to explore the new approach, identify problems, assess the value, refine the vision, and formulate plans. Activities include development of pilot interfaces, testing different approaches to user training, and developing approaches to the filtering and aggregation of results. The ultimate impact will be a broader scientific understanding of human manipulation, and a large dataset to support research in robotic manipulation and human behavior recognition. Results will be disseminated through publication of discoveries related to human manipulation, open access to the database, and open access to the crowd-sourcing interface and related software."
"1339470","III: Medium: Collaborative Research: Developing a 3D Browser to Explore Genomes","IIS","INFO INTEGRATION & INFORMATICS","02/01/2013","03/21/2013","Wenjin Zheng","TX","University of Texas Health Science Center Houston","Standard Grant","Sylvia J. Spengler","09/30/2016","$342,813.00","","wenjin.j.zheng@uth.tmc.edu","7000 FANNIN ST","HOUSTON","TX","770305400","7135003999","CSE","7364","7924, 9150","$0.00","New genome technologies enabled us to analyze the spatial conformation and interaction of chromatin together with their functional implication in important cellular activities such as gene regulation and cell state determination. With the influx of new details about the higher-level structure and dynamics of the genome, novel techniques will be required to visualize and model the full extent of genomic interactions to gain insight about genome functions. Current genome browsers are specifically aimed at viewing primary sequence information. Although supplemental information can be annotated via new tracks, representing structural hierarchies and interactions is quite difficult in these browsers, particularly across non-contiguous genomic segments. In addition, in spite of many recent efforts to measure and model the genome structure at various resolutions and detail, little work has focused on combining these models or taken advantage of the large amount of genomic and epigenomic data generated from new high-throughput approaches. To address these issues, the team has created a proof-of-concept interactive 3D viewer, Genome3D, to enable integration and visualization of genomic and epigenomic data in three dimension. Substantial development is needed to take advantage of the newest genomic technologies and to enable its integration with analysis pipelines. While enormous amount of spatial information for eukaryotic chromosomes have been generated, the size and complexity of these data require the design and development of new algorithms and methods in data integration and model construction. The goal is to develop a full-fledged, platform independent system that enables biologists to build and refine their own 3D genome models to analyze their data. <br/><br/>The intellectual merits of the research include: 1) Implementing a novel strategy to employ new engines with strong interactive design element to transform the prototype into a cloud-based 3D genome browser that can be used on various platforms including web browsers and tablets, making 3D structural genome information available to a broader research community. 2) Adding integrated tools that can analyze 3D features of genomes and support model building and validation. 3) Designing and providing robust set of APIs and scripting for customized data analysis. 4) Collaborating with other researchers to explore and visualize new three dimensional genome models.<br/><br/>There are a number of broader impacts in this research. A multi-scale three dimensional genome browser is crucial to achieve fuller understanding of genome functions and will provide a new way to teach genomics. Exploring genomes through 3D visualization will significantly advance genome research and will have a profound impact on comparative genomics and genetics. The use of new user interaction-intensive engines into scientific research tools and will encourage researchers in every area to use interactive visualization to analyze data. New algorithms to analyze models and visualize genomic information can be extended to problems of similar size in other fields and form the basis for new computational approaches. This project provides valuable interdisciplinary training experiences to undergraduate and graduate students and will attract more students to computational biology research. Results and the new browser will be disseminated through publications, workshops and tutorials and will enable customized development by providing detailed APIs and tutorials."
"1351029","CAREER: Web Information Extraction: Integration and Scaling","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","07/29/2014","Douglas Downey","IL","Northwestern University","Continuing grant","Maria Zemankova","08/31/2019","$108,376.00","","ddowney@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7364","1045, 7364","$0.00","This project studies Web Information Extraction (WIE), the task of automatically extracting computer-understandable knowledge bases (KBs) from the World Wide Web. The project addresses two key challenges in WIE. First, many different teams in academia and industry are pursuing WIE, but they lack methods for combining their KBs into a more powerful whole. This project explores how to integrate knowledge automatically across WIE systems and approaches. Secondly, a long-standing goal for WIE is to construct systems that can scale to billions of facts, by continually improving themselves over time. This project is investigating new methods that continually optimize a WIE system with limited human intervention. The project's goal of scaling and integrating WIE systems promises to address needs in the research community, the computing industry, and the public. Methods that allow different WIE systems to seamlessly exchange knowledge could dramatically hasten the progress of Web extraction efforts currently underway in academia and industry. For the public, advances in Web extraction promise to enable improved search engines that can assist users with tasks and answer complex questions. Further, through application prototypes, the project will provide public-facing information retrieval tools that promise to help users retrieve, understand, and analyze the Web's knowledge more rapidly. The project's research is also integrated with an education plan that includes outreach to underrepresented groups.<br/><br/>The technical solutions pursued in the project utilize probability distributions over natural language. For the integration challenge, the project is developing new Application Programming Interfaces (APIs) that leverage the expressiveness of natural language to automatically integrate current and future WIE systems, even when the systems extract from different types of corpora and represent knowledge in different ways. For the scaling challenge, the project is developing ways to continually optimize new Statistical Language Models (SLMs) over text on the Web. The project investigates the SLM approach for WIE theoretically, asking what types of knowledge different SLMs can encode, and how much text is required to obtain the knowledge. Further, the project introduces new SLM capabilities, including methods for scaling to larger corpora and more semantic classes, and novel models that incorporate collocations, quantitative attributes, sense disambiguation, and actively-selected human input. The project web site (http://websail.eecs.northwestern.edu/wie/) provides additional information and access to results, including software, corpora, and evaluation data sets."
"1117388","RI: SMALL: Collaborative Research: Investigations of the Role of Dorsal versus Ventral Place and Grid Cells during Multi-Scale Spatial Navigation in Rats and Robots","IIS","ROBUST INTELLIGENCE","09/01/2011","08/20/2011","Jean-Marc Fellous","AZ","University of Arizona","Standard Grant","Kenneth C. Whang","08/31/2015","$219,484.00","","fellous@email.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7495","7923","$0.00","Spatial navigation is a complex cognitive process that relies on robust and adaptive mechanisms to relate current and future spatial positions to specific locations in the environment. The goal of this project is to provide a better understanding of spatial navigation by integrating information obtained from experimental studies in rats, computational models, and experiments on robots that will test new hypotheses on how these mechanisms work. <br/><br/>The hippocampus and medial entorhinal cortex (MEC) are major brain regions involved in mammalian spatial navigation. While the role of place cells in the hippocampus has been extensively studied, there are still many open questions on the functional role of MEC grid cells and their interaction with the hippocampal place cells. Of interest to this proposal is the recent finding that grid cells are organized in an orderly fashion along the dorso-ventral axis of the MEC, with dorsal grids being much more tightly spaced than ventral ones. The investigators hypothesize that this multiscale organization endows the navigation system with a coding mechanism that will inherently achieve robustness with respect to external perturbations such as obstacles or unexpected changes in visual cues. In order to evaluate this hypothesis the investigators will develop computational and robotic models while systematically performing experiments in rat in which the dorsal or ventral portions of MEC or hippocampus will be inactivated. They will introduce new types of mazes in which the spatial frequency of the trajectories will be controlled. This work will contribute to better spatial navigation in robotics by: (1) providing a robotic testbed to evaluate hypotheses on the role of the entorhinal cortex and (2) providing biologically plausible models for robust spatial navigation under uncertain and dynamic environments. These models will suggest alternatives to classical probabilistic methods commonly used in robot Simultaneous Localization And Mapping paradigms. This work will also contribute to studies of spatial navigation in rats by: (1) showing the usefulness of robots in providing a physical testbed beyond pure computational modeling, and (2) exploiting the shorter cycle of robot experimentation to produce maze configurations that are optimal for testing specific hypotheses in rat experiments."
"1421929","CHS: Small: Methods to Enhance Teamwork in Computer-Mediated International Collaboration","IIS","Cyber-Human Systems","08/01/2014","07/29/2014","Malte Jung","NY","Cornell University","Continuing grant","William Bainbridge","07/31/2017","$177,135.00","Susan Fussell","mfj28@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923","$0.00","This research will draw from understanding of moment-by-moment team dynamics to develop new interventions to help international teams overcome collaboration challenges. Communication tools and social media have the potential to allow people to interact fluidly across national, cultural and linguistic boundaries in ways that would have been difficult if not impossible in the past. In computer-mediated organizations, teams of people from across the globe now work together on common problems, each bringing his or her own perspective and expertise. Despite the promise of new media for interaction across national and cultural boundaries, however, much of this potential fails to be realized. Multicultural teams are challenged by mismatches in social conventions, work styles, power relationships and conversational norms, which can lead to misunderstandings that negatively affect relationships among team members and the quality of group work. This project will lead to new tools and knowledge for communication across geographic and cultural boundaries that will be made widely available to the research community and general public.<br/><br/>Just as successful teams work together to ground the informational content of their messages, they need to likewise work together to build a shared understanding about the affective meaning of each other's behavior. Particularly a team's ability to regulate its interaction dynamics has been found to be a significant predictor of its performance. This project will contribute to the fields of computer-mediated communication and computer-supported cooperative work by developing new theories and understandings of how people use technology to communicate and collaborate across cultural boundaries. It will contribute to human-computer interaction, information science, and related fields through the development of new techniques and tools for improving a team's ability to regulate its interaction, thereby leading to better relationships among teammates and better outcomes. It will also contribute novel tools to evaluate coordination of affect in team interaction in real time and to provide interventions to improve team functioning. Finally, the work will explore new technical issues around real-time automated assessment of team dynamics."
"1010172","CRCNS: Long Term Reactivations in Cortex and Hippocampus","IIS","CRCNS, ROBUST INTELLIGENCE","09/15/2010","06/16/2013","Jean-Marc Fellous","AZ","University of Arizona","Continuing grant","Kenneth C. Whang","08/31/2015","$468,334.00","Masami Tatsuno","fellous@email.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7327, 7495","7327, 7495, 9251","$0.00","Understanding how memory is encoded and maintained in our brain is paramount to understanding cognitive functions. Unlike in a computer, human memories are continuously consolidated, reconsolidated, and integrated within the context of what has already been learned. This process is thought to involve exchanges of information between the cortex and the hippocampus during sleep. The investigators will study the ability of small groups of cells in the rodent hippocampus and medial prefrontal cortex (mPFC) to become transiently co-active during sleep periods occurring many hours after learning has taken place. Rats will be engaged in learning tasks aimed at selectively activating one or both of these areas. It is expected that the activity recorded during post-task sleep will be correlated with the activity of the same cells during the task in a manner compatible with the nature of the task and the specifics of the learning. This type of reactivation is considered to be a basic mechanism for memory consolidation.<br/><br/>The investigators have developed new analytical tools based on fuzzy clustering and information geometry. Preliminary data show that short episodes of reactivation occur with different time courses in these two structures, as is often proposed on theoretical grounds. In this project, the investigators will study how this reactivation is coordinated across two connected brain areas (CA3-CA1, CA1-mPFC) on very long time scales, and how single neurons contribute to single reactivating episodes.<br/><br/>These studies will yield insights into the long-term temporal and spatial dynamics of reactivation in the adult rodent. They will also contribute to a better understanding of the neural basis of memory consolidation and reconsolidation in cortex and hippocampus, and the relationship between memory consolidation and sleep."
"0964613","III: Medium: Collaborative Research: Data Mining and Cleaning for Medical Data Warehouse","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","06/28/2013","Elmer Bernstam","TX","University of Texas Health Science Center Houston","Continuing grant","Maria Zemankova","08/31/2015","$599,607.00","","Elmer.V.Bernstam@uth.tmc.edu","7000 FANNIN ST","HOUSTON","TX","770305400","7135003999","CSE","7364","7364, 7924","$0.00","A clinical data warehouse (CDW) is a repository that aggregates medical patient data from many different sources: billing records, electronic medical records including structured data (e.g., codes for diagnoses, procedures, vital signs, etc.), semi-structured reports and free-text dictations. A key benefit of maintaining a CDW lies in its ability to provide the raw data that are needed for large-scale study of real-world health care -- for example, finding a previously unknown association between a pain killer (e.g., Vioxx) and heart disease. Unfortunately, CDWs are riddled with systematic errors that make it difficult to answer even the simplest questions (such as ""What fraction of female outpatients have breast cancer?"") with any accuracy.<br/><br/>This project focuses on statistical models and learning algorithms for quantifying and correcting errors in CDW records. For example, the project is developing semi-supervised learning methods that use the structured data present in electronic medical records (patient age, weight, medications, billing codes, etc.) in order to quantify the likelihood of error that is associated with the diagnosis codes present in the record (for example, being able to state ""There is a 0.2 probability that the correct code was migraine instead of the listed headache""). The project will also develop methods that attempt to control for confounding variables present in the records, in order to remove systematic biases from the data.<br/><br/>These models and learning algorithms will allow CDW users to manage and monitor the uncertainty and error in the data. This in turn will allow fundamentally new types of analysis to be undertaken, which will result in the discovery of actionable medical knowledge that saves both lives and money. To make the models and algorithms accessible to medical professionals who may lack computational or statistical background, they will be added to an open-source release of the widely-used I2B2 CDW software.<br/><br/>The project is a collaboration between the Computer Science Department at Rice University and the School of Biomedical informatics at the University of Texas Health Science Center at Houston. All project results will be made available online (http://www.cs.rice.edu/~cmj4/CDW.htm)."
"1116782","RI: Small: A Bayesian Approach to Dynamic Lexical Resources for Flexible Language Processing","IIS","ROBUST INTELLIGENCE","09/01/2011","07/28/2014","Martha Palmer","CO","University of Colorado at Boulder","Continuing grant","Tatiana D. Korelsky","08/31/2015","$300,000.00","","mpalmer@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7495","7923","$0.00","This project uses statistical models and human judgment to determine dynamic, probabilistic representations of extensible usages of words; these representations are suitable for incorporation into VerbNet, a lexical resource widely used in the Natural Language Processing (NLP) community. Existing lexical resources reflect a binary notion of usages as grammatical or not. However, in actual language use, forms vary in acceptability; moreover, the process of coercion extends words beyond their standard usages. For example, a strictly intransitive action verb such as 'sneeze' may be used as in 'She sneezed the foam off the cappuccino', expressing manner of motion. This research has a two-pronged approach involving extensive use of machine learning and a fundamental shift in the development and use of VerbNet. Specifically, the research develops probabilistic methods for: (1) analyzing usages of verbs in large corpora and incorporating the resulting probabilistic information into VerbNet classes; and (2) representing information about the likelihood of potential constructional coercions and the productivity of such extensions. These developments use the Hierarchical Bayesian Model of Parisien and Stevenson, which are an ideal framework for marrying probabilistic reasoning about complex, real-world data within the hierarchically-organized VerbNet lexicon. In addition to statistical models, the representations are also informed by human judgments with respect to the use of such constructions. Thus, this research enriches the current symbolic verb representations in VerbNet with probabilistic distributional information, which becomes salient through the influence of construction grammar. <br/><br/>Encoding verb knowledge probabilistically provides the necessary flexibility to represent extensional constructions and support their appropriate interpretation by NLP systems. This is especially useful for interpretation in new domains and genres, leading to advances in NLP technologies, such as question answering and machine translation, thus improving information access. Additionally, insights into statistical properties of constructions gained through this research are valuable for psycholinguistic models of language acquisition and second language learning."
"1111124","Collaborative Research: Programming with Crowds: Models and Tools for General Purpose Crowdsourcing","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2011","08/02/2013","Aniket Kittur","PA","Carnegie-Mellon University","Standard Grant","Frederick M Kronz","08/31/2015","$386,149.00","","nkittur@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7953","7367, 7953, 9251","$0.00","Crowdsourcing is a powerful way to marshal small contributions from large numbers of people to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk). This project moves towards a vision of crowdsourcing that extends it to support complex, creative, and interdependent tasks, and embeds it into computing systems as part of our everyday lives. The project will focus on two application areas for complex crowdsourcing: science journalism and software development.<br/><br/>The intellectual merits of the project include the uncovering of new scientific knowledge about how to model online crowd behavior, and the development of new methods and tools for using crowds as part of computer system designs, particularly for complex, interdependent, real time work. The project will also show that these methods can be used for real-world problems. <br/><br/>The potential broader impacts include those specifically having to do with the two application areas, which could have significant impacts on society. Crowdsourcing science journalism will directly involve citizens in the process of science dissemination, making scientific information more accessible to the general public, and promoting greater awareness of science and the scientific process. Crowdsourcing software development can transform the way that software is created, lowering barriers and broadening participation in open source software development, and helping larger masses of people use and improve their programming skills. Other impacts will flow from the researchers' plans to publically share the infrastructure that they develop to facilitate complex crowdsourcing in many other areas. They also plan to integrate their research results into undergraduate courses."
"1421100","III: Small: Collaborative Research: Functional Network Discovery for Brain Connectivity","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/28/2014","Jieping Ye","AZ","Arizona State University","Standard Grant","Sylvia J. Spengler","07/31/2017","$200,000.00","","jieping.ye@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7364, 7923","$0.00","Neuroscience is at a moment in history where mapping the connectivity of the human brain non- invasively and in vivo has just begun with many unanswered questions. While the anatomical structures in the brain have been well known for decades, how they are used in combination to form task specific networks has still not been completely explored. Understanding what these networks are, and how they develop, deteriorate, and vary across individuals will provide a range of benefits from disease diagnosis, to understanding the neural basis of creativity, and even in the very long term to brain augmentation. Though machine learning and data mining has made significant inroads into real world practical applications in industry and the sciences, most existing work focuses on lower-level tasks such as predicting labels, clustering and dimension reduction. This requires the practitioner to shoe-horn their more complex tasks, such as network discovery, into the algorithm's settings. <br/><br/>The focus of this grant is a transition to more complex higher-level discovery tasks and in particular, eliciting networks from spatio-temporal data represented as a tensor. Here the spatio-temporal data is an fMRI scan of a person represented as a four dimensional tensor with each entry in the tensor being a data point that indicates the brain activity at that time and location. The overall problem focus is to simplify this data into a cognitive network consisting of identifying active regions of the brains and the interactions that occur between them. The work will consist of three intertwined tasks as follows: i) Supervised and Semi-supervised Network Discovery, ii) Complex Network Discovery and iii) Network Discovery in Populations. In the supervised/semi-supervised setting, the networks discovered involves coordinated activity among some combination of anatomical structures Since all or some of the structures are given along with their boundaries, this is termed a supervised (or semi-supervised) problem. With complex network discovery the team will move beyond finding a single network of coordinated activity to finding multiple networks with complex (beyond coordinates) relationships between the structures/regions. Finally with network discovery in populations , the previous work that studies an individual scan will be expanded to a population of scans. A population may be a collection of individuals performing the same task or a single individual's scans collected over time. Studying such populations allows addressing innovative questions such as: ""How does one individual's network change over the course of development, aging, or disease?"" and ""How do the networks differ for one group of individuals to that of another group?"""
"1423487","III: CGV: Small: A Scalable Visual Analytics Framework for Exascale Scientific Simulations","IIS","INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","01/01/2015","07/28/2014","Hongfeng Yu","NE","University of Nebraska-Lincoln","Standard Grant","Maria Zemankova","12/31/2017","$397,378.00","","yu@cse.unl.edu","2200 Vine St, 151 Whittier","LINCOLN","NE","685830861","4024723171","CSE","7364, 9150","7364, 7453, 7923, 9150","$0.00","By leveraging advanced parallel computing systems, scientists can answer important questions that are critical to US energy and economic security. Exascale computing will further enable scientists to perform detailed simulations at higher resolution and greater complexity. Advanced visualization is necessary for scientists to explore massive and complex simulation data at high interactivity and fidelity to study various physical, chemical, and biological phenomena. Although visualization technology has significantly progressed in recent years, conventional visualization techniques are not yet ready for exascale systems and applications. Future exascale systems are expected to be characterized with many-core processors, deep memory hierarchies, and high levels of concurrency. The design of new visualization techniques must adapt to the need for timely discovery from complex and extremely large data sets as well as these emerging hardware and software trends. The goal of this project is to address the current technology gap by investigating a complete course of visualization pipeline with scientific simulations in a holistic fashion, and thus ensure parallelism and efficiency in exascale data visual analytics. This project will integrate research with teaching and outreach programs, where visualization of scientific applications will be used as an effective means to promote students' interest and proficiency in science and engineering studies, and to attract and retain both undergraduate and graduate students, particularly female students, into research.<br/><br/>This project plans to account directly for the complex interdependencies with and among the critical components of visual analytics for exascale computing. This project focuses on three key research tasks: (1) developing a novel in-situ data reduction and indexing algorithm to capture essentials from large-scale simulations; (2) studying parallel visualization algorithms to promise scalable performance for high-throughput and high-resolution exploration of large-scale simulation data based on in-situ compact data representations; and (3) designing user interface to parse and deploy application knowledge for visual analytics to acquire critical scientific discovery from in-situ simulation output with enhanced user experience and performance. This project is driven by real-world large-scale scientific applications that involve the modeling and analysis of evolving phenomena with heterogeneous data types, and demand scalable capabilities of visual analytics. Scientific collaborators will be involved into the development, evaluation, and deployment of the solutions to close the gap between advanced visualization techniques and scientific applications, and help solve some of the most challenging scientific problems. The techniques developed within this project will be readily adapted for use by many applications beyond the primary demonstration targets with similar needs, and thus will have a significant impact on scientists' capability for data analysis and visualization. The success of this research will potentially change the conventional scientific discovery pipeline and accelerate the study of large-scale simulation data. The project results will be disseminated through different venues and forms that are publicized at the project website (http://cse.unl.edu/~yu/research/nsf15_exascale/)."
"1344256","INSPIRE Track 1: Human reasoning and learning in a complex but tractable decision-making paradigm","IIS","PERCEPTION, ACTION & COGNITION, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE, INSPIRE","10/01/2013","07/28/2014","Whee Ky Ma","NY","New York University","Continuing grant","Kenneth C. Whang","09/30/2018","$799,782.00","","weijima@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7252, 7484, 7495, 8078","7252, 8089, 8653","$0.00","This INSPIRE award is partially funded by the Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering and the Perception, Action, and Cognition Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral, and Economic Sciences.<br/><br/>This project studies a hallmark of human intelligence, namely the ability to think ahead. Anticipating the consequences of one's own actions and those of others is of crucial importance in areas as diverse as business negotiations, military strategy, and teaching. In each of these domains, the quality of one's decisions depends on the quality of one's mental simulations of event sequences, which might be limited by cognitive capacity limitations, one's grasp of the complexities of the decision space, or both. The project's goal is to identify the factors that affect people's performance in thinking ahead, and investigate to what extent this performance can be improved through training. The project ties into the study of heuristics (general rules used by decision-makers) in psychology and behavioral economics.<br/><br/>Thinking ahead is difficult to measure and model in real-world problems. Therefore, the investigator has developed a two-person strategic decision-making task as a controllable experimental environment. Participants take turns to put tokens on a 4x11 board and try to get four of their own tokens in a row. The rules are unfamiliar to subjects, yet easy to learn. The size of the state space for this task is of the order of 10^20, much smaller than that of chess (~10^47), yet of appreciable complexity and much too large for humans to easily grasp. The investigators have ""weakly solved"" this task using an improved version of alpha-beta pruning. It can most likely also be solved strongly, which means that one can determine in any given position whether any given decision is an error. Human data will be collected in three task modes: one in which the subject is given a position and has to win in a set number of moves; human versus computer; and human versus human. The investigators will track subjects' eye movements, which could reveal aspects of planning and perhaps even serve to visualize the process of mental simulation. <br/><br/>An important component of the project will be computational modeling of the data. Humans cannot think ahead to the end of the task, so we hypothesize that they use simple features of positions (heuristics) to value certain moves over others. Examples of features could be the presence of a three-in-a-row, or of an adjacent, open-ended two-in-a-row. Preliminary human data suggest ""strategic blind spots"" created by the application of the incorrect heuristics. The investigators aim to predict the probability that a subject will in a given position make a particular move, based on features of the position that would be created by that move, as well as the subject's limited depth of reasoning. The resulting model will allow to quantitatively address the question of whether learning mostly serves to increase one's depth of reasoning or to refine one's palette of heuristics. The behavioral and eye movement data will lay the foundation for studies of the neural substrates of reasoning in complex decision-making contexts.<br/><br/>The project is positioned at the intersection of computer science, cognitive psychology, management and decision science, and education, and has the potential to contribute to each of these fields. In the long run, the project might be able to contribute to understanding and perhaps avoiding failures to think ""out of the box"" in real-life problem-solving. Moreover, strategic tasks like the one used in this project could serve as a mini-environment for testing hypotheses about teaching methods."
"1012083","HCC: Large: Collaborative Research: Always-On Relational Agents for Social Support of Older Adults","IIS","Cyber-Human Systems","09/15/2010","07/30/2013","Candace Sidner","MA","Worcester Polytechnic Institute","Continuing grant","William Bainbridge","08/31/2015","$1,123,361.00","Charles Rich","sidner@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7367","7367, 7925, 9251","$0.00","This project will create a new category of intelligent, autonomous virtual or robotic agent, which is continuously operating and interacting with humans - always on - for long periods of time and whose primary motivation is building and maintaining long-term social relationships with humans. The initial application focus of this research is to provide companionship and social support and to promote wellness for older adults who are living alone. For example, during a typical day, an always-on relational agent might play a social game of cards with the adult, act as an exercise coach and help arrange visits or phone calls with the adult's family and friends.<br/><br/>A new integrated theory of social agency, called SharedPlans Relationship Theory, will be developed to serve as a principled foundation for these relational agents. The theory will be grounded in an always-on relational software architecture, which will be distributed as open-source for others to use and extend. Using a participatory design process, including home and laboratory studies, the target user population will help develop the specifications for a relational agent, which will then be constructed using the theory and software architecture, and placed in users' homes for long-term (month or more) longitudinal evaluation.<br/><br/>This project will make fundamental, theoretical contributions to models of relationship, sociality, interactional engagement and social support. The effort will also produce new insights into how people in general, and older adults in particular, enact social support at the relational, activity and micro-behavioral levels of analysis. The new always-on relational software architecture will be a fundamental advance over current agent architectures, which only support brief, focused interactions around a well-specified task. This architecture will also support incremental extension of agent capabilities and be able to control either virtual and robotic agent embodiments.<br/><br/>Social isolation is a broadly troubling trend in modern society. Always-on relational agents have the potential to counteract this isolation both directly, by providing companionship, and as intermediaries, by putting isolated people in contact with other people, both electronically and physically. Companionship and social support are also known to be significant positive factors in disease recovery and mortality, especially for older adults. The application focus of this project therefore has the potential for helping with health care cost control."
"1237080","SHB: Type II (INT): Collaborative Research: Creating Learning Systems with Mobile Technology to Improve Coordination in Perioperative Services","IIS","INFO INTEGRATION & INFORMATICS, Smart and Connected Health","10/01/2012","07/28/2014","Nathan Huynh","SC","University South Carolina Research Foundation","Standard Grant","Sylvia J. Spengler","09/30/2016","$585,916.00","Jose Vidal","huynhn@cec.sc.edu","901 Sumter Street","COLUMBIA","SC","292080001","8037777093","CSE","7364, 8018","8018, 8062, 9150, 9251, 7364","$0.00","This project proposes to create a framework using a combination of mobile technology, learning systems, data analytics, education, and training to enhance cooperation and coordination of staff within and across perioperative services departments (POS). Perioperative services comprise surgery preparation, operating rooms, post-anesthesia care, sterile processing and a variety of other services, such as radiology and endoscopy. The specific objectives of this project are to: (1) enhance communication and coordination among POS staff to improve the quality of care by gathering and using important workflow milestones and introducing artificial intelligence techniques through the use of a smart-app, (2) analyze workflow data gathered with smart-apps using data analytics to provide intuitive displays of real-time information for frontline staff and a daily performance dashboard for managers, and (3) induce behavioral and cultural change in healthcare systems through training and education. While existing information technology capabilities such as natural language processing, artificial intelligence, and speech recognition technology are promising developments in computing, their uses in health care are limited and thus need to be thoroughly investigated before they can be used in health care effectively. To accomplish these objectives, the research team will work closely with the partnering healthcare organizations, Greenville Hospital System (GHS), Palmetto Health (Palmetto), and the Medical University of South Carolina (MUSC), in developing the tools and models which will be pilot-tested at these organizations by their staff. <br/><br/>The developed tools and models will be widely disseminated among health care providers in South Carolina. In addition, the smart-apps and agent-based simulation model will provide the team with a teaching and training tool that can be used in the classroom at Clemson University and the University of South Carolina (USC) to teach students across a variety of fields, such as business, engineering, science and healthcare students about information and workflow management techniques."
"0917017","III: Small: Query Mesh - A Novel Paradigm for Query Processing","IIS","INFO INTEGRATION & INFORMATICS","09/15/2009","07/07/2011","Elke Rundensteiner","MA","Worcester Polytechnic Institute","Continuing grant","Frank Olken","08/31/2014","$496,556.00","","rundenst@cs.wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7364","7364, 7923, 9216, 9251, HPCC","$0.00","Technological advances in positioning, sensor and monitoring<br/>technology drive data acquisition devices to generate massive streams<br/>of data. The goal of this research is to develop a new class of<br/>high-performance stream data management systems capable of coping with<br/>scenarios with infinite data arriving in large volumes, and with<br/>near-real time response requirements. <br/><br/>The proposed query processing paradigm, <br/>termed the multi-route query mesh model (QM), overcomes a<br/>major limitation in current query optimizers, both static and stream<br/>ones alike, namely the assignment of a single `best' query execution<br/>plan for all input data. This approach, being based on the strong<br/>assumption of data uniformity, results in substandard performance for<br/>possibly all data items. Instead, query mesh adopts a processing<br/>structure composed of a data classifier and a multiple route plan<br/>infrastructure. Different learning models can be plugged as<br/>classifier logic into the QM model. Given the complexity of the QM<br/>solution space, cost-based search heuristics are designed to<br/>efficiently find high-quality query meshes. QM is adaptive supporting<br/>the detection and incremental modification of the QM classifier and<br/>its routes. <br/><br/>The intellectual merit of this project lies in the design, development and<br/>evaluation of a novel multi-route paradigm for stream query<br/>processing, -- a perfect middle ground between the two current<br/>extremes of single-plan versus route-less solutions. Experimental<br/>studies compare query mesh to state-of-the-art solutions. QM impacts<br/>society by facilitating a wide range of stream-centric applications,<br/>including medical out-patient monitoring, emergency management, and<br/>business intelligence processing, and by integrating project<br/>activities with education.<br/><br/>Further information on this project can be found at the project<br/>web page: http://dsrgweb.cs.wpi.edu:8180/DSRG/"
"1144938","EAGER: Recurring Pattern Discovery","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","09/01/2011","07/28/2014","Yanxi Liu","PA","Pennsylvania State Univ University Park","Standard Grant","Jie Yang","08/31/2015","$158,000.00","","yanxi@cse.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7453, 7495","7495, 7916, 9251","$0.00","Similar yet visually non-identical objects form recurring patterns that are ubiquitous in the world we live in. Thus an automatic recurring pattern detection algorithm can serve as a stepping stone towards robust higher level machine intelligence. The recognition of such recurring patterns is especially relevant for computer vision since it can lead to saliency detection, image segmentation, image compression and super-resolution, image retrieval and semantically meaningful organization of unlabeled data. This project explores automatic recurring pattern discovery from domain independent images and videos to capture, robustly and flexibly, varying mid-level visual cues emerging from any cluttered background. The work leads to effective and efficient object discovery and scene interpretation. The research team develops an un-supervised method for discovering recurring patterns in a single or multiple images . The key property is the nature of recurring without knowing what recurs. Differing from previous feature- or object-level pairwise-matching-based approaches, recurring pattern discovery from real images is formulated as a joint, 2-dimensional feature assignment optimization problem where multiple objects and multiple feature clusters are considered simultaneously. <br/><br/>The project disseminates the results through publications and sharing data with other researchers. The research of this project contributes to the understanding and capturing of recurring patterns in higher spatial dimensions and spatiotemporal domains. Besides computer vision and computer graphics, many other research fields can also benefit from this research."
"1406578","CHS: Medium: Design Tools for Physical Computing Objects","IIS","Cyber-Human Systems","08/01/2014","07/28/2014","Dan Olsen","UT","Brigham Young University","Continuing grant","Anthony Hornof","07/31/2018","$272,606.00","Kevin Seppi, Michael Jones","olsen@cs.byu.edu","A-285 ASB","Provo","UT","846021231","8014226177","CSE","7367","7367, 7924, 9150","$0.00","As computers decline in cost and interactive computation moves off of the desktop, computation can assume a variety of physical forms. At present, the creation of new computer interfaces is limited to already-available formats, such as smartphones, and even then is constrained to relatively simplistic computer interfaces. Computing in the future will push beyond desktops, laptops, tablets and smartphones into objects that fit into every part of our lives. But for this to happen, design tools are needed that can rapidly adapt computing to different physical forms and task needs. This project will study toolkits for the development of interactive physical objects. The project will increase national competitiveness in the invention and development of new uses of computation, and make possible rich and diverse usability research with physical computing objects in the wild rather than in the lab. Creating physical computing objects will allow a greater proportion of society to use computers in ways that fit their work requirements in fundamentally new ways. The rapid design and creation of such devices will open new markets for consumer computing.<br/><br/>These ends are achieved through three interrelated efforts: (1) A pluggable toolkit for creating sensor/actuator systems that form the computational basis for such objects. This toolkit will be unique in that the components when plugged together not only form an initial prototype of the device but self-reveal their physical and computational characteristics to automatically support the other design tools. A prototype constructed with this toolkit will inherently contain sufficient information to drive its own fabrication. By plugging together the prototype our tools will automatically know how to perform a custom fabrication of the electronics at a size that can be readily deployed. (2) Development of physical form via 3D printing such that the physical shape, sensors and actuators integrate with the software and electronics so as to easily prototype a complete physical/computational object. One goal is to suppress the challenges of mechanical design so that designers can focus on shape and usability. (3) Interactive machine learning techniques will be created to easily develop the mapping between human activities (as detected by sensors) and their recognition in software. It is known that putting humans in the training loop for machine learning changes the way training sets are built. Algorithms will be developed that both adapt to and exploit this behavior. This project will produce new knowledge of the concepts that are most difficult for designers when creating physical computational objects."
"1422218","III: Small: Collaborative Research: Functional Network Discovery for Brain Connectivity","IIS","CRCNS, INFO INTEGRATION & INFORMATICS","08/01/2014","07/28/2014","Ian Davidson","CA","University of California-Davis","Standard Grant","Sylvia J. Spengler","07/31/2017","$299,980.00","Owen Carmichael","davidson@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7327, 7364","7364, 7923, 8089, 8091","$0.00","Neuroscience is at a moment in history where mapping the connectivity of the human brain non- invasively and in vivo has just begun with many unanswered questions. While the anatomical structures in the brain have been well known for decades, how they are used in combination to form task specific networks has still not been completely explored. Understanding what these networks are, and how they develop, deteriorate, and vary across individuals will provide a range of benefits from disease diagnosis, to understanding the neural basis of creativity, and even in the very long term to brain augmentation. Though machine learning and data mining has made significant inroads into real world practical applications in industry and the sciences, most existing work focuses on lower-level tasks such as predicting labels, clustering and dimension reduction. This requires the practitioner to shoe-horn their more complex tasks, such as network discovery, into the algorithm's settings. <br/><br/>The focus of this grant is a transition to more complex higher-level discovery tasks and in particular, eliciting networks from spatio-temporal data represented as a tensor. Here the spatio-temporal data is an fMRI scan of a person represented as a four dimensional tensor with each entry in the tensor being a data point that indicates the brain activity at that time and location. The overall problem focus is to simplify this data into a cognitive network consisting of identifying active regions of the brains and the interactions that occur between them. The work will consist of three intertwined tasks as follows: i) Supervised and Semi-supervised Network Discovery, ii) Complex Network Discovery and iii) Network Discovery in Populations. In the supervised/semi-supervised setting, the networks discovered involves coordinated activity among some combination of anatomical structures Since all or some of the structures are given along with their boundaries, this is termed a supervised (or semi-supervised) problem. With complex network discovery the team will move beyond finding a single network of coordinated activity to finding multiple networks with complex (beyond coordinates) relationships between the structures/regions. Finally with network discovery in populations , the previous work that studies an individual scan will be expanded to a population of scans. A population may be a collection of individuals performing the same task or a single individual's scans collected over time. Studying such populations allows addressing innovative questions such as: ""How does one individual's network change over the course of development, aging, or disease?"" and ""How do the networks differ for one group of individuals to that of another group?"""
"1311446","US-French Collaboration: Auditory computations for interpreting and producing communication signals.","IIS","COLLABORATIVE RESEARCH, CRCNS, ROBUST INTELLIGENCE","10/01/2013","07/28/2014","Frederic Theunissen","CA","University of California-Berkeley","Continuing grant","Kenneth C. Whang","09/30/2016","$642,855.00","","theunissen@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7298, 7327, 7495","5918, 5980, 7298, 7327","$0.00","Human speech and animal communication require both the extraction of meaning from sound and the processing of one's own voice to guide the production of these vocalizations. These processes require non-trivial computations that have challenged linguists and engineers but that are performed effortlessly by our brains. To understand what are the neural computations performed to decode the behavioral meaning and vocal gestures of communication signals, this study will examine how the auditory cortex of a songbird processes the complete vocal repertoire of its own species. <br/><br/>The Theunissen Lab acquired a unique database of all the vocalizations emitted by adult and juvenile, and both male and female zebra finches. This database contains the complete repertoire with multiple exemplars of each vocalization type for many individuals. Because the behavioral context of each communication sound was carefully recorded, these sounds are classified in meaning categories. This database will thus enable the detailed investigation of how the auditory system extract meaning from vocalizations, while controlling for variability of production within vocalization type as well as between individuals.<br/><br/>The approach of this project consists in obtaining neural responses to these communication sounds using advanced neurophysiological recording techniques, and then investigating the neural computations by finding the statistics models that best predict these responses. Multi-electrode arrays will be used to record the simultaneous neural activity of large sets of single neurons in the primary and secondary auditory areas. The response of these neurons will then be fitted using statistical models that incorporate increasing levels of abstraction: from elementary sound features, to vocal gestures and semantic labels. The representation in terms of vocal gestures will be obtained from a reduced physical model of the avian vocal organ. This analysis will not only point out the brain regions that are involved in semantic processing but also the nature of the hierarchical computations that lead to these higher-level representations. The research will also investigate the link between perception and production by directly assessing the role of a motor-based representation of sounds in high-level auditory areas. <br/><br/>By combining ethological, neurophysiological and computational studies of acoustic communication in a songbird, the project will establish an appropriate animal model system to elucidate how the auditory cortex extracts and categorizes sound features in order to link sound to meaning. Given the similarities in the anatomy and physiology of the auditory system across vertebrates and the common signal processing problems shared in all vocal communications, this study can also contribute significantly to the neurophysiological understanding of neural mechanisms underlying speech perception. <br/><br/>This award is being co-funded by NSF's Office of the Director, International Science and Engineering. A companion project is being funded by the French National Research Agency (ANR)."
"1018443","III: Small: Complex Event Analytics","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","06/21/2013","Elke Rundensteiner","MA","Worcester Polytechnic Institute","Standard Grant","Sylvia J. Spengler","08/31/2015","$523,894.00","","rundenst@cs.wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7364","7364, 7923, 9251","$0.00","Recent advances in sensor technologies and expansion of wired and<br/>wireless communication protocols enable us to continuously collect<br/>information about the physical world, resulting in a rich set of novel<br/>services. The ability to infer relevant patterns from these event<br/>streams in real-time and at various levels of abstractions to make<br/>near instantaneous decisions is crucial for a wide range of mission<br/>critical applications ranging from real-time crisis management to<br/>security. This project designs, implements, and evaluates a novel<br/>complex event processing methodology, henceforth called Complex Event<br/>Analytics (CEA). CEA integrates the capabilities of pattern matching<br/>from complex event processing with the power of multi-level analysis<br/>from static OLAP engines to provide multi-dimensional sequential<br/>pattern analysis over high-speed event streams. The CEA Model<br/>combines CEP and OLAP techniques for efficient multi-dimensional event<br/>pattern analysis at different abstraction levels. Based on<br/>interrelationships in both concept and pattern refinement among<br/>queries, sequence queries are composed into an integrated event<br/>pattern hierarchy. OLAP like operations enable analysts to navigate<br/>from one E-cuboid to another in this event analytics space. CEA<br/>optimization strategies, including rewriting rules, physical<br/>operators, and cost-based search algorithms, achieve scalable event<br/>processing. CEA offers high-performance analytics by maximal shared<br/>processing of event pattern queries. Experimental studies compare the<br/>CEA solution to the state-of-the-art, including traditional stream<br/>query systems and customized event engines. Intellectual merit lies<br/>in the design, development and evaluation of a novel Complex Event<br/>Analytics technology for real-time event stream analysis, -- a perfect<br/>middle ground offering both the sophisticated power of pattern<br/>matching found in modern event processing systems and the capability<br/>of online analytic techniques at multiple levels of abstraction of<br/>OLAP engines. CEA impacts society by facilitating a broad range of<br/>stream-centric applications ranging from monitoring of hygiene<br/>compliance to prevent the spread of infectuous diseases in medical<br/>settings to business intelligence processing, and by integrating<br/>project activities with education.<br/><br/>For further information see the project web site at the URL:<br/>http://davis.wpi.edu/dsrg/PROJECTS/CEA"
"1017344","RI: Small: Theory and Experiments with Tumbling Robots","IIS","ROBUST INTELLIGENCE","08/01/2010","07/28/2014","Nikolaos Papanikolopoulos","MN","University of Minnesota-Twin Cities","Standard Grant","Jie Yang","07/31/2015","$497,995.00","","npapas@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7923, 9251","$0.00","This project revolves around tumbling which is an exciting area of robotic locomotion that takes advantage of ground-body interactions to achieve high mobility on smaller scales when compared to conventional methods. Additionally, the required hardware complexity to produce such locomotion is very low. In this respect, tumbling can be viewed as a minimalistic approach to producing miniature mobile robots capable of traversing complex and dynamic terrains. Due to the nature of tumbling however, the added mobility comes at the price of increased control complexity. The minimalistic nature of tumbling robots generally results in underactuated systems that exhibit nonholonomic constraints which greatly complicate the motion planning problem. Additionally, tumbling often involves time-varying supports and sliding contacts with the ground. Ultimately, this research views tumbling as a largely unexplored yet promising area of research. This work addresses the intricacies of tumbling locomotion. Specifically, we are developing general planning algorithms for tumbling robots and identify important design characteristics of tumbling robots that lead to simplified control. <br/><br/>Seminars and workshops to bring together practitioners, end-users, researchers, and policy makers will be organized to have the maximal impact. Web-based dissemination of the algorithms and rapid prototyping/simulation tools ensure that the results of this project reach all communities. Students trained in this project participate in the US FIRST competitions, summer mentoring programs for high school students, summer schools in robotics, and other outreach programs."
"1237077","SHB: Type II (INT): Collaborative Research: Creating Learning Systems with Mobile Technology to Improve Coordination in Perioperative Services","IIS","SERVICE ENTERPRISE SYSTEMS, INFO INTEGRATION & INFORMATICS, Smart and Connected Health","10/01/2012","07/28/2014","Kevin Taaffe","SC","Clemson University","Standard Grant","Sylvia J. Spengler","09/30/2016","$821,066.00","Joel Greenstein, Lawrence Fredendall","taaffe@clemson.edu","300 BRACKETT HALL","CLEMSON","SC","296340001","8646562424","CSE","1787, 7364, 8018","8018, 8023, 8062, 9150, 9251, 7364","$0.00","This project proposes to create a framework using a combination of mobile technology, learning systems, data analytics, education, and training to enhance cooperation and coordination of staff within and across perioperative services departments (POS). Perioperative services comprise surgery preparation, operating rooms, post-anesthesia care, sterile processing and a variety of other services, such as radiology and endoscopy. The specific objectives of this project are to: (1) enhance communication and coordination among POS staff to improve the quality of care by gathering and using important workflow milestones and introducing artificial intelligence techniques through the use of a smart-app, (2) analyze workflow data gathered with smart-apps using data analytics to provide intuitive displays of real-time information for frontline staff and a daily performance dashboard for managers, and (3) induce behavioral and cultural change in healthcare systems through training and education. While existing information technology capabilities such as natural language processing, artificial intelligence, and speech recognition technology are promising developments in computing, their uses in health care are limited and thus need to be thoroughly investigated before they can be used in health care effectively. To accomplish these objectives, the research team will work closely with the partnering healthcare organizations, Greenville Hospital System (GHS), Palmetto Health (Palmetto), and the Medical University of South Carolina (MUSC), in developing the tools and models which will be pilot-tested at these organizations by their staff. <br/><br/>The developed tools and models will be widely disseminated among health care providers in South Carolina. In addition, the smart-apps and agent-based simulation model will provide the team with a teaching and training tool that can be used in the classroom at Clemson University and the University of South Carolina (USC) to teach students across a variety of fields, such as business, engineering, science and healthcare students about information and workflow management techniques."
"1149876","CAREER: Towards Robots that Learn from Everyday Users","IIS","Cyber-Human Systems","03/01/2012","04/17/2014","Sonia Chernova","MA","Worcester Polytechnic Institute","Continuing grant","Ephraim P. Glinert","02/28/2017","$314,911.00","","soniac@cs.wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7367","1045, 7367, 9251","$0.00","The development of robots that work cooperatively with people is of critical importance for industries as diverse as manufacturing, medicine, healthcare, military, and consumer products. Key to this goal is the development of robotic technologies that are adaptable to changing task and user needs. As usability demands change - whether due to modifications in the manufacturing process, the introduction of a new patient, or the relocation to a new home - users with limited technical skills must have the ability to customize the functionality of robotic systems. This project will contribute new theoretical models, techniques and open source implementations that will enable users to effectively communicate high level task knowledge to robots without programming. <br/><br/>Intellectual merit: The project will leverage human-robot interaction to improve the efficiency of object recognition, feature selection and policy learning algorithms, as well as develop new techniques for data reuse and algorithm evaluation. Hypotheses will be validated through the development of an innovative dual-reality framework for Internet-scale rapid evaluation and testing. Theories will be tested in two robotic applications areas: home assistance and manufacturing. The outcome of this project will be a domain independent interactive learning framework capable of adaptive object recognition, feature selection and policy learning from brief interactions with a single, non-expert user. <br/><br/>Broader impact: The long term goal of this research is to one day make personal robots accessible to everyday people. This research will contribute new theoretical models, techniques and open source implementations that will accelerate the development and adoption of robots that work alongside people. The resulting theories and methodologies for adaptive interactive systems will have potential societal impact beyond robotics, in software systems such as personal computers and mobile devices. To promote research in this area, the investigator will make all developed software components available as open source. The research will also be integrated into courses at the undergraduate and graduate levels, as well as into outreach activities for middle and high school students. The web-based evaluation framework will provide a unique opportunity to educate the general public by providing access to cutting-edge robotic technology and empowering them to contribute to its development."
"0910992","RI: Large: Collaborative Research: Richer Representations for Machine Translation","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","09/01/2009","07/28/2014","Martha Palmer","CO","University of Colorado at Boulder","Continuing grant","Tatiana D. Korelsky","08/31/2015","$560,000.00","James Martin","mpalmer@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","1640, 7495","7495, 7925, 9102, 9215, HPCC","$0.00","Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br/>generation. One part of this work determines what types of semantic <br/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English.<br/><br/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future."
"0954310","EAGER: Autonomous Data Partitioning Using Data Mining for High End Computing","CCF","INFO INTEGRATION & INFORMATICS, HIGH-PERFORMANCE COMPUTING, HECURA","09/01/2009","07/28/2014","Le Gruenwald","OK","University of Oklahoma Norman Campus","Standard Grant","Almadena Y. Chtchelkanova","08/31/2015","$150,000.00","","ggruenwald@ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7364, 7942, 7952","7583, 7916, 7942, 9150, 9218, HPCC, 7364","$0.00","Query response time and system throughput are the most important metrics when it comes to database and file access performance. Because of data proliferation, efficient access methods and data storage techniques have become increasingly critical to maintain an acceptable query response time and system throughput. One of the common ways to reduce disk I/Os and therefore improve query response time is database clustering, which is a process that partitions the database/file vertically (attribute clustering) and/or horizontally (record clustering). To take advantage of parallelism to improve system throughput, clusters can be placed on different nodes in a cluster machine. <br/><br/>This project develops a novel algorithm, AutoClust, for database/file clustering that dynamically and automatically generates attribute and record clusters based on closed item sets mined from the attributes and records sets found in the queries running against the database/files. The algorithm is capable of re-clustering the database/file in order to continue achieving good system performance despite changes in the data and/or query sets. The project then develops innovative ways to implement AutoClust using the cluster computing paradigm to reduce query response time and system throughput even further through parallelism and data redundancy. The algorithms are prototyped on a Dell Linux Cluster computer with 486 compute nodes available at the University of Oklahoma. For broader impacts, performance studies are conducted using not only the decision support system database benchmark (TPC-H) but also real data recorded in database and file formats collected from science and healthcare applications in collaboration with domain experts, including scientists at the Center for Analysis and Prediction of Storms (CAPS) at the University of Oklahoma. The project also makes important impacts on education as it provides training for graduate and undergraduate students working on this project in the areas of national critical needs: database and file management systems, and high-end computing and applications. The developed algorithm and prototype, real datasets and performance evaluation results are made available to the public at the Website: http://www.cs.ou.edu/~database/AutoClust.html."
"1251827","EAGER: Declarative Crowdsourcing","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/06/2012","Neoklis Polyzotis","CA","University of California-Santa Cruz","Standard Grant","Maria Zemankova","09/30/2014","$199,931.00","","alkis@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7364","7364, 7916","$0.00","A variety of applications are increasingly relying on crowdsourcing services, such as Amazon Mechanical Turk or CrowdFlower, in order to access human computation at a large scale and solve problems that cannot be tackled using only machine computation. Despite the surge in crowdsourcing platforms, it remains very difficult and error-prone to employ crowdsourcing within an application: existing services mostly expose a procedural interface to post individual human-computation tasks, and provide little support (if any) for task coordination, reward management, or clean-up of the obtained answers. As a result, a large fraction of the application logistics is devoted to orchestrating and optimizing the interaction with the crowdsourcing service. This project explores the novel paradigm of declarative crowdsourcing through the development of the Deco database system. Deco models and offers support for accessing the collective knowledge of the crowd by posing declarative queries over a relational-like database. The project explores methods to mitigate the effect of ""noisy"" human workers who provide data of low quality and to model the resulting uncertainty in the answers returned by Deco. The two problems are tightly coupled with a tradeoff among the latency to contact human workers, the expense to recruit them and the quality of the data they provide. Handling this tradeoff in the context of query optimization is one of the key technical challenges addressed by the project. <br/><br/>The project represents a high-risk research effort, as it targets non-trivial problems that are inherent in the usage of crowdsourcing in practice. The corresponding high payoff is that the results of this research provide a robust and principled foundation for declarative crowdsourcing, thus enabling a wide variety of applications to incorporate crowdsourcing as a core component of their software stack. Moreover, this project identifies desirable features of crowdsourcing services in order to support this novel declarative interface, thereby providing valuable guidance for the design of next-generation crowdsourcing platforms. Finally, the project provides training to students and the opportunity to engage in the emerging research area that lies in the intersection of databases and crowdsourcing. Details for the project can be found at the project web site (http://db.cs.ucsc.edu/deco)."
"1302690","III: Medium: Collaborative Research: Scaling Machine Learning to Massive Datasets---A Logic Based Approach","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/25/2014","Neoklis Polyzotis","CA","University of California-Santa Cruz","Continuing grant","Sylvia J. Spengler","08/31/2017","$333,000.00","","alkis@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7364","7924, 7364","$0.00","Machine learning (ML) algorithms have become ubiquitous across applications as diverse as science, engineering, business, finance, education and healthcare. However, development of ML software that can scale to massive datasets and that are also easy-to-use remains a challenge in part due to the fact that developing an ML tool currently requires the implementation of a deep software stack, from the actual runtime (i.e., how an ML algorithm is executed) to the API exposed to the users.<br/><br/>This project aims to develop DeML, a system to support the authoring and execution of ML tools. Specifically, DeML would allow ML algorithms to be formulated in the form of a declarative query over the training dataset. DeML optimizes the execution of the query over a computing platform (e.g., Amazon EC2 or SQL Azure), taking into account the characteristics of the algorithm, the data, and the available computational resources. Adoption of DeML would greatly reduce the effort required to develop scalable implementations of ML algorithms. The project is organized around three thrusts: (i) Development of a declarative query language, based on extensions of Datalog; (ii) Analysis of runtime of DeML queries; (iii) Optimization of dataflow of DeML queries based on the characteristics of data sources and the capabilities of the underlying execution platform. The resulting open source DeML prototype implementation will be made freely available to the community through the project web page at: http://deml.cs.ucla.edu.<br/><br/>The availability of the DeML could greatly lower the effort needed to author scalable implementations of ML algorithms for analysis of massive datasets, which in turn would increase the availability of such tools to the broader community. Experience gained by implementing and deploying ML algorithms at scale over modern cloud-computing platforms, could help inform critical design choices in the development of future cloud computing platforms for big data analytics, and hence impact a broad range of scientific, engineering, national security, healthcare and business applications of big data analytics. The project offers enhanced opportunities for research-based advanced training of graduate and undergraduate students, including members of groups that are currently under-represented in computer science, in databases, machine learning, and cloud computing."
"1319618","RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","IIS","ROBUST INTELLIGENCE","10/01/2013","07/25/2014","Michael Littman","RI","Brown University","Continuing grant","James Donlon","09/30/2015","$147,999.00","","mlittman@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","7495, 7923, 9150","$0.00","Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br/><br/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are."
"1344269","INSPIRE Track 1: Gradient Symbolic Computation","BCS","LINGUISTICS, PERCEPTION, ACTION & COGNITION, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE, ALGORITHMS, INSPIRE","09/15/2013","07/25/2014","Paul Smolensky","MD","Johns Hopkins University","Continuing grant","Joan Maling","02/28/2018","$999,997.00","Benjamin Van Durme, Akira Omaki, Kyle Rawlins, Geraldine Legendre","smolensky@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","SBE","1311, 7252, 7484, 7495, 7926, 8078","1311, 7252, 8089, 8653","$0.00","This INSPIRE award is partially funded by the Linguistics Program and the Perception, Action & Cognition Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral & Economic Sciences; by the Robust Intelligence Program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering; and by the Algorithmic Foundations Program in the Division of Computer and Network Systems in the Directorate for Computer & Information Science & Engineering.<br/><br/>Discrete, combinatorial systems of structured symbols permeate human cognition in domains such as language, motor control, complex action planning, learning, and higher-level vision. Nonetheless, the computational apparatus that the brain exploits is based on continuous, activation-based propagation of information through complex networks of neurons. A fundamental problem of the cognitive sciences is how to integrate gradient, continuous neural computation with the discrete combinatorial dimension of cognition. The solution to this puzzle will provide a deeper understanding of the mind and may also serve as the basis of a new generation of computing systems capable of authentically brain-like behavior.<br/><br/>Under the direction of Dr. Smolensky, the research team will develop an approach to this puzzle by exploring and testing the predictions of their theory of Gradient Symbolic Computation (GSC) in the domain of language. Their efforts will include the development of the formal, mathematical foundations of GSC. In parallel, the PIs will develop a framework for modeling Gradient Symbolic Processing. To that end, the PIs will use computational modeling and experimental psycholinguistic studies of phenomena that typify the morpho-phonological, syntactic, and semantic characteristics of language and language processing. <br/><br/>The broader impacts of the work include the potential to transform general computing for future approaches to computer design, to provide innovations in computer language processing, and to empower major advances in our understanding of human language, its impairment in disease, and its learning and remediation. The project also strongly engages STEM education. Undergraduate, graduate, and post-doctoral researchers will all play key roles in highly interdisciplinary STEM research integrating experimental, theoretical, and computational methods. The new type of computation created will provide an integrative framework for developing courses bridging computation theory, psychology, and linguistics. Pedagogical materials developed in these courses will be made publicly available to facilitate undergraduate and graduate program development at other institutions."
"0832804","Collaborative Research: Computational Sustainability: Computational Methods for a Sustainable Environment, Economy, and Society","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, ROBUST INTELLIGENCE","08/15/2008","03/05/2013","Thomas Dietterich","OR","Oregon State University","Continuing grant","Ralph Wachter","07/31/2015","$1,909,480.00","Heidi Albers, Weng-Keen Wong, Claire Montgomery","tgd@cs.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","1640, 1714, 7495","0000, 7495, 7723, 9178, 9218, 9251, HPCC, OTHR","$0.00","Balancing environmental, economic, and societal needs for a sustainable future encompasses problems of unprecedented size and complexity. With naturally occuring settings, global scale, dynamic and uncertain behavior, mixture of discrete and continuous effects, and highly interactive components, problems associated with sustaining the earth's resources can greatly benefit from computational methods and thinking. There is a key role to be played by computing and information sciences in increasing the efficiency and effectiveness in the way humanity manages and allocates natural resources. Toward that objective, this Expedition aims to establish and nurture a new field of study--Computational Sustainability--driven by a wide range of hard computational problems and critical challenges in the area of sustainability. This applied theoretical Expedition will pursue interdisciplinary research across three computational sustainability themes: conservation and biodiversity; balancing socio-economic demands and the environment; and renewable energy. With the view that natural problems may have a special structure discoverable by machine learning techniques that allows them to be solved even though they are NP-hard, this research attempts to stimulating new research synergies that cross boundaries and merge ideas from combinatorial optimization, dynamical systems, machine learning and constraint reasoning. An ""Institute for Computational Sustainability"" will be based at Cornell to serve as the nexus of foundational science advancements and practical applications in sustainability. Part of its mission and outreach is to establish a vibrant and diverse research community in the area of computational sustainability, drawing new students into the field from all backgrounds including students from underrepresented groups via summer research experiences and other such proactive activities."
"1319412","RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","IIS","ROBUST INTELLIGENCE","10/01/2013","07/25/2014","Matthew Taylor","WA","Washington State University","Continuing grant","James Donlon","09/30/2015","$135,000.00","","taylorm@eecs.wsu.edu","NEILL HALL, ROOM 423","PULLMAN","WA","991643140","5093359661","CSE","7495","7495, 7923","$0.00","Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br/><br/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are."
"1018914","III: Small: Novel Paradigms for Automated Index Tuning","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","07/07/2011","Neoklis Polyzotis","CA","University of California-Santa Cruz","Continuing grant","Frank Olken","08/31/2014","$499,676.00","","alkis@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7364","7923","$0.00","Indexes impact crucially the performance of a database system, and hence creating the right indexes for a workload, also known as index tuning, is an important task in database administration. Automated index tuning techniques have thus become an indispensable tool for administrators. However, existing techniques target the simplified scenario of a single database hosted on a single machine, which does not match the more complex system architectures observed in practice, e.g., multi-tenant systems with virtualized databases, or shared-nothing parallel databases. This mismatch results in suboptimal tuning that underutilizes the available system resources. Moreover, the majority of techniques require the administrator to have detailed knowledge of the anticipated database workload, which is not feasible when the workload has unpredictable characteristics (e.g., workload in ad-hoc data analysis). An alternative is techniques that analyze the workload online, but such techniques assume total control of index-maintenance decisions and essentially sidestep the administrator. The proposed project develops novel index tuning techniques that address the aforementioned shortcomings. The first contribution is a new tuning paradigm that couples online workload analysis with feedback and interaction from the administrator, thus combining the best features of previous approaches. The theoretical foundation is a novel extension of previous results from the field of online optimization. Subsequently, the paradigm is specialized for databases on compute clusters and virtualized databases, two practical architectures that are not covered by previous techniques. The project will impact the education of Computer Science students in database systems and will lead to more effective tools for database administration. For further information see the project page at http://www.cs.ucsc.edu/~alkis/tuning."
"1064965","HCC: Medium: Collaborative Research: Generating Accurate, Understandable Sign Language Animations Based on Analysis of Human Signing","IIS","Cyber-Human Systems","07/01/2011","07/25/2014","Dimitris Metaxas","NJ","Rutgers University New Brunswick","Continuing grant","Anthony Hornof","06/30/2015","$469,996.00","","dnm@cs.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7367","7367, 7924","$0.00","American Sign Language (ASL) animations have the potential to make information accessible to many deaf adults in the United States who possess only limited English literacy. In this research, which involves collaboration across three institutions, the PIs' goal is to gain a better understanding of ASL linguistics through computational techniques while advancing the state of the art in the generation of ASL animations for accessibility applications for people who are deaf. To these ends, the PIs will develop linguistically based models of two aspects of ASL production: movements required for head gestures and facial expressions that carry essential grammatical information and frequently extend over domains larger than a single sign, and the timing and coordination of manual and non-manual elements of ASL signing. Preliminary work has shown that these issues significantly affect how well signers understand ASL animations, and that these aspects of current ASL animation technologies require improvement. How should the face of a human or animated character be articulated to perform, with accuracy, the linguistically meaningful facial expressions that are part of ASL grammar? How should the onsets, offsets, and transitions of these movements be produced? How should the facial expressions and hand movements be temporally coordinated so that the ASL production is as grammatically correct and understandable as possible? To answer open questions such as these, the PIs' novel approach will apply techniques from computer vision to linguistically annotated video data collected from human signers, in order to produce models for use in animation-production. The PIs will expand their existing annotated video ASL corpora through new data collection and annotation, and will analyze these data to study the use, timing, and synchronization of manual and non-manual components of ASL production. The annotated videos will be used to train high quality computer vision models for recognition of linguistically significant facial expressions and timing subtleties. Parameters of these computer vision models will be used to hypothesize computational models of ASL timing and facial movements, to be incorporated into ASL-animation generation software and evaluated by native signers. The models will be iteratively refined in cycles of user-based studies and incorporated into ASL animation technologies to more accurately mimic human signing. Project outcomes will include high quality models of the movement of virtual human characters for animations of ASL performance. The analysis of video corpora of ASL will produce new linguistic insights into the micro-facial expressions and the temporal coordination of the face and hands in ASL production, while advances in the analysis of ASL prosody will contribute to an understanding of the fundamental commonalities and modality-specific differences between signed and spoken languages that is essential to a full understanding of the human language faculty. The creation of new modeling approaches and recognition techniques will advance the field of computer vision, by benefiting the identification and tracking of the human face and body in video during the rapid and complex movements of ASL (and other forms of human movement).<br/><br/>Broader Impacts: This research will lead to significant improvements to technology for generating linguistically accurate ASL animations, which will make information, applications, websites, and services more accessible to the large number of deaf individuals with relatively low English literacy. Advances in computer vision techniques for recognizing ASL in videos of humans will have general applicability in human-computer interaction, recognition and animation of facial expressions, and computer vision. The corpora created in this project will enable students and researchers in both linguistics and computer science (including those without access to the requisite technological and human resources to carry out their own data collection from native signers and time-intensive linguistic annotations) to engage in research on ASL. The techniques to be developed will also enable partial automation of the time-consuming creation of annotated ASL video corpora. As in the PIs' earlier work, the proposed research will create opportunities for people who are deaf and members of other underrepresented groups to participate in scientific research."
"0953870","CAREER: Rational Language Processing with Uncertain and Noisy Input","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","04/15/2010","08/21/2012","Roger Levy","CA","University of California-San Diego","Continuing grant","Tatiana D. Korelsky","03/31/2016","$501,529.00","","rlevy@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7252, 7495","1045, 1187, 7495, 9215, HPCC","$0.00","This CAREER award investigates how humans integrate a wide variety of <br/>information sources to achieve rapid, accurate natural language <br/>comprehension subject to the physical and cognitive constraints under <br/>which it takes place. The project's primary empirical focus is on <br/>reading, a mode of information exchange of unexceeded importance in <br/>literate societies. Reading involves a rapid sequence of targeted eye <br/>movements throughout a text -- recordable through modern eye-tracking <br/>technology -- from which noisy sensory input are obtained and <br/>integrated with prior knowledge to resolve perceptual and linguistic <br/>uncertainty. The central goal of this project is thus to develop, <br/>implement, and test a computational model of language comprehension <br/>and eye movement control in reading built on principles of <br/>probabilistic inference and rational action, using the tools of <br/>natural language processing (NLP) technology, reinforcement learning, <br/>and behavioral psycholinguistic experimentation.<br/><br/>The success of this project is likely to have major impact in the <br/>field of human sentence processing, bringing a new level of nuance and <br/>detail to both theory and data analysis, and will bear on broad <br/>current debates in cognitive science regarding rationality in <br/>cognition. Additionally, the results of this basic research project <br/>have a wide range of potential applications ranging from intelligent <br/>tutoring technology to language-impairment diagnosis to cognitive <br/>ergonomics. Together with this research program, the project involves <br/>an educational program including a new textbook on probabilistic <br/>models in the study of language, new undergraduate and graduate <br/>courses, and tutorials and courses on computational psycholinguistics <br/>at major conferences and summer institutes.<br/><br/>This CAREER award is co-funded by two directorates:: CISE/IIS and SBE/BCS."
"1450992","EAGER: Variance and Invariance in Voice Quality","IIS","LINGUISTICS, ROBUST INTELLIGENCE","08/01/2014","07/24/2014","Abeer Alwan","CA","University of California-Los Angeles","Standard Grant","Tatiana D. Korelsky","07/31/2015","$200,000.00","Jody Kreiman, Patricia Keating","alwan@ee.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","1311, 7495","7495, 7916","$0.00","This EArly Grant for Exploratory Research aims at developing a database and model of voice source variability. A model of voice variations across people and speech tasks could improve the naturalness of speech synthesis systems. In addition, understanding what aspects of the voice, if any, are speaker-specific, should aid in developing better speaker identification and verification algorithms. Knowing how much a person could change his or her voice quality without compromising their vocal identity, could also inform medical rehab applications. A better understanding of the human voice will, thus, be of significant impact scientifically, and for engineering and medical applications. The project has strong outreach and dissemination programs and fosters interdisciplinary activities in Electrical Engineering, Linguistics, and Speech and Hearing Science at UCLA. It will train undergraduate and graduate students in important cross-disciplinary activities of technological and scientific significance. <br/><br/>This exploratory project will analyze and discover how the voice source varies within and across talkers under circumstances that introduce variability in everyday life situations. The project aims to address three questions: 1) Does an individual talker's voice source vary significantly across recording sessions and speech tasks?, 2) Do bilingual talkers show more or less intra-talker variation when speaking in English?, and 3) Most importantly, how does intra-talker variability from all these sources compare with inter-talker variability? Understanding these issues will require a high-quality speech database with multiple voice samples from many talkers (in this case 200) which will be collected and distributed to other researchers. Acoustic analyses will reveal inter- and intra-talker variability in the voice source across different situations by generating a multi-dimensional acoustic profile of each talker that specifies the range of parameter values that are typical in the corpus for that talker, and the likelihood of deviations from that usual profile."
"1406858","CHS: Medium: Collaborative Research: Intelligent Context-Aware Peer-to-Peer Transaction Brokering","IIS","Cyber-Human Systems","08/01/2014","07/24/2014","John Carroll","PA","Pennsylvania State Univ University Park","Standard Grant","William Bainbridge","07/31/2017","$279,621.00","","jcarroll@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7924","$0.00","Peer-to-peer exchange is transforming economic activity, through unprecedented integration of social and practical action. This project will produce a full-scale implementation of a more efficient model of it that can be emulated across many social and economic domains. Peer-to-peer exchange is the direct exchange of goods and services by citizens, mediated by a brokering entity, typically embodied as an information system. It is an emerging paradigm that integrates economic and social interaction, creating many possibilities for innovation. It encompasses diverse services such as ride sharing, everyday tasks, textbook sharing, accommodation sharing , car sharing , sharing parking, local food exchange, sharing household items, exchanging home-cooked meals, sharing workspace and expertise, timebanking, and municipal development . Many of these applications make use of otherwise wasted resources such as parked cars, empty bedrooms, and idle time, increasing the efficiency and sustainability of economic activity. Their number and size have mushroomed; they are now referred to collectively as the ""collaborative economy.""<br/><br/>Many peer-to-peer exchanges involve sharing goods and services ""just in time,"" that is, sharing precisely when someone needs something and someone else is prepared to provide it. Thus, one key to the success of peer-to-peer exchanges is close coordination of providers/offerers and recipients/requesters. In a recent NSF project, members of the current research team investigated mobile timebanking using smartphone clients, a system in which members of a community can volunteer specific hours of labor they are well prepared to perform, in exchange for hours of labor from other community members, counting each hour equally. A key challenge was a lack of coordination in arranging ""just in time"" service exchanges. <br/><br/>This new research will investigate computational approaches to coordinating collaborative interactions mediated by contextual intelligence. Also studied will be what sorts of user, task, and interaction information facilitate effective ""just in time"" service exchanges, and how users appropriate and experience these exchanges. A large field trial will investigate the adoption, usability, and utilization of context-aware peer-to-peer transaction brokering and will provide early reports of results and help a variety of organizations implement techniques that have been shown to work.<br/><br/>The research will extend current understanding of motivations for engaging in helpful economic transactions, the formation of social connections through such transactions, and of how to enhance subjective wellbeing by fostering practical helping behaviors through context-aware technology. A prime objective is to identify strategies for contextually facilitated peer-to-peer exchange that can energize economic exchange activity, and support new kinds of exchange, while enhancing social consequences and concomitants of exchange interactions."
"1407630","CHS: Medium: Collaborative Research: Intelligent Context-Aware Peer-to-Peer Transaction Brokering","IIS","Cyber-Human Systems","08/01/2014","07/24/2014","Victoria Bellotti","CA","Palo Alto Research Center Incorporated","Standard Grant","William Bainbridge","07/31/2017","$462,478.00","","victoria.bellotti@parc.com","3333 Coyote Hill Road","Palo Alto","CA","943041314","6508124078","CSE","7367","7367, 7924","$0.00","Peer-to-peer exchange is transforming economic activity, through unprecedented integration of social and practical action. This project will produce a full-scale implementation of a more efficient model of it that can be emulated across many social and economic domains. Peer-to-peer exchange is the direct exchange of goods and services by citizens, mediated by a brokering entity, typically embodied as an information system. It is an emerging paradigm that integrates economic and social interaction, creating many possibilities for innovation. It encompasses diverse services such as ride sharing, everyday tasks, textbook sharing, accommodation sharing , car sharing , sharing parking, local food exchange, sharing household items, exchanging home-cooked meals, sharing workspace and expertise, timebanking, and municipal development . Many of these applications make use of otherwise wasted resources such as parked cars, empty bedrooms, and idle time, increasing the efficiency and sustainability of economic activity. Their number and size have mushroomed; they are now referred to collectively as the ""collaborative economy.""<br/><br/>Many peer-to-peer exchanges involve sharing goods and services ""just in time,"" that is, sharing precisely when someone needs something and someone else is prepared to provide it. Thus, one key to the success of peer-to-peer exchanges is close coordination of providers/offerers and recipients/requesters. In a recent NSF project, members of the current research team investigated mobile timebanking using smartphone clients, a system in which members of a community can volunteer specific hours of labor they are well prepared to perform, in exchange for hours of labor from other community members, counting each hour equally. A key challenge was a lack of coordination in arranging ""just in time"" service exchanges. <br/><br/>This new research will investigate computational approaches to coordinating collaborative interactions mediated by contextual intelligence. Also studied will be what sorts of user, task, and interaction information facilitate effective ""just in time"" service exchanges, and how users appropriate and experience these exchanges. A large field trial will investigate the adoption, usability, and utilization of context-aware peer-to-peer transaction brokering and will provide early reports of results and help a variety of organizations implement techniques that have been shown to work.<br/><br/>The research will extend current understanding of motivations for engaging in helpful economic transactions, the formation of social connections through such transactions, and of how to enhance subjective wellbeing by fostering practical helping behaviors through context-aware technology. A prime objective is to identify strategies for contextually facilitated peer-to-peer exchange that can energize economic exchange activity, and support new kinds of exchange, while enhancing social consequences and concomitants of exchange interactions."
"1319305","RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","IIS","ROBUST INTELLIGENCE","10/01/2013","07/24/2014","David Roberts","NC","North Carolina State University","Continuing grant","James Donlon","09/30/2015","$156,203.00","","robertsd@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7495","7495, 7923","$0.00","Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br/><br/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are."
"1319365","RI: Small: Reinforcement Learning with Predictive State Representations","IIS","ROBUST INTELLIGENCE","08/01/2013","07/24/2014","Satinder Baveja","MI","University of Michigan Ann Arbor","Continuing grant","Todd Leen","07/31/2016","$450,000.00","","baveja@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7495, 7923","$0.00","Like animals and humans, artificial autonomous agents that are able to predict short-term and long-term consequences of their actions can then plan their behavior, act more intelligently, and achieve greater reward. Agents that can learn such predictive models from experience can be more robust in their intelligence than agents that rely on pre-built models. The PI and graduate students are focused on the particularly challenging but natural case where observations from the agent's sensors far in the past can continue to influence the predictions of consequences of actions long into the future. (For example, the observation of where you park the car in the morning will help predict where you will see the car later in the day.) There are two broad classes of approaches to learning predictive models in such 'partially observable' settings. Finite-history models use short-term history of observations to predict future observations conditioned on actions; these are fast to learn but are limited because they cannot capture the effects of long-term history. Latent-variable models can capture the effects of long-term history by positing hidden or latent variables that capture the true state of the environment (e.g., the location of the car), but such models are difficult to learn because the latent variables have to be inferred from data. <br/><br/>This project builds on previous work by the PI and others on a third approach, called Predictive State Representations (or PSRs), in which the agent maintains predictions of future observations conditioned on future actions as a summary-representation of history; these models can both be fast to learn and capture the effect of long-term history. This project develops new PSR-based methods and algorithms for hierarchical models, rich-feature-based models, and local and modular models. The project applies the new methods to challenging applications from active perception and robotics. In addition, theoretical understanding of these richer and newer methods will be developed. Altogether the project significantly expands the applicability of PSR-methods as well as their theoretical foundations and algorithms. <br/><br/>Broader Impacts: New methods that allow artificial agents to robustly build predictive models would advance the state of knowledge across the fields of artificial intelligence, reinforcement learning, control, operations research, psychology, and neuroscience. The PI is co-leading an effort to create a new undergraduate degree in Data Sciences at the University of Michigan to be jointly managed by Computer Science & Engineering and Statistics. This future degree as well as other current undergraduate research programs will be targeted to recruit, mentor, and train students for this project."
"1302668","Collaborative Research: RI: Processing Opinion Sharing Dialogue in Social Media","IIS","ROBUST INTELLIGENCE","09/01/2013","07/24/2014","Marilyn Walker","CA","University of California-Santa Cruz","Continuing grant","Tatiana D. Korelsky","08/31/2016","$716,460.00","Pranav Anand, Steve Whittaker, Jean Fox Tree","mawalker@ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7495","7495, 7924, 9251","$0.00","When people make decisions or form beliefs, they often discuss them with others, seeking out others' opinions and sharing their own. Recently such conversations are occurring online, providing a public source of information of interest to companies, the military, the government, public policy bodies, and educators. Moreover these dialogs occur at scale, allowing researchers in natural language processing access to large-scale dialog datasets for the first time. However, automatically processing such dialogs is challenging, because current tools are targeted to traditional language resources such as newspaper articles. This project develops innovative algorithms for automatically processing and identifying important phenomena in such dialogs including: (a) stance - participants' views on a topic; (b) subjective dialog acts - including sarcasm and humor; and (c) central propositions - core ideas in the dialog, by combining methods of crowd-sourced annotation, bootstrapping and machine learning, and cognitive science. A critical project output is a new corpus, including annotations and dialogic summaries. <br/><br/>Longer term impacts include public policy, providing government and the military with methods to discover what ""the man on the street"" is saying about current topics. Educators can re-use the corpora and tools to expose children to compelling arguments about important issues. Greater understanding of opinion sharing dialog enables new cognitive experiments and theory: automatically identifying compelling arguments allows political science and social psychology researchers to examine learning and opinion formation. The project trains undergraduate and graduate students in interdisciplinary research combining social media, human computer interaction, computational linguistics and natural language processing."
"0753144","INTEROP: A Community-Driven Scientific Observations Network to Achieve Interoperability of Environmental and Ecological Data","DBI","ADVANCES IN BIO INFORMATICS, ECOSYSTEM STUDIES, LONG TERM ECOLOGICAL RESEARCH, INFO INTEGRATION & INFORMATICS, DATA INTEROPERABILITY NETWORKS","08/01/2008","06/07/2012","Mark Schildhauer","CA","University of California-Santa Barbara","Continuing grant","Peter H. McCartney","07/31/2015","$750,000.00","Phillip Dibner, Deborah McGuinness, Shawn Bowers, Corinna Gries","schild@nceas.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","BIO","1165, 1181, 1195, 7364, 7701","1165, 1181, 1195, 7364, 9139, 9183, 9184, 9199, BIOT","$0.00","This project will build a ""Scientific Observations Network""--as a multi-disciplinary, community-driven effort to define and develop a unified model for observational data, to enhance data sharing, merging and reuse in the earth and life sciences. This effort will coordinate work of a community of experts drawn from numerous disciplines, including ecology, hydrology, oceanography, geo-sciences, the geospatial community, and life sciences, working closely with computer scientists and information managers, to develop necessary specifications and technologies to facilitate intelligent interpretation and seamless integration of observational data. Advances in environmental science and ecology increasingly depend on information from multiple disciplines to address broad, complex questions about the natural world. Researchers are extremely challenged, however, in effectively locating, interpreting, and integrating data that might be relevant for these investigations. This is due to extreme variability in the structure and contents of the data that scientists collect. This project will support the growing interest in the earth and life sciences in the possibilities of describing data at the level of observation and measurement, rather than the traditional focus at the level of the data set, in order to achieve stronger data discovery and interoperability. <br/><br/>The Scientific Observations Network will work to develop compatible, open-source, standards-based approaches to the semantic modeling of observational data. A key goal will be the development of a core conceptual data model for representing scientific observations. This core observations model will provide a common basis for developing, extending, and applying highly specialized scientific terminologies required for detailed descriptions of data relevant for environmental research. Subgroups of experts will engage in extending the core data model to include a broad range of specific measurements collected by the representative disciplines, and a series of demonstration projects will illustrate the capabilities of these approaches to confederate data for reuse in broader and unanticipated contexts. The scientific Observations Network will help to insure that scientific data, once collected, is put to the greatest possible use by the broadest group of users."
"1249722","EAGER: Scaling the Preprocessor and Making it More Intelligent in Deterministic Database Systems","IIS","INFO INTEGRATION & INFORMATICS","08/15/2012","08/09/2012","Daniel Abadi","CT","Yale University","Standard Grant","Frank Olken","07/31/2015","$200,000.00","","daniel.abadi@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7364","7364, 7916","$0.00","This research aims to bridge the gap between the current reality and the potential for database system deployments on large clusters of servers in a data center or large numbers of virtual machines in the cloud. There does not exist a scalable, elastic, ACID-compliant database system implementation today. In general, applications that require elastic scalability are forced to program around the lack of ACID guarantees of the database system, and many applications are too complicated to be rewritten to work around these issues. The goal of this project is to overcome these issues using the following approaches: (1) Implementing a database system using an innovative deterministic architecture that guarantees that nondeterministic processing events will not affect database state, (2) Leveraging this new architecture to avoid ""commit protocols"" for distributed transactions in a cluster, (3) Designing a scalable preprocessor for the deterministic database that collects, analyzes, and dispatches transactions to the database cluster in order to further improve scalability, and (4) Developing a new lazy transaction evaluation approach in order to spread out load and avoid damaging effects of database load spikes. Overall, this research enables thousands of applications written for many different use-cases (such as e-commerce, telecommunications, and online auctions) to achieve scalability ""for free"" without having to rewrite the application code. This research involves both Ph.D. students and undergraduates, with significant outreach efforts to encourage undergraduates to get involved in research. Open source code, publications, and technical reports from this research will be disseminated via the project web site http://db.cs.yale.edu/determinism/."
"1118088","III:Small: A Logic-Based, Provenance-Aware System for Merging Scientific Data under Context and Classification Constraints","IIS","INFO INTEGRATION & INFORMATICS","10/01/2011","08/08/2012","Bertram Ludaescher","CA","University of California-Davis","Continuing grant","Frank Olken","09/30/2014","$479,186.00","Todd Green, Shawn Bowers","ludaesch@illinois.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7364","7923","$0.00","There is a rich research literature on information integration (e.g., on data fusion, data integration, and data exchange, including schema matching, mapping, and composition), knowledge-representation, ontologies, and semantic web technologies. However, there has been little prior work on the related problem of merging annotated datasets that already have largely compatible schemas, but where data values of some fields can come from (or link to) different concept hierarchies (taxonomies). Combining datasets into a single, consistent representation is a prerequisite for addressing many important scientific questions (e.g. those that rely on data to be expressed at broad spatial, temporal, and taxonomic scales). In practice, scientists combine multiple datasets manually, a time-intensive and error-prone process. In many application domains (e.g., biodiversity, ecology, systematics) data are often annotated with concepts from different but interrelated taxonomies. For instance, scientists who wish to combine datasets that record the presence or absence of species at given locations are often faced with datasets that draw species names from different taxonomies. In such cases, merging datasets requires aligning the different taxonomies. However, even for aligned taxonomies (i.e., where formal articulation constraints are given), many different dataset merges are possible, including inconsistent or incomplete ones. These in turn can yield different or even contradictory outcomes in subsequent interpretations and downstream data analysis. The primary goals of this project are to develop new techniques at the interface of data integration, knowledge-representation, and reasoning, to empower scientists by giving them new tools for merging and 'logically debugging' taxonomies and annotated datasets. The proposed Euler toolkit will include a formal framework with a broad range of constraints and data types; novel provenance-based techniques to detect, explain, and repair inconsistencies in taxonomy alignments; and new techniques to reduce uncertainty in alignments. <br/><br/>For further information see the project web site at the URL: http://www.daks.ucdavis.edu/projects/euler"
"1422910","AF: Small: Foundations for Learning in the Age of Big Data---New Frameworks and Algorithms for Interactive, Distributed, and Multi-Task Machine Learning","CCF","ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS","08/01/2014","07/24/2014","Maria-Florina Balcan","PA","Carnegie-Mellon University","Standard Grant","Balasubramanian Kalyanasundaram","07/31/2017","$400,000.00","","ninamf@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495, 7796","7923, 7926, 7495","$0.00","Machine learning is a broad discipline with important application domains including computer vision, robotics, sustainability, and bio-surveillance. Its past successful evolution was heavily influenced by mathematical foundations developed for core problems of generalizing from labeled data. However, with the variety of applications of machine learning across science, engineering, and computing in the age of Big Data, re-examining the underlying foundations of the field has become imperative. This project aims to substantially advance the field of machine learning by developing foundations and algorithms for a number of important modern learning paradigms. These include interactive learning, where the algorithm and the domain expert engage in a two-way dialogue to facilitate more accurate learning from less data compared to the classic approach of passively observing labeled data; distributed learning, where a large dataset is distributed across multiple servers and the challenge lies in learning with limited communication; and multi-task learning, where the goal is to solve multiple related learning problems from less data by taking advantage of relationship among the learning tasks. The project also aims to develop new connections between machine learning and property testing, a flourishing area of theoretical computer science. In addition to solving fundamental questions in each of these directions, the project will highlight and leverage synergies between these topics.<br/><br/>More specifically, the key research directions of this project are: (1) Developing mathematical foundations for interactive learning by analyzing new forms of interactions between the learning algorithm and the domain expert that could lead to fast and efficient learning of difficult tasks by wisely exploiting the capabilities of domain experts. (2) Developing new algorithms for distributed learning, an important modern scenario where data is distributed among several locations. This project will develop protocols that trade off the various types of resources involved in such settings (computation, communication, and domain expertise). (3) Developing new algorithms with provable guarantees for learning multiple related tasks from limited amounts of labeled data and massive amounts of unlabeled data by wisely exploiting explicitly known or latent relationships between the given tasks. (4) Developing mathematical foundations for property testing, where the question is to quickly determine whether there exists a low-error rule of a desired form by using significantly less data than needed to actually find the rule itself. This project will specifically focus on active and distributed scenarios, with the goal of using testing as a way to improve learning efficiency itself.<br/><br/>Broader impacts include mentoring women in CS and actively organizing workshops and seminars in the interdisciplinary area."
"1404698","CHS: Medium: Collaborative Research: Intelligent Context-Aware Peer-to-Peer Transaction Brokering","IIS","Cyber-Human Systems","08/01/2014","07/24/2014","Anind Dey","PA","Carnegie-Mellon University","Standard Grant","William Bainbridge","07/31/2017","$457,083.00","","anind@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","7367, 7924","$0.00","Peer-to-peer exchange is transforming economic activity, through unprecedented integration of social and practical action. This project will produce a full-scale implementation of a more efficient model of it that can be emulated across many social and economic domains. Peer-to-peer exchange is the direct exchange of goods and services by citizens, mediated by a brokering entity, typically embodied as an information system. It is an emerging paradigm that integrates economic and social interaction, creating many possibilities for innovation. It encompasses diverse services such as ride sharing, everyday tasks, textbook sharing, accommodation sharing , car sharing , sharing parking, local food exchange, sharing household items, exchanging home-cooked meals, sharing workspace and expertise, timebanking, and municipal development . Many of these applications make use of otherwise wasted resources such as parked cars, empty bedrooms, and idle time, increasing the efficiency and sustainability of economic activity. Their number and size have mushroomed; they are now referred to collectively as the ""collaborative economy.""<br/><br/>Many peer-to-peer exchanges involve sharing goods and services ""just in time,"" that is, sharing precisely when someone needs something and someone else is prepared to provide it. Thus, one key to the success of peer-to-peer exchanges is close coordination of providers/offerers and recipients/requesters. In a recent NSF project, members of the current research team investigated mobile timebanking using smartphone clients, a system in which members of a community can volunteer specific hours of labor they are well prepared to perform, in exchange for hours of labor from other community members, counting each hour equally. A key challenge was a lack of coordination in arranging ""just in time"" service exchanges. <br/><br/>This new research will investigate computational approaches to coordinating collaborative interactions mediated by contextual intelligence. Also studied will be what sorts of user, task, and interaction information facilitate effective ""just in time"" service exchanges, and how users appropriate and experience these exchanges. A large field trial will investigate the adoption, usability, and utilization of context-aware peer-to-peer transaction brokering and will provide early reports of results and help a variety of organizations implement techniques that have been shown to work.<br/><br/>The research will extend current understanding of motivations for engaging in helpful economic transactions, the formation of social connections through such transactions, and of how to enhance subjective wellbeing by fostering practical helping behaviors through context-aware technology. A prime objective is to identify strategies for contextually facilitated peer-to-peer exchange that can energize economic exchange activity, and support new kinds of exchange, while enhancing social consequences and concomitants of exchange interactions."
"1219138","HCC: Small: Examining the Super User versus the Crowd in Human-Centered Computation","IIS","Cyber-Human Systems","08/15/2012","07/23/2014","Albert Lin","CA","University of California-San Diego","Continuing grant","William Bainbridge","07/31/2015","$497,250.00","Falko Kuester","a5lin@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367","7367, 7923","$0.00","This project investigates the nature of crowd-based human analytics at various scales, specifically how the concentrated efforts of a few contributors differ from the summed micro contributions of many. Automated approaches are good at handling huge amounts of data, but they lack the flexibility and sensitivity of human perception when making decisions or observations, especially when computational challenges revolve around visual analytics. Networks of humans, as an alternative, can scale up human perception by facilitating massively parallel computation through the distribution of micro-tasks, but human data interpretation is variant between individuals. Wide variability in the amount of participation of individuals in crowd-based computation creates non-uniform representations of a crowd, which is an important discrepancy that could significantly impact the validity of the term ""crowd"" in crowdsourcing. The research will explore data generated from the extreme ends of the participation curve and quantify the quality of data produced from a broad sampling of a crowd versus concentrated voice of the few ""super users."" <br/><br/>As one measure of comparison, the researchers will observe how characteristically variant samplings of human generated analysis alter the outcome when used as training data in a machine learning framework. This investigation will utilize data generated from a crowdsourcing effort that tapped over 10,000 volunteer participants to generate over 2 million human annotations on ultra-high resolution satellite imagery in search for tombs across Mongolia. Image tiles were distributed at random to participants who tagged anomalies of interest, while crowd consensus on points of interest provided a field survey team with locations to ground truth in Mongolia. Participation ranged widely, as illustrated by the fact that 20 percent of the data came from the most active 1 percent of participants, while at the other extreme 20 percent of the data came from the 80 percent of participants who were least active. While consensus of the crowd provided one metric to measure the quality of anomaly identifications, ground truth observations showed actual validation tended to correspond with identifications made from higher interest participants. This study will explore the nature of data generated from experts versus crowds of non-experts, starting from the discrepancies in participation levels.<br/><br/>Crowd-based human analytics has been welcomed as a potential solution to some of the world?s largest data challenges. Examples of crowdsourcing have shown that the power of distributed microtasking can engage challenges as overwhelming as categorizing the galaxies, or as complicated as folding proteins. However this concept depends upon the recruitment of human help, often at whatever levels of participation an individual is willing to contribute. The variation in contributions, and thus impact levels, between individuals can be staggering, with participation typically distributed across a longtail curve. That fundamental aspect of a recruited crowd should be recognized and understood when extracting knowledge from the data that is generated. This project will contribute to the necessary understanding by determining how the distributed inputs from a crowd differ from the concentrated efforts of an individual. Insight into the effects of crowd dynamics on results will determine how we pool and retain participation and, thus, have transformative impact on the development of crowdsourcing as a concept for analytics."
"1117433","III: Small: A Discriminative Modeling Framework for Mining of Spatio-Temporal Data in Remote Sensing","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","06/30/2011","Slobodan Vucetic","PA","Temple University","Standard Grant","Sylvia J. Spengler","08/31/2015","$499,959.00","Zoran Obradovic","vucetic@ist.temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7364","7923","$0.00","Understanding the physical and chemical processes of Earth's atmosphere, land, and ocean presents significant scientific challenges. Due in part to the societal impact of addressing these challenges, recent years have seen significant investments in a large number of satellite and ground-based sensors dedicated to Earth observation. The observations from these sensors are used to estimate important geophysical properties such as temperature, clouds, aerosols, greenhouse gases, snow and ice, and used in scientific studies aimed at climate modeling, weather forecasting, air quality monitoring, and disease management. Current techniques from spatial statistics and data fusion fall short of what is needed because of computational constraints, difficulties in modeling and parameter estimation, or inability to provide uncertainty estimates. The objective of this project is to develop methods that help best utilize large quantities of multi-source observations from satellite and ground-based instruments for Earth observation having different capabilities regarding coverage, resolution, and quality. <br/><br/>This project develops a novel discriminative modeling framework for fusion of multi-sensor remote sensing data based on the Gaussian conditional random field model. The framework is designed to be flexible, robust, and computationally efficient, and hence suitable for use on large spatio-temporal data sets. It allows learning from a mixture of labeled and unlabeled data with partially observable attributes, in the presence of sampling bias. The methods will be implemented in an open source, user-friendly, software tool for use by practitioners. The resulting tools will be evaluated on the problems of atmospheric aerosol and surface level pollution estimation, which are some of the important problems in climate research and environmental science. <br/><br/>The broader impacts of this project include methodological advances in the current state of the art in spatio-temporal data mining and geostatistics as well as Earth remote sensing. It will enable improved characterization of the effects of aerosols on the Earth's radiation budget and climate. The data fusion framework is directly applicable to estimations of many other atmospheric, land, and ocean properties. The research activities in this project are integrated with education. They will help broaden the participation of students ranging from doctoral to K-12 level and increasing diversity in Computer Science through already established channels at Temple University for engaging students from underrepresented groups. <br/><br/>Additional details about the project can be found at: http://www.dabi.temple.edu/~vucetic/nsf_fusion.htm"
"1111423","III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/23/2014","Stanley Zdonik","RI","Brown University","Continuing grant","Maria Zemankova","08/31/2015","$736,987.00","Ugur Cetintemel","sbz@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7364","7925, 9150","$0.00","This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br/><br/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br/><br/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists ""in the loop"" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http://www.scidb.org/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http://database.cs.brown.edu/projects/scidb)."
"1149737","CAREER: Spectral Deformable Models: Theory and Applications","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","09/01/2012","07/23/2014","Xiaohu Guo","TX","University of Texas at Dallas","Continuing grant","Jie Yang","08/31/2017","$314,372.00","","xguo@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7453, 7495","1045, 7453, 9251","$0.00","With the popularity of real-time 3D/4D data capturing capabilities, there is an emerging need to compute the deformable models over the networks. Traditional model-driven deformable models have their bottlenecks since the spatial information for large-scale datasets cannot be efficiently solved and adaptively minimized over different network conditions. This project centers on the concept of spectrum-driven deformable models. Analogous to Fourier analysis being applied to image processing, the spectral deformable models employ manifold harmonics to efficiently and effectively perform segmentation, registration, physics-based simulation, compression, and streaming of 3D deformable surfaces and volumes.<br/><br/>In this project, manifold harmonics are used to transform arbitrary scanned datasets into a reduced diffusion subspace, in which real-time segmentation, registration, and physics-based simulation can be performed. Besides the stretching deformations, the rotational and tensor fields are encoded with manifold harmonics, which provides a ""spectral multiresolution"" structure to compress and stream deformable models over different network conditions.<br/><br/>The PI works with the medical imaging experts at UT Southwestern Medical Center, to build a tele-diagnosis system for evaluating each component in the spectral deformable models. The test-bed on tele-medicine has impacts on the next-generation diagnosis and treatment services, as well as on clinical education. The theoretical and technical breakthrough can benefit our society at large, from tele-immersion, remote sensing, to speech training, through the PI?s further outreach activities. The research and education are integrated by taking research advances into existing and future courses; developing the visualization software for education; and attracting more undergraduate students into research."
"1110370","III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/23/2014","Magdalena Balazinska","WA","University of Washington","Continuing grant","Maria Zemankova","08/31/2015","$370,781.00","","magda@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7364","7925","$0.00","This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br/><br/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br/><br/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists ""in the loop"" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http://www.scidb.org/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http://database.cs.brown.edu/projects/scidb)."
"1422021","RI: Small: Geometry- and Symmetry-Driven Computer Vision Methods for High-Throughput Automated Microscopic Imaging","IIS","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, ROBUST INTELLIGENCE","08/01/2014","07/23/2014","Davi Geiger","NY","New York University","Continuing grant","Jie Yang","07/31/2017","$268,073.00","","geiger@cs.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","1165, 1640, 7275, 7495","7495, 7923, 8750","$0.00","Humans not only outperform current Computer Vision methods in complex general problems such as object detection/recognition, but also in domain-specific tasks such as counting cells and detecting cell divisions in time-lapse videos of mammalian embryos. This project develops a key computer vision component to reach human-like recognition performance in shape recognition for biology applications. The project provides automated methods and software tools for biology research. The project also develops a framework for addressing fundamental issues in geometry to contribute to computer vision research. <br/><br/>This research is rooted on pair wise symmetry and the construction of six dimensional histograms from symmetry measures. It hypothesizes that shape properties of objects can be robustly represented by marginalizing this histogram. The research team develops a method to build shape properties by performing products of marginalized histograms as to create higher level shape descriptions. The short-term goal of this project is to apply this concept to count and track overlapping cells in early mouse and human embryos. The outcome of the work includes a database of hierarchical trees of cell divisions in a mouse-embryo up to the 8-cell is essential for the analysis of particular genes in the early phases of life. The mid-term goal is to develop a shape database available to all researchers, where other computer vision methods can be tested. The long-term goal is to crack the challenging problem of understanding shapes in images. This project impacts the development of detection and recognition of objects in images and the mathematical description of shapes. It also impact on the development of a theory of leaning from big data, as it investigates shape-structures of high dimensional data."
"1423082","RI: Small: Collaborative Research: Stochastic Sampling for Rendering, Imaging, and Modeling","IIS","ROBUST INTELLIGENCE","09/01/2014","07/23/2014","Rui Wang","MA","University of Massachusetts Amherst","Standard Grant","Jie Yang","08/31/2017","$319,956.00","","ruiwang@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7495","7495, 7923","$0.00","Stochastic sampling is a fundamental component in most computer graphics applications, including rendering, imaging, modeling, and simulation. For example, in rendering, stochastic sampling is crucial to efficiently solving complex integrals; in texture synthesis, it is the key to generate visually pleasing patterns; in geometry processing, it is used to characterize important geometry features. While much previous work has focused on planar samples with blue noise spectrum, little research has studied more general types of stochastic sampling. This research aims to advance the state of the art in general stochastic sampling, providing new theoretical insights, computational methods, and practical applications. The outcome benefits not only computer graphics and vision, but many other disciplines that rely on stochastic sampling techniques.<br/><br/>This project studies new methods for analyzing and synthesizing stochastic samples. On the analysis side, the research introduces new techniques, based on spatial statistics, to quantify the distribution properties of stochastic samples. On the synthesis side, the research presents computationally efficient methods to generate high-quality samples with desired distribution properties. Modern GPUs are employed to achieve parallel computation. These techniques in turn enable new applications. In rendering, the project answers fundamental questions such as the optimal sample patterns for anti-aliasing and half-toning. In computational photography, the project introduces novel scene-dependent coded patterns that allow a camera system to capture more details (spatially, temporally, and spectrally) in a single shot. In geometry processing, the project presents new technique to generate samples on surfaces, for remeshing, defining shape features, and performing shape matching."
"1422477","RI: Small: Collaborative Research: Stochastic Sampling for Rendering, Imaging, and Modeling","IIS","ROBUST INTELLIGENCE","09/01/2014","07/23/2014","Jingyi Yu","DE","University of Delaware","Standard Grant","Jie Yang","08/31/2017","$179,664.00","","yu@cis.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7495","7495, 7923, 9150","$0.00","Stochastic sampling is a fundamental component in most computer graphics applications, including rendering, imaging, modeling, and simulation. For example, in rendering, stochastic sampling is crucial to efficiently solving complex integrals; in texture synthesis, it is the key to generate visually pleasing patterns; in geometry processing, it is used to characterize important geometry features. While much previous work has focused on planar samples with blue noise spectrum, little research has studied more general types of stochastic sampling. This research aims to advance the state of the art in general stochastic sampling, providing new theoretical insights, computational methods, and practical applications. The outcome benefits not only computer graphics and vision, but many other disciplines that rely on stochastic sampling techniques.<br/><br/>This project studies new methods for analyzing and synthesizing stochastic samples. On the analysis side, the research introduces new techniques, based on spatial statistics, to quantify the distribution properties of stochastic samples. On the synthesis side, the research presents computationally efficient methods to generate high-quality samples with desired distribution properties. Modern GPUs are employed to achieve parallel computation. These techniques in turn enable new applications. In rendering, the project answers fundamental questions such as the optimal sample patterns for anti-aliasing and half-toning. In computational photography, the project introduces novel scene-dependent coded patterns that allow a camera system to capture more details (spatially, temporally, and spectrally) in a single shot. In geometry processing, the project presents new technique to generate samples on surfaces, for remeshing, defining shape features, and performing shape matching."
"1421729","III: Small: Core: Monotonic Retargeting: A Scalable Learning Framework for Determining Order","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","07/23/2014","Joydeep Ghosh","TX","University of Texas at Austin","Continuing grant","Christopher Clifton","08/31/2017","$164,061.00","","ghosh@ece.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7364","7364, 7923","$0.00","Determining preferences, or identifying and ordering items of most interest or relevance based on very limited information, is a fundamental problem in many disciplines. While perhaps most obvious in search, the problem shows up in areas as diverse as economics and health informatics. This project is developing a broad methodology to address challenging learning problems that involve ordering, including determining top choices for recommendation, multi-label classification, and learning to rank-order a set of query results. The key insight is that if the objects to be ordered are given numeric scores, only the relative values of these scores affect their ranking, and not the actual values. This project is using this insight to develop new and better learning algorithms for ranking.<br/><br/>Specifically, the project is developing methods that can efficiently optimize over all possible monotonic (that is, order preserving) transformations of scores. Since these scores become the target values for regression, this class of approaches is being called monotonic retargeting. A systematic way of alternating between readjusting scores and updating the regression model is being developed, with nice properties for scalability and distributed implementation, as well as strong convergence guarantees. Themes common to different types of preference learning or ranking studies are being identified to help bring together the diverse communities, including students, that work on this topic. This wide coverage is possible as it easy to relate to the need to determine priorities and make choices in various walks of life. The applications and impacts of the project are expected to be wide and diverse as well."
"1423276","RI: Small: CompCog: Modeling Latent Discrete Knowledge Across Utterances","IIS","ROBUST INTELLIGENCE","08/01/2014","07/23/2014","Jason Eisner","MD","Johns Hopkins University","Continuing grant","Tatiana D. Korelsky","07/31/2017","$145,808.00","","jason@cs.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7495, 7923","$0.00","Each human language is a system of conventions for communicating information. Yet how does everyone know this complex system? Describing it is difficult even for linguists. Yet young children somehow figure out the rules and vocabulary of their native language. Adults continue to learn when confronted with unfamiliar words, with new conventions associated with social media, or with the layout conventions of a new website. <br/><br/>This project develops new artificial intelligence methods for tasks of this kind. These methods will enable computers to deal with a wider variety of human language data, thus improving information access and global communication. They will also provide insight as to why human intelligence is able to succeed at these problems.<br/><br/>The methods will seek to discern the systematic structure that explains the patterns in naturally occurring linguistic data. Specifically, our computers will analyze naturally occurring data in order to learn:<br/><br/>* How to break down words into meaningful parts and reassemble those parts into new words. This is a subject that linguists call morphophonology. It is practically important in automated analysis and translation of speech and text.<br/><br/>* How to break down sentences into meaningful phrases. This requires determining the basic word order facts of the language -- the problem of grammar induction, considered to be a central mystery of human language learning.<br/><br/>* How to extract machine-readable data from large websites that present databases in human-readable form. This involves automatically figuring out the database structure and layout conventions of a website.<br/><br/>* How to track names across large quantities of informal text. By discovering the principles that govern how people use and modify names, a computer can recognize that the nickname ""Vlad P."" or the misspelled patronymic ""Vladimir Vladimirovich"" might be variant ways of referring to ""Vladimir Putin,"" especially in a political comment. <br/><br/>The project will address each of these domains in a principled way. Our strategy in each domain is to develop a novel Bayesian generative model along with efficient, principled machine learning algorithms for approximate inference. We expect to expand the range of modeling and inference techniques that are available to the natural language processing community. <br/><br/>Innovative technical directions include the automatic reconstruction of phonological underlying forms, a novel treatment of grammar induction as structured prediction, a nonparametric model of databases and database-backed websites, and a phylogenetic model of name variation."
"1258335","EAGER: Data Analysis for Nursing Care Assistance","IIS","Cyber-Human Systems","09/15/2012","09/12/2012","Jing Xiao","NC","University of North Carolina at Charlotte","Standard Grant","Ephraim P. Glinert","08/31/2015","$55,389.00","Srinivas Akella, Jianping Fan, Sonya Hardin","xiao@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","7367","7367, 7916","$0.00","The rising cost of long-term patient care, the shortage of nurses, and the increasing number of seniors in the United States make it imperative to investigate the possibility of intelligent systems for elder/patient care. One challenge is how to prevent falls, which often result in serious injury and considerable hospital and patient costs. In this exploratory project the PI and her team will focus on analyzing sensory data of patient actions in an effort to develop algorithms for the automatic detection and prediction of falls among elderly patients. Their goal is to gain a good understanding of how multimodal sensory data combined with domain knowledge of falls can be used to characterize pre-fall patient actions, in order to determine the feasibility of developing automatic alert systems that incorporate machine learning algorithms to assist human nurses and robotic caregivers by warning of potential falls. <br/><br/>Broader Impacts: Project outcomes will pave the way for future development of intelligent systems to reduce the incidence of patient falls, which is a major societal concern. The project will provide a rich spectrum of interdisciplinary training for graduate student researchers, and will also strengthen UNC Charlotte's existing programs in broadening participation in computing and in research experiences for undergraduates (REU) by deepening involvement of women and minority undergraduate students in research."
"1110917","III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/23/2014","David Maier","OR","Portland State University","Continuing grant","Maria Zemankova","08/31/2015","$365,348.00","","maier@cs.pdx.edu","1600 SW 4th Ave","Portland","OR","972070751","5037259989","CSE","7364","7925","$0.00","This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br/><br/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br/><br/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists ""in the loop"" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http://www.scidb.org/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http://database.cs.brown.edu/projects/scidb)."
"1422127","RI: Small: Improving Multi-label Classifiers by Learning Output Representations","IIS","ROBUST INTELLIGENCE","08/01/2014","07/23/2014","Yuhong Guo","PA","Temple University","Standard Grant","Todd Leen","07/31/2017","$439,191.00","","yuhong@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7495","7495, 7923","$0.00","Multi-label classification refers to automated classification in which multiple target labels are assigned to each instance. For example articles often contain several topics, and images contain multiple types of objects. Multi-label classification is a central problem in big data analysis. Complex data --- such as documents, images and videos --- require automated content annotation to support ranking, retrieval and monitoring operations. Unfortunately, automatic annotation is difficult because multiple labels, exhibiting complex inter-relationships, must be assigned from a large open vocabulary. This research project addresses the three main challenges faced by automated annotation systems that learn multi-label classifiers from data: (1) capturing and exploiting label dependence to overcome data sparsity, (1) exploiting partially labelled data to expand the range of usable resources, and (3)reducing prediction model size to allow practical usability. These three challenges will be tackled from a unified perspective of output representation learning, which has the potential to deliver automated methods for semantic annotation that demonstrate greater autonomy, robustness and accuracy. This research will be integrated into graduate and undergraduate courses, which will allow students to develop analytical and computational skills for big data analysis that are currently in high demand. Being centered at a university with a strong program for minority students, this project will also engage participation from underrepresented groups. Undergraduate and high school students will also be engaged through student project competitions. <br/><br/>The core technical challenges addressed by this research project arise from the phenomena of complex label spaces and sparse data: annotations in big data exhibit ontological structure and missing labels, while even in massive data collections, like Flickr, most labels do not have sufficient positive examples to allow an accurate classifier to be trained independently for each label. To address these challenges, this research project will pursue three main research aims: First, methods for learning multi-label output kernels will be developed that allow auxiliary label information to be combined with state of the art multi-label training losses. These methods will provide important new approaches for addressing the label dependence challenge. Second, methods for learning distributed label representations will be developed that also incorporate auxiliary label information with effective training losses. These methods will provide new approaches for addressing the label dependence and label dimension challenges that make an alternative computational trade-off to output kernel learning. Third, new methods for learning output representations from incomplete labels will be developed that combine missing label imputation with predictor training under effective multi-label losses. This work will greatly extend the practical applicability of multi-label classification learning methods to the type of partially labeled data that is usually encountered in big data. By using output representation learning to improve the quality of multi-label classifiers, this research will advance ranking and retrieval capabilities in important applications, including document and health record management, image and video management, and semantic web analysis. Moreover, by offering flexible engagement opportunities via diverse application studies, algorithm development, experimentation and analysis, this project is well suited to engaging students in research."
"1449155","EAGER: Toward Ethical Intelligent Autonomous Systems, A Case-Supported Principle-Based Behavior Paradigm","IIS","Cyber-Human Systems","09/01/2014","07/23/2014","Michael Anderson","CT","University of Hartford","Standard Grant","Ephraim P. Glinert","08/31/2016","$201,347.00","","anderson@hartford.edu","200 Bloomfield Avenue","West Hartford","CT","061171545","8607685938","CSE","7367","7367, 7916","$0.00","Intelligent autonomous systems (IAMs) are on the verge of being widely deployed in domains in which they will interact closely with people (e.g., personal assistance, healthcare, driverless cars, search and rescue), and they will be expected to navigate this ethically-charged landscape responsibly. As correct ethical behavior not only involves not doing certain things, but also doing certain things to bring about an ideal state of affairs, ethical issues concerning the behavior of IAMs are likely to elude simple, static solutions and exceed the grasp of their designers. The PI argues that the behavior of such systems should be guided by explicit ethical principles abstracted from particular cases where a consensus of ethicists exists. Laying the foundations for such technology is the focus of this exploratory research. Project outcomes will help alleviate concerns with intelligent autonomous systems, since the behavior of such systems guided by ethical principles is likely to be more acceptable in real-world environments than that of such systems without this dimension. Indeed, ethical intelligent autonomous systems capable of functioning with more autonomy might be permitted to assist human beings in a wider range of domains. The PI expects that an important byproduct of this work is that a more thorough understanding of the ethical theory involved is likely to result, as it is made concrete.<br/><br/> To ensure correct ethical behavior, IAMs should weigh alternative possible actions against each other to determine which is ethically preferable at any given moment. The PI will leverage his previous research in developing and deploying principles that weigh the ethical preference of actions, and justify action choices for autonomous systems across multiple domains, to develop a paradigm of case-supported principle-based behavior (CPB) in which intensionally defined ethical action preference is abstracted from particular cases of ethical dilemmas and used to order ethically significant actions. The PI will refine and codify CPB using the domain of eldercare robots as a test bed by, first employing a virtual component based upon simulation and then reifying this simulation in a laboratory setting. In particular, the PI will define a comprehensive set of ethically significant actions for an eldercare robot. He will then develop and validate via an Ethical Turing Test an ethical principle that can be used to order this set by ethical preferences, and use this principle to guide the behavior of a simulated Unbounded Robotics UBR-1 robot with this set of behaviors situated in a Gazebo simulation of an assisted-living facility. He will next reify this simulation with an actual UBR-1 robot in a laboratory setting. Finally, he will refine and codify the requirements, methods, implementation specifics, and testing aspects of the case-supported principle-based behavior paradigm. Besides developing and implementing a general methodology for ensuring ethical behavior in intelligent autonomous systems, this research will provide evidence that ethical principles and decision-making can be computed and function effectively in domains where machines are likely to interact with human beings."
"1423321","III: Small: A Novel Framework for Mining Multi-relation and Labeled Graphs","IIS","INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","08/01/2014","07/23/2014","Saeed Salem","ND","North Dakota State University Fargo","Standard Grant","Christopher Clifton","07/31/2017","$345,551.00","","saeed.salem@ndsu.edu","Dept 4000 - PO Box 6050","FARGO","ND","581086050","7012318045","CSE","7364, 9150","7364, 7923, 9150","$0.00","Complex networks appear in a wide spectrum of fields including bioinformatics and neuroscience. They are governed by intricate webs of interactions among constituent elements. Entities and relationships in graphs are increasingly being annotated with content, thus giving rise to rich attributed graphs. Effective integration of attribute data with network topology will enable scientists to ask new questions and discover novel findings that are not possible using only one source of data. This project is developing methods to find interesting patterns in networks that represent multiple types of information, e.g., gene expression and protein-protein interaction networks along with disease information, or co-authorship graphs with information on both the conference and year of publication. As an example of the value of such pattern discovery, protein-protein interaction subnetworks whose genes are dysregulated in multiple disease genome-wide expression datasets are useful for disease diagnosis and mechanism understanding.<br/><br/>The proposed research aims to develop a suite of algorithmic and analytic methods for analyzing large multi-relation and attributed graphs. Specifically, the project is: (i) developing novel concepts and algorithms for mining cross-graph interesting patterns from multi-relation graphs, and coherent patterns from attributed graphs, and (ii) designing computational methods for integrating biological data (e.g., gene expression, protein-protein interaction networks) for discovering coherent and phenotype-specific subnetworks. This poses interesting challenges due to the computational complexity of many subgraph discovery tasks; this project is using application (e.g., biologically) motivated definitions as a starting point to identify interesting pattern definitions for which discovery is tractable. In addition to dissemination to the research community, outcomes will include software tools for use by the broader scientific community, developing new courses in the area of network analysis, educational material for introducing high school students to computational thinking, and increasing minority undergraduate students involvement in research."
"1350160","CAREER: Human-Aware Autonomy for Team-Oriented Environments","IIS","ROBUST INTELLIGENCE","08/01/2014","07/23/2014","Julie Shah","MA","Massachusetts Institute of Technology","Standard Grant","Satyandra Gupta","07/31/2019","$398,575.00","","arnoldj@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","1045, 7495","$0.00","Robots are an increasingly common presence in human environments, working alongside people in factories, hospitals, and military field operations. However, today people must change how they work to accommodate robots in their workspace. This poses a significant barrier to adoption of robot technology by creating inefficiencies. This project provides an integrated research and educational approach to develop intelligent robotic technologies that more seamlessly integrate with human work environments. <br/><br/>The technical approach translates qualitative and quantitative insights from human studies into explicit computational models, and exploits these models to redesign robot algorithms for learning, decision-making, and control. The research effort specifically investigates three types modifications to robot behavior: (1) modifying robot motion planning using anticipatory signals of human motion, (2) customizing robot task plans using statistical models of human task execution, and (3) inferring and applying human domain expertise to expedite automated planning for mixed human-robot teams. Human subject experimentation is planned to assess ease-of-interaction, worker trust, and task performance, and the approach is validated using metrics to quantitatively assess the degree to which a robot's behavior preserves natural human workflow. By designing robot autonomy that minimizes disruption to human workflow, the approach supports graceful transitions from robotic work back to human work and vice versa."
"1250395","EAGER: Toward a User-centered, Inclusive, and Personalized Approach to Mobile Web Adaptation","IIS","Cyber-Human Systems, ","10/01/2012","08/16/2013","Dongsong Zhang","MD","University of Maryland Baltimore County","Standard Grant","Ephraim P. Glinert","09/30/2015","$287,870.00","Lina Zhou","zhangd@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7367, L654","7367, 7916","$0.00","The PI's goal in this exploratory research is to seek ways to fundamentally improve the user experience when browsing the Web on mobile handheld devices. Existing approaches to mobile Web adaptation have a number of major problems or limitations. Although no single interface design can address the different needs of individual users, existing adaptation methods typically offer one-size-fits-all solutions. While many contextual factors affect Web navigation on handheld devices, relatively little context data is systematically captured today in real-time and exploited in adaptation. Current techniques do not provide users with cues to help them find information of interest. And almost all existing adaptation solutions do not consider the problem of mobile Web accessibility for disabled users; in particular, there is a paucity of knowledge on how to design and deploy the ability to invoke on a mobile device in a personalized, device-aware manner assistive technologies or special features that may be needed by an individual user. In this project the PI will take the first steps toward development and evaluation of a transformative user-centered, inclusive, and personalized approach to mobile Web adaptation that dynamically adapts the content and display of Web pages based on users' information needs, device characteristics, and accessibility requirements. To these ends, he will focus on users with visual impairments. Specific research questions to be addressed include the following: Can a user-centered approach to mobile Web adaptation better meet the preferences and needs of both typical users and those with visual impairments? Can device-aware mobile Web adaptation better support accessibility? Can we design and build a cloud-based integrative, personalized mobile Web adaptation system that provides ubiquitous access to not only typical users but to users with visual impairments as well? Project outcomes will include design, implementation and evaluation of a prototype cloud-based service that integrates a novel user-centered approach to mobile Web adaptation that enables users to specify and adjust adaptation preferences and strategies, a novel device-aware adaptation that dynamically adapts Web pages based on characteristics of individual mobile devices, and novel personalized adaptation techniques for restructuring Web content so as to provide useful information cues and accessibility.<br/><br/>Broader Impacts: This research will benefit not only researchers in the related fields of computer science and information systems, but also manufacturers and designers of handheld devices as well as individual users. The project will provide unique insights to manufacturers of mobile devices and to mobile application designers on how to achieve user-centered, context-aware adaptive interfaces for handheld devices that improve the user's navigation performance and overall Web browsing experience. It will lay the foundations for a novel personalized adaptation solution that improves mobile Web accessibility, for different user communities. And it will provide technical guidance and empirical evidence on how to reduce the digital divide as it relates to the mobile Web. Project findings will be disseminated through interdisciplinary conferences, workshops and journals, and they will be incorporated into existing graduate and undergraduate courses at UMBC as well as a variety of K-12 outreach programs."
"1117913","III: Small: Building Linked Open Services from Online Sources","IIS","INFO INTEGRATION & INFORMATICS","10/01/2011","06/11/2013","Craig Knoblock","CA","University of Southern California","Standard Grant","Frank Olken","09/30/2015","$516,000.00","Jose Luis Ambite","knoblock@isi.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7364","7364, 7923, 9251","$0.00","Most of the work on the Semantic Web and more broadly Information Integration assumes that accurate semantic models of sources exist. In practice, although there is a tremendous amount of data available on the Web, there is rarely any semantic description of the sources and the information provided by them. This project will develop a new approach that addresses the problem of automatically discovering and modeling sources by building on the recent development of Linked Open Data within the Semantic Web. The resulting system will be able to learn about any source where there is background knowledge in the Linked Open Data. This work will be a significant advance over what was done previously since it will allow an intelligent system to expand its knowledge to learn models of sources that cover information for which the system has no known sources. The system will start with all of the data and knowledge in the Linked Open Data as well as semantic descriptions of some related services (through the work on Linked Open Services). The system will then learn how a new source relates to the known sources by exploiting the knowledge already available the the Linked Open Data. The result will be a rich semantic description of the individual sources that can be used in Semantic Web applications and information integration systems.<br/><br/>The ability to automatically discover and learn detailed semantic descriptions across a range of sources that go beyond the current source descriptions will greatly expand the utility of Semantic Web and information integration systems. This capability will allow people and systems to better exploit the massive amount of data available today on the Internet and provide a tool to keep up with its growth. Within the bioinformatics world, for example, the amount of data continues to grow rapidly, and the ability to find and structure this data will have a significant impact on ability of researchers to fully exploit all of this information to solve biomedical research questions, such as finding more effective treatments for cancer. More information about the project can be found at http://www.isi.edu/integration/people/knoblock/projects/prj_source_modeling.html"
"0713688","HCC: Easy-to-Learn and Easy-to-Use Eye-Controlled Musical Expression For Children with Severe Disabilities","IIS","Cyber-Human Systems","07/15/2007","01/06/2014","Anthony Hornof","OR","University of Oregon Eugene","Continuing grant","Ephraim P. Glinert","12/31/2014","$481,319.00","","hornof@cs.uoregon.edu","5219 UNIVERSITY OF OREGON","EUGENE","OR","974035219","5413465131","CSE","7367","7367, 9215, 9251, HPCC","$0.00","Despite the opportunity afforded by the relatively low-cost eye tracking technology now becoming available, practical eye-control of computers is still very limited. This is particularly unfortunate for children with severe motor impairments who retain control of their eye movements and have the potential to use an eye tracker, but who miss out on important childhood developmental activities because of a lack of suitable interactive software to support these activities. In a previous research project in which he developed EyeDraw, software that enables children with severe motor impairments to draw pictures with their eye movements, the PI showed that for this community eye tracking can provide a powerful and noninvasive means of creative expression. Though EyeDraw was in many ways a success, during its development the PI identified three major problems that hinder efforts by researchers and practitioners to create eye-controlled software for these children. Firstly, no rapid prototyping tools or software application frameworks are available specifically for developing eye-controlled applications. Furthermore, eye-controlled software is typically intended for expert use and does not provide enjoyable experiences at first glance. Last but not least, there is no established practice for working with children with severe disabilities as partners in software design. This project responds to these problems by pursuing a number of related activities, within the concrete context of computer applications that support playing music. The PI will determine which participatory design techniques can work with children with severe motor impairments, and will establish a design practice that allows him to collaborate directly with them and their caregivers, to develop software that enables the children to make music with eye movements. He will create a framework that supports rapid prototyping of eye-controlled applications for this user community by giving caregivers, practitioners, and researchers a means to quickly generate eye-interactive sketches so that the children can communicate, explore alternatives, provide feedback, and express themselves creatively. And he will design intervention techniques that address the difficulties associated with the initial use of eye-controlled software, to ensure an immediate sense of accomplishment, satisfaction, interaction, control, encouragement, and expression. This last goal will be accomplished through interfaces that support musical expression even with a low-fidelity zero-point calibration, and which incrementally improve the calibration during expressive musical activities while also gradually introducing advanced functionality and opportunities for creative musical expression. <br/><br/>Broader Impacts: This project will advance an understanding of how to build eye-controlled software for children with severe disabilities, a challenge that is not addressed by the current scientific or design literature. Project outcomes will provide young people with severe motor impairments with a means of engaging in artistic pursuits that are currently out of reach. The rapid prototyping framework for eye-controlled applications will provide an infrastructure for university classroom instruction and future researchers."
"1421057","III: Small: Large-Scale Structured Sparse Learning","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/22/2014","Jieping Ye","AZ","Arizona State University","Continuing grant","Christopher Clifton","07/31/2017","$333,360.00","Sudhir Kumar","jieping.ye@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7364, 7923","$0.00","Recent technological revolutions have lead to dramatically growing scale, diversity, and complexity of data. Modern data analysis is facing new challenges in handling this complexity. Although complex, the underlying representations of many real-world data are often sparse. This sparseness often exhibits intrinsic structure, e.g., spatial or temporal smoothness, graphs, trees, and groups. Finding effective sparse representations is fundamentally important for scientific discovery; the a-priori structure information may significantly improve the sparse learning model. This project is developing algorithms and tools (including open source software) to enable knowledge discovery from massive high-dimensional and complex data, as well as a new curriculum that incorporates the proposed research into the classroom.<br/><br/>Most sparse learning algorithms are based on the L1 norm due to its sparsity-inducing property and strong theoretical guarantees, but this does not capture structure. This project is advancing structured sparse learning by (1) analyzing the so-called proximal operators associated with various feature structures, which explains how and why they can induce the desired structured sparsity; (2) developing efficient algorithms for computing the proximal operators, which plays a key building block role in the proposed optimization algorithms; (3) developing a structured sparse learning framework, which includes various sparse learning models and algorithms developed in this project."
"1449202","EAGER: A Corpus of Aligned Speech and ANS Sensor Data","IIS","Cyber-Human Systems, ROBUST INTELLIGENCE","08/01/2014","07/22/2014","Elizabeth Shriberg","CA","SRI International","Standard Grant","Tatiana D. Korelsky","07/31/2015","$49,990.00","Massimiliano de Zambotti, Andreas Kathol","elizabeth.shriberg@sri.com","333 RAVENSWOOD AVE","MENLO PARK","CA","940253493","6508592651","CSE","7367, 7495","7367, 7495, 7916","$0.00","Despite a sizeable literature on emotional speech and speech under stress, little is understood about how features in continuous speech vary with subtle and real-world-relevant changes in physiological state within any particular speaker. This EArly Grant for Exploratory Research relates speech features to direct measures of physiological activation, rather than to categorical hand-annotated labels of emotion or state. The study collects and analyzes a corpus of speech and autonomic nervous system (ANS) sensor data to discover what changes occur in speech features when a person is exposed to different activation-relevant emotional, cognitive, stress-related conditions. The broader significance and impact is discovery of cues in speech that can be used to estimate changes in a speaker's physiological activation level when no sensors are available. Applications include health care (monitoring physical, mental, cognitive states), education and learning (monitoring engagement), social interaction (monitoring activation level), and law enforcement/intelligence (monitoring behavioral changes of high interest individuals).<br/><br/>In Phase 1 (Corpus Collection), the project creates a 40-subject corpus of time-aligned speech and physiological signals. Activation is measured using state-of-the-art methods to extract cardiovascular (ECG), blood pressure, respiration rate, and skin conductance signals. Each subject participates in five conditions: (1) neutral baseline; (2) emotional (description of emotionally salient pictures); (3) stressed (speaking task incentivized for accuracy and completion time); (4) cognitive load (speaking task with a visual distractor, incentivized for task completion and distractor task accuracy); and (5) computer-directed speech (task requiring perfect recognition from a speech recognizer). In Phase 2 (Analysis), sensor output is post-processed to calibrate the signals and look for changes. These changes are then compared to a range of automatically extracted features (based on acoustics, prosody, discourse patterns, and disfluency patterns) from the time-aligned speech. Analyses and machine learning experiments then examine which speech feature changes correlate with changes in sensor output, both within and across speakers. Results shed light on how information from natural continuous speech can be used to estimate changes in a speaker?s physiological activation level in ongoing, subtle and everyday contexts."
"1302285","III: Medium: Geometric and topological approaches to biomolecular structure and dynamics","IIS","Cellular Dynamics and Function, INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, INFO INTEGRATION & INFORMATICS","09/15/2013","09/09/2013","Guowei Wei","MI","Michigan State University","Standard Grant","Sylvia J. Spengler","08/31/2017","$1,016,489.00","Yang Wang, Yiying Tong","wei@math.msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","1114, 1640, 7275, 7364","7924, 8750","$0.00","Experimental exploration of self-organizing biomolecular systems, such as viruses, molecular motors and proteins in Alzheimer's disease, has been a dominating driving force in scientific discovery and innovation in the past few decades. Unfortunately, quantitative understanding of biomolecular structure, function, and dynamics severely lags behind the pace of the experimental progress. An average protein in human body has about 5500 atoms, which, together with its surrounding water molecules, involve about 100,000 degrees of freedom. The dimensionality increases dramatically for complex biological processes and biomolecular systems. The real time structure optimization, dynamic simulation, and data analysis of molecular motors and/or viruses in human cells are intractable with full-atom models at present. A crucial question is how to reduce the number of degrees of freedom, while retaining the fundamental physics in complex biological systems. The proposed research may be transformative. As the first differential geometry based multiscale/ multiresolution approach to biomolecular systems, it will open a new direction and foster similar approaches in multiscale modeling of other large data systems in future research. Additionally, new persistently stable manifold strategy can be applied to other fields, such as image processing, computer aided design, and fluid mechanics. Furthermore, the proposed new coupled equations will lead to new research topics in geometry, topology, PDE analysis and mathematical biology. Finally, our new theoretical framework is directly integrated into popular software packages to ensure extensive usage by the community of researchers throughout mathematics, computer science and biology. The proposed research has a solid educational component. The project will support the training of student and junior researchers in mathematical modeling, data analysis and algorithm development. The enhancement of curricula from the proposed research is planned as a continuation of PIs teaching-research practice. Special curriculum development, outreach program and annual workshops are designed to further broaden educational and societal impacts. <br/><br/><br/>The proposed research addresses grand challenges in the structure, function and dynamics of self-organizing biomolecular systems due to exceptionally massive data sets. These challenges are tackled through the introduction of a new differential geometry based multiscale model, together with a multiresolution coarse grained method based on persistently stable manifolds in molecular dynamics data. This proposal offers innovative new approaches to an important area in massive data management, dimensionality reduction, computational mathematics and mathematical modeling. This project uses a number of geometric and topological approaches to address the scaling issues.. First, the multidisciplinary team will use multiscale framework which reduces the dimensionality and number of degrees of freedom by a macroscopic continuum description of the aquatic environment, and a microscopic discrete description of biomolecules. To further reduce the dimensionality of excessively large biomolecular systems, they introduce a multiresolution coarse-grained approach based on persistently stable manifolds in molecular dynamics data. A total free energy functional is introduced to bring the macroscopic surface tension and microscopic potential interactions on an equal footing. The differential geometry theory of surfaces is utilized to describe the interface between macroscopic and microscopic domains. Potential driven geometric flows are constructed to minimize the total free energy functional. Euler characteristic and total curvature are employed to analyze the topology and corresponding function of biomolecules. Frenet frames are utilized to characterize the local geometry and associated stable manifolds in dynamical data of biomolecular systems. Machine learning algorithms are proposed to extract stable manifolds. In the last step, a strategy is introduced to explore the persistence of stable manifolds, which provides the assurance for the reliability of the coarse grained model. In addition to promising and extensive preliminary results illustrating the power of this approach, extensive validation and application have been proposed to ensure that this methodology yields robust and powerful tools for biomolecular structure optimization and dynamical simulation."
"1118050","III: Small: Statistical Knowledge Translation and Knowledge Integration Using Markov Logic","IIS","INFO INTEGRATION & INFORMATICS","07/01/2011","05/03/2013","Dejing Dou","OR","University of Oregon Eugene","Standard Grant","Sylvia J. Spengler","06/30/2015","$510,695.00","Daniel Lowd","dou@cs.uoregon.edu","5219 UNIVERSITY OF OREGON","EUGENE","OR","974035219","5413465131","CSE","7364","7364, 7923, 9251","$0.00","With the rapid proliferation of knowledge bases and their use in automated inference in a variety of applications, there is a growing need for effective approaches for (i) knowledge translation, i.e., the task of applying knowledge learned or developed in one domain to another semantically different domain, and (ii) knowledge integration, i.e., the task of building a unified knowledge base from disparate sources. While the problem of data translation and integration has received a great deal of attention in the literature, the problem of knowledge integration remains relatively under-explored. Existing work on this topic has focused on primarily logical frameworks which make it difficult to take into account uncertainty in knowledge and in semantic mappings used for knowledge translation and integration. <br/><br/>This project aims to use Markov Logic Networks to express both knowledge and semantic mappings to obtain a unified probabilistic model for jointly translating knowledge and refining semantic mappings. This provides a basis for addressing the challenges of integrating heterogeneous knowledge with uncertain mappings, assessing the correctness of translated knowledge, simplifying the resulting models to obtain more compact approximate translations, and evaluating the methods in realistic application scenarios. <br/><br/>The results of the proposed work are likely to be applicable in a number of application domains that require integration or translation of knowledge across disparate knowledge sources. The work strengthens and facilitates interdisciplinary collaborations, provides enhanced research-based training opportunities for graduate and undergraduate students. The knowledge translation and integration software, and the benchmark data will be made available to the broader community through the project web site: http://aimlab.cs.uoregon.edu/SKTI/"
"1422557","RI: Small: Finding Patterns in Complex Data with Probablistic Graphical Models","IIS","ROBUST INTELLIGENCE","08/01/2014","07/22/2014","Arindam Banerjee","MN","University of Minnesota-Twin Cities","Standard Grant","Todd Leen","07/31/2017","$449,991.00","","banerjee@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7923","$0.00","The ability to find patterns --- groups of variables working together --- and their dependencies in high dimensional problems are becoming crucially important in a wide variety of scientific, societal, and commercial applications. Important areas include cancer genomics, climate science, forest ecology, healthcare, and social media analytics. Typical patterns involve one or more groups of variables jointly exhibiting similar or dependent behavior in certain situations. In a predictive setting, activation of certain groups of variables often serves as a key signal for the prediction task. There is an urgent need for probabilistic models which go beyond identifying pairwise interactions, to understand higher order interactions between variables. Towards this end, the project will investigate novel methods based on structurally constrained dependency estimation and high-dimensional inference in probabilistic graphical models. This work will consider two important applications: climate and home care. Across the globe, climate change is impacting both the frequency and intensity of weather events, such as precipitation. The proposed methods will enable more accurate modeling of precipitation driven hydrological events. In the US, health care expenditures are expected to increase to 19.6% of the Gross Domestic Product (GDP) by 2019. The proposed work in home care is unique in scope and will be broadly applicable to any health care data, thus providing a foundation for future meaningful use of electronic health records, a national priority in the US. This project naturally spawns many educational opportunities, and will engage students through classroom teaching and associated modalities. The project will engage under-represented groups in the research, and disseminate the findings through workshops and tutorials.<br/><br/>From a technical perspective, there are two central challenges for probabilistic pattern analysis with higher-order interactions: the combinatorial challenge, as one has to potentially look at all possible subsets of variables and their interactions, and the statistical challenge, as one typically has a small number of samples available, which can be unsuitable for testing significance of dependencies or relations found. The project will build on recent advances in structured estimation in regression and pairwise graph structure learning to develop novel approaches to structure estimation and associated inference for graphical models with higher order dependencies. In particular, the work will focus on estimation with structural constraints or regularization which can estimate complex dependencies, including overlapping and block-correlated patterns. For inference and pattern completion, the focus will be on approximate inference based on novel randomized block updates for constrained optimization and associated ideas."
"1422066","CHS: Small: Collective Design through Remixing","IIS","Cyber-Human Systems","08/01/2014","07/22/2014","Jeffrey Nickerson","NJ","Stevens Institute of Technology","Standard Grant","William Bainbridge","07/31/2017","$499,150.00","John Nastasi","jnickerson@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7367","7367, 7923","$0.00","The project is set in the context of open innovation communities in which people design physical products that may be based in part on previously contributed designs, exploring how creativity could be enhanced in these communities by presenting the right related designs to an inventor at the right time in order to inspire a creative remixing. 3D printing online communities allow makers, designers characterized as expert amateurs, to share, modify, combine, and print each other's designs. These communities present an opportunity to understand and improve collective design, a form of cumulative innovation. Improvements to innovative processes will contribute to the growth of the economy, and design is an activity that is educationally appealing to many different age groups, demographics, and academic interests.<br/><br/>This research will analyze an existing open innovation community. From data gathered, tools will be built that suggest designs that when combined are more likely to result in an impactful invention. These tools will consider a wide range of possible innovations, suggesting areas of the design space that may lead to fruitful discoveries. Because collective design depends on the varied expertise of its participants, the project brings together makers with professional engineers, architects, and fabricators through an innovation contest. The makers bring energy, diversity, and experience with online collaborative design processes. The professionals bring detailed knowledge of practical problems, as well as an understanding of modeling and simulation technology in relation to materials used in additive manufacturing. The primary method is experimental, informed by the analysis of existing online communities, and testing the new creativity support tools that will be developed. The envisioned tools will analyze the products and social networks of remix communities in order to suggest candidate designs for modification or recombination. Long-held theories about innovation processes will be tested in a new context, potentially leading to new insights concerning collective innovation that will be instantiated in new tools and systems. Data will be gathered, a system will be built, experiments will be run, a contest will be hosted, and the accumulated learning, data, and software will be made available to other interested researchers."
"1422591","III: Small: Algorithmic Techniques for Determining Alterations in the Patterns of Chromosome Spatial Organization inside the Cell Nucleus","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/22/2014","Jinhui Xu","NY","SUNY at Buffalo","Continuing grant","Sylvia J. Spengler","07/31/2017","$332,507.00","Ronald Berezney","jinhui@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7364","7364, 7923","$0.00","Recent research in cell biology has led to the emerging view that the 3-D arrangement of chromosome territories (CT) and the spatial positioning of genes within these territories are linked to genomic function and regulation. Despite this progress, it is not clear what is the spatial organization patterns of CTs inside the cell nucleus and how such patterns dynamically change during the cell cycle and at different stages of cell differentiation and cancer progression. To facilitate more in-depth studies of these important biological problems, in this project, the Pi will develop a set of efficient algorithmic techniques for determining the patterns and their alterations of three chromosome organization problems. First, how are chromosomes spatially positioned inside the nucleus? Second, how are chromosomes neighboring or associating with each other? Third, what is the internal structure of each individual chromosome? The core of this project is to develop efficient algorithms for solving a set of challenging computational problems which are essential for the chromosome organization problems, thus addressing the emerging science at the interface of computing and biology. This project will bring research and educational opportunities to both graduate and undergraduate students. It will involve several Ph.D. students (including 2 female students), and one or two undergraduate students, from both the Computer Science and Engineering Department and Biological Sciences Department. As an integral part of this project, a new course in biomedical imaging will be developed that will enable the solving of biomedical problem with a knowledge of computer science.<br/><br/>This project will yield a set of efficient algorithmic techniques for the proposed problems, and will be used as automatic (or semi- automatic) tools to accurately determine the patterns of chromosome spatial organization inside the cell nucleus and how such patterns dynamically change during the normal cell cycle, during differentiation of keratinocytes into skin cells and following progression of normal breast cells to malignant cancer. This could provide new insight into how the global arrangement of chromosomes in the cell nucleus is related to the malignant state. The set of algorithms will be implemented and tested using randomly generated data and real biological data. They will be integrated into an Algorithmic Toolbox developed in our previous research on the spatial positioning of the cell nucleus, and will be made available to the research community. (3) Results from this projects are likely to be used in other areas, and have a positive impact on them. For example, the problems of k-prototype learning, chromatic median, chromatic k-median clustering, median point-sets, and projective clustering are all fundamental problems in computer science and have applications in many other areas, such as machine learning, computer vision, and data mining. Some of the solutions can be used as information integration tools."
"1445936","RAPID: Data collection and curation of SR-530 mudslide with small unmanned aerial vehicles","IIS","ROBUST INTELLIGENCE","08/01/2014","07/22/2014","Robin Murphy","TX","Texas Engineering Experiment Station","Standard Grant","Satyandra Gupta","07/31/2015","$42,000.00","Frank Shipman","murphy@cse.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495","7495, 7914","$0.00","This project conducts research on small unmanned aerial systems while protecting the safety of recovery workers who will be working at the 2014 SR530 mudslide near Oso, Washington, for at least the next year to remediate the site and repair the road. The flights also help increase the safety of residents along other portions of the Stillaguamish River. A small fixed-wing and a rotorcraft unmanned aerial system are used to conduct longitudinal surveys of the inaccessible region of the mudslide and river. The surveys in August and November, combined with earlier flights during the immediate response, capture the evolving state of the mudslide and river over time, validate the models of how the river and mudslide are expected to change over the seasons, refine new geological and hydrological models, and predict the potential for continuing sloughing and flooding that will impact residents and other sections of SR530 in the spring of 2015. The research is providing the robotics and cyber-physical systems communities with small unmanned aerial systems performance data under uncontrolled weather conditions, the human-robot interaction community with how users from different agencies interact with the robot data, and Big Data with datasets to explore how to best archive, curate, and visualize data over time. The research is guiding the design of new small unmanned aerial systems to support applications where rapid or cost-effective geospatial reconstruction of the situation is important, such as emergency response and critical infrastructure inspection."
"1319973","III: Small: Collaborative Research: Conflicts to Harmony: Integrating Massive Data by Trustworthiness Estimation and Truth Discovery","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","07/22/2014","Jing Gao","NY","SUNY at Buffalo","Continuing grant","Frank Olken","07/31/2016","$288,814.00","","jing@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7364","7923","$0.00","Big data leads to big challenges, not only in the volume of data but also in its dynamics and variety. Multiple descriptions about the same set of objects or events from different sources unavoidably lead to data or information inconsistency. Then, among conflicting pieces of data or information, it is crucial to tell which data source is reliable or which piece of information is correct. Accurate information is referred to as the truth and the chance of a source providing accurate information is denoted as source reliability or trustworthiness. The objective of this project is to detect truths without supervision, by integrating source reliability estimation and truth finding. A unified framework is developed to model complex trustworthiness factors, heterogeneous data types, incremental and parallel computation, and source and data dependencies so that truth and trustworthiness can be inferred from multiple conflicting sources of heterogeneous, disparate, correlated, gigantic, scattered, and streaming data.<br/><br/>This project makes tangible contributions to data integration, information understanding and decision making, and benefits many applications where critical decisions have to be made based on the correct information extracted from diverse sources. Research results of this project are integrated into course materials and projects, and into training students and new generation researchers, especially female and minority students. For further information about this project, please refer to the project website: http://www.cse.buffalo.edu/~jing/truth.htm"
"1017593","HCC: Small: A Computational Theory of Perceptual Integration in Multimodal Multitasking","IIS","Cyber-Human Systems","07/01/2010","08/17/2012","Anthony Hornof","OR","University of Oregon Eugene","Standard Grant","Ephraim P. Glinert","06/30/2015","$499,591.00","","hornof@cs.uoregon.edu","5219 UNIVERSITY OF OREGON","EUGENE","OR","974035219","5413465131","CSE","7367","7923, 7367, 9150","$0.00","Much contemporary computing is done in multitasking environments in which multiple visual and auditory displays compete for a person?s perceptual, cognitive (decision), and motor (movement) processing. In some task domains, such as air-traffic control, emergency vehicle dispatching, and in-car navigation, multitasking cannot be avoided, and people need to interleave secondary tasks such as navigation with primary life-critical tasks such as driving. To maximize overall human effectiveness, user interfaces intended for life-critical and time-critical complex multitasking need to be designed to account for a person?s ability to monitor and respond to multiple information sources in parallel. And yet, there is little or no practical scientific theory to explain the human abilities, limitations, and strategies for multimodal (auditory and visual) multitasking.<br/><br/>This project develops the science base needed for predictive modeling of human abilities to integrate across multiple modalities to accomplish multiple tasks in parallel. The project will develop a theory of Perceptual Integration in Multimodal Multitasking with rigorous, detailed, high-fidelity computational cognitive modeling of carefully collected human data, including detailed eye movement data, for tasks that are positioned between the lab for high resolution tasks and data and the real world to insure practical application. The modeling will emphasize the role of central executive cognitive decisions for managing perceptual processing, moving the eyes, and coordinating motor responses to interleaved task demands.<br/><br/>The project benefits society by studying and revealing the limitations to human multimodal multitasking performance at the core, and by providing theory that can be put to practice in the design of mission control centers, subway dispatching centers, emergency rooms, and computer systems for vehicles. The theory will lead to practical design decisions that will improve the safety of subways, nuclear power plants, highways, hospitals, and vehicles."
"0964541","NetSE: Medium: Collaborative Research: Privacy Preserving Social Systems","IIS","INFO INTEGRATION & INFORMATICS, NETWORK SCIENCE & ENGINEERING","09/15/2010","06/10/2013","Samrat Bhattacharjee","MD","University of Maryland College Park","Standard Grant","Sylvia J. Spengler","08/31/2015","$896,000.00","Jonathan Katz, Neil Spring","bobby@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364, 7794","7794, 7924, 9251","$0.00","The success of the future Internet will not be measured by performance alone, but by its social and societal effects that alter our quality of life. The next-generation Internet must connect not only machines but also users: families and friends, representatives and rights advocates. There are immense technical challenges in facilitating communication while protecting user privacy and guarding their security. We address three key challenges. First, we apply user-focused research into developing practical secure communication between friends, laying the groundwork for social messaging without trusting centralized authorities to provide identities. Second, we develop advanced cryptographic techniques for processing private data without divulging it to application providers, placing private social applications on a solid theoretical foundation. Finally, we propose to fundamentally change how cooperation is encouraged and misbehavior is punished in distributed applications by embedding social network data into the design of applications.<br/><br/>This work has important broader impacts. Social networking is incredibly popular and maintaining privacy is a significant problem within these systems. The desire for privacy prevents individuals from participating fully and makes those who do participate vulnerable to various problems including potential identity theft. Because of the importance of the problem and problem domain, the results of our research will have significant public impact. Graduate and undergraduate students working on this proposal will gain experience with social applications, evaluating cryptographic protocols, and building systems that combine social data. We have actively involved undergraduate students in our research, and expect to continue."
"1420667","RI: Small: Improving Crowd-Sourced Annotation by Autonomous Intelligent Agents","IIS","ROBUST INTELLIGENCE","08/01/2014","07/22/2014","Daniel Weld","WA","University of Washington","Standard Grant","Todd Leen","07/31/2017","$460,000.00","","weld@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7923","$0.00","Supervised machine learning methods are arguably the greatest success story for Artificial Intellitence with a deep underlying theory and applications ranging from medical diagnosis and scientific data analysis to ecommerce recommender systems and credit-card fraud detection. Unfortunately, all these methods require labeled training data, which has been annotated by a human --- a time consuming and extremely expensive process. This project will use automated decision theory to control the annotation process, saving significant amounts of human labor and extending the practical use of machine learning to a much broader array of societal problems. <br/><br/>Specifically, the methods address the case where labeled data is crowd-sourced by a large number of human annotators whose skill and error rates are variable. The project develops new control algorithms that let the learner efficiently ask specific workers to label (or redundantly re-label) specific examples. To test the practicality of their methods, the PIs build and conduct studies with the Information Omnivore, a fully autonomous agent that optimizes the annotation of natural language processing (NLP) training data. By continuously posing questions to paid workers and volunteer citizen-scientists, the Omnivore 1) will learn which problems are hard and which are easy, 2) will learn about the skills of the various workers, 3) and will decide questions to ask which workers in order to maximize the accuracy of the learned model given scare human help. Besides contributing to the science of automated control, the Omnivore will generate labeled training data for two important NLP problems: named entity linking (NEL) and information extraction (IE), greatly helping the community of NLP researchers. Furthermore, the researchers plan a number of outreach efforts, including curriculum development, participation in the K12 Paws on Science program at the Pacific Science Center and interaction with the diverse students comprising the Washington STate Academic RedShirt (STARS) in Engineering program. The specific algorithms proposed by the PIs are notable in several respects. Their decision-theoretic optimization framework operationalizes intuitions like (1) one should assign more or better workers to hard problems and (2) one should redirect effort away from easy questions or from tasks that are too hard to solve. Automating this reasoning is hard because problem difficulty and worker skill are latent variables and thus the agent must confront an exploration / exploitation tradeoff as it balances actions that enable it to learn about the capabilities of workers with the ultimate goal of producing quality annotations. The PIs consider two cases: Task Allocation for Annotation Accuracy tries to maximize the overall annotation accuracy of a fixed size data set through batch assignment of workers to tasks. Re-Active Learning seeks instead to directly construct an accurate ML classifier through a balanced mix of annotator requests to re-label old or label new examples. In both cases they propose a model based on decision-theoretic methods (e.g., partially-observable Markov decision processes (POMDPs) and multi-armed bandits). The PIs propose to integrate their methods in the Information Omnivore, a long-lived software agent that integrates planning and execution, acts in the real world, and learns a model of its environment. The Omnivore will allow large-scale latitudinal studies of their algorithms, and as a byproduct will generate NLP training data that will greatly assist a large community of other researchers."
"1353346","EAGER: Immunization in Influence and Virus Propagation on Large Networks","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/05/2013","B. Aditya Prakash","VA","Virginia Polytechnic Institute and State University","Standard Grant","Frank Olken","08/31/2015","$88,821.00","","badityap@cs.vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7364","7364, 7916","$0.00","Given a graph, like a social/computer network or the blogosphere, in which an infection (or meme or virus) has been spreading for some time, how does one select the k best nodes for immunization/quarantining immediately? This team was the first to show that the propagation (specifically, the so-called ""epidemic threshold"") depends on a single number, the first eigenvalue of the adjacency matrix of the network, for any graph and almost any propagation model in the literature. This team also gave linear-time provably near-optimal algorithms for static pre-emptive node/edge removal, by minimizing the eigenvalue on arbitrary graphs. They were also the first to give a a linear-time algorithm to automatically detect the number and identity of possible culprits under perfect information, carefully using the Minimum Description Length principle, again on arbitrary graphs. <br/><br/>The major thrust of this proposal is: Given a graph, a virus model (SIR, SIS etc.), a set of already infected nodes, and a fixed<br/>budget of k nodes/edges to immunize or quarantine, can one quickly find an optimal or near-optimal solution to best contain the virus?<br/><br/>Technical Merit: This is the first to study the short-term immunization problem on arbitrary graphs. The problem has received limited attention in past literature: the few current results (except the PI's past work, see related work) all are on specific graphs like random graphs, and not arbitrary graphs. The focus of this work is on scalable techniques (linear or sub-quadratic on nodes/edges) which can be applied to large graphs.<br/><br/>Impact: The work has numerous immediate applications in public health and epidemiology, e.g., designing dynamic ""what to do next"" policies etc. Leveraging state-of-the-art simulators from the Virginia Bio-Informatics Institute, this work helps in realistic simulations, as well as in making more informed choices and policy decisions for future. The work also has high broader impact, as propagation-style processes on networks appear in many other settings like viral marketing, cyber security, social media like Twitter and blogs etc.<br/><br/>Education: The PI will incorporate research findings in graduate level classes, give tutorials at conferences, and aim to engage undergraduate students from underrepresented groups into this exciting area of research through programs like NSF REU and MAOP/VTURCS (Minority Academic Opportunities Program and VT Undergraduate Research in CS) at VT.<br/><br/>For further information, please see the project web page: <br/>URL: http://www.cs.vt.edu/~badityap/NSF-PROJECTS/EAGER-13/"
"1013054","HCC: Large: Collaborative Research: Delivery of Personalized Reading Strategies for People with Cognitive Impairments in Post-Secondary Settings","IIS","Cyber-Human Systems","08/15/2010","05/09/2014","Stephen Fickas","OR","University of Oregon Eugene","Continuing grant","Ephraim P. Glinert","07/31/2015","$2,723,879.00","McKay Sohlberg","fickas@cs.uoregon.edu","5219 UNIVERSITY OF OREGON","EUGENE","OR","974035219","5413465131","CSE","7367","7367, 7925, 9251","$0.00","Reading comprehension deficits are pervasive for a disproportionate number of post-secondary students. These students have cognitive impairments that impact high level text processing skills and result in diverse reading profiles with difficulties in skills such as discerning between relevant and irrelevant information, drawing inferences, connecting background knowledge to new learning, and retaining and applying what was learned at a later date. Typically such deficits are managed by teaching the use of study-skills strategies. While there is strong face validity for these practices there is a lack of evidence-based practice, and virtually no information on candidacy or what types of deficits respond best to what types of strategies and supports. On the technology side, the popularity of electronic reading tablets offers a platform to deliver supports to improve reading comprehension and retention that could be adopted by college students. This project seeks to bridge the gap by developing the technology to support a diverse set of reading strategies in a highly adoptable form for college students with high-level reading impairments, by doing the science necessary to define a process that can assess each individual student, and by prescribing a set of strategies that eventually will be delivered in a hardware-software package. By using an iterative design process and a participatory action research model, this research will make the following contributions: a dynamic assessment process that matches reading profiles/impairments to strategy supports; a mapping of reading impairments to reading strategies; translation of reading strategies to delivery on electronic reading tablets; a demonstration that personalization and adaptation are possible using our software engineering models; and a dissemination package that uses open source software and hardware to deliver a research tool that could be used by companies designing commercialized reading tablets. To achieve these goals, the PI will partner with three institutions that have large populations of struggling readers in post-secondary educational settings: two VA facilities that support and train veterans returning to educational settings, and a student disability services program at a large urban state university. These groups have experience with the pervasive, high level reading challenges preventing educational success, and provide the natural contexts to evaluate the PI's models and shape the tools generated from this research. Pilot studies, laboratory experiments and longitudinal studies will be employed to develop and evaluate the technology for a dynamic reading assessment and support tool.<br/><br/>Broader Impacts: A growing population not able to meet the reading demands of college and community college courses is the large number of veterans returning form Iraq and Afghanistan seeking education and training benefits. It is estimated that 15-20% of these veterans have suffered mild brain injury sufficient to affect academic ability. Another large group of post-secondary students that is challenged by difficulties with reading comprehension are those with developmental conditions including adult attention deficit and hyperactivity disorder (ADHD) and attention deficit disorder (ADD). Estimates regarding the number of students enrolled in colleges who report clinically significant ADHD or ADD symptoms vary between 2% to 8%; approximately 25% of students receiving disability support services are receiving those for ADHD. The PI expects two important outcomes from this work: the science missing from the literature that links reading impairments with reading strategies; and a demonstration tool, built on the science, that supports an assessment process and a delivery mechanism. With this latter outcome in mind, the PI intends to devote a large part of Year 5 of the project to making his tool highly attractive to companies who have the infrastructure to deliver products to the target populations."
"1117766","III: Small: On the Conceptual Evaluation and Optimization of Queries in Spatiotemporal Data Systems","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","08/08/2011","Walid Aref","IN","Purdue University","Standard Grant","Frank Olken","08/31/2015","$496,889.00","Mourad Ouzzani","aref@cs.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7923","$0.00","The goal of this project is to research and develop techniques for the correct conceptual evaluation, processing, and optimization of multi-predicate spatial (MPS) queries in support of location-based services. The project achieves its goal using the following approaches: (1) Study the characteristics of MPS queries and develop a new consistent and provably correct conceptual evaluation strategy for MPS queries similar to the one for relational SQL queries; (2) Develop various query transformation rules that not only retain correctness but also transform MPS query execution plans into more efficient ones; (3) Investigate the validity of well-known relational optimization heuristics in the context of MPS queries and develop innovative optimization algorithms unique to MPS queries; (4) Develop a cost model to aid the query optimizer in selecting the best query execution plans for MPS queries and study the impact of the variation on temporal and spatial moving object distributions on MPS query execution plans; (5) Develop new adaptive spatiotemporal query processing techniques that can cope with the dynamic nature and scale of moving object environments; (6) Prototype an MPS location server that reflects the correct evaluation and efficient optimized execution of continuous and adaptive MPS operators; and (7) Develop simulators and analytical models to evaluate the performance of the developed techniques. The research results are beneficial to many applications including location servers, intelligent transportation systems, smart cities, supply chain management, and emergency response and recovery.<br/><br/>This project supports Ph.D. students to pursue research in the areas of spatiotemporal data management systems and advanced location servers, and involves undergraduate students in related research projects. The project develops and introduces a new entry-level undergraduate programming course around 2D and 3D map operations and queries that utilizes MPS queries and integrates the research results from the project to increase the interest in programming of students from Computer Science as well as from other Science disciplines. The project involves minority students through the Discovery Learning Center at Purdue Discovery Park and the Louis Stokes Alliance for Minority Participation (LSAMP) project and Alliances for Graduate Education Program (AGEP). Publications, technical reports, software and experimental data from this research are available at the project web site (http://www.cs.purdue.edu/~aref/MPS)."
"1422341","CHS: Small: C3DaR - Collection, Creation, and Collaboration for Engineering Design and Reflection","IIS","Cyber-Human Systems","09/01/2014","07/21/2014","Niklas Elmqvist","MD","University of Maryland College Park","Standard Grant","Kevin Crowston","08/31/2017","$500,000.00","Karthik Ramani","elm@purdue.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","7367, 7923","$0.00","Innovation is now recognized as critical to economic growth and international competitiveness. While prototyping, manufacturing and even engineering work are routinely outsourced to foreign markets, design remains a key output of the nation. It is therefore imperative to improve the innovative capacity of designers, particularly those in engineering, through new design concepts, methods and tools to support transformative and creative design thinking. The goal of this project is to develop and test a digital platform for early design called C3DaR (Collection, Creation and Collaboration for Engineering Design and Reflection). C3DaR will transform the creative process of early design for engineering by applying a computer-as-partner paradigm in which the system becomes as an active contributor to the partnership between designers, artifacts and media. The research, education and dissemination efforts conducted as part of this project will greatly facilitate a paradigm shift in design to improve our nation?s creative design capacity.<br/><br/>Early design for engineering is characterized by informal, unstructured and heavily collaborative work processes involving multiple participants, disparate forms of representational media and a plethora of interactions between designers and artifacts. To explore and evaluate novel ways to support design, the project includes three research streams, corresponding to the 3 Cs in C3DaR. <br/>(i) Collection incorporates mechanisms to help designers gather materials in the early stages of the creative process. Examples of proposed mechanisms include web browser integration for collecting inspirational material, design scrapbooking for composing content into multimedia montages and diagramming for organizing and recording textual and hierarchical ideas. <br/>(ii) Creation encompasses techniques to help designers to make and modify design artifacts. Examples of such techniques include textual and visual prompting to guide the designer's sketching process, integration with a naive physics engine to enable an intuitive sketch-to-life design approach and auto-completion of 2D sketches to enable rapid content creation. <br/>(iii) Collaboration includes mechanisms to enable multiple designers to coordinate their combined efforts while avoiding interference and maximizing their productivity. Examples include allowing social-media-like discussion, tagging and voting for design artifacts, motion gestures and annotation to facilitate expressing dynamic behavior and integrated visual conflict resolution techniques to coordinate the team. <br/>The contribution of this project is to develop and test a radically new early design process for engineering that is scaffolded by, as well as closely intertwined with, digital media."
"1319922","HCC: Small: The Development and Evaluation of a Full-Page Refreshable Braille Display","IIS","Cyber-Human Systems","10/01/2013","07/21/2014","Sile O'Modhrain","MI","University of Michigan Ann Arbor","Continuing grant","Anthony Hornof","09/30/2016","$499,286.00","Richard Gillespie, Mark Burns","sileo@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7367, 7923","$0.00","This project will develop a large-area dense-array tactile display device suitable for displaying a full-page of braille characters and tactile diagrams. This device will co-locate tactile input and output and will make interaction with text and graphic content on mobile devices as direct and meaningful for visually impaired users as touchscreen interaction is for sighted users. Current braille display technology can only render a single line of content at a time. This project will address this problem by developing new display technology based on microfluidic actuators and microfluidic logic circuits. This technology holds tremendous promise for creating refreshable tactile features on a flat screen, and for new multipurpose displays because the microfluidic substrate can be designed as a transparent overlay to a visual display. There are just a few technological barriers remaining until microfluidics is practical for creating programmable haptic features. One of these barriers is the ""piping problem"", packing a dense array of bubble actuators without an independent channel dedicated to each actuator. A second problem involves matching the microfluidic actuators to the properties and sensitivity of the fingertip skin through an appropriately engineered surface. The research team has piloted solutions to both of these problems and will construct analytical models that will enable these solutions to be scaled, both up and down, for rendering a variety of features from individually perceivable braille dots to perceptually continuous lines, curves and tactile forms. The design of the display technology will be guided and informed by a series of user evaluations that will advance the science of surface haptics while at the same time comparing this microfluidic approach to alternative assistive technologies currently under development in academia and industry. The collaborative team is uniquely qualified to develop microfluidics technology specifically for a braille display. Mark Burns will further develop microfluidic logic circuits and shift registers to individually address braille pin actuators. Brent Gillespie will optimize the mechanics of the actuators and braille dots and adapt them to the mechanics of the skin and actively guided touch. Sile O'Modhrain will develop the science of surface haptics to guide the match between microfluidic technology and application in human-computer interaction through braille. <br/><br/>Broader Impacts: The project will develop a full-page electronic braille device that will increase braille literacy among blind persons worldwide. At the same time, the project will solve the most pressing problems blocking the application of microfluidics in shape display and surface haptics on touchscreens. The availability of a large-area tactile display would open up the possibility for a wide range of scientific exploration and would also have a huge commercial impact because it would have a profound impact on what is fundamentally possible with touchscreen devices. The project will recruit and engage blind persons, under-represented minorities, women, and undergraduate researchers."
"1343948","Signing Creatures Workshop","IIS","LINGUISTICS, Cyber-Human Systems, ROBUST INTELLIGENCE, Science of Learning Activities","09/01/2013","09/10/2013","Laura-Ann Petitto","DC","Gallaudet University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$38,827.00","David Traum","LauraAnn.Petitto@gmail.com","800 Florida Avenue, NE","Washington","DC","200023660","2026515401","CSE","1311, 7367, 7495, 7704","7484, 7556","$0.00","An innovative union of Cognitive Neuroscience, Robotics, and Avatar scientists are coming together for a NSF ""Signing Creatures Workshop"" on November 14-15, 2013 at Gallaudet University (Washington, D.C.). The goal of the Workshop is to explore the feasibility of creating Robot and Avatar creatures that can sign and engage in interactive communication with young deaf and hearing children during critical periods of human development. Language acquisition research has established that children must receive early language exposure to achieve language and reading success. Despite research demonstrating the healthy brain benefits afforded to deaf children with early sign language exposure, this is not available to deaf children born to non-signing parents. Signing Robots and Avatar virtual humans can provide sign language to deaf children in communicative toys and games, similar to learning products for hearing children. The Workshop stems from a NSF grant to Cognitive Neuroscientist, Laura-Ann Petitto, PI, (and Science Director and Co-PI of the NSF Science of Learning Center, VL2, at Gallaudet) and Avatar scientist, David Traum, Co-PI, University of Southern California. Joining them is Robotics scientist Paul Oh of Drexel University. Broader Impact: The Workshop brings together deaf and hearing scientists from a broad range of disciplines to address critically important problems for education, learning, and reading in deaf children. The Workshop gives rise to new cross-disciplinary scientific knowledge and exciting explorations into the development of groundbreaking translational learning and reading products for deaf and hearing children. Additional broad applications include language translation, and high school and adult education."
"1041725","Collaborative Research: Science of Learning Center: Visual Language and Visual Learning (VL2)","SMA","DEVELOP& LEARNING SCIENCES/CRI, SCIENCE OF LEARN CTRS- CENTERS, ROBUST INTELLIGENCE, Science of Learning Activities","10/01/2011","09/14/2013","Thomas Allen","DC","Gallaudet University","Cooperative Agreement","Soo-Siang Lim","09/30/2015","$7,697,348.00","Laura-Ann Petitto","thomas.allen@gallaudet.edu","800 Florida Avenue, NE","Washington","DC","200023660","2026515401","SBE","1698, 7278, 7495, 7704","7704, 7278","$0.00","NSF and Gallaudet University?s Science of Learning Center for Visual Language and Visual Learning (VL2) entails multidisciplinary projects sharing in scientific purpose the discovery of how aspects of higher cognition are realized through one of human?s most central senses, vision. Through the enhancing lens of natural signed languages, projects investigate how deafness and visual languages provide a window into the flexibility and structure of the human mind. Projects identify the effects of visual processes, visual language, and social experience on visual learners? development of cognition, language, and reading and literacy. Visual learning is unraveled in monolinguals and bilinguals spanning development, to promote optimal practices across educational settings. Center projects are divided into seven Strategic Focus Areas. Four involve state-of-the-art scientific research, neuroimaging, and/or computational modeling, each rendering emerging findings to educational intervention design, including, Visual & Cognitive Plasticity, Language Development & Bilingualism, Reading & Literacy, and Translational Research to Educational Practice. Three involve, Translational outreach, Center Management, and Diversity. Uniqueness: Deaf and hearing scientists and educators; two-way dialog among researchers and teachers/public; Student Leadership Teams; infrastructure promoting national and international resource sharing across vast partnership institutions; capacity to serve as the nation?s ?first-response? regarding educational priorities. Broader Significance: Center products ensure advances in education for students at risk for low achievement. Comparative analyses of auditory and visual bases for language, reading, and print-literacy lead to new paradigms for understanding learning essential for enhancing educational, social, and vocational outcomes for all humans, deaf and hearing, consequently transforming the Science of Learning."
"1219015","III: Small: Parametric Statistical Models to Support Statistical Hypothesis Testing over Graphs","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/20/2014","Vishwanathan Swaminathan","IN","Purdue University","Continuing grant","Sylvia J. Spengler","08/31/2015","$491,841.00","Jennifer Neville","vishy@stat.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7364, 7923","$0.00","Graphs provide a natural representation of real-world networks e.g. world-wide web, biological networks, social networks. There is a growing body of work on both models of network structure and algorithms to automatically discover patterns (e.g., communities) in the structure. However, statistical methods for assessing the significance of discovered patterns or distinguishing between alternative models have received less attention. <br/><br/>Robust statistical models, which can accurately represent distributions over collections of graphs, are critical for principled quantitative investigation of networks and their properties. Specifically, since sampling distributions (either analytical or empirical) can be used to determine the likelihood of a given sample, statistical models facilitate hypothesis testing and anomaly detection (e.g., graphs with low likelihood can be flagged as anomalous). However, unlike metric spaces the space of graphs exhibits a combinatorial structure which poses significant theoretical and practical challenges which need to be overcome for accurate estimation and efficient inference. <br/><br/>This project investigates the interplay between choice of model representation, parameter estimation, and sampling/inference to develop statistical models that can accurately estimate (parametric) probability distributions over the space of graphs (i.e., graph populations). Speicifically, the project focuses on a novel probabilistic graph model that generates graphs by quilting together a set of subgraphs sampled from simpler basis graph models and the application of the resulting model to (i) explore and define graph classes, (ii) detect anomalies and assess their significance, and (iii) investigate graph dynamics and formally characterize notions of temporal stationarity and dynamic evolution.<br/><br/>The proposed work will advance the state of the art in probabilistic models, and rigorous statistical methods for analyis, of graph structured data. The proposed work also contributes to research-based training of graduate and undergraduate students at Purdue University. All of the software, publications, and data resulting from the project will be freely disseminated to the larger research and educational community."
"1016648","III: Small: Algorithmic Approaches for Pathway and Gene Group Analysis in Genetic Studies","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","05/06/2013","Benjamin Raphael","RI","Brown University","Standard Grant","Sylvia J. Spengler","07/31/2015","$527,627.00","Eli Upfal","Benjamin_Raphael@brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7364","9251, 7923, 9150","$0.00","Recent cancer genome sequencing projects and human genome-wide association studies (GWAS) have underscored the principle that complex phenotypes like cancer or disease susceptibility do not result from single DNA sequence variants in the same gene in all individuals. Rather, the inherited or somatic variants responsible for these phenotypes affect multiple genes in cellular signaling, regulatory, and metabolic pathways. New genome sequencing technologies are now providing measurements of these sequence variants in large numbers of samples, while other technologies are measuring whole-genome networks of interactions between genes. There is an urgent need for computational techniques to identify pathways, or groups of genes, that are associated to a phenotype.<br/><br/>This project will develop robust algorithmic and statistical techniques for four challenges in the analysis of DNA sequence variants in the context of known and novel gene-gene interactions. (1) Incorporating prior knowledge of gene interactions. This project develops a diffusion model to determine subnetworks of a genome-scale interaction network that are enriched for genetic variants across multiple samples. (2) Deriving robust statistical tests to overcome multiple hypothesis-testing problems in network analysis. Biological interaction networks containing tens to hundreds of thousands of nodes and edges have an enormous number of subnetworks that might be enriched for variants. This proposed work will design techniques to evaluate multiple candidate subnetworks with rigorous bounds on the false discovery rate. (3) Performing de novo identification of gene groups without an interaction network. The proposed work will examine combinatorial approaches to extract subsets of altered genes without prior knowledge of their interactions. These approaches will leverage the increasingly large number of sequenced samples that are becoming available. (4) Implementation of algorithms for evaluation on biological data from two applications: (a) somatic mutations identified in cancer genome sequencing studies, and (b) rare genetic variants in human association studies. These applications will be conducted in collaboration with two biomedical research groups. <br/><br/>Algorithms developed in this proposal will be implemented and released as open-source software for use by the biological and medical community. The project will partially support the training of graduate students, and undergraduates will be involved in implementing proposed algorithms. Finally, research from this project will use incorporated as pedagogical examples in multiple undergraduate and graduate courses."
"1208413","NRI-Small: Mixed Human-Robot Teams for Search and Rescue","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","08/01/2012","07/31/2013","Maria Gini","MN","University of Minnesota-Twin Cities","Standard Grant","James Donlon","12/31/2014","$138,001.00","","gini@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495, 8013","7923, 8086, 9251","$0.00","The project aims at increasing the ability to respond to large-scale disasters and manage emergencies by including robots and agents as teammates of humans in search and rescue teams. The project focuses on large teams of humans and robots that have only incomplete knowledge of the disaster situation while they accomplish the mission to rescue people and prevent fires.<br/><br/>The methodology to achieve cooperation within the teams will be based on the development of mental models shared by team members. The shared mental models will facilitate the interactions among robots and humans by providing a suitable level of abstraction enabling them to share beliefs, desires, and intentions as they work to accomplish their tasks.<br/><br/>The performance of teamwork models will be measured by comparing various task performance metrics (such as time to save people), system level metrics (such as computation time or message traffic), and amount of sharedness of the mental models. The experimental work will be conducted using the open source RoboCup Search and Rescue Simulator.<br/><br/>Broader impacts include integration of research results in undergraduate courses, availability of the software produced as open source, outreach activities to expose K-12 students to research issues and to excite them about using computing methods for real-world problems. The long term objective is to improve preparadeness for emergency situations, which will help saving lives and minimizing loss of properties."
"1110916","HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","IIS","Cyber-Human Systems","09/01/2011","03/27/2012","Anita Sarma","NE","University of Nebraska-Lincoln","Standard Grant","Kevin Crowston","08/31/2015","$267,936.00","","asarma2@unl.edu","2200 Vine St, 151 Whittier","LINCOLN","NE","685830861","4024723171","CSE","7367","7925, 7367, 9251, 9150","$0.00","In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br/><br/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br/><br/>Broader Impacts: As society enters the era of ""ultra large scale"" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities."
"1318143","HCC: Small: Prompting Intentional Social Media Use Among Children and Parents","IIS","Cyber-Human Systems","08/15/2013","06/27/2014","Sarita Schoenebeck","MI","University of Michigan Ann Arbor","Continuing grant","William Bainbridge","07/31/2016","$469,519.00","","yardi@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7367, 7923","$0.00","This research will develop new ways to (1) prompt intentional behavior and reflection among children when they become new social media users; (2) support parents in taking a proactive, rather than reactive, role in guiding their children's social media use; and (3) develop theoretical insights about prompting self-awareness among users with and through social systems. Parents are concerned about the content, context, and frequency of their children?s social media use and struggle to cope with these facets. Unfortunately, many parenting approaches to date are reactive and are focused on tracking, logging, or cutting off access to social media. Furthermore, the lack of empirical research in this area has left parents ill-equipped to try alternate strategies. Trying to cut off access to social media could lead to psychological reactance, where children engage in risky behaviors secretly instead of communicating openly with their parents. If we expect parents to raise their children effectively in a complex and rapidly changing digital world, we must develop new tools, approaches, and theories to help them do so. To address this gap, this research casts a new perspective on social media design that focuses on the study and development of social systems that prompt proactive and reflective behavior based on context-dependent cues. <br/><br/>The research will use a mixed-methods approach with four phases: (1) conduct parent-child interviews to understand why parents worry about social media and how their worries relate to children?s behaviors; (2) conduct a mobile phone experiment to prompt intentionality and reflection with mobile phone use among children and parents; (3) conduct a web-based experiment to prompt intentionality and reflection with laptop use among children and parents; and (4) synthesize results and develop new theories about ways of prompting reflection and self-awareness in social media systems. Mobile phones and laptops were chosen because they are widely adopted among youth and they are personal and portable, which introduces new parenting challenges. Effectiveness will be evaluated by comparing experimental and control group outcomes using a variety of measures including mobile phone logs, browser logs, self-reports, and validated behavioral scales.<br/><br/>Understanding how to prompt regular, real-time reflection with and through social media can guide the design of new kinds of social systems that prompt increased self-awareness and competency. The project will disseminate mobile phone and web-based tools to local parents, schools, and community organizations and will make them publicly available online. It will also disseminate research outcomes for a non-technical audience in the form of presentations, media outputs, and short reports. This research can have a vital and potentially transformative impact on early social media use among children and their parents, addressing a challenge that almost every parent in the U.S. now faces."
"1344288","INSPIRE Track 1: What is Normal Milk? Sociocultural, Evolutionary, Environmental, and Microbial Aspects of Human Milk Composition","IOS","INSPIRE, INFO INTEGRATION & INFORMATICS, IIS SPECIAL PROJECTS, CROSS-EF ACTIVITIES, SYMBIOSIS DEF & SELF RECOG","10/01/2013","07/18/2014","Michelle McGuire","WA","Washington State University","Continuing grant","Liliana Jaso-Friedmann","09/30/2017","$950,000.00","Sophie Moore, James Foster, Courtney Meehan, Lars Bode","smcguire@wsu.edu","NEILL HALL, ROOM 423","PULLMAN","WA","991643140","5093359661","BIO","8078, 7364, 7484, 7275, 7656","1228, 8653, 9178, 9179, 5926, 5976, 5977, 5991, 7391","$0.00","This INSPIRE award is partially funded by the following programs (a) the Symbiosis, Defense & Self-Recognition Program (Division of Integrative Organismal Systems, Biology Directorate) (b) the Emerging Frontiers Office ( Biology Directorate) (c) the Information Integration and Informatics and Special Projects programs of the Division of Information and Intelligent Systems (Directorate for Computer & Information Science & Engineering) (d) The Africa/Middle East/South Asia cluster (Kenya, Ghana) and Americas (Latin America, SDC) Cluster of the Office of International Science and Engineering. <br/>It is well-known that breastfeeding protects infants from illness, especially in the poorest regions of the world. The full nature of this protective effect, however, is less well understood. A major barrier to understanding is the fact that almost nothing is known about the factors that influence the considerable variation in milk composition around the globe, or about the effects of this variation on infant health. This INSPIRE project represents the first comprehensive investigation of the global differences in human milk composition along with the various microbial, evolutionary, environmental, and sociocultural factors that might influence both milk composition and infant health. An international, interdisciplinary collaboration of physiologists, nutritional scientists, anthropologists, microbiologists, and mathematicians will collect biological data from breastfeeding women and their infants, in concert with extensive anthropologic and ecological data, in both developed (US, Spain, Sweden) and developing countries (Central African Republic, Gambia, Ghana, Peru, and Kenya). To test the possibility of a correlation between milk oligosaccharide composition, milk microbiota, and the gastrointestinal microbiome of infants, milk samples and infant fecal samples will be analyzed using state-of-the-art biochemical and genomic techniques. This study will allow important cross-cultural comparisons of milk composition and infant feeding practices; it also will utilize sophisticated computational methods to integrate the extensive, diverse body of combined biological and anthropological data to elucidate the relationships among sociocultural factors, evolutionary history, environmental exposures, microbial constituents and milk composition. The researchers predict that what is considered ""normal"" milk composition in one population may not support optimal health in another. This information is crucial to the humanitarian quest to understand how infant nutrition and overall health can be improved around the world. In addition, this project will provide extensive research training opportunities for undergraduate, graduate and postdoctoral scientists."
"1016205","III: Small: Using Empirical Generalization to Develop Predictive Models of DBMS Processing","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","03/14/2012","Richard Snodgrass","AZ","University of Arizona","Continuing grant","Frank Olken","12/31/2014","$505,541.00","","rts@cs.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7364","7923, 9251","$0.00","Database management systems (DBMSes) are now an essential component of a vibrant information technology industry. Despite research and development efforts over several decades, DBMSes are not well understood. There is surprisingly little known about quite basic questions such as, how often does the optimizer pick the wrong plan for a query? does adding a physical operator for an algebraic operation always improve the effectiveness of query optimization, or is there a limit to the number of operators that can be practically accommodated? how do throughput and disk utilization depend on multiprogramming level? or when does thrashing occur?<br/><br/>This project extends an existing laboratory information management system to develop and thoroughly test predictive models of centralized DBMSes. These models concern the role of schema complexity, effective operator set, and cardinality estimation errors on the plan chosen by the optimizer, the structure of the optimizer search space, and the interaction of multiprogramming level on throughput, disk utilization, and response time in predicting thrashing. These models predict important characteristics of DBMSes that share a common architecture, quantify the relative contributions of identified causal factors, and determine fundamental limits of that architecture.<br/><br/>These models can be used to further improve DBMSes through engineering efforts that benefit from the fundamental understanding that this perspective can provide. Additionally, this novel research infrastructure, being made available to the community and to students via a web portal, encourages a culture of empirical generalization and the sharing of experimental results: http://www.cs.arizona.edu/projects/soc/sodb/"
"0911009","RI: Large: An Integrated Approach to Creating Context Enriched Speech Translation Systems","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","08/15/2009","07/18/2014","Shrikanth Narayanan","CA","University of Southern California","Continuing grant","Tatiana D. Korelsky","08/31/2015","$2,200,000.00","Margaret McLaughlin, Panayiotis Georgiou","shri@sipi.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","1640, 7495","7495, 7925, 9215, HPCC","$0.00","The project creates robust, widely-deployable and cost-effective technologies for supporting cross-lingual spoken interaction between people who do not share a common language. The target application supports communication between healthcare personnel who speak English only and patients with limited-English proficiency. The state-of-the-art technologies that enable such cross-lingual interactions are characterized by a pipelined architecture of speech recognition, machine translation and speech synthesis, that largely ignore the rich information present in spoken language beyond those conveyed by words. They also do not take advantage of the humans in the loop for collaboratively managing the interaction. Overcoming these limitations requires improving robust intelligence at all levels ? signal, system, and human ? and set the research goals for this project. <br/><br/>The project?s intellectual merit comes from the unique combination of theoretical, computational model-ing and empirical elements: The theoretical framework is centered on notions of social co-presence to de-velop new models for translation-mediated communication. The computational modeling focuses on capturing prosody, dialog and user state from spoken language for enriching the technology components. The empirical work relies on a participatory approach to iterative design and evaluation of the system, working directly with the stakeholders.<br/><br/>The broader impact can be seen in the potential for facilitating multilingual efforts ranging from disaster relief and global business operations to servicing diverse immigrant populations notably in health care. The effort brings together engineers, linguists, human communication experts, and medical professionals to tackle a broad range of problems, and offers integrated interdisciplinary research training and mentor-ing."
"1439355","CAREER: Social and Economic Consequences of Information Diffusion in Networks","IIS","Cyber-Human Systems","09/01/2013","05/16/2014","Sinan Aral","MA","Massachusetts Institute of Technology","Continuing grant","Kevin Crowston","12/31/2015","$85,678.00","","sinan@stern.nyu.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","1045, 9215, HPCC, 1187","$0.00","This project is a three-pronged program of research and education focused on information in networks - its distribution, diffusion, value, and consequences for social and economic outcomes. First, this project will map the flow of information in real organizations over time and will combine economic theories of production with social network theory to estimate the effects of information diffusion on the productivity of individuals and teams. This work will advance economic theory concerning information worker production and productivity; sociological theory concerning the movement of information in social networks; technical methods for analyzing information content in digital networks while preserving privacy; and statistical methods to identify causal relationships between network structure and productivity. Second, the research will utilize data on online social networks to identify estimates of peer influence in product adoption and demand, and it will develop and apply new statistical techniques to separate influence from selection, homophily and confounding factors to optimize targeted peer-to-peer information diffusion. Third, the research will develop a general class of network-based models of the diffusion of behavior change in social networks, and parameterize and validate these models using empirical data on social relationships and health related behaviors from five massive networked datasets.<br/><br/>The central goals of the project are: 1) to estimate and enhance the productivity of information workers, 2) to model, measure and improve peer-to-peer viral marketing and demand estimation, and 3) to improve health-related prevention and intervention strategies. The proposed activities are designed to have broader impact for science, education and society. Our understanding of information worker productivity is a cornerstone of our future economic growth and thus our prosperity and welfare. The project also aims to improve intervention and prevention strategies for behaviors and outcomes such as disease prevention, obesity, and drug use. Developing reliable, scalable statistical methods for establishing causality in the diffusion of disease, obesity, smoking and delinquency can change social policy to ensure health interventions are appropriately targeted. Development of technical infrastructures to deal with large dynamic networked datasets, privacy preserving text analysis, and statistical methods for estimating the impacts of information diffusion in networks have implications for telecommunications, epidemiology, medicine, social policy and any industry or social sphere characterized by network externalities and local network effects. Educationally, the project will utilize the research program in classes to highlight the importance of networks and information for business strategy, society and health. Workshops will develop a new collaborative research community across academia and industry around topics related to information diffusion in networks."
"1320347","III: Small: Discovering Complex Anomalous Mappings","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/18/2014","Artur Dubrawski","PA","Carnegie-Mellon University","Continuing grant","Sylvia J. Spengler","08/31/2015","$499,282.00","Gilles Clermont","awd@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7923, 7364","$0.00","A 2000 report by the Institute of Medicine indicated that 100,000 patients die in the U.S. each year due to suboptimal treatment decisions made by healthcare professionals who operate under pressure of time while processing overwhelming amounts of data, particularly in the operating rooms and intensive care units. Corrective measures and new regulations have not led to improvements yet. In developed countries, about 6% of the economy is spent on upkeep of infrastructure, and about 50% of the original acquisition cost is spent on maintenance of equipment. Managers of, e.g., fleets of aircraft, are too often unable to maintain the required levels of equipment availability due to unexpected, but identifiable in data, crises in maintenance and logistics: only about 2/3 of the U.S. military aircraft can be flown at once. Expediting solutions often causes hundreds of millions in avoidable expenses. These two examples, as well as many other societally, economically, and scientifically important domains of human activity, involve large amounts of multi-stream data, which may carry information helpful in mitigating some of the adversities. Existing research efforts produce algorithms that extract useful information from individual sources of data. Substantial new benefits, however, could be realized by exploiting relationships between streams of data. This research program will comprehensively and pragmatically explore that opportunity, and impact communities of healthcare practitioners, equipment managers, as well as users in other domains wherever multiple streams of corroborative evidence are available, it will also benefit students and trainees, and the scientific community at large.<br/><br/>This research project will develop and extensively evaluate new algorithms to identify informative correlations between multiple and diverse streams of large, multivariate, numeric and symbolic, potentially sparse data. These algorithms will identify subsets of features and records of data that follow distinct cross-stream relationship patterns, enable descriptive and predictive analytics in static and temporal settings, and allow robust forecasts. The proposed work will build on prior efforts towards detection of complex anomalous patterns in single streams of multidimensional data, and expand it towards cross-stream analysis of multiple data sources. Expected results will allow, e.g., detection of patterns of change in relationships between vital signs measured at the bedside of intensive care patients and their records of treatment or medication, and outcomes. These patterns may be indicative of non-standard responses of a patient to a treatment, or signal emergence of a health crisis. In a broader perspective, this effort will substantially expand capabilities of current techniques of cross-stream analytics such as Canonical Correlation Analysis, it will develop a new variant of Gaussian Processes framework to model inter-stream dynamics, produce new information-theoretical modeling of correlations between streams of symbolic variables (with an extension to handle datasets with a mix of numeric and symbolic features), and it will provide a framework for identifying multimodal structures of cross-stream relationships, including disjunctive and conjunctive-disjunctive patterns. It will take on highly challenging intellectual endeavors while aiming for significant benefits of societal importance, with the primary impact demonstration areas in bed-side informatics and equipment health management. Resulting software implementations of the new algorithms and illustrative examples of their use will be shared with the general research community. The bulk of the proposed work will be performed by graduate students and medical fellows who will immediately use the acquired knowledge in their careers. The PIs will include the results in outreach activities and in their training and teaching course materials."
"1320542","III: Small: Managing and Mining Uncertain Graphs","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/18/2014","George Kollios","MA","Trustees of Boston University","Continuing grant","Frank Olken","08/31/2016","$500,000.00","Evimaria Terzi","gkollios@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364","7923, 7364","$0.00","Network and graph data appear in many diverse applications such as social networks, biological networks, and mobile ad-hoc networks. In many cases, there is an inherent uncertainty in the available graph data either due to the data collection process or the preprocessing of the data. Furthermore, uncertainty or imprecise information becomes a critical impediment to understanding and effectively utilizing the information contained in such graphs. In this project, we address the problem of managing and mining such uncertain graphs. To do that, we adopt the possible-world semantics to probabilistic and uncertain graphs and within this framework we study algorithms for well-established data-mining problems. Motivated by real-life applications, we focus on specific data-analysis tasks. However, we make our framework general enough so that it can be used for a wide set of tasks and applications. In particular, we develop scalable and efficient algorithms and approaches to address a number of important tasks including nearest neighbor retrieval, clustering and partitioning, finding important nodes and edges, and summarizing large uncertain graphs. <br/><br/>We expect the results of this project to have an impact on several application domains. For example, they can help internet-based and social-media related companies to analyze their data and improve their targeting advertisement policies and practices. This will create opportunities for making these companies viable and help the economy of internet-based business. In medicine, biology and biochemistry, networks play a very important role and many of these networks can be better modeled as uncertain networks. Our project can help analyze these networks and lead to new biological insights. The results of this project are disseminated as follows: (1) we develop publicly available prototypes; (2) we include the results of our work in our classes/lectures; (3) we communicate our results to scientists of computer science and other fields and our industry collaborators through publications and demos. We also actively try to engage in our research graduate and undergraduate students, including women and minorities.<br/><br/>For further information see the web site at: http://www.cs.bu.edu/~gkollios/ugraphs/"
"1320580","III: Small: Investigating Spatial Big Data for Next Generation Routing Services","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","07/18/2014","Shashi Shekhar","MN","University of Minnesota-Twin Cities","Continuing grant","Maria Zemankova","08/31/2016","$499,860.00","","shekhar@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","7923, 7364","$0.00","Increasingly, location-aware datasets are of a size, variety, and update rate that exceed the capability of spatial computing technologies. This project addresses the emerging challenges posed by such datasets, which sometimes are also referred to as Spatial Big Data (SBD). SBD examples include trajectories of cell-phones and GPS devices, temporally detailed (TD) road maps, vehicle engine measurements, etc. SBD has the potential to transform society. A recent McKinsey Global Institute report estimates that personal location data could save consumers hundreds of billions of dollars annually by 2020 by helping vehicles avoid congestion via next generation routing services such as eco-routing. Eco-routing may leverage various forms of SBD to compare routes by fuel consumption or greenhouse gas (GHG) emissions rather than total distance or travel-time. <br/><br/>To develop next-generation eco-routing services, this project innovates in three areas. Frist, Lagrangian Xgraphs, a novel concept in computer science, is explored at conceptual, logical and physical database levels to model traveler's frame of reference, a major departure from traditional binary relationship (e.g., adjacency) graphs. Second, it probes the concept of route-collections, and scalable algorithms for finding route-collections. For example, to identify a route-collection over all possible start-times of a given time-interval, the project explores a critical time point approach which divides a given time-interval into a set of disjoint sub-intervals of stationary-rankings among alternative routes. The approach is not only novel but also very important for the field. Critical time points may become a vital component of dynamic programming (DP) solutions, which would need reconsideration in the face of emerging temporally detailed SBD that violate DP assumptions about stationary ranking of alternate solutions. Third, to address the increasing diversity of SBD methods, algorithm-ensembles and flexible architectures that allow rapid integration of new data sources and routing algorithms are developed. <br/><br/>The proposed work serves national goals for energy independence and sustainability by laying the ground work for eco-routing and other travel-related services that reduce fuel consumption and greenhouse gas emissions. By increasing the availability of SBD, the project also enhances the research infrastructure for other researchers. Educational activities include curriculum development and training of students in the emerging area of SBD and Eco-routing. Result dissemination is planned via publication in relevant peer-reviewed conferences and journals. More details are available on the project website (www.spatial.cs.umn.edu/eco-routing/)."
"0953495","CAREER: Evolutionary Computation and Bioinformatics","IIS","EXP PROG TO STIM COMP RES, INFO INTEGRATION & INFORMATICS","06/01/2010","07/18/2014","Clare Congdon","ME","University of Southern Maine","Continuing grant","Sylvia J. Spengler","05/31/2015","$496,000.00","","congdon@gmail.com","96 Falmouth St","Portland","ME","041049300","2077804413","CSE","9150, 7364","1045, 1187, 9150, 9215, HPCC, 9251, 7364, 9102","$0.00","The research focus of this project is to develop a novel evolutionary computation-based approach for identifying candidate modules in non-coding DNA that respond to environmental toxins (such as arsenic) and that alter gene expression. These modules are composed of short pieces of DNA that are binding sites for proteins; the cooperative and combinatorial interactions are believed to contribute to the inducibility and specificity of environmentally responsive genes. Since each gene has an enormous number of possible modules, searching for them in the laboratory is untenable; even an exhaustive computational search for candidate modules is impractical, given the large space. Thus, the development of artificial intelligence techniques is called for.<br/><br/>This is an interdisciplinary proposal that makes contributions in both computer science and biology. The computational contributions include designing an effective search through the large and complex space of possible modules. While a few existing tools have been designed to search the thousand base pair region immediately upstream of the gene, the work here is designed to search significantly longer sections, 1 million base pairs and longer in length. The existing approaches cannot be expected to scale to the larger search, requiring the development of a novel approach.<br/><br/>The PI has plans for introducing undergraduates to research, both through coursework and in supervised research projects. This proposal will support and encourage the creation of a new upper-level course in informatics as well as the development of informatics-themed exercises to be incorporated at the introductory level. The project will further directly support undergraduate researchers who will contribute to the core research project.<br/>This project will result in a well integrated program of research and teaching for the PI, contribute to the available tools and our understanding of evolutionary computation approaches for informatics work, and introduce scores of students to this work."
"0855272","CI-ADDO-NEW: CRCNS.ORG - online repository for high-quality neuroscience data and resources for computational neuroscience","CNS","COMPUTING RES INFRASTRUCTURE, ROBUST INTELLIGENCE, COLLABORATIVE RESEARCH","09/01/2009","06/11/2012","Friedrich Sommer","CA","University of California-Berkeley","Continuing grant","Kenneth C. Whang","08/31/2015","$1,225,000.00","Bruno Olshausen","fsommer@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7359, 7495, 7298","5936, 5979, 7495, 9218, HPCC","$0.00","This project will develop and operate a community infrastructure, CRCNS.ORG, to enable the sharing of data needed by the computational neuroscience community, to enhance and foster collaborations among theoretical and experimental researchers, and to further the development and testing of computational theories of brain function. This infrastructure will widen the spectrum of techniques applied to brain data, enabling discoveries that go beyond the scopes of individual laboratories.<br/><br/>The infrastructure targets the communities of neuroscience and related fields such as computer science, physics, mathematics, statistics, and engineering in which investigators seek access to high-quality neurophysiology data, including electrical, magnetic, and optical recordings from single neurons, neural ensembles, and brain regions. Development activities are aimed at lowering the barriers to contributing, accessing, and using neurophysiology data. Standardized methods will be developed for storing and annotating data in a self-describing, hierarchical format, and enabling flexible on-line access. Scalable methods will be developed to enable users to find potentially useful data and to provide means for online visualization and some on-line analysis. Operations activities will support users and data contributors as well as community outreach activities. Three summer training courses will be held to introduce students and researchers to methods and conventions concerning organization, visualization, and analysis of neuroscience data, and how to use the specific resources of the repository."
"1143926","EAGER: Visual Analytics for Ontology Matching","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/17/2014","Maria Cruz","IL","University of Illinois at Chicago","Standard Grant","Maria Zemankova","08/31/2015","$166,000.00","","ifc@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364","7364, 7916, 9251","$0.00","Ontologies are developed to provide semantics for a particular domain and to support information retrieval, reasoning and knowledge discovery. However, as separate groups develop ontologies, there is a need to combine or match ontologies to support connecting information across heterogeneous sources. Ontology matching is a complicated process that stems from the need to involve several types of matching algorithms that take into account syntactic, lexical, structural, instance, and logic features of the ontologies. The current support provided to users to understand and evaluate the results provided by ontology matching systems is very limited; therefore ontology matching is an arduous and time consuming task. This exploratory project focuses on development of a novel approach to ontology matching that employs visual analytics to guide the users in the process. It is expected to result in increased quality of resulting ontologies while also reducing the time and effort of experts involved in ontology matching.<br/><br/>Visual analytics is at the confluence of information visualization, data analytics, and data transformation. This project explores the potential of visual analytics to effectively assist real-time decisions by domain experts and ontology researchers alike during the ontology matching process. The project is organized around three key research challenges:<br/>(1) Visualization: Data and analytically extracted features need to be encoded into rich visualizations that can be effectively manipulated. In particular, visualizations should lend themselves well to complex transformations that facilitate the discernment of trends or patterns.<br/>(2) Architecture: The interaction between the automatic matching and the visual analytics modules is central to the proposed approach. The envisioned architecture will support a quality-controlled feedback loop in which users will intervene to change the analytic and visual parameters of the system.<br/>(3) Performance evaluation: Performance measures will be developed to objectively identify the obtained gains in terms of the effort saved by users and of the quality of the matching results as enabled by the proposed visual analytics approach to ontology matching.<br/><br/>If successful, this proof-of-concept project is expected to make a significant contribution in effective ontology matching that in turn will enable semantically enriched access to complex, heterogeneous, and distributed data to an increasing number of users in a variety of domains. Research results, including developed software, will be made available via the project web site (http://agreementmaker.org/wiki/index.php/Visual_Analytics). The project provides research experience to students and results from this research will be included in the computer science curriculum."
"1412969","CHS: Large: Collaborative Research: Achieving Development Goals with Information Technology","IIS","Cyber-Human Systems","07/15/2014","07/17/2014","Paul Leonardi","CA","University of California-Santa Barbara","Continuing grant","William Bainbridge","06/30/2018","$4,605.00","","leonardi@northwestern.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7367","7367, 7925","$0.00","This research seeks to discover the factors that can predict project success and guide decisions about funding, designing, and implementing major projects intended to use information and communication technology for socio-economic development. In the past five years, over ten billion dollars of US and international government funding have been invested in such projects, with private technology funding adding substantially to that figure. Yet, many of these projects fail. Existing theories emphasize the inability of technology designers in developed countries to understand the needs and context of users in developing countries. But that approach is at best incomplete because it focuses on the technology while ignoring the link between the technology and development outcomes. This research will go beyond a strict technology focus by exploring the interplay between technology plans and development goals. <br/><br/>The project will be organized in a series of steps employing multiple research methodologies, that logically build on each other. Case studies of four existing information technology development projects, including interviews and extended observation, will provide a deep conceptual basis for the subsequent work. Based on analysis of the observational and interview data, a questionnaire survey will be developed and administered to about sixty other comparable projects. Following analysis of the survey, a set of ten to twelve shorter case studies will then explore a diversity of projects and their contexts, to expand the theoretical system of analysis and identify issues that were not apparent in the first four case studies. <br/><br/>The resulting extensive, mixed-methods base of data will allow identification of the factors that shape project success or failure, as well as building and testing of emerging hypotheses so that the research team can construct strong theory. The resulting theory will provide the groundwork for future research, and enhance the existing scientific literature on this problem with the development scholarship and sensibility that currently is missing from it. This effort to better understand and predict project success and failure will have the potential to reap significant benefits for the populations that these projects target, for the nations whose development is at hand, and for the entities who provide the funding and who share the aspirations of those who seek to see life improved."
"1320219","III: Small: Organizational Responsiveness to Open Outside Input: A Modeling Approach based on Statistical Text and Network Analysis","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/17/2014","Hanna Wallach","MA","University of Massachusetts Amherst","Continuing grant","Sylvia J. Spengler","08/31/2016","$479,628.00","Bruce Desmarais","wallach@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","7923, 7364","$0.00","This project focuses on the development of new analytical tools for modeling the relationships between intra-organizational communication networks and open, external sources of text data. The massive quantities of textual communications generated within organizations constitute a largely untapped source for insightful, timely organizational analytics. The tools under development for this project are designed to jointly analyze the content of communications and the socio-organizational structure comprised by communication ties, thereby allowing researchers and practitioners to identify and analyze the ways in which government officials' extra-governmental communications are related to intra-governmental communications and operations. In producing these tools, this project builds upon extant textual and network analysis methods by focusing on novel probabilistic methods for identifying topics that cut across network domains (e.g., informal email communications, official meeting minutes, and final policy records) and representing the complex flow of topics through government decision and policy-making processes. These methods, along with data collected during the course of this project, enhance organizations' ability to connect streams of external input to their internal operations. In conjunction with a new, publicly available database of local government communication records, this project showcases and builds upon the success of recent efforts, encompassing the gov2.0 movement, to improve government responsiveness through the solicitation of open outside input."
"1302517","HCC: Medium: Collaborative Research: Force Feedback for Fingertips","IIS","Cyber-Human Systems","06/01/2013","07/17/2014","Thomas Royston","IL","University of Illinois at Chicago","Continuing grant","Ephraim P. Glinert","05/31/2016","$272,323.00","Dieter Klatt","troyston@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7367","7367, 7924","$0.00","Surface haptics is the creation of programmable haptic effects on physical surfaces such as touch screens and touch pads. Unlike traditional force feedback devices that require the operator to grasp an end effector, surface haptic devices must provide feedback directly to the fingertips. With the dramatic rise of touch screen interfaces in recent years, many approaches to surface haptics have been explored, including vibrotactile, shape morphing, and variable friction. The PI and his team have pioneered an approach in which the surface generates controlled shear forces on each fingertip. Force Feedback for Fingertips (F3), gives fingertips the opportunity to interact with physics-based virtual environments, much like force feedback devices enable the whole hand to do. With F3, fingers can interact with virtual objects that have mass, stiffness and damping as well as more complicated dynamics (e.g., collisions, mechanisms, and force fields). By coordinating haptic effects at multiple fingertips, even more compelling illusions can be generated.<br/><br/>The technology, underlying science, and application of F3 are, however, still in their infancy. F3 works by coupling lateral vibrations to some form of rectification. For example, one approach involves high-frequency lateral vibrations of the surface synchronized with a friction reduction effect, resulting in a slip-push transition at each oscillation. The friction is modulated by means of electrostatic forces or acoustical stimulation. Current approaches work at ultrasonic frequencies, but little is known about the mechanical or electrical behavior of fingertips at these frequencies, or how energy transfer from a surface to the finger can be optimized.<br/><br/>This research will produce new knowledge in three main areas: the physical underpinnings of F3, device design and interaction design. First, both tribological and acoustic measurements will be made to elucidate the mechanisms by which shear forces are generated. A high-bandwidth tribometer and optical imaging system will allow friction to be studied, and a custom-built exciter will allow the propagation of acoustic energy in the fingertip to be studied. Laser Doppler vibrometry will be used to measure surface wave propagation while magnetic resonance elastography will be used to study shear wave propagation within the subcutaneous tissues. Fractional calculus and finite element techniques will then be used to build biologically plausible models of fingertip tribology and mechanics that match the data. Second, a new generation of high-performance F3 devices will be developed. Armed with good models, it will be possible to design impedance-matched devices so that force production is maximized and energy wastage is minimized. Additionally, these new devices will provide control over the force vector at each of multiple fingertip locations. Thirdly, novel multi-finger interactions will be designed. The key idea is that sophisticated percepts, such as ""objects"" that can be grasped and that feel as though they are moving relative to the surface, can emerge from properly coordinated fingertip forces due to Gestalt-like grouping principles.<br/><br/>Broader Impacts: Historically, the PI and his team have had greatest impact when providing technology to and collaborating with colleagues in human-computer interaction. Inspired by this, an open source F3 kit will be developed and shared. In addition, undergraduate and high school students will participate in the research, developing software routines and sample applications for the open source kit. Finally, the kit will be integrated with two pedagogical innovations already implemented by the investigators: flipped classrooms and portable laboratories."
"1319802","HCC: Small: Perception of Accurate Interactions through Bimanual Integrated Forces and Motions","IIS","Cyber-Human Systems","08/01/2013","05/09/2014","Kyle Reed","FL","University of South Florida","Standard Grant","Ephraim P. Glinert","07/31/2016","$365,973.00","","kylereed@usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139745465","CSE","7367","7367, 7923, 9251","$0.00","It is difficult to simultaneously convey the subtle forces and motions of a task to another person when teaching a physical skill. A common technique is for the expert to move the novice through the task. But this guiding motion is only partially effective at portraying the full experience because the novice only performs the task passively. To fully experience the physical interaction, an active recreation of the actions would be much more effective. The PI's goal in this research is to enable a person to recreate the actions performed by another person while fully experiencing the forces that result from those actions. To this end, the PI will explore a bimanual approach that takes advantage of our inherent ability to synchronize motions between both sides of our bodies, to allow a person to independently generate a desired path while feeling the task-related forces actively. Note how easy it is to simultaneously draw a pair of identical circles (or other shape) with both hands. Based on this observation, and in contrast to training methods that guide the dominant hand, the PI's method will guide the non-dominant hand and ask the individual to recreate the motions in the dominant hand, which will receive all the forces involved in the interaction. In this way, one arm will both receive forces while actively generating motions and will fully experience the task forces. Prior to implementing and testing this bimanual guidance method, several experiments will be conducted to determine the involved sensorimotor control parameters; specifically, hypotheses will be tested to evaluate our abilities to recreate a motion that is applied to one hand and to evaluate whether people can be taught to perceive passively applied forces similarly to actively applied forces. In contrast to methods that aim to make the physical interaction with an environment as realistic as possible, this method is transformative in that it aims to make the perception of the physical interaction as similar as possible to another person's actions by incorporating the human's sensorimotor control system. The scientific challenge lies in determining how the two modalities (force from one side and position from the other) are integrated and in determining and overcoming the sensorimotor delays associated with perception and recreating the force.<br/><br/>Broader Impacts: This research will fundamentally advance our understanding of force perception, bimanual interactions, and how forces and motions are cognitively integrated to perceive objects in active and passive tasks. The work will enable one person to fully experience the same physical interaction as another person, which will transform teaching and training techniques for surgeons, athletes, and helicopter and airplane pilots, among others. In addition to directly supporting a graduate and an undergraduate student, this research will also impact engineering students in the PI's class on haptics who will learn about performing psychophysical experiments on humans."
"0424422","Team for Research in Ubiquitous Secure Technology (TRUST)","CCF","SCI & TECH CTRS (INTEG PTRS), STC CLASS OF 2005, INFO INTEGRATION & INFORMATICS, TRUSTWORTHY COMPUTING, , , , , , FED CYBER SERV: SCHLAR FOR SER, , , ","06/01/2005","07/17/2014","S. Shankar Sastry","CA","University of California-Berkeley","Cooperative Agreement","Sylvia J. Spengler","10/31/2015","$39,971,095.00","Janos Sztipanovits, John C. Mitchell, Stephen Wicker, Michael Reiter, Adrian Perrig","sastry@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","1297, 7555, 7364, 7795, I303, K528, k535, k578, K155, 1668, L556, L555, M560","0000, 7555, 7925, 9178, 9218, 9251, HPCC, OTHR","$0.00","PROJECT ABSTRACT<br/><br/>Team for Research in Ubiquitous Secure Technology (TRUST)<br/>Dr. S. Shankar Sastry, Principal Investigator<br/>University of California at Berkeley<br/><br/><br/>Computer trustworthiness continues to increase in importance as a pressing scientific, economic, and social problem. The last decade has seen a rapid increase in computer security attacks at all levels, as more individuals connect to common networks and as motivations and means to conduct sophisticated attacks increase. A parallel and accelerating trend of the last decade has been the rapidly growing integration role of computing and communication in critical infrastructure systems, such as financial, energy distribution, telecommunication and transportation which now have complex interdependencies rooted in information technologies. These overlapping and interacting trends and needs force us to recognize that trustworthiness of our computer systems is not an IT issue alone; it has a direct and immediate impact on our nation's critical infrastructure and workforce issues. As a consequence, there is an acute need for developing a much deeper understanding of the scientific foundations of cybersecurity and critical infrastructure systems, understanding the economic and public policy drivers and impacts for cybersecurity, and assuring the workforce required for research and development. <br/>In response to these needs, the Team for Research in Ubiquitous Secure Technology (TRUST) will be devoted to the development of a new science and technology that will radically transform the ability of organizations (software vendors, operators, local and federal agencies) to design, build, and operate trustworthy information systems for our critical infrastructure. The Center will bring together a team with a proven track record in relevant areas of computer security, systems modeling and analysis, software technology, economics, and social sciences. The team consists of investigators from the University of California at Berkeley, Carnegie Mellon University, Cornell University, Stanford University, Vanderbilt University, and San Jose State University. The research team will be advised and supported by an External Advisory Committee (EAC) with strong representation of vendors of information technology, critical infrastructure protection providers, and other relevant stakeholders. The STC team, including the researchers, education group, and the knowledge transfer group, the EAC, and participant groups will promote workforce diversity.<br/>Through the active coordination and integration of efforts, TRUST researchers will consider security in a hierarchy of approaches that ranges from secure embedded systems to complex interdependent systems, each approach informing and building upon the others. Equally important, TRUST will address economic, social, and privacy considerations as the technology is acquired and absorbed into cybersecurity products and the critical infrastructure. The integrated, multidisciplinary approach made possible by the Center mode of funding will allow solutions to synergistically emerge from a ""holistic systems"" view of computer security, software technology, analysis of complex interacting systems, and economic and public policy.<br/>The unifying approaches of TRUST are computer security for component technologies, composition of components into secure systems, test and evaluation strategies, social and economic factors for successful security and the integration of the Center's research with education and knowledge transfer. Leveraging the prior investments of NSF, DoD and other agencies in various application testbeds, TRUST will continuously test the technologies resulting from its research. The role of the testbeds will be to integrate and evaluate technologies in specific and realistic systems, keep the research on track to answer societal objectives, and demonstrate the technologies for stakeholders in real systems. <br/>To achieve and demonstrate the core objectives in the selected real-life testbeds, TRUST will pursue a strongly coordinated research agenda in the following areas Security Science (1) Software Security; (2) Trusted Platforms; (3) Applied Cryptographic Protocols; and (4) Network Security<br/>Systems Science: (1) Complex Interdependency Modeling and Analysis; (2) Secure Network Embedded Systems; (3) Model-based Integration of Trusted Components; and (4) Secure Information Management Software Tools.<br/>Social Science: (1) Economics, Public Policy and Societal Challenges; (2) Digital Forensics and Privacy; and (3) Human Computer Interfaces and Security.<br/>TRUST will have an education and outreach component that focuses on integrating research and inquiry-based education and on transferring new and existing knowledge to undergraduate colleges, educational institutions serving under-represented populations, and the K-12 community. In so doing, TRUST will help lay the groundwork for training the scientists and engineers who will develop the next generation of trustworthy systems, as well as to help prepare the individuals who will ultimately become the users, consumers and beneficiaries of such systems.<br/>TRUST will also take a comprehensive approach to knowledge transfer. Since TRUST addresses well-defined and long term societal needs, the results in computer security, privacy and critical infrastructure protection will be easily communicated to decision makers, policy makers, and government agencies. With respect to industry, the selected integrative testbeds will be the focal points to interact with major stakeholder industries: power, telecommunication and embedded systems. Since TRUST will comprise multiple institutions, including technology vendors, infrastructure providers and leading research universities, the result will be wide spread dissemination, adaptation and continued evolution of ubiquitous secure technology. <br/>The legacy of TRUST to the nation will be the creation of a science and technology base, policy base, educational base, and technology transfer methodology for cybersecurity. The long-term research agenda of TRUST will not only advance the frontiers of knowledge in trustworthy computing; it will influence on a national scale future academic research, industrial R&D and education as TRUST researchers identify new directions of inquiry, disseminate their findings to the broader community, and produce a diverse group of skilled graduates who will advance the field further yet."
"0953908","CAREER: Future of Search: User, Social Networks and Language","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","07/17/2014","Yi Zhang","CA","University of California-Santa Cruz","Continuing grant","Maria Zemankova","08/31/2015","$536,692.00","","yiz@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7364","1045, 7364, 9251, 1187, 9102, 9215, HPCC","$0.00","How to retrieve relevant information for a specific user under a specific set of circumstances is a challenging research problem. The goal of this research project is to tackle this challenge and lay the foundation for the next generation of search engines. Instead of simply matching a query to documents that contain query words, the approach developed here is a unified user-centric retrieval framework that consists of: (1) personalization: learning a user model that takes into consideration the content, context and decision criteria of a user; (2) language processing: learning better text representation for retrieval from heterogeneous corpus and linguistic resources; and (3) social networks: further improving the user model based on social norms and a user's social networks. To evaluate the framework, a personalized social search engine will be developed. <br/><br/>The result of this project will be a unified retrieval framework with a set of novel techniques applicable across a wide range of information retrieval (IR) tasks, including: search engines, recommender systems and adaptive filtering systems. Through the PI's industry collaboration, the results of this project are expected to be incorporated in commercial systems, and thus benefit millions of users. <br/><br/>K-12 students, undergraduate, graduate students, and engineers in Silicon Valley will be involved and benefit from the project. The project will lead to research-based educational materials (lecture slides, video lectures, book chapters and course projects). Project results, including publications, open source software, annotated data sets, demos and course materials, will be disseminated via the project website (http://www.soe.ucsc.edu/~yiz/futureofsearch)."
"0948101","Workshop Proposal: Content of Linguistic Annotation: Standards and Practices (CLASP)","IIS","ROBUST INTELLIGENCE","09/01/2009","08/02/2013","Adam Meyers","NY","New York University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$22,500.00","","meyers@cs.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","7495, 9215, HPCC","$0.00","At a September, 2009 NSF-sponsored meeting in New York City, the NLP community is discussing the standardization and harmonization of the content of manual/automatic linguistic annotation. The meeting is building on the results of the previous Computing Research Infrastructure (CRI) award ""Towards a Comprehensive Linguistic Annotation of Language"" by establishing standards that researchers and developers are likely to follow. These standards govern tokenization, part of speech, head selection and other basic components<br/>of linguistic content that higher level annotation schema assume in common. Once standards are set, violations should be conscious (not accidental) and researchers should justify any violations. The meeting also aims to set up incentives, in the form of grants for small (e.g., student) projects, because several initial standard-compliant annotation projects could plant the seeds needed for the standards to take root.<br/><br/>Intellectual merit: Establishing a common base for linguistic annotation will: (1) make it easier to use, merge and compare different types of annotation (from different transducers, different manual sets of annotation, etc.); (2) make a more rigorous set of annoation standards possible; and (3) facilitate the use of sophisticated natural language informed applications that can draw on annotation created by several different projects simultaneously.<br/><br/>Broader impact: This standardization process will bring about greater cooperation among annotation researchers and, as a result, greatly improve the efficiency of such research. This could significantly improve the state of the art of all linguistic processing, and thus, all applications (automatic search, translation, etc.) that rely on the automatic linguistic analysis of text."
"1149789","CAREER: Machine Learning Methods and Statistical Analysis Tools for Single Network Domains","IIS","INFO INTEGRATION & INFORMATICS","01/01/2012","07/17/2014","Jennifer Neville","IN","Purdue University","Continuing grant","Sylvia J. Spengler","12/31/2016","$285,725.00","","neville@cs.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","1045","$0.00","CAREER: Machine Learning Methods and Statistical Analysis Tools for Single Network Domains<br/><br/>Machine learning researchers focus on two distinct learning scenarios for structured network data (i.e., where there are statistical dependencies among the attributes of linked nodes). In the first scenario, the domain consists of a population of structured examples (e.g., chemical compounds) and we can reason about learning algorithms asymptotically, as the number of structured examples increases. In the second scenario, the domain consists of a single, potentially infinite-sized network (e.g., the World Wide Web). In these ""single network"" domains, an increase in data corresponds to acquiring a larger portion of the underlying network. Even when there are a set of network samples available for learning and prediction, they correspond to subnetworks drawn from the same underlying network and thus may be dependent. <br/><br/>Although estimation and inference methods from the field of statistical relational learning have been successfully applied in single-network domains, the algorithms were initially developed for populations of networks, and thus the theoretical foundation for learning and inference in single networks is scant. This work focuses on the development of robust statistical methods for single network domains -- since many large network datasets about complex systems rarely have more than a few subnetworks available for model estimation and evaluation. Specifically, the aims of the project include (1) strengthening the theoretical foundation for learning in single network domains, (2) creating accurate methods for determining the significance of discovered patterns and features, (3) formulating novel model selection and evaluation methods, and (4) developing improved approaches for network learning and prediction based on the unique characteristics of single network domains.<br/><br/>The research will enhance our understanding of the mechanisms that influence the performance of network analysis methods and drive the development novel methods for complex network domains. Expanding the applicability of machine learning techniques for single network domains could have a transformational impact across a broad range of areas (e.g., psychology, communications, education, political science) where current methods limit research to the investigation of processes in dyad or small group settings. Also, the project results will serve as an example application of computer science in the broader network science context, which will attract and retain students that might not otherwise be engaged by conventional CS topics. For more details see:<br/>http://www.cs.purdue.edu/homes/neville/research-nsf-career.html"
"1302698","III: Medium: Collaborative Research: Scaling Machine Learning to Massive Datasets---A Logic Based Approach","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/17/2014","Tyson Condie","CA","University of California-Los Angeles","Continuing grant","Sylvia J. Spengler","08/31/2017","$500,250.00","Carlo Zaniolo","tconde@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7364, 7924","$0.00","Machine learning (ML) algorithms have become ubiquitous across applications as diverse as science, engineering, business, finance, education and healthcare. However, development of ML software that can scale to massive datasets and that are also easy-to-use remains a challenge in part due to the fact that developing an ML tool currently requires the implementation of a deep software stack, from the actual runtime (i.e., how an ML algorithm is executed) to the API exposed to the users.<br/><br/>This project aims to develop DeML, a system to support the authoring and execution of ML tools. Specifically, DeML would allow ML algorithms to be formulated in the form of a declarative query over the training dataset. DeML optimizes the execution of the query over a computing platform (e.g., Amazon EC2 or SQL Azure), taking into account the characteristics of the algorithm, the data, and the available computational resources. Adoption of DeML would greatly reduce the effort required to develop scalable implementations of ML algorithms. The project is organized around three thrusts: (i) Development of a declarative query language, based on extensions of Datalog; (ii) Analysis of runtime of DeML queries; (iii) Optimization of dataflow of DeML queries based on the characteristics of data sources and the capabilities of the underlying execution platform. The resulting open source DeML prototype implementation will be made freely available to the community through the project web page at: http://deml.cs.ucla.edu.<br/><br/>The availability of the DeML could greatly lower the effort needed to author scalable implementations of ML algorithms for analysis of massive datasets, which in turn would increase the availability of such tools to the broader community. Experience gained by implementing and deploying ML algorithms at scale over modern cloud-computing platforms, could help inform critical design choices in the development of future cloud computing platforms for big data analytics, and hence impact a broad range of scientific, engineering, national security, healthcare and business applications of big data analytics. The project offers enhanced opportunities for research-based advanced training of graduate and undergraduate students, including members of groups that are currently under-represented in computer science, in databases, machine learning, and cloud computing."
"1351055","CAREER: Interactive Gesture-Based Data Manipulation and Visualization for Exploratory Learning and Research","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","07/17/2014","Christopher Weaver","OK","University of Oklahoma Norman Campus","Standard Grant","Maria Zemankova","07/31/2019","$496,124.00","","weaver@cs.ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7364","1045, 7364, 7453, 9150","$0.00","Visual exploration and analysis of data is increasingly important for advancement in virtually every area of human endeavor. Whether recorded directly by people or indirectly using machines, data captures our observations and interpretations of the world. When people interact with data, it is almost always in a visual form like graphics or text. The goal of this project is to vastly expand the usefulness of interactive visualizations by providing a general way to create and edit data inside the visualizations themselves. The key new idea of the project is that visualization users can perform sequences of gestures with common input devices to express their observations and interpretations directly in visual form. The visualizations not only show data, but also serve as meaningful graphical spaces in which to edit that data. By extending the data processing workflows and display techniques that are currently used in popular visualization tools and software libraries, we can flexibly and expressively translate the details of interactions into precise data changes with simultaneous visual feedback.<br/><br/>The innovative contributions of the project will include a general method to support interactive data editing in visualizations, a diverse collection of data editing gestures, a set of patterns to guide the process of designing visualization tools with data editing features, a declarative programming language for quickly building those tools, and a variety of built tools that show off real applications of data editing in visualizations. The project focuses on developing, evaluating, and distributing tools for scholarly research in the digital humanities. It tightly integrates education to bring together students and researchers from computer science, information science, and the humanities, and provide them with concrete opportunities to engage in authentic interdisciplinary collaboration. Scholarly research and education in the humanities involves open-ended exploration, analysis, and interpretation of complex data sets in diverse areas of study. This makes it an exemplary first target to demonstrate how gesture-based visual editing can be broadly applied to data analysis in virtually every segment of society. The broader impacts of the project will spring from the availability of a new, foundational, general-purpose methodology to support data entry, organization, annotation, and correction. Project products will include publications, tutorials, videos, the visualization gesture system as open source software, a compendium of data editing gestures, and a gallery of demonstration visualization tools for public download. Information on the project and resulting resources can be accessed on the project web site (http://www.cs.ou.edu/~weaver/nsf-career/)."
"1054783","CAREER: Picturing Motion: Analyzing Multidimensional Time-Varying Data through Perceptually Accurate Exploratory Visualization","IIS","GRAPHICS & VISUALIZATION, INFO INTEGRATION & INFORMATICS","02/01/2011","07/17/2014","Daniel Keefe","MN","University of Minnesota-Twin Cities","Continuing grant","Maria Zemankova","01/31/2016","$399,806.00","","keefe@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7453, 7364","1045, 7364, 7453, 9251, 1187","$0.00","The goal of this research project is to transform the way that complex time-varying scientific phenomena are analyzed using computers. The project makes possible a new style of aggregate and comparative analysis of large, high-resolution scientific motion databases. The approach combines the high-bandwidth channel of the human visual system with computational algorithms and interactive data exploration.<br/><br/>The experimental research is integrated with educational efforts, including training computer scientist students in interdisciplinary research via a new course, a new writing-focused curriculum, and broadly disseminated lesson plans. Artists and designers are direct participants in the research, opening up new career paths in the sciences for visually creative students. Hands-on interactive visualizations engage 7-12th grade minority and underprivileged students in scientific computing. <br/><br/>The results include experimentally grounded guidelines for perceptually accurate visualization, new techniques for coupling dimensionality reduction with illustrative data visualization, and tested human-computer interfaces for exploring spatially complex multidimensional data. These results are significant because they lead to new understandings of the coupled relationship between people and computing, specifically helping scientists move from vast, complex datasets to new insights. The broader impacts of the work lie in applications to multiple disciplines including musculoskeletal biomechanics, evolutionary biology, and geospatial science. Through specific applications, the work yields insights that could lead to improved treatments for spinal disorders and diseases in children and adults, and inform new theories of historical diversification among animals. Project results will be disseminated via open source software, videos, publications, and demos, all available on the project web site (http://www.cs.umn.edu/~keefe/NSFCAREER)."
"1012086","HCC: Large: Collaborative Research: Always-On Relational Agents for Social Support of Older Adults","IIS","Cyber-Human Systems","09/15/2010","09/20/2010","Timothy Bickmore","MA","Northeastern University","Standard Grant","William Bainbridge","08/31/2015","$725,982.00","","bickmore@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7925","$0.00","Abstract <br/>This project will create a new category of intelligent, autonomous virtual or robotic agent, which is continuously operating and interacting with humans - always on - for long periods of time and whose primary motivation is building and maintaining long-term social relationships with humans. The initial application focus of this research is to provide companionship and social support and to promote wellness for older adults who are living alone. For example, during a typical day, an always-on relational agent might play a social game of cards with the adult, act as an exercise coach and help arrange visits or phone calls with the adult's family and friends. <br/><br/>A new integrated theory of social agency, called SharedPlans Relationship Theory, will be developed to serve as a principled foundation for these relational agents. The theory will be grounded in an always-on relational software architecture, which will be distributed as open-source for others to use and extend. Using a participatory design process, including home and laboratory studies, the target user population will help develop the specifications for a relational agent, which will then be constructed using the theory and software architecture, and placed in users' homes for long-term (month or more) longitudinal evaluation. <br/><br/>This project will make fundamental, theoretical contributions to models of relationship, sociality, interactional engagement and social support. The effort will also produce new insights into how people in general, and older adults in particular, enact social support at the relational, activity and micro-behavioral levels of analysis. The new always-on relational software architecture will be a fundamental advance over current agent architectures, which only support brief, focused interactions around a well-specified task. This architecture will also support incremental extension of agent capabilities and be able to control either virtual and robotic agent embodiments. <br/><br/>Social isolation is a broadly troubling trend in modern society. Always-on relational agents have the potential to counteract this isolation both directly, by providing companionship, and as intermediaries, by putting isolated people in contact with other people, both electronically and physically. Companionship and social support are also known to be significant positive factors in disease recovery and mortality, especially for older adults. The application focus of this project therefore has the potential for helping with health care cost control."
"1161007","III: CCF: Medium: Collaborative Research: Combinatorial Analysis of Biological and Social Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/17/2014","Reka Albert","PA","Pennsylvania State Univ University Park","Continuing grant","Sylvia J. Spengler","08/31/2015","$272,845.00","","ralbert@phys.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7364","7924, 9102","$0.00","In this collaborative interdisciplinary proposal involving a researcher at the University of Illinois at Chicago (UIC) and one at the Pennsylvania State University (Penn State), the investigators will design and apply novel algorithmic tools to explore several fundamental graph-theoretic problems that have significant applications in biological and social interaction networks. The research problems addressed in the proposal can be broadly classified into graph partitioning type of problems and graph sparsification type of problems. For example, one such problem in the context of social interaction networks is to partition the nodes into so-called ""communities of statistically significant interactions"" to study the behavioral patterns of a group of individuals in a society. The PIs will formulate precise computational problems, study their properties, use novel algorithmic tools to design efficient algorithms, and implement the resulting algorithms to test their accuracy and efficiency. The proposed research will leverage further development of novel combinatorial tools previously developed by the PIs, in addition to developing new techniques, to design efficient algorithms for complex optimization problems. The algorithms developed in the course of this project will be implemented for validation on simulated and real data, and will lead to open-source software for the life science and social science communities.<br/><br/>On a broader level, since this proposal deals with fundamental combinatorial optimization problems that arise in diverse scientific fields, the proposed research will have a strong impact on research areas beyond the primary research area, such as in stability analysis of computer networks and in social network visualization. A central component of the proposal is the creation of meaningful educational activities that leverage the proposed interdisciplinary research and build on the PIs' substantial past experience in teaching, mentoring and outreach and on the diverse communities in Chicago . Additionally, the PIs plan to integrate research and education via course and curriculum development, involvement of undergraduates, minorities and under-represented groups, effective dissemination of research, mentoring of undergraduate and graduate students, outreach and community involvement, and promoting diversity in research and educational activities.<br/><br/>The outcomes of the project will be made freely available through the following websites of the investigators and their labs: http://www.cs.uic.edu/~dasgupta; http://www.cs.uic.edu/~dasgupta/professional/algo-lab.html; and http://www.phys.psu.edu/~ralbert."
"1412924","CHS: Large: Collaborative Research: Achieving Development Goals with Information Technology","IIS","Cyber-Human Systems","07/15/2014","07/17/2014","Diane Bailey","TX","University of Texas at Austin","Standard Grant","William Bainbridge","06/30/2018","$1,089,490.00","","diane.bailey@ischool.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7367","7367, 7925","$0.00","This research seeks to discover the factors that can predict project success and guide decisions about funding, designing, and implementing major projects intended to use information and communication technology for socio-economic development. In the past five years, over ten billion dollars of US and international government funding have been invested in such projects, with private technology funding adding substantially to that figure. Yet, many of these projects fail. Existing theories emphasize the inability of technology designers in developed countries to understand the needs and context of users in developing countries. But that approach is at best incomplete because it focuses on the technology while ignoring the link between the technology and development outcomes. This research will go beyond a strict technology focus by exploring the interplay between technology plans and development goals. <br/><br/>The project will be organized in a series of steps employing multiple research methodologies, that logically build on each other. Case studies of four existing information technology development projects, including interviews and extended observation, will provide a deep conceptual basis for the subsequent work. Based on analysis of the observational and interview data, a questionnaire survey will be developed and administered to about sixty other comparable projects. Following analysis of the survey, a set of ten to twelve shorter case studies will then explore a diversity of projects and their contexts, to expand the theoretical system of analysis and identify issues that were not apparent in the first four case studies. <br/><br/>The resulting extensive, mixed-methods base of data will allow identification of the factors that shape project success or failure, as well as building and testing of emerging hypotheses so that the research team can construct strong theory. The resulting theory will provide the groundwork for future research, and enhance the existing scientific literature on this problem with the development scholarship and sensibility that currently is missing from it. This effort to better understand and predict project success and failure will have the potential to reap significant benefits for the populations that these projects target, for the nations whose development is at hand, and for the entities who provide the funding and who share the aspirations of those who seek to see life improved."
"1319846","RI: Small: RUI: AIR: Automatic Idiom Recognition","IIS","ROBUST INTELLIGENCE","08/01/2013","07/29/2013","Anna Feldman","NJ","Montclair State University","Standard Grant","Tatiana D. Korelsky","07/31/2015","$176,514.00","Jing Peng","feldmana@mail.montclair.edu","1 Normal Avenue","Montclair","NJ","070431624","9736556923","CSE","7495","7495, 7923, 9229","$0.00","The main goal of this research project is to develop a language independent method for automatic idiom recognition. Idiomatic expressions, such as 'a blessing in disguise' and 'kick the bucket' are plentiful in everyday language, though they remain mysterious, as it is not clear exactly how people learn and understand them. There is no single agreed-upon definition of idiom that covers all members of this class, but idioms tend to be relatively fixed in grammatical form and meaning, but with relatively little predictability in the relation between form and meaning. Also, many idiomatic expressions can appear with both literal, i.e. fully predictable, interpretations given their form -- compare 'The little girl made a face at her mother.' (idiomatic) vs. 'The little girl made a face on the snowman using a carrot and two buttons.' (literal) As a result, idioms present great challenges for a variety of natural language processing applications, including machine translation systems, which often do not detect idiomatic language. To address these challenges, an algorithm is proposed that neither relies on target idiom types, lexicons, or large manually annotated corpora, nor limits the search space by a particular type of linguistic construction. The starting point is that idioms are semantic outliers that violate cohesive structure, especially in local contexts. The following properties are quantified and are incorporated into the outlier detection algorithm: 1) lack of compositionality comparing to literal expressions or other types of collocations; 2) violation of local cohesive ties, so that they tend to be semantically distant from the local topics; 3) while not all semantic outliers are idioms, non-compositional semantic outliers are likely to be idiomatic; 4) idiomaticity is not a binary property; rather, idioms fall on the continuum from being compositional to being partly unanalyzable to completely non-compositional.<br/><br/>This research contributes to the better understanding of idiomatic language, to the computational treatment of such phenomena and, with the creation of high quality, publicly available linguistic resources annotated for idioms, to the facilitation of machine learning research and big data science. Additional benefits include efficient algorithms for computing compositionality and topicality from large corpora, interesting new generalizations about the nature of figurative language, and the training of a cadre of undergraduate and graduate students in highly practical work on a difficult interdisciplinary problem."
"1353120","EAGER: 3D Event Reconstruction from Social Cameras","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","09/15/2013","07/17/2014","Yaser Sheikh","PA","Carnegie-Mellon University","Standard Grant","Jie Yang","08/31/2015","$216,000.00","","yaser@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7453, 7495","7453, 7495, 7916, 9251","$0.00","This EAGER project explores the use of social cameras to reconstruct and understand social activities in the wild. Social cameras are an emerging phenomenon, producing video captures of social activity from the point of view of members of the social group itself. They are proliferating at an unprecedented rate, as smartphones, camcorders, and recently wearable cameras, become broadly adopted around the world. Users naturally direct social cameras at areas of activity they consider significant, by turning their heads towards them (with wearable cameras) or by pointing their smartphone cameras at them. The core scientific contribution of this work is the joint analysis of both the 3D motion of social cameras (that encodes group attention) and the 3D motion in the scene (that encodes social activity) towards understanding the social interactions in a scene. A number of internal models (such as maximizing rigidity or minimizing effort) for event reconstruction are being investigated to address the ill-posed inverse problems involved.<br/><br/>This research is establishing a new area of visual analysis by providing the requisite framework for social activity understanding in 3D rather than in 2D. The ability to analyze social videos in 3D space and time provides useful tools for almost any activity that involves social groups working together, such as citizen journalism, search-and-rescue team coordination, or collaborative assembly teams. The project is integrated with education through teaching and student training, and outreaches industry through collaborations."
"1041637","EAGER: An Exploratory Pilot Project to Build an Intelligent Human-Computer Interface System for Neurological Disorder Assessment and Rehabilitation","IIS","Cyber-Human Systems","08/01/2010","07/17/2014","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Ephraim P. Glinert","07/31/2015","$152,053.00","Zhengyi Le","makedon@cse.uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7367","7916","$0.00","In this EAGER the PI will explore issues relating to the development and use of data from game playing for assessment and rehabilitation of neurological disorders. The focus is on Cerebral Palsy (CP), a disease that causes a variety of motor and other impairments. The most common symptoms of CP are a lack of muscle coordination, stiff muscles, exaggerated reflexes, and impaired gait, and treatment includes Physical Therapy (PT) and Occupational Therapy (OT), speech therapy, drugs, surgery, and orthotic devices. Initially, the PI will investigate game-based systems for the upper extremities. Traditionally, OT experts use subjective judgment in conjunction with the Manual Ability Classification System (MACS) to measure the motor skills without connection to cortical level activity. The PI's approach is to connect cortical activity with motor activity. She will explore the coupling and integration of computer games and wearable sensors for both neurological and motor assessment testing, as well as for long-term rehabilitation at home. In particular, she will design a family of computer games that correspond to OT exercises and build an initial set of feature classifiers for types of CP with motor skill assessment. She will also build computer infrastructure for remote rehabilitation and a cyclical evaluation methodology. The primary outcome of this research will be an initial setup for remote rehabilitation that uses machine reinforcement learning and fuses multimodal information collected from a variety of sensors. Using computer games in conjunction with brain imaging and traditional rehabilitation outcomes is a radical and untested but potentially transformative approach to healthcare practices for chronic conditions such as CP.<br/><br/>Broader Impacts: The PI's long-term goal is to develop an intelligent system called CPLAY, whose front end is a set of computer games to provide controlled stimuli to children with CP in order to facilitate a desired motor response and generate performance data for diagnosis and rehabilitation treatment. CPLAY's backend will be a set of computational engines to enable data logging (from a child playing the game), data fusion, analysis and decision support. The @lab version of CPLAY will be used for functional near infrared (fNIR) imaging, while the @home version will be used for rehabilitation with various additional sensors capturing and fusing data during game playing. The fNIR imaging is used to determine neuro-plasticity and motor recovery. The @home version tracks performance over time, considers context of the game, and can be monitored remotely if needed. Both versions will allow for game adjustments to provide personalized treatment. The CPLAY approach promises to lower costs and facilitate family engagement in the rehabilitation. Project outcomes will include a paradigm, methodology and tools with broad applicability to other neurological disorders."
"0917228","III: Small: Collaborative Research: Mining and Optimizing Ad Hoc Workflows","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","07/17/2014","Xifeng Yan","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","08/31/2015","$264,607.00","","xyan@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7923, 9216, 9251, HPCC","$0.00","Ad hoc workflows are everywhere in service industry, scientific<br/>research, as well as daily life, such as workflows of customer<br/>service, trouble shooting, information search, etc. Optimizing ad<br/>hoc workflows thus has significant benefits to the society.<br/>Currently the execution of ad hoc workflows is based on human<br/>decisions, where misinterpretation, inexperience, and ineffective<br/>processing are not uncommon, leading to operation inefficiency.<br/><br/>The goal of this research project is to design and develop<br/>fundamental models, concepts, and algorithms to mine and optimize ad<br/>hoc workflows. The project includes novel research on the following<br/>key areas: (1) Network Modeling and Structure Mining. A network model<br/>is built that statistically captures the execution characteristics<br/>of ad hoc workflows, and is optimized to improve the execution of<br/>new workflows with respect to different optimization objectives.<br/>(2) Workflow Artifact Mining. The network model built on workflow<br/>executions is then extended with workflow artifact mining to realize<br/>an optimization system that is able to take advantage of both<br/>executions and text contents. (3) Role Discovery and Relation<br/>Assessment. A computational framework is built to analyze the roles<br/>and relationships of agents involved in ad hoc workflow executions<br/>in order to further optimize workflows.<br/><br/>Advances from this project include models to represent ad hoc<br/>workflows, algorithms for mining hidden collaborative models, and<br/>techniques that optimize ad hoc workflow processing. The project<br/>bridges two emerging research areas: service science and network<br/>science, and enriches the principles and technologies of data mining.<br/>It also enhances research infrastructure through the collaboration of<br/>team members from different areas (data mining, database, and<br/>network). This research is tightly integrated with education through<br/>student mentoring and curriculum development. <br/><br/>Publications, software and course materials that arise<br/>from this project will be disseminated on the project website:<br/>URL: http://www.cs.ucsb.edu/~xyan/smartflow.htm"
"0916868","RI: Small: Learning-Based Systems for Single-Image Photometric Reconstruction","IIS","ROBUST INTELLIGENCE, ","08/15/2009","07/17/2014","Marshall Tappen","FL","University of Central Florida","Standard Grant","Jie Yang","01/31/2015","$393,005.00","Hassan Foroosh","mtappen@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7495, I331","0000, 7484, 7495, 7923, 9215, HPCC, OTHR","$0.00","This project focuses on developing algorithms and datasets that can transform photometric reconstruction systems from hand-designed systems into learning-based systems that are optimized on real-world data. <br/>Photometric reconstruction systems derive cues from the perceived intensity of different locations on a surface. Shape-from-shading, where the surface is assumed to have a diffuse reflectance, is a well-known example of photometric reconstruction. This project produces the datasets and methods necessary to use machine learning techniques to build models for photometric reconstruction.<br/><br/>This learning-based approach enables systems to be optimized on real-world data so that they produce the most accurate results possible. In addition, this learning-based approach enables the development of more sophisticated methods with more parameters than typically used in hand-designed systems. The ability to find optimal parameters in an automated fashion can not only improve existing approaches, such as by incorporating image data more effectively, but can also enable the development of algorithms that push the boundaries of current systems. In particular, algorithms are developed for estimating the shape of objects without knowing the illumination or even trying to explicitly model it.<br/><br/>The power of the learning approach cannot be realized without data for training and testing. A major task in this work is the construction of a database of images and ground-truth 3D reconstructions of the objects in the images. The 3D models can be found using an example-based photometric stereo technique."
"1421034","RI: Small: From Impact to Impulsive Manipulation","IIS","ROBUST INTELLIGENCE","07/15/2014","07/16/2014","Yan-Bin Jia","IA","Iowa State University","Standard Grant","Jeffrey Trinkle","06/30/2017","$499,889.00","","jia@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","7495","7495, 7923, 9150","$0.00","When people work, they often take advantage of impacts between objects, for example, a worker impacts a nail with a hammer to drive it in. These impacts generate what are known as ""impulsive forces"" to do work. People take advantage of smaller impulsive forces to complete many common daily tasks too; inserting a key into a key hole, opening a stuck window, and cracking an egg. While the impacts between a plate and a table is much lighter than that applied to a nail, it is nonetheless just as useful. Today's robots have not been designed to take advantage of impulsive forces to accomplish tasks. The PI conducts an investigation into several fundamental and experimental issues surrounding impulsive robotic manipulation and develops methods for their use in robot control. Project results are advancing the theory of multi-body impacts and widening the capabilities of robots. Direct applications of the results are leading to faster and more agile robots for civil and military services and improved efficiency of industrial processes.<br/><br/>The technical goal of this project is to gain in-depth understanding about control of collision outcomes and, more importantly, integration of impact planning with motion planning in robot manipulation. The project consists of three phases. The first phase advances the Principal Investigator's recent work on compliant and multiple impacts to modeling of n-body simultaneous collisions, tackling issues that include state space condensation, impulse growth in high-dimensional space, sensitivity to physical parameters, and area and nonlinear contacts. In parallel with the analysis is the development of a graphical interface called MultiCollide for interactive collision simulation. The second phase investigates how a manipulator can impart via impact a desired motion to an object, solving an inverse impact problem that connects impact dynamics with trajectory planning and manipulator dynamics. The final phase focuses on two impulsive manipulation tasks that respectively address the following important issues: how to leverage contact compliance and geometry, and how to interleave impact planning with robot motion planning."
"1421435","RI: Small: Micro-GPS: Localization using Visual Landmarks in Commonplace Texture","IIS","ROBUST INTELLIGENCE","07/15/2014","07/16/2014","Szymon Rusinkiewicz","NJ","Princeton University","Standard Grant","Jie Yang","06/30/2017","$499,993.00","Adam Finkelstein","smr@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085400036","6092583090","CSE","7495","7495, 7923","$0.00","This project develops a Micro-GPS system that provides centimeter-level accuracy and is reliable both indoors and out, based on specific landmarks in the ""random"" textures present in the world. The key idea is that all floors, such as the carpet in a building, the grain of a wood floor, the concrete on a sidewalk, and the asphalt on a road, have small imperfections, bumps, or variations in color from location to location. A downward-pointing camera mounted underneath a vehicle can observe specific, unique arrangements of these seemingly random variations, looking them up in an index to find out their precise position in the world. The developed technology can provide capabilities for better in-car navigations, such as accurate parking in a particular spot, pothole avoidance, and lane departure warning. Other applications might include smart wheelchairs that can stay on a sidewalk and avoid rough patches, scooters for the elderly and disabled, assistive technologies for the visually impaired, marker-free smart highways, smart robots in warehouses that can precisely position themselves next to shelves, and even domestic assistants that can handle day-to-day chores inside a home.<br/><br/>This research is based on a key idea that localization is possible based on specific features in the ""random"" textures present in the world: seemingly-heterogeneous textures that have unique variations everywhere but globally consistent image statistics. The key challenges of this project include developing methods for (1) detecting uncommon locations or ""features"" in a close-up image of the ground surface; (2) computing a feature descriptor for each detected landmark, in a way that is invariant to changes in orientation and lighting; (3) matching the features against a map: a pre-built database of features, their arrangements, and their locations in the world; and (4) being able to create and update the database to increase coverage and to account for changes. All of these are common components in contemporary systems for tracking, image alignment, and recognition. However, the individual algorithms have been tuned to work best for ""natural"" images. Instead, the project focuses on developing detectors, descriptors, matching algorithms, and update strategies that are tuned to the statistics of common ground textures. The research team investigates whether accuracy can be improved by combining descriptors based on color with ones based on surface normals or height fields; and the systems issues involved in scaling the system to widespread coverage."
"1344227","INSPIRE Track 1: Is Evolvability Driven By Emergent Modularity? Biomimetic robots, gene inspired information structures, and the evolvability of intelligent agents","DEB","INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, INFO INTEGRATION & INFORMATICS, EVOLUTIONARY GENETICS, ANIMAL BEHAVIOR, INSPIRE","01/01/2014","07/16/2014","Kenneth Livingston","NY","Vassar College","Continuing grant","George W. Gilchrist","12/31/2017","$999,314.00","Jodi Schwarz, John Long, Marc Smith, Joshua Bongard","livingst@vassar.edu","124 Raymond Avenue","Poughkeepsie","NY","126040657","8454377092","BIO","1640, 7275, 7364, 7378, 7659, 8078","7378, 8653, 8750, 1640, 7275, 7364, 7659","$0.00","This INSPIRE award is partially funded by the Evolutionary Processes program in the Division of Environmental Biology in the Directorate for Biological Sciences, the Behavioral Systems program in the Division of Integrative Organismal Systems in the Directorate for Biological Sciences, and the Information Integration and Informatics program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering.<br/><br/>For millennia, humans have bred organisms to produce better food, clothes, and companionship. Recently, scientists have learned how to breed robots, evolving simulated creatures in virtual worlds, or physical robots in the real world. By combining the evolutionary process with robotic engineering, more complex and novel designs should be possible compared to traditional methods. In spite of the promise, so far evolved robots only do simple things like walk, navigate, or pick up objects. What limits progress is a lack of understanding of ""evolvability,"" the capacity of organisms (or robots) to change and become more complex. Understanding evolvability is the main goal of this project: researchers will borrow ideas from modern genetics so their robots mutate and develop in ways that are similar to how biological creatures do. In theory, this could produce simple robots that evolve into ever more complex, capable and useful robots.<br/><br/>Understanding how complexity evolves is central to the study of life, and may enable even non-specialists to automatically and continuously produce diverse kinds of machines. By linking complexity, genetics, and evolution, this project seeks to discover new principles that can be applied in science and industry. To help convert scientific principles into innovation drivers, online software will be created to show how to evolve virtual or physical robots; this will help students learn about engineering, biology, and how to apply both to technology. Finally, evolutionary robotics can be used to solve complex problems in robotic control that defy logical programming solutions, so this research can help companies that manufacture robots."
"1054913","CAREER: Building and Searching a Structured Web Database","IIS","CAREER: FACULTY EARLY CAR DEV, INFO INTEGRATION & INFORMATICS","03/15/2011","07/16/2014","Michael Cafarella","MI","University of Michigan Ann Arbor","Continuing grant","Maria Zemankova","02/29/2016","$504,548.00","","michjc@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","1045, 7364","1045, 1187, 7364, 9251","$0.00","This project investigates techniques for extracting and searching Web-embedded structured datasets. For example, a manufacturer's site may contain technical product data, and a governmental site may contain economic statistics. Unfortunately, such data can be hard to isolate from surrounding text, and difficult to find using existing search engines that focus exclusively on documents. The approach for the extraction step is to use current incomplete datasets to induce a large ""portfolio"" of possible extractors, apply all of them to crawled Web content, then test which are most successful. The approach for the search step is to examine user query logs to find common patterns that describe the relationship between topic words and words that describe the dataset's structure; e.g., ""endangered species near the Mississippi River"" is a prototype for a many-to-many geographic relationship. The central goal of this work is to eventually construct a working search engine for the structured-data component of the Web.<br/><br/>The success of this project is likely to increase access to structured datasets for a very broad population of users. The project will also yield a large amount of novel extracted data relevant for scientific research, plus useful tools and query logs. To accompany the research program, this project involves an educational plan that includes revised undergraduate course material, development of online educational material surrounding the datasets and tools, and a course on Web topics taught to a local rural high school. All project results will be distributed at the project's Web site (http://www.eecs.umich.edu/~michjc/structuredweb/index.html)."
"1065250","III: Medium: Development and Evaluation of Search Technology for Discovery of Evidence in Civil Litigation","IIS","INFO INTEGRATION & INFORMATICS","06/01/2011","07/16/2014","Douglas Oard","MD","University of Maryland College Park","Continuing grant","Sylvia J. Spengler","05/31/2015","$1,199,996.00","David Doermann, David Kirsch","oard@glue.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7924","$0.00","The civil litigation system of the United States serves as the ultimate arbiter for commercial and personal disputes. Under this system, plaintiffs and defendants are entitled to request relevant evidence from each other. Although digital records seem easier to find than their older paper counterparts, rapid growth in the volume, diversity, and possible locations of these records has actually made it harder to find the proverbial needles within the digital haystacks. The resulting rapid increase in the cost of discovery and exchange of relevant evidence, if left unchecked, raises concerns about access to justice. Hence, there is an urgent need for demonstrably accurate and cost-effective technologies to support ""e-discovery"" of the relevant records.<br/><br/>Professor Douglas W. Oard and colleagues of the University of Maryland are developing techniques to automatically decide within minutes the responsiveness of more documents than one person could examine in a lifetime. These techniques use ""semi-supervised learning"" algorithms for ""training"" the software to replicate the kinds of decisions that people make on representative examples. Using Finite Population Annotation, a new framework for integrating learning with evaluation, novel methods are being developed to achieve and measure the highest possible effectiveness for any specified level of human effort. These learning methods draw on rich approaches to representing the content of both born-digital structured documents and scanned paper. Measures for rigorously assessing the effectiveness of the resulting automated review techniques are being developed both to support decisions by legal professionals and by the courts about which methods to use, and to help developers further improve their algorithms.<br/><br/>The legal system demands technology whose effectiveness has been demonstrated on collections that are representative of what is actually expected in a real case. For that reason, this project is creating real world benchmarks in collaboration with the National Institute of Standards and Technology's Text Retrieval Conference (TREC). The project's results are expected to help to shape professional practice through workshops for legal and technical stakeholders, and through university courses to prepare the next generation of attorneys and information professionals to employ these new capabilities. ""E-discovery"" technologies resulting from this effort are likely to be broadly applicable in domains beyond the law practice, including preparation of systematic reviews of scientific literature, scholarly access to digital archives, and government responses to public information requests from citizens. Additional information is available at http://ediscovery.umiacs.umd.edu."
"1408345","CHS: Medium: Towards Transparency of Personalization on the Web","IIS","Cyber-Human Systems","07/15/2014","07/16/2014","Christopher Wilson","MA","Northeastern University","Standard Grant","William Bainbridge","06/30/2018","$727,094.00","David Lazer, Alan Mislove","c.wilson@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7367, 7924","$0.00","This project will develop new research methods to map and quantify the ways in which online search engines, social networks and e-commerce sites use sophisticated algorithms to tailor content to each individual user. This ""personalization"" may often be of value for the user, but it also has the potential to distort search results and manipulate the perceptions and behavior of the user. Given the popularity of personalization across a variety of Web-based services, this research has the potential for extremely broad impact. Being able to quantify the extent to which Web-based services are personalized will lead to greater transparency for users, and the development of tools to identify personalized content will allow users to access information that may be hard to access today.<br/><br/>Personalization is now a ubiquitous feature on many Web-based services. In many cases, personalization provides advantages for users, because personalization algorithms are likely to return results that are relevant to the user. At the same time, the increasing levels of personalization in Web search and other systems are leading to growing concerns over the Filter Bubble effect, where users are only given results that the personalization algorithm thinks they want, while other important information remains inaccessible. From a computer science perspective, personalization is simply a tool that is applied to information retrieval and ranking problems. However, sociologists, philosophers, and political scientists argue that personalization can result in inadvertent censorship and ""echo chambers."" Similarly, economists warn that unscrupulous companies can leverage personalization to steer users towards higher-priced products, or even implement price discrimination, charging different users different prices for the same item. As the pervasiveness of personalization on the Web grows, it is clear that techniques must be developed to understand and quantify personalization across a variety of Web services.<br/><br/>This research has four primary thrusts: (1) To develop methodologies to measure personalization of mobile content. The increasing popularity of browsing the Web from mobile devices presents new challenges, as these devices have access to sensitive content like the user's geolocation and contacts. (2) To develop systems and techniques for accurately measuring the prevalence of several personalization trends on a large number of e-commerce sites. Recent anecdotal evidence has shown instances of problematic sales tactics, including price steering and price discrimination. (3) To develop techniques to identify and quantify personalized political content. (4) To measure the extent to which financial and health information is personalized based on location and socio-economic status. All four of these thrusts will develop new research methodologies that may prove effective in other areas of research as well."
"1422381","CHS: Small: Making sense of information in online discussion boards with novel social computing platforms","IIS","Cyber-Human Systems","09/01/2014","07/16/2014","Olena Mamykina","NY","Columbia University","Standard Grant","William Bainbridge","08/31/2017","$499,931.00","","lena.mamykina@dbmi.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7923","$0.00","This project will analyze how individuals make sense of information collected within online health forums and how existing computing platforms facilitate or inhibit this process. Increasingly, individuals of all walks of life go online to collect and share information, collectively make sense of it and negotiate its meaning, reach a consensus, or agree to disagree, and, thus, generate a repository of collective wisdom that can be shared and reused. These social behaviors, often referred to as ""sensemaking,"" are particularly consequential in health and wellness management, as increasing numbers of individuals join online health support communities and rely on their peers for help and advice. Despite the ongoing research on social computing platforms and on attitudes, perceptions and behaviors of their users, the dynamics of computer-mediated sensemaking remain poorly understood. Moreover, most of the information collected within these forums continues to exist in the form of discussion threads that provide little guidance as to the main topics discussed, the relationships between posts within the thread, different attitudes towards the topics of interest, and the overall dynamics of the discussions. The overarching goal of this research is to develop novel summarization, visualization, and interaction mechanisms to help individuals make sense of information and opinions collected in online forums. <br/><br/>Specifically, the research will seek to understand how sensemaking unfolds within discussion threads, describe it through a set of formalizations, or semantic discussion typologies, and identify ways to study it computationally. Participatory design methods will then be used to develop novel visualization and interaction mechanisms for facilitating individual and collective sensemaking within online forums. A combination of computational data analysis and visualization techniques will automatically generate visual summaries of discussions threads that can help users to understand the evolution of meaning in discussions. This research will build upon previous work in natural language processing and data mining, to represent salient properties of the discussion threads, such as discussion topics and their transformation overtime, and the various attitudes towards the topics among the users. Finally, the discussion visualization tools will be evaluated on their impact on individual and collective sensemaking in controlled experiments and in a deployment study within an existing online health community oriented toward the difficult health issues associated with diabetes."
"1421330","CHS: Small: Investigating an Interactive Computational Framework for Nonverbal Interpersonal Skills Training","IIS","Cyber-Human Systems","08/01/2014","07/16/2014","Stefan Scherer","CA","University of Southern California","Standard Grant","William Bainbridge","07/31/2017","$499,992.00","Ari Shapiro, Louis-Philippe Morency","scherer@ict.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7367, 7923","$0.00","This project will advance social skill training by developing and evaluating a multimodal computational framework specifically targeted to improve public speaking performance through repeated training interactions with a virtual audience that perceives the speaker and produces meaningful nonverbal feedback. Interpersonal skills such as public speaking are essential assets for a large variety of professions and in everyday life. The ability to communicate in social environments often greatly influences a person's career development, can help build relationships and resolve conflict. Public speaking is not a skill that is innate to everyone, but can be mastered through extensive training. Nonverbal communication is an important aspect of successful public speaking and interpersonal communication, and at the same time difficult to train. This research effort will create the computational foundations to automatically assess interpersonal skill expertise and help people improve their skills using an interactive simulated virtual human framework.<br/><br/>There are three fundamental research goals: (1) Developing a probabilistic computational model to learn the temporal and multimodal dependencies and infer a speaker's public speaking performance from acoustic and visual nonverbal behavior; (2) Understanding the design challenges of developing a simulated audience that is interactive, believable, and most importantly providing meaningful and training-relevant feedback to the speaker; and (3) Understanding the impact of the virtual audience on speakers' performance and learning outcomes by performing a comparative study investigating alternative feedback and training approaches. This work builds upon the promising results of a pilot research study and upon a prototype virtual human infrastructure allowing for the seamless integration of automatically modeled interpersonal skill expertise for flexible virtual human interaction and gesture control.<br/><br/>Virtual audiences have the great advantage that their appearance and behavioral patterns can be precisely programmed and systematically presented to pace the interaction. The algorithms developed as part of this research to model temporal and multimodal dependencies will have a broad applicability outside the domain of public speaking assessment, including healthcare applications. The interactive virtual human technology may serve as the basis for novel teaching applications in a wide range of areas in the future, due to its extensibility and availability. The programming code and data will be made available to the research community and students."
"1350896","CAREER: Design Decision Patterns for Visualizing Multivariate Graphs","IIS","INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","07/15/2014","07/16/2014","Miriah Meyer","UT","University of Utah","Continuing grant","Maria Zemankova","06/30/2019","$400,000.00","","miriah@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7364, 9150","1045, 7364, 9150","$0.00","Multivariate graphs, or datasets that link together entities that are associated with multiple different variables, occur in a broad range of problems. For example, the dataset could be geospatial locations that include socio-economic statistics, linked together through a public transportation system. These multivariate graphs are notoriously difficult to visualize because the number of data variables exceeds the number of available visual cues - these cues include color, size, position, etc. The goal of this project is to establish a set of validated and generalizable techniques for visualizing and interacting with multivariate graphs. Three target application areas will drive the investigations: one in cancer biology, a second in urban transportation, and a third in particle physics. These areas were chosen to represent a wide spectrum of possible applications in which multivariate graphs play a central role, thus fostering generalizable results. The multidisciplinary nature of the research and the close collaboration with domain experts in our target application areas will provide a unique educational environment for undergraduate and graduate students, while also broadening the participation in computer science beyond traditional boundaries.<br/><br/>This is the first systematic, problem-driven effort to consider the visualization of multivariate graphs using a diverse set of application areas, with the goal of developing a generalizable set of techniques and principles for supporting a broad range of visualization and data analysis tasks. The research will be conducted with domain experts using a design study methodology, which is a deeply collaborative and user-centered approach to visualization research. The primary impact of this work will be validated visualization design decision patterns for effective visual representation and user-driven exploration of complex multivariate graphs, resulting in a more comprehensive foundation of techniques for visualizing this increasingly important data type. The resulting design decision patterns will support ongoing research and discovery in our target application areas, as well generalize to a broad class of real-world problems. Furthermore, these patterns will form the foundation of software tools for visualizing multivariate graphs that effectively support exploration and sense-making of these complex data types by taking into account the varied relationships embedded within. Results and software will be disseminated to both the research communities of our target application areas, but also more broadly through the project website at http://mvgraphs.sci.utah.edu."
"1344201","INSPIRE Track 1: UDiscoverIt: Integrating Expert Knowledge, Constraint-Based Reasoning and Learning to Accelerate Materials Discovery","IIS","OFFICE OF MULTIDISCIPLINARY AC, INFORMATION TECHNOLOGY RESEARC, SOLID STATE & MATERIALS CHEMIS, INFO INTEGRATION & INFORMATICS, INSPIRE","09/15/2013","07/16/2014","Carla Gomes","NY","Cornell University","Continuing grant","Sylvia J. Spengler","08/31/2016","$699,986.00","Francis DiSalvo, Bart Selman, Robert van Dover","gomes@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","1253, 1640, 1762, 7364, 8078","1640, 7364, 8653","$0.00","This INSPIRE award is partially funded by the Information Integration and Informatics Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering and the Solid State and Materials Chemistry Program in the Division of Materials Research and the Office of Multidisciplinary Activities in the Directorate for Mathematical and Physical Sciences.<br/><br/>The past two decades have seen a rapid development in experimental high-throughput experimentation (HTE) methodologies that would be extremely valuable for (i) the discovery of new applied materials with high complexity and (ii) the generation of deep understanding of structure/function, structure/activity and structure/performance relationships. Especially high photon flux X-ray techniques have enormous transformative potential in materials discovery. The research team leverages the data being collected by the Cornell High Energy Synchrotron Source (CHESS) and at Caltechs Joint Center for Artificial Photosynthesis (JCAP). While high-throughput inorganic library synthesis is relatively well-established, high-throughput structure determination, which is at the heart of the proposed research, is in its infancy. X-ray diffraction is well-suited for rapidly collecting information on the atomic arrangements in an inorganic sample, but the data do not immediately reveal a crystal structure. The development of data analysis, data mining and interpretation methodologies has not kept pace with the development of experimental capability. Consequently, data acquired in a week can take many months of traditional analysis by researchers. Automation and machine-intelligent processing of the data are absolutely necessary to maximise the impact of complex multidimensional datasets. <br/><br/>This project addresses this state of affairs head-on; It investigates computational techniques that allow dealing with the multiparameter space associated with HTE structure determination of materials libraries, through constraint guided search adn optimization, statistical machine learning, and inference techniques in combination with direct human input into the process. Anticipated advances include new probabilistic methods and computational discovery tools that integrate soft and hard constraints that capture the complex background knowledge from the underlying physics and chemistry of materials with insights gained from high throughput data analytics and machine learning. If the project succeeds in achieving the anticipated enormous efficiency gains in complex structure determination, it could have have a transformative impact on materials discovery and complex solid state chemistry and physics. <br/><br/>The ability to reduce complex materials dicovery and optimization from timeframes of months or years to hours or days could lead to a paradigm shift in the development of products benefiting society, with technological advances as well as commercial impact on energy, sustainability, health and quality of life. The planned free dissemination of data sets and computational tools to the larger scientific community is likely to enhance the broader impacts of the project. The project facilitates increased interdisciplinary interactions between computer scientists and material scientists at Cornell University and offer enhanced opportunities for training of a new generation of researchers at the interface between the two disciplines."
"1345052","Climate Informatics Workshop","IIS","INFORMATION TECHNOLOGY RESEARC, COMPUTER SYSTEMS, INFO INTEGRATION & INFORMATICS, EarthCube","09/15/2013","09/04/2013","Claire Monteleoni","DC","George Washington University","Standard Grant","Sylvia J. Spengler","08/31/2016","$90,702.00","","cmontel@gwu.edu","2121 Eye Street NW","Washington","DC","200522000","2029946255","CSE","1640, 7354, 7364, 8074","1640, 7354, 7364, 7433, 7484, 7556","$0.00","Understanding and responding to climate change is a key scientific and societal challenge of the 21st century. Recent advances in satellites and environmental sensors have made it possible to gather vast quantities of data concerning temperature, sea ice, sea level, rainfall, vegetation, etc. There is an urgent need for scientific and technical expertise for developing and effectively applying computational tools that can make use of such data to build increasingly accurate predictive models that offer insights to inform our understanding of, and response to, climate change. <br/><br/>This award supports a series of three workshops on Climate Informatics, an emerging discipline at the intersection of climate sciences and data sciences. The workshops, through a combination of tutorials that introduce climate scientists and data scientists to each other's disciplines, invited talks by established researchers in climate informatics, breakout sessions and for identifying research challenges and opportunities for interdisciplinary collaborations, serve a critically important role in building a vibrant Climate Informatics research community. The award provides support for the participation of approximately 60 to graduate students in each of the three workshops. The workshops contribute to the education and interdisciplinary training of a diverse workforce in STEM areas that span Climate Sciences and Data Sciences (including Machine Learning, Data Mining, Inference, Decision Making) as well as efforts to broaden the participation of women and other underrepresented groups in STEM research and education. Additional information about the Climate Informatics Workshop Series can be found at: https://sites.google.com/site/1stclimateinformatics/"
"1218160","HCC: Small: Designing Tangible Computing for Creativity","IIS","Cyber-Human Systems","09/01/2012","07/16/2014","Mary Lou Maher","NC","University of North Carolina at Charlotte","Continuing grant","William Bainbridge","08/31/2015","$499,981.00","Allison Druin, Timothy Clausner","marylou.maher@gmail.com","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","7367","7367, 7923","$0.00","The objective of this project is to develop a better understanding of the relationships between the design features of tangible user interfaces (TUIs), the gestures used when thinking about creative tasks, and creative problem solving. There is an increasing interest in developing tangible user interfaces to digital environments that has resulted in a large number of graspable interactive devices. This project seeks correlations between tangible computing and cognition, and more specifically, with creative cognition, and then uses that correlation to impact the design of environments for tangible interaction. One hallmark of creative problem solving is the ability to solve a problem by recognizing its similarity to another already solved problem, particularly if the problems appear dissimilar on the surface, but share an underlying structure. The act of recognizing that two superficially different problems are analogous requires a key creative step, which can be characterized as making a mental leap. TUIs may facilitate a mental leap in creative problem solving by enhancing perception and therefore cognition of spatial or structural similarities. <br/><br/>The intellectual merit of the project, arising from the synthesis of the results of the observation and design sessions are: a methodology for studying children's activities while they use TUIs that has two parts: observation and design; a reusable coding scheme for observation data that is based on research in tangible computing, gesture and thought, and creativity; and design principles for tangible devices. <br/><br/>Broader impacts: The results of this project can be used to develop motivating learning technology for children and adults that encourage learning in non-traditional ways. The project will also have an impact on public and professional understanding of the role of tangible computing in education through an association with the University of Maryland HCILab activities and their association with pubic radio. The proposed project has benefits to society more broadly by focusing on the importance of creativity in education and learning, which leads to a more innovative and competitive society."
"1422396","CHS: Small: Modeling Cyber Transportation and Human Interaction in Connected and Autonomous Vehicles","IIS","Cyber-Human Systems","12/01/2014","07/16/2014","Changxu Wu","NY","SUNY at Buffalo","Standard Grant","Ephraim P. Glinert","11/30/2017","$499,952.00","Chunming Qiao, Adel Sadek, Kevin Hulme","seanwu@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7367","7367, 7923","$0.00","The human element will constitute a critical component of tomorrow's Cyber Transportation Systems (CTS), either as drivers interacting with wireless messages in connected vehicle settings or as driver-passengers when vehicles are automated. Given that no engineered system will work perfectly all of the time, this raises important questions relating to the nature of the interaction between CTS and the human driver. Whereas the focus of the current literature has primarily been on hardware and software, in this pioneering project the PI and his research team will instead explore human-CTS interaction as the central design consideration. In accordance with this vision, they will develop and experimentally validate an innovative computational framework (mathematical model) for CTS that quantifies the effects of system design parameters on the key elements of human cognition and performance, which in turn will enable the derivation of design requirements and optimal parameter settings for connected and automated vehicles in order to maximize human safety.<br/><br/>For connected vehicles the model could be employed to determine minimal notification requirements (e.g., message transmission reliability) so as to maintain driver alertness and minimize driver distractions. For automated vehicles, the framework could be utilized to derive the minimal acceptable system reliability, optimal re-practice to minimize motor skill decay, and optimal lead time and design of the messages informing a driver to take over control of the vehicle (machine to human driver hand-over). Project outcomes will provide researchers in the field with the first tool to understand the fundamental mechanisms of human-CTS interaction (e.g., the impact of system reliability on human acceptance and trust), by predicting the effects of technology on driver behavior. The software will be open source, so that CTS researchers can easily modify their designs and/or explore the effect of modifying existing features and/or adding new ones as changes in technology may warrant."
"1443760","CAREER: Closed-Loop Crowd Support for People with Disabilities","IIS","Cyber-Human Systems","08/31/2013","07/16/2014","Jeffrey Bigham","PA","Carnegie-Mellon University","Continuing grant","Ephraim P. Glinert","01/31/2017","$148,885.00","","jbigham@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","1045, 7367, 9251","$0.00","To overcome accessibility problems, people with disabilities have traditionally relied upon the support of others in their community. For instance, a volunteer may offer a few minutes of her time to read a blind person's mail aloud, or a fellow traveler may answer a quick question at the bus stop (e.g., ""Is that the 45 coming?""). Professionals such as sign language interpreters and narrators of audio descriptions convert sensory information into alternative forms that enable a deaf student to participate in a conventional lecture and a blind person to enjoy a movie. Internet connectivity has dramatically expanded the pool of potential human supporters, but finding reliable assistance on demand remains difficult. The PI's goal in this project is to enable dynamic and diverse groups of people reachable via the Web (""the crowd"") to interactively support people with disabilities. The crowd is whoever happens to be available, from paid workers recruited on burgeoning micro-task marketplaces, to friends and family recruited via existing social networks, to volunteers willing to give a few minutes of their time. While someone is always available, the crowd is dynamic and individual workers can be unreliable. Thus, developing interactive systems to support people with disabilities presents numerous challenges, including how to enable crowd support that is real-time and high-quality, how to design interfaces that provide effective feedback even when an individual's directions may not be followed, and how to support collaboration among individual crowd workers without subverting methods of ensuring reliability. To these ends, the PI will explore closed-loop crowd support with a number of applications. VizWiz Stream will enable blind users to engage in an interactive conversation with the crowd about their visual environment. AudioWiz Stream will provide nearly real-time transcription of aural speech. And Legion and Legion VM will enable the crowd to collectively assume control of the keyboard and mouse to complete a user-specified task on existing desktop interfaces (whereas research in human-computer interaction usually assumes either a single user or a group of users collaborating in the same virtual space each in control of a personal cursor, this project will advance a new model in which a diverse and dynamic group collectively acts as a single operator). These applications will inform a common model for closed-loop crowd support, and will be iteratively improved and evaluated in lab studies and field deployments with blind and deaf users.<br/><br/>Broader Impacts: Project outcomes will enable people with disabilities to overcome more accessibility problems independently and on demand. The PI will release the software tools developed as part of this research as open source code, thereby enabling other researchers to build on his results. Although initially intended for use by blind and deaf people, the tools will likely prove useful as well to people with other disabilities such as cognitive or motor impairments, and people without disabilities may want to outsource interactive tasks which they cannot do, do not want to do, or think the crowd may do better. The PI will conduct annual summer programs in which blind and deaf high school students will develop tools for closed-loop crowd support, and also serve as supporters for people with different disabilities; these activities may encourage some of the participants with disabilities to pursue careers in computing, and the undergraduate students who help develop and run these activities will gain personal exposure to accessible computing and the challenges people with disabilities face in computing that they will carry with them into their careers."
"0917266","RI: Small: Scalable Roadmap-Based Methods for Simulating and Controlling Behaviors of Interacting Groups: from Robot Swarms to Crowd Control","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2009","07/16/2014","Nancy Amato","TX","Texas Engineering Experiment Station","Continuing grant","Satyandra Gupta","08/31/2014","$504,000.00","Lawrence Rauchwerger","amato@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495, 8013","7495, 7923, 8013, 9102, 9215, 9251, HPCC","$0.00","Simulating and controlling communities of characters that can <br/>interact with each other and their environment, and dynamically <br/>react to changes, is a challenging problem with many important <br/>applications ranging from homeland security (e.g., simulation <br/>of disaster scenarios and responses), to civil crowd control <br/>(e.g., planning exit strategies for sporting events), to <br/>education and training (e.g., providing immersive museum exhibits <br/>and training systems). While there are existing methods that <br/>attempt to address the simulation aspect, there is a lack of <br/>methods that support interaction of multiple types/groups of <br/>agents and little work has been done on the control or steering <br/>aspect. <br/><br/>This work aims to address these challenges by integrating <br/>roadmap-based planning with agent-based modeling. This hybrid <br/>approach enables the development of methodology for modeling group <br/>interactions which are also influenced by constraints imposed by <br/>the environment (e.g., wide or narrow corridors) and techniques, <br/>including interfaces that enable planning and experimentation, that <br/>can scale to large numbers of agents. The results of this work will <br/>be shared with the community via publications and open source <br/>software. An anticipated outcome of this research is a tool for <br/>simulation and control of large crowds at major events (e.g., <br/>sporting events, political rallies, emergency evacuations of a <br/>building, region, or city). This could allow emergency response <br/>planners to investigate the crowd response when officials are placed <br/>in particular positions, or architects to study how evacuation times <br/>are affected by widening or narrowing corridors."
"0915527","HCC-Small: Displaying Prosodic Text for Reading Aloud with Expression","IIS","Cyber-Human Systems","08/01/2009","07/16/2014","Rupal Patel","MA","Northeastern University","Continuing grant","Ephraim P. Glinert","07/31/2015","$498,407.00","","r.patel@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7923, 9215, HPCC, 7367","$0.00","Reading aloud is a complex motor, perceptual, cognitive and linguistic feat that takes years to learn and master. Text is problematic for developing readers because punctuation does not reliably mark phrase units or appropriate pause structure; commas do not always necessitate a pause, and question marks do not always necessitate rising intonation. Young readers who are learning these conventions are left to decode the author's intended prosody by trial and error; even those who have accurate decoding skills often experience difficulty chunking text into meaningful units. As a result, they read in a word-by-word manner with insufficient prosodic variation, which adversely impacts their ability to comprehend what they have read aloud. Traditional reading instruction and software programs emphasize rapid, accurate decoding and word recognition; little or no emphasis is placed on facilitating expressive, prosodic oral reading. Yet prosodic cues such as fundamental frequency F0 (perceived as pitch/intonation), intensity (perceived as loudness), and duration (perceived as length), convey a wide range of linguistic and affective functions that link the speech code to underlying semantic and syntactic content, which is crucial for language comprehension. In this project, the PI will explore a number of innovations to enable developing readers to read aloud with expression. She will design an interactive reading interface that displays prosodically varying text to help children read aloud fluently with appropriate expression. Prosodic targets (F0 contour, intensity envelop, and word and pause duration) will be derived from recordings made by a fluent adult reader and translated into textual manipulations using novel semi-automated acoustic-to-graphic mappings. The software will provide auditory and visual cues corresponding to the model adult production; near-real time visual and auditory feedback of the child's own production will enable self-monitoring to further support learning. The resulting electronic media will resemble a children's book, displaying a story image along with the corresponding prosodic text, and will include additional listening and recording functions. The software will be assessed using a repeated measures design, in which 32 children aged 6-8 years will read age and grade-level appropriate stories with and without the prosodic text. The PI's hypothesis is that providing explicit visual cues pertaining to the underlying prosodic targets will improve oral reading fluency, including accuracy, rate, and expressiveness. The additional cues may also provide the scaffolding to support comprehension of spoken text. Efforts to scale the prosodic text rendering techniques to a larger set of spoken content will be undertaken. Project outcomes will contribute to the fields of, digital signal processing, speech acoustics, speech and language development, reading acquisition, visual typography, and human-computer interaction.<br/><br/>Broader Impacts: The ultimate goal of this project is to inspire young readers to make the words on the page ""come alive"" through their expressive realization of the text. The PI expects the tools and methodologies developed in this work will also be applicable to improving spoken prosody for non-native speakers, for individuals with speech impairments, and for those with learning disabilities."
"1217886","III: Small: Parameter Inference and Parameter Advising in Computational Biology","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","07/15/2014","John Kececioglu","AZ","University of Arizona","Continuing grant","Sylvia J. Spengler","09/30/2015","$512,575.00","","kece@cs.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7364","7923, 9251","$0.00","Computational biology researchers often need to reconstruct an unobserved phenomenon from available data, such as the unknown evolutionary tree for a set of species, the unknown evolutionary alignment of related protein sequences, or the unseen folded state of an RNA molecule. Finding the reconstruction is usually modeled as an optimization problem, whose optimal solution is intended to correspond to the correct reconstruction. A key ingredient in such a model is the criterion that is being optimized, which is captured by the objective function. This function often has many free parameters, and the choice of values for these parameters critically affects whether the correct reconstruction is actually an optimal solution. This project will build a general software system that solves two complementary problems: (1) parameter inference, which learns optimal values for the parameters of the objective function for classes of inputs, given examples of correct reconstructions; and (2) parameter advising, which recommends good values of the parameters for a specific input. Consider a developer and a user of a software tool that solves a reconstruction problem: parameter inference finds the best default values for the tool developer, while parameter advising finds good specific values for the particular input being run by the tool user.<br/><br/>Parameter inference will be tackled via a recent algorithmic breakthrough in inverse parametric optimization. Given examples of input-output pairs for a reconstruction problem, values for the parameters of the objective function that make each output be an optimal solution for its input can be found in polynomial time, as long as: (a) the objective function is linear in the parameters, and (b) the reconstruction problem is efficiently solvable when parameter values are fixed. Parameter advising will be tackled by: (1) learning a polynomial that combines feature functions into an estimator for the accuracy of a reconstruction, and (2) selecting the parameter value from a set of choices that yields the reconstruction of highest estimated accuracy. An optimal parameter set that maximizes the average true accuracy of the advisor will be found by integer linear programming.<br/><br/>The general software system for parameter inference and advising will be made freely available for researchers as open source through the Internet. Outreach educational activities include conducting a summer workshop for high school biology and mathematics teachers to develop bioinformatics curriculum modules for their classrooms, and mentoring economically disadvantaged and minority undergraduate students through the McNair Scholars program. The tools developed by the project are poised to have very broad impact throughout computer science, not just computational biology, as the most widely-used optimization models, such as shortest paths, minimum spanning trees, maximum matchings, and network flow, all have linear objective functions, to which the parameter inference techniques apply."
"1117591","RI: Small: Ensemble Methods for Structured Prediction","IIS","ROBUST INTELLIGENCE","08/01/2011","07/29/2011","Mehryar Mohri","NY","New York University","Standard Grant","Todd Leen","07/31/2015","$407,074.00","","mohri@cims.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","7923","$0.00","Ensemble methods are general techniques in machine learning for combining several hypotheses to create a more accurate predictor. In the batch learning setting, techniques such as bagging, boosting, stacking, error-correction techniques, Bayesian averaging, or other averaging schemes are common instances of these methods. These methods often significantly improve performance in practice and often benefit from favorable learning guarantees, typically in terms of the margins of the training samples. <br/><br/>However, ensemble methods and their theory have been developed primarily for the common binary classification problem, or standard regression tasks where the target labels are real numbers and thus have no structure. These techniques do not readily apply to structured prediction problems such as pronunciation modeling, speech recognition, parsing, machine translation, or image processing. The objective of this proposal is to create the theoretical foundation, large-scale algorithms, and practical techniques for devising effective ensembles of structured prediction techniques. The benefits of these algorithms are likely to be at least as significant as those resulting from ensemble techniques in binary classification.<br/><br/>Our solutions will be crucial to a broad set of applications and will be made widely accessible through open-source software programs. These software and open-source programs will make the use of our learning algorithms accessible to a broad community of researchers and engineers. More broadly, our techniques will benefit the society through the discovery of significantly more accurate solutions to a variety of important problems including speech recognition, speech synthesis, and machine translation."
"1340619","EAGER: Information and complexity in the analysis of biological data sets and networks","IIS","INFO INTEGRATION & INFORMATICS","07/01/2013","06/17/2013","David Galas","WA","Pacific Northwest Research Institute","Standard Grant","Sylvia J. Spengler","06/30/2015","$299,740.00","","dgalas@pnri.org","720 Broadway","Seattle","WA","981224327","2067261220","CSE","7364","7916, 7364","$0.00","A living system is distinguished from most of its non-living counterparts by the way it stores and transmits information. It is just this biological information that is the key to the biological functions. It is also at the heart of the conceptual basis of what we call systems biology. Much of the conceptual structure of systems biology can be built around the fundamental ideas concerning the storage transmission and use of biological information. Biological information resides, of course, in digital sequences in molecules like DNA and RNA, but also in 3-dimensional structures, chemical modifications, chemical activities, both of small molecules and enzymes, and in other components and properties of biological systems at many levels. The information depends critically on how each unit interacts with, and is related to, other components of the system. Biological information is therefore inherently context-dependent, which raises significant issues concerning its quantitative measure and representation. An important and immediate issue for the effective theoretical treatment of biological systems then is: how can context-dependent information be usefully represented and measured? This is important both to the understanding of the storage and flow of information that occurs in the functioning of biological systems and in evolution. This work involves both new ideas and the integration of new ideas. It represents new mathematical methods as well as a novel integration of approaches that are focused on the very real and practical problems of biological data analysis. The PI as developed a new conceptual approach that is novel and mathematically well-defined, exploring the relationships between graph properties and set complexity and considering new approaches to network analysis. New interaction distance measures are considered with a new way of dealing with especially large data sets, especially the maximal information coefficient, for which a general approach may be possible, certainly for a small number of variables, and possibly in the general case. The ideas will be tested on a number of diverse biological data sets, especially around gene expressions, and other variants. Current methods often fail in the face of truly complex dependencies in large data sets, and powerful new methods would be of high value. This work involves both new ideas and the integration of new ideas. It represents new mathematical methods as well as a novel integration of approaches that are focused on the very real and practical problems of biological data analysis."
"0954256","CAREER: Shape Model Selection: Theory and Practice","IIS","ROBUST INTELLIGENCE","06/01/2010","05/28/2010","Kathryn Leonard","CA","California State University Channel Islands","Standard Grant","Jie Yang","05/31/2015","$417,231.00","","kathryn.leonard@csuci.edu","One University Drive","Camarillo","CA","930128584","8054373282","CSE","7495","1045, 1187","$0.00","This project explores shape models that unite human shape perception, computational tractability and mathematical rigor. In particular, it establishes geometry-based selection criteria for skeletal models, defining the best model to be the one that requires the fewest bits to approximate within a specified error tolerance. The goals of the project are to develop theoretical results establishing selection criteria for skeletal models and to apply those results to shape-dependent industrial projects.<br/><br/>Skeletal shape models are attractive for shape-based applications because they decompose shapes into salient parts that can be manipulated independently. Their primary downfall for practical applications, a lack of robustness to noises in the shape boundary, has only recently been addressed. In the classical definition of the skeletal model, each shape has a unique skeleton. That uniqueness creates a geometric rigidity that in turn leads to the lack of robustness. A recent generalized skeletal definition relaxes the uniqueness constraint, allowing multiple skeletal models for each shape. Multiple models provide the flexibility to accommodate noisy shape boundaries, but introduce a new problem in selecting the best skeletal model for a given shape.<br/><br/>The project engages capable but disadvantaged students who would otherwise be unaware of research as a career in exciting and relevant research. Broader impacts include extensive collaboration between research students and future teachers to develop learning activities for K-12 classrooms, development of course modules to incorporate concepts from digital image analysis into standard sophomore-level mathematics courses, and development of industrial applications in collaboration with students and industrial partners."
"1219321","HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics","IIS","Cyber-Human Systems","11/01/2011","04/15/2014","Jose Contreras-Vidal","TX","University of Houston","Continuing grant","Ephraim P. Glinert","05/31/2015","$356,870.00","","jlcontreras-vidal@uh.edu","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","7367","7367, 7924, 9251","$0.00","This research involves collaboration among investigators at four institutions. Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning. While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms. For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control. The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions. These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof). The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags. The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date. In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics. To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR). An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis. Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder. To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined. <br/><br/>Broader Impacts: This research will revolutionize the control and interface of upper limb prosthetics. The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease. The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research. The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering."
"1162606","RI: Medium: Advances and Applications in Submodularity for Machine Learning","IIS","ROBUST INTELLIGENCE","07/01/2012","07/15/2014","Jeffrey Bilmes","WA","University of Washington","Continuing grant","Todd Leen","06/30/2016","$701,821.00","","bilmes@ee.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7924","$0.00","Submodularity is an intuitive diminishing returns property, stating that adding an element to a smaller set helps more than adding it to a larger set. Submodularity allows one to efficiently find provably optimal or near-optimal solutions to discrete problems. Submodular minimization has found use, e.g., in graphical model inference and clustering, whereas maximization has been applied, e.g., to variable/feature selection and active learning. Submodularity, however, is still only beginning to show applicability in machine learning and its applications. Moreover, work on submodular optimization in the combinatorics and operations research literature has been primarily unaware of unique problems arising in machine learning. Therefore, existing standard algorithms do not exploit certain structures or variants of the submodular problems arising in machine learning. Studying novel machine learning problems involving submodular objectives can thus lead to advances in the pure combinatorics literature. We propose to pursue activities that bring together research in machine learning and combinatorial optimization to solve problems which neither of the communities can solve alone.<br/><br/>In particular, we propose to use insights from machine learning to enable scaling up typical submodular optimization problem sizes (by focusing on problem instances arising in learning). We also propose to further chart the territory that submodularity plays in machine learning. In this grant, we will introduce new submodular structures specifically related to submodularity. We will introduce submodular learning problems for machine learning. We will introduce new submodular optimization problems with constraints. And lastly, we will apply these submodular instances to real-world applications in computer vision, speech recognition, and natural language processing."
"1421498","CHS: Small: Non-use as a Transformative Lens for Understanding Social Technology","IIS","Cyber-Human Systems","08/01/2014","07/15/2014","Geraldine Gay","NY","Cornell University","Standard Grant","William Bainbridge","07/31/2017","$499,860.00","Eric Baumer","gkg1@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923","$0.00","This research will analyze the factors associated with non-use of Facebook, in order to develop a deep, rich understanding of how social technologies more generally mediate and are embedded in complex sociotechnical milieux. It will address three primary research questions: How can our understanding of technology use and ""the user"" be advanced by exploring its relationship with different types, degrees, and varieties of non-use? How is privacy conceptualized and enacted through non-use, and how do those practices help us reconsider the definition and constitution of privacy? What are the processes and experiences of leaving online groups and communities? When particular technologies become nearly pervasive, intentional and pointed absence from them becomes both analytically conspicuous and potentially informative. Questions of group persistence or dissolution apply broadly to a wide variety of domains and contexts integral to the composition of society. This research will help understand how social technologies mediate these processes, thus contributing to the design of systems that better meet the needs of people.<br/><br/>Four lines of research will explore these themes. First, a pair of large-scale surveys, one each during the first and third years, will establish the prevalence of different practices of and motivations for non-use. Second, statistical modeling and network analysis, using both survey data and samples of usage data, will examine how both individual and group predictors relate to these motivations and practices. Third, a series of focus groups involving participants with diverse experiences of use and non-use will help understand conversations and conflicts that may occur around non-use. Fourth, an intervention wherein study participants will be asked to deactivate their Facebook account will enable observation of the processes and experiences of non-use as they happen. <br/><br/>This project will contribute to and expand on the previous limited work on technology non-use, deepening our conceptualizations both of non-use and of ""the user."" The combination of quantitative and qualitative analyses will build an understanding of the influences on and practices of social technology avoidance. To facilitate research in this area, the anonymized survey data will be made available to other researchers. Finally, this work offers non-use as a potentially transformative lens through which to examine long-standing issues of privacy and groups in technologically-mediated systems."
"1423305","RI: Small: Inferring the ""Dark Matter"" and ""Dark Energy"" from Image and Video","IIS","ROBUST INTELLIGENCE","07/15/2014","07/15/2014","Song-Chun Zhu","CA","University of California-Los Angeles","Standard Grant","Jie Yang","06/30/2017","$454,400.00","","sczhu@stat.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7495, 7923","$0.00","This project develops core techniques for improving the performance of key tasks in computer vision, such as recognizing objects, understanding scenes and events. Improving the performance of these tasks is able to generate broader impacts to the following applications: (1) video surveillance for security and timely intelligence; (2) intelligent robots for rescue in disaster areas; and (3) aerial scene and activity understanding from videos taken by unmanned aerial vehicles. In these applications, a significant portion of the contents in images, including i) entities such as objects, stuff like liquid, human actions, and scenes; and ii) relations, such as intents of humans, causal effects of actions, physical fields and attractions in a scene, cannot be recognized by the geometry and appearance features that are commonly used in current computer vision research. These entities and relations are referred as the ""dark matter"" and ""dark energy,"" by analogy to cosmology models in physics, and plans to develop a unified representation that integrate the ""visible"" and the ""dark"" in a common model where the visible can be used to infer the dark, and the dark pose constraints for the inference of the visible in return. The research team is collaborating with industrial partner for technology transfer.<br/><br/>More specifically, the project studies the following topics: i) Representing causal knowledge to go beyond associational knowledge in computer vision. Casual models are a large part of human knowledge and crucial for answering deeper questions on why, why not, what if (counterfactual). This research is the first formal study of causality (learning, modeling, and reasoning) in the vision literature. ii) Reasoning the dark entities and relations to go beyond the current geometry and appearance-based paradigm. Perceptual causality, human intents and physics are generally applicable to all categories of object, scene, action and events, i.e., transportable across datasets. These entities and relations are deeper, and more invariant, than geometry and appearance - the dominating features used in visual recognition. iii) Developing joint representation and joint inference algorithm. The rich contextual and causal links in this joint representation are essential for building robust vision systems where each visual entity can be inferred through multi-routes, but are not systematically studied and integrated in the existing paradigm."
"1301560","6th International IEEE EMBS Conference on Neural Engineering, Nov 3-6, 2013, San Diego, CA","CBET","BIOMEDICAL ENGINEERING, ROBUST INTELLIGENCE","09/01/2013","09/04/2013","Metin Akay","TX","University of Houston","Standard Grant","Athanassios Sambanis","02/28/2015","$10,000.00","","makay58@gmail.com","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","ENG","5345, 7495","004E, 005E, 017E, 137E, 138E, 7556","$0.00","PI: Metin Akay<br/>Proposal ID: 1301560<br/><br/>Neural engineering is an emerging discipline that combines multiple engineering disciplines, including electronic and photonic technologies, computer science, physics, chemistry, mathematics with cellular, molecular, cognitive and behavioral neuroscience to understand the organizational principles and underlying mechanisms of the biology of neural systems and the behavioral dynamics and complexity of neural systems in nature. To highlight this emerging discipline, the 6th International IEEE EMBS Conference on Neural Engineering will be held in San Diego, CA from November 3 through November 6, 2013.<br/><br/>Intellectual Merits: The objective of this conference is to highlight progress in Neural and Cognitive Engineering, an emerging field bridging molecular, cellular, systems, cognitive and behavioral neuroscience with engineering, physics, chemistry, mathematics and computer science. We strongly believe that the neural engineering conference further stimulates neural engineering research and education among neuroscientists, chemists, engineers, computer scientists and mathematicians.<br/><br/>Broader Impact: In addition to the keynote, plenary, platform and poster sessions, we will also have a panel to focus on the challenges of making a career in the rapidly growing, interdisciplinary fields of neural engineering, from being hired as part of a team and finding<br/>exciting new research opportunities, to becoming a team leader and what to look for when organizing that team and choosing its members. Options will be discussed for graduate studies and research both internationally and within the U.S., as well as the potential for collaboration among researchers and students internationally."
"1117652","HCC: Small: Embodied Mediated Communication in Collaborative Work","IIS","Cyber-Human Systems","08/01/2011","05/11/2012","Bilge Mutlu","WI","University of Wisconsin-Madison","Continuing grant","Ephraim P. Glinert","07/31/2015","$503,810.00","Leila Takayama","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7367","7367, 7923, 9251","$0.00","The goal of this project is to gain a deeper understanding of mobile remote presence systems (MRPs) and to create guidelines for their effective design, development, and adaptation into organizational use. MRP systems enable embodied mediated communication in which individuals at a remote location connect to a local robot that is used to physically navigate in the local environment and to interact with local users via audio and video. MRP systems allow remote users to visit individuals in an organization and attend group meetings, seminars, and social gatherings in the local environment. MRPs enable new forms of interactions and offer remote users an improved sense of presence compared with stationary video-conferencing systems.<br/><br/>The project will study the use of MRPs in communication from an interdisciplinary approach drawing from and building on knowledge and methods from design, social and cognitive psychology, communication studies, and computer science. A series of field and laboratory studies will focus on four topics: (a) how remote users present themselves through MRPs; (b) how local users perceive remote users; (c) the role that social cues play in embodied mediated communication; and (d) the social and organizational outcomes of embodied mediated communication.<br/><br/>Intellectual merit: The project will advance understanding of the role of embodiment in mediated communication in collaborative work and inform the design of future mobile remote presence systems. In addition, the results will contribute to basic science in human-computer and human-robot interaction.<br/><br/>Broader impact: The results will enable more effective embodied mediated communication in organizations, thereby improving collaboration in distributed work groups. The results will also inform the development of tools that help individuals with mobility-related disabilities interact with their social and professional communities. In addition, the project will enhance the undergraduate and graduate curriculum at the University of Wisconsin-Madison, and there will be an outreach program to disperse interdisciplinary knowledge in and methods for designing robotic technology into K-12 education through an annual summer camp and biannual daylong workshops."
"1342252","RAPID: Social Media: Learning from the Boston Marathon Bombing","IIS","Cyber-Human Systems","06/01/2013","05/24/2013","Robert Mason","WA","University of Washington","Standard Grant","Kevin Crowston","05/31/2015","$72,879.00","Kate Starbird","rmmason@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7914","$0.00","The April 15, 2013 Boston Marathon Bombing (BMB) is a fresh reminder that societies can be shocked not only by natural disasters such as earthquakes and hurricanes but also by acts of terrorism. The bombing engaged the public in multiple ways, and social media platforms (Twitter, YouTube, Facebook, etc.) enabled the public to become both informed and to some extent involved. Digital traces that can be collected from these sites present a brief window of opportunity for research on how, and to what extent, this involvement emerged. This RAPID project will collect data from social media such as Twitter and other linked sources to address questions about the flow of information about the event across traditional and social media, the propogation and amplification of unsubstantiated information and misinformation, differences between official and popular social media use, self-organization of efforts for assistance or suspect tracking and changes in public sentiment over time. Data from this event may reveal differences in the dynamics of social media use in the wake of terrorist events vs. natural disasters. <br/><br/>The intellectual merit of the proposed project is that it combines emerging methods and techniques for social media research with recent research on disaster response coordination and planning to develop a conceptual model of the BMB information flows to guide data collection and analysis. Because the Boston Marathon attracted participants from around the world, this bombing has a global dimension that may affect the nature and reach of the social media communications. <br/><br/>Broader impacts of the project include educational benefits from students involved in the project and in courses that will be informed by the project findings. The collected data will be made available to other researchers and the principal investigators plan to coordinate their work with others examining this event, thus contributing to the infrastructure for science. The proposal includes funding for dissemination of the results of preliminary analysis of the collected data. Results from analysis may offer an improved guide for research on communication and information flows in crises and disasters (whether natural or human-initiated), thus benefiting society."
"1302339","HCC: Medium: Collaborative Research: Neural Control of Powered Artificial Legs","IIS","Cyber-Human Systems","06/15/2013","05/27/2014","Jose Contreras-Vidal","TX","University of Houston","Continuing grant","Ephraim P. Glinert","05/31/2017","$309,626.00","","jlcontreras-vidal@uh.edu","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","7367","7367, 7924, 9251","$0.00","Recent breakthroughs in the mechatronics of powered lower limb (LL) prostheses hold the promise of enabling restoration for the large and growing population of lower limb amputees of a broad spectrum of functionality (e.g., standing up when seated in a chair, climbing stairs, and even running). The PIs argue that to realize this potential it is essential to provide neural control of artificial legs. The application of existing upper limb (UL) neural control approaches is inappropriate to this end, because the UL and LL neural control mechanisms are significantly different. In particular, most activities involving the lower limbs recruit both involuntary (spinal cord) and voluntary (supra-spinal) neural control, present high dynamics, and require multi-joint coordination and control of unstable locomotion, characteristics which combine to make the design specifications for neural control of LL prostheses much more demanding than those for UL devices. In this project the PIs will address this challenge by developing an innovative neural control system for powered artificial legs that can recognize and exploit multi-scale user intent (e.g., general motor commands such as intended task vs. detailed motor commands such as intended joint motion) to modulate intrinsic (autonomous) control of multiple LL prosthetic joints for locomotor and nonlocomotor task performance. The goals are to support reverse-engineering of the neural control of human locomotion while creating innovative neural-machine interfacing (NMI) technology that enables users to control the dynamics of LL prostheses in a natural, adaptive and flexible way. Inspired by what is currently known about the neurological organization and function of the human motor control system, the PIs' approach is to design a novel NMI based on a combination of noninvasive scalp electroencephalography (EEG) and surface electromyography (EMG). The hypothesis is that fusion of low-level peripheral and high-level central neural control sources can achieve multi-scale user intent recognition with higher accuracy and more rapid response time than can be realized with either EEG or EMG alone. A hierarchical control scheme for powered LL prostheses, in which multi-scale user intent identified by the NMI modulates intrinsic (autonomous) control, will support intuitive and efficient prosthesis use in dynamic, multi-joint coordinated movements while significantly reducing the mental burden of the prosthesis user in locomotion because the cyclic motion is achieved autonomously (this is desired because we rarely think about knee and ankle control when walking). The PIs will also explore correlation across EEG and EMG signals, which may provide insight into neural adaption and the time course of cortical control during the initiation and generation of gait, including how the brain initiates walking and regulates motor output in anticipation of key events such as foot placement at landing or during stepping up and down, weight acceptance, and push-off into swing phase. Finally, the PIs will use translational research to validate their novel approach in patients with trans-femoral amputations (a high and challenging amputation level).<br/><br/>Broader Impacts: The PIs' long-term objective is to develop true bionic prostheses that feel and work just like real legs. Their approach in this project represents a paradigm shift in the control of lower limb wearable prosthetics. As such, project outcomes will directly impact both the Human-Robot Interaction and Brain-Machine Interface research communities. The findings will also be relevant to the neuroscience and rehabilitation communities, in that they will help elucidate the adaptive spinal cord and cortical contributions to human locomotion, while providing innovative and functional neuro-prosthetics solutions to improve the lives of lower limb amputees."
"1351212","CAREER: Implementing and Assessing Inexpensive, Effective Methods of Exploring Virtual Environments","IIS","Cyber-Human Systems, EXP PROG TO STIM COMP RES","07/15/2014","07/15/2014","Betsy Sanders","TN","Rhodes College","Standard Grant","Anthony Hornof","06/30/2019","$551,747.00","","sandersb@rhodes.edu","2000 North Parkway","Memphis","TN","381121624","9018433958","CSE","7367, 9150","1045, 7367, 9150","$0.00","Virtual environments (VEs) are computer-generated depictions of three-dimensional worlds in which humans can navigate to explore. VEs have been shown to be effective in a wide variety of applications and disciplines such as to train miners on safety procedures, educate doctors and nurses, provide therapy for post-traumatic stress disorder, and treat children with autism. Despite the abundance of research that shows their usefulness, however, VEs are not widely used. This is largely due to the fact that current VE systems remain expensive and complex to operate. However, with recent improvements in the fidelity and accuracy of relatively low-cost consumer-grade sensors and head-mounted displays (HMDs), it is now increasingly possible to create high-fidelity and yet low-cost immersive virtual reality systems. It should now be possible to make VEs useful to the general public to an extent that was not previously attainable. However, significant challenges remain, such as how to give a person a means of moving around and navigating in a VE, especially when the person needs to move in all possible directions including up and down, such as when exploring a virtual model of a molecule or the solar system. Another challenge is to better understand the capabilities and limitations of VEs as general learning environments.<br/><br/>This project will make it more feasible to create VE systems that are both high-fidelity and cost-effective, which will make it easier for educators, researchers, workers in many fields, and the general public, to use VEs to improve knowledge and livelihood. The project will make it more practical to use VEs for applications such as to assess the evacuation plans of a building before it is built, provide therapy for post-traumatic stress disorder, or teach children about topics such as molecular biology or planetary phenomena. It has been shown that skills or knowledge acquired in a VE transfers to the real world if the experience closely mimics the real world situation; this project creates a general purpose inexpensive VE in which the perceived experience mimics a similar real world experience as closely as possible, but using cost-effective computer systems. This project take place at a small liberal arts undergraduate college and will offer a number of opportunities for undergraduate student involvement in the research.<br/><br/>The research outlined in this proposal enables both undergraduates and researchers to contribute to the body of knowledge in computer science, human-computer interaction, virtual reality, cognitive science, perceptual psychology, and education. The project will expand and extend the frontiers of the foundational science needed to conduct science and solve practical problems using VEs. Specific project activities include: (a) Explore how human spatial orientation in VEs is both similar and different relative to the real world, by conducting a series of user experiments, in different environmental contexts, where the primary experimental condition is VE versus real world. These experiments will fill in a missing gap in the existing knowledge of VE spatial orientation. (b) Develop and evaluate techniques for navigation and exploration within a VE. The project will systematically build and evaluate different navigation methods in both human-scaled virtual environments as well as multi-scale environments. Multi-scale virtual environments encompass virtual models that have no natural human scale, such as a model of a molecule or the entire solar system. The project will systematically evaluate navigation techniques for this type of VE. (c) Evaluate the human perceptual implications of the specific type of VE hardware (motion trackers and visual displays) that are used, specifically by comparing inexpensive commodity hardware and to expensive specialized high-end hardware. The goal is to allow the navigation techniques developed earlier in the project to be implemented on commodity devices. (d) Apply the VE navigation system to an intelligent tutoring system. The project will build a virtual front-end to an existing intelligent tutoring system that covers an entire first-year college biology sequence, and evaluate the extent to which the resulting system permits students to learn biology concepts such as by interacting with 3D DNA molecules in a VE."
"0932272","CPS: Medium: Image Guided Robot-Assisted Medical Interventions","CNS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, CYBER-PHYSICAL SYSTEMS (CPS)","09/01/2009","06/25/2014","Nikolaos Tsekos","TX","University of Houston","Standard Grant","David Corman","02/28/2015","$1,400,395.00","Javad Mohammadpour, Zhigang Deng, Karolos Grigoriadis, Ioannis Kakadiaris","ntsekos@cs.uh.edu","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","1640, 7364, 7918","7918, 7924, 9216, 9218, HPCC","$0.00","The goal of this project is to develop a novel cyber-physical system (CPS) for performing multimodal image-guided robot-assisted minimally invasive surgeries (MIS). The approach is based on: (1) novel quantitative analysis of multi-contrast data, (2) control that uses this information to maneuver conformable robotic manipulators, while adjusting on-the-fly scanning parameters to acquire additional information, and (3) human-information/machine-interfacing for comprehensive appreciation of the physical environment. <br/><br/>The intellectual merit arises from the development of: (1) a CPS that relies on ""real"" and ""real-time"" data, minimizing parametric and abstracted assumptions, extracts and matures information from a dynamic physical system (patient and robot) by combining management of data collection (at the physical sensor site) and data analysis (at the cyber site), (2) ""smart sensing"", to control data acquisition based on disruptive or situation altering events, (3) control coordination by interlacing sensing, control and perception, and the incorporation of steerable tools.<br/><br/>The societal impact arises from contributions to a leap in MIS: from ""keyhole"" visualization (i.e., laparoscopy) to in-situ real-time image guidance, thereby enabling a wider range of MIS. This will directly benefit patients and their families (faster recovery/reduced trauma). Economic impact arises from the cost-effectiveness of MIS to the health care system, faster patient return to the workplace, and technology commercialization. The project will integrate research and education, diversity and outreach, by enhancing current and introducing new research-intensive courses in Cyber-physical Systems, Medical Imaging and Medical Robotics, and dissemination via trans-institutional collaborations, a comprehensive web site, multimedia web-seminars, and distribution to high schools."
"1429910","EAGER: Automatically Generating Formal Human-Computer Interface Designs From Task Analytic Models","IIS","Cyber-Human Systems","01/01/2014","01/30/2014","Matthew Bolton","NY","SUNY at Buffalo","Standard Grant","Anthony Hornof","08/31/2015","$149,976.00","","mbolton@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7367","7367, 7916","$0.00","The concurrent nature of human-computer interaction (HCI) can result in situations unanticipated by designers. Usability may not always be properly maintained or human operators may not be able to complete the task goals that a system was designed to support. This can result in poor adoption of the system, decreased productivity with its use, or unsafe operating conditions. Mathematical tools and techniques called ""formal methods"" exist for modeling and providing proof-based evaluations of different elements of HCI including the human-computer interface, the human operator's task analytic behavior, and usability. Unfortunately, these approaches require the creation of formal models of interface designs, something that is non-standard practice and prone to modeling error. This project will show that a formal-methods approach can be used to automatically generate formal human-computer interface designs that are guaranteed to adhere to usability properties and to support human operator tasks. Specifically, a system that uses the L* machine learning algorithm will be created that will generate formal interface designs using task analytic behavior models and formal representations of usability properties.<br/><br/>The researchers will implement an interface generation system, test its performance with a suite of benchmark examples, and evaluate its ability to generate an interface for a realistic application. To implement the generator, the researchers will first construct an oracle system capable of accepting or rejecting interface state transition sequences based on analyst-specified task models and usability properties. This oracle system will be connected to an implementation of the L* algorithm that will progressively learn a formal interface model by observing how generated sequences of interface state transitions are accepted or rejected by the oracle. Artificial test cases that exploit the different features of the system will be used to generate interface designs, and formal verification will be used to check that the designs exhibit the intended properties. The system will be used to generate the human-computer interface for programming a patient controlled analgesia pump, a medical device that automatically delivers pain medication to patients intravenously. The generated interface will then be compared against the formal interface design standard that exists for these devices.<br/><br/>The automatic generation of human-computer interface designs from task analytic models and usability properties constitutes a novel approach to user-centered design. By using this method in the creation of interfaces, designs will be guaranteed to always exhibit certain properties. This will potentially help ensure that designs will be accepted by users, improve the associated system's efficiency, and facilitate safer operation. The formal representation of user interfaces that result from the implementation of this method will also permit HCI designers to pursue formal analysis and verification of other interface properties, and will facilitate the automated generation of test cases for usability verification and certification purposes.<br/><br/>Broader Impacts: The proposed research has the potential to significantly change the way human-computer interfaces are designed. By guaranteeing that generated interfaces are always usable, this research could improve the usability and safety of user interfaces across many domains. The performance guarantees of the generated designs could allow development and testing times to be reduced, thus decreasing development and software costs. This work will also enhance the education and research experience of UIC's diverse engineering student body. The computational resources acquired for this work will be made available to student for research projects and study results will be incorporated into the curriculum of the PI's graduate and undergraduate courses. Project results will be presented at conferences by student researchers and published with open access in high quality journals. A dedicated website will be used to rapidly disseminate results and tools produced during this effort."
"1349462","CAREER: Effective Analysis, Exploration and Visualization of Big Flow Data to Understand Dynamic Flows","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","04/30/2014","Chaoli Wang","MI","Michigan Technological University","Continuing grant","Sylvia J. Spengler","04/30/2019","$143,882.00","","chaoli.wang@nd.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","CSE","7364","1045, 7364","$0.00","The ever-growing size and complexity of flow data produced from many scientific, engineering and medical simulations pose significant challenges which are not thoroughly addressed by existing visualization techniques. These challenges include computation, interaction, visualization and user challenges. Addressing the computation challenge is a central research focus and remains a prominent direction in the field, while the other challenges are often overlooked. The goal of this CAREER project is to address these less investigated challenges by pioneering a comprehensive framework toward effective visual understanding of flow fields. It contributes to the state of the art flow visualization by promoting an innovative database approach to shape-based field line modeling and classification, investigating new string-, sketch- and graph-based interfaces and interactions for flow field exploration, and exploring occlusion and clutter reduction through unconventional streamline repositioning and automatic tour generation. The general approach developed in this research is expected to substantially improve our ability to visually understand a wide spectrum of flow fields, ranging from the traditional application of fluid flows to new applications such as traffic flows, cash flows and message flows. This project will provide training for graduate and undergraduate students in the area of data visualization and scientific computing via capstone class projects. A pedagogical toolbox will be designed along with web-based resources to support teaching visualization classes through expressive demos, potentially benefiting universities nationwide with a similar teaching need. The PI will continue to attract underrepresented students through university and department outreach programs and engage local middle and high school students through summer youth programs. <br/><br/>This research tackles the fundamental challenges in visualizing large, complex three-dimensional steady and unsteady flow fields. Underlying the proposed work is a novel database approach to field line shape encoding, classification and interrogation. The PI will integrate and unify a variety of concepts from geometric modeling, computer vision and data mining to create robust visual characters and words from field lines for shape analysis and organization. Novel interfaces and interactions will be introduced to enable intuitive retrieval of partial field lines via textual and visual forms, and examination of hierarchical field lines and their spatiotemporal relationships in the transformed graph space. Innovative streamline repositioning for focus+context viewing and automatic tour for examining hidden or occluded flow features will be devised to move from clutter to clarity in the visualization. The success of this research will benefit a wide variety of applications within and beyond graphics and visualization, such as shape analysis, visual perception, database organization, game development, and visualization in education.<br/><br/>The PI will collaborate with scientists and researchers at university, industry and national labs, applying the proposed solutions to solve real-world problems. Research results will be evaluated through both domain expert reviews and formal user studies. Selected research outcomes will be integrated into user-engaging educational applications that will be run on tablet devices and delivered to the general public for wide dissemination. This CAREER project will build a solid foundation for addressing key challenges in flow visualization, and lead to multidisciplinary collaborations spanning atmospheric cloud, combustion chemistry and cardiovascular research. It will also produce fruitful deliverables, featuring the first-ever benchmark field line shape database, tutorials and workshops at premier visualization conferences, and pedagogical tools and game apps."
"1319432","III: Small: Enabling Declarative Querying and Analytics over Large Dynamic Information Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/14/2014","Amol Deshpande","MD","University of Maryland College Park","Continuing grant","Frank Olken","08/31/2016","$500,000.00","","amol@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923, 7364","$0.00","In this project, we are building a graph data management system and a suite of tools aimed at supporting real-time, historical, and analytics queries over very large, dynamic, heterogeneous, and noisy information networks. Examples of such information networks include social networks, communication networks, financial transaction networks, citation networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks, social contact graphs, and many more. Network data is most naturally represented as a graph, with nodes representing the entities and edges denoting the interactions between them. There is, however, a lack of established data management systems that provide declarative frameworks for querying and analysing such graph-structured data, especially very large volumes of heterogeneous, complex-structured, and rapidly changing data. <br/><br/>In this project, we are developing a set of formalisms that include: (a) a declarative query language for graph data, (b) a declarative framework for specifying complex, iterative network analysis tasks like entity resolution, link prediction, etc., and (c) a general-purpose neighborhood-centric distributed programming framework. Our declarative interfaces and the programming framework are based on ""Datalog"", a well-established database query language, providing the users or the analysts a consistent abstraction of the graph data to specify their queries or tasks. <br/><br/>We are designing a suite of techniques, algorithms, and index data structures, to efficiently store large volumes of time-evolving graph data, and to execute queries and analysis tasks over it. We are addressing the challenges in minimizing network communication overhead during distributed computation through designing new partitioning and adaptive replication techniques. We are also developing a compression-based approach to minimize the resources needed for graph processing, and a framework for extrapolating missing historical information to enable querying over incomplete historical traces. <br/><br/>Managing and reasoning about graph data is increasingly becoming crucial in many real-world application domains including social media, e-science, disease epidemics, and financial markets, to name a few. The frameworks and tools that we are developing make it easier and more intuitive for domain experts and analysts to process, analyze, and extract insights from large volumes of dynamic time-evolving graph data. Our system enables temporal evolutionary analytics over very large historical traces, and continuous and real-time analytics over highly dynamic graphs, thus enabling a rich class of applications that would not have been possible before. The declarative frameworks and the query language that we are developing have the potential to transform and streamline the highly fragmented research area of graph query processing and analytics. This project provides research opportunities for graduate and undergraduate students, and is aligned with several undergraduate and graduate courses offered by the PI. For further information, see the project web site at: http://www.cs.umd.edu/~amol/GrDB"
"1302164","RI: Medium: Collaborative Research: Object and Activity Recognition as the Maximum Weight Subgraph Problem with Mutual Exclusion Constraints","IIS","ROBUST INTELLIGENCE","09/01/2013","06/12/2014","Longin Jan Latecki","PA","Temple University","Continuing grant","Jie Yang","08/31/2017","$282,779.00","","latecki@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7495","7495, 7924, 9251","$0.00","It has been widely acknowledged that recognizing objects in images, and human activities in video - the basic problems in computer vision - can be significantly improved by accounting for object (activity) parts, context, and their spatiotemporal relationships. This is because these constraints facilitate resolving ambiguous hypotheses in the face of uncertainty. Since parts and contexts can be efficiently modeled by graphical models (e.g., Conditional Random Field), object and activity recognition are often formulated as probabilistic inference of graphical models. The project develops a new theoretical framework of graphical models that explicitly encodes high-order, spatiotemporal, hierarchical, and contextual interactions among objects (activities) as Quadratic Mutual-Exclusion Constraints (QMCs), for the purposes of object and activity recognition in images and video.<br/><br/>The key contributions of the project work include: 1) Approaches to view-invariant object and activity recognition; 2) Formulations of learning and inference of graphical models representing objects and human activities, as finding a maximum weight subgraph (MWS) under the QMCs; 3) Polynomial-time algorithms for solving the MWS problem subject to QMCs; and 4) Explicit performance bounds and theoretical guarantees of tightness and convergence of the proposed learning and inference algorithms. <br/><br/>The project framework encodes hard constraints from the domain of interest that have never been used in prior work, and uses principled, polynomial-time algorithms for learning and inference. The research of this project advances the state of the art in object and activity recognition, and enables new applications including video surveillance, retrieval from large datasets, and perception of mobile robots."
"1350521","CAREER: High-order Tensor Analysis for Groupwise Correspondence: Theory, Algorithms, and Applications","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","02/01/2014","03/06/2014","Haibin Ling","PA","Temple University","Standard Grant","Jie Yang","01/31/2019","$239,846.00","","hbling@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7453, 7495","1045, 7453, 7495","$0.00","Visual matching is a fundamental problem in computer vision (CV) and intensive research efforts have been devoted to building correspondence between a pair of visual objects. By contrast, finding correspondence among an ensemble of objects remains challenging. This project develops a unified framework for this problem and to apply the framework to different applications. The research establishes a close correlation between the classical multi-dimensional assignment (MDA) problem and low-rank tensor approximation. Such correlation paves a way of using high-order tensor analysis for groupwise visual matching that assumes an MDA formulation. Along the way, a series of algorithms are developed to address challenging issues such as computational efficiency and context modeling. These algorithms are then deployed to different tasks including simultaneous tracking of multiple targets, tracking of deformable structures, and batch alignment of visual ensembles. <br/><br/>This project can generate broad impact on areas of computer vision, computer graphics, combinatorial optimization, oral and maxillofacial radiology, image-guided intervention, physical therapy, security and defense, education research, etc. On the one hand, the fundamental importance of visual matching makes the project transformative to many other CV problems. On the other hand, the project benefits a wide range of fields outside the CV community through the use of interdisciplinary applications as test beds. This project also integrates tightly research and education with highlights on supervising students from underrepresented groups, combining computer vision and education research, and involving undergraduates in research."
"1318788","III: Small: Data Management for Real-Time Data Driven Epidemic Spread Simulations","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/14/2014","K. Selcuk Candan","AZ","Arizona State University","Continuing grant","Sylvia J. Spengler","08/31/2016","$325,144.00","Gerardo Chowell-Puente, Maria Luisa Sapino","candan@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7923, 7364","$0.00","The speed with which recent pandemics had immense global impact highlights the importance of realtime response and public health decision making, both at local and global levels. For instance, the SARS (Severe Acute Respiratory Syndrome) epidemic is estimated to have started in China in November 2002, had spread to 29 countries by August 2003, and generated a total of 916 confirmed deaths. A pandemic similar to the swine flu in 2009 is estimated to cost $360 billion in a mild scenario to the global economy and up to $4 trillion in an ultra scenario, within just the first year of the outbreak. Today, the key arsenal in the hands of decision makers who try to plan for and/or react to these outbreaks is software that enable model-driven epidemics and as well as the impacts of pharmaceutical and computer simulations for disease spreading. These software help predict geo-temporal evolution of non-pharmaceutical control measures and interventions, relying on data and models including social contact networks, local and global mobility patterns of individuals, transmission and recovery rates, and outbreak conditions. Unfortunately, because of the volume and complexity of the data and the models, the varying spatial and temporal scales at which the key transmission processes operate and relevant observations are made, today running and interpreting simulations to generate actionable plans are extremely difficult.<br/><br/>If effectively leveraged, models reflecting past outbreaks, existing simulation traces obtained from simulation runs, and real-time observations incoming during an outbreak can be collectively used for obtaining a better understanding of the epidemic's characteristics and the underlying diffusion processes, forming and revising models, and performing exploratory, if-then type of hypothetical analyses of epidemic scenarios. More specifically, the proposed epidemic simulation data management system (epiDMS) will address computational challenges that arise from the need to acquire, model, analyze, index, visualize, search, and recompose, in a scalable manner, large volumes of data that arise from observations and simulations during a disease outbreak. Consequently, epiDMS fill an important hole in data-driven decision making during health-care emergencies and, thus, will enable applications and services with significant economic and health impact.<br/><br/>The key observation is that the modeling and execution can be significantly reduced using a data-driven approach that supports data and simulation reuse in new settings and contexts. Relying on this observation, in order to support data-driven modeling and execution of epidemic spread simulations, this team will develop<br/><br/>+ an epidemic data and model store (epiStore) to support acquisition and integration of relevant data and models.<br/><br/>+ a novel networks-of-traces (NT) data model to accommodate multi-resolution, interconnected and inter-dependent, incomplete/imprecise, multi-layer (networks), and temporal (time series or traces) epidemic data.<br/><br/>+ algorithms and data structures to support indexing of networks-of-traces (NT) data sets, including extraction of salient multi-variate temporal features from inter-dependent parameters, spanning multiple simulation layers and geo-spatial frames, driven by complex dynamic processes operating at different resolutions.<br/><br/>+ algorithms to support the analysis of networks-of-traces (NT) datasets, including identification of unknown dependencies across the<br/>input parameters and output variables spanning the different layers of the observation and simulation data.<br/><br/>The proposed NT data model and algorithms will be brought together in an epidemic simulation data management system (epiDMS). For broadest impact, the proposed epidemic simulation data management system (epiDMS) will be designed in a way that interfaces with the popular Global Epidemic and Mobility (GLEaM) simulation engine, a publicly available software suit to explore epidemic spreading scenarios at the global scale. To achieve necessary scalabilities, epiDMS will employ novel multiresolution data partitioning and resource allocation strategies and will leverage massive parallelism."
"1017614","III: Small: Simultaneous Decomposition and Predictive Modeling on Large Multi-Modal Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","07/13/2011","Joydeep Ghosh","TX","University of Texas at Austin","Continuing grant","Sylvia J. Spengler","08/31/2014","$489,323.00","","ghosh@ece.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7364","7923","$0.00","Several modern data mining applications involve predictive modeling on large <br/>amounts of multi-relational data with added structures such as product <br/>hierarchies or social networks among customers. The broad goal of this proposal <br/>is to develop a comprehensive framework for predictive modeling on large, <br/>heterogeneous, multi-relational data based on ""Simultaneous Decomposition and <br/>Prediction"" (SDaP) approaches that iteratively partition the problem into more <br/>homogeneous and manageable pieces while concurrently building multiple <br/>predictive models, one for each piece. Such approaches lead to simpler and more <br/>accurate solutions. The proposed algorithmic strategies that determine how many <br/>models to learn and where they should apply, which data to discard and which to <br/>keep, how to learn multiple related tasks defined on multi-modal data, and how <br/>to scalably implement the solutions on distributed computers, provide practical <br/>solutions to certain real-world problems for which current learning and data <br/>mining techniques are severely lacking. Application domains of ecology, bio-<br/>informatics, market research and web mining are specifically identified and <br/>targeted. <br/><br/>There are two broad research impacts of the proposed project: (a) it further <br/>vitalizes the research in data mining towards better algorithms for predictive <br/>modeling on rich and heterogeneous multi-modal data, and (b) provides and <br/>promotes the SDaP approach as a fundamental data analysis tool across multiple <br/>disciplines. The PI will organize a workshop and offer a tutorial at major data <br/>mining conferences to foster and promote research on various aspects of SDaP <br/>analysis. Moreover, the curated complex datasets and software developed under <br/>this project will be shared with the scientific community via a public web site <br/>as part of the proposed one-of-a-kind multi-relational data benchmarking <br/>facility. The PI will further develop a novel graduate course on Modeling and <br/>Analysis of Complex Data. Outreach modules that illustrate data analysis <br/>concepts and capabilities at levels appropriate for pre-college students will <br/>also be developed. For further information see the project web site at the URL:<br/>http://www.ideal.ece.utexas.edu/projects/sdap/"
"1218156","RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","09/01/2012","03/26/2013","Haibin Ling","PA","Temple University","Standard Grant","Jie Yang","08/31/2015","$264,928.00","","hbling@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7364, 7495","7495, 7923, 9251","$0.00","Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair. On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br/><br/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms."
"1218437","III: Small: Entity Selection and Ranking for Data-Mining Applications","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/14/2014","Evimaria Terzi","MA","Trustees of Boston University","Continuing grant","Sylvia J. Spengler","08/31/2015","$499,958.00","","evimaria@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364","7923, 7364","$0.00","Expert-management portals like linkedin.com, odesk.com and guru.com are indicative sites that allow people to advertise their work or set of skills to the broader public. For example, linkedin features more than 120 million members which allows potential employers, collaborators, etc. to discover individuals or groups of individuals with the desired expertise. Similarly, review-management sites like Amazon or Yelp collect large number of reviews about products or services. For example, kindle has more than 30,000 reviews on Amazon. Naturally, users cannot go over all these reviews and are helped significantly by the identification of a small subset of reviews that is sufficiently informative. Finally, as online social and media networks grow in importance as sources of news and other information, there is an urgent need for tools that automatically identify and recommend important nodes of the network, that specific users may need to follow to fully exploit the power of online social media. In each of these scenarios, given a collection of entities (e.g., reviews about a product, experts that declare certain skills, network nodes or edges), the goal is to identify a subset of important entities (e.g., useful reviews, competent experts, influential nodes respectively). <br/><br/>Existing work on recommender systems attempts to identify important entities either by entity ranking or by entity selection. Entity-ranking methods associate a a score with each entity; They ignore the redundancy between the highly-scored entities. Entity-selection methods try to overcome this drawback by evaluating the desirability of a group of entities taken together; They attempt to identify the best subset of entities, while ignoring other subsets of entities that may be equally-good or almost as good as the best subset. Against this background, this project aims to overcome the drawbacks of existing entity selection and entity ranking methods through a synergistic integration of both into a common framework that allows entity-ranking based on entity selection and entity-selection that based on entity ranking. In the resulting framework, the scores of individual entities are determined in part by the number of good groups of entities they can be part of; and good group of entities consist of entities with high scores. <br/><br/>The main challenge addressed by this work is how to explore the solution space of combinatorial problems in order to identify subsets of entities that participate in many good solutions. The resulting new practical methods for exploring the solution space of combinatorial problems find applications related to expert management systems, management of online product reviews, and network analysis (including physical and social networks). The project also offers enhanced opportunities for research-based training of graduate and undergraduate students at Boston University. All of the research results including publications, software, and data will be freely disseminated to the broader research and educational community through the project website at: http://www.cs.bu.edu/~evimaria/sel-and-ranking.html."
"0954125","CAREER: Graph Information System: Deciphering Complex Networks","IIS","INFO INTEGRATION & INFORMATICS","04/01/2010","07/14/2014","Xifeng Yan","CA","University of California-Santa Barbara","Continuing grant","Frank Olken","03/31/2015","$495,536.00","","xyan@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","1045, 1187, 7364, 9215, HPCC","$0.00","Graphs and networks are ubiquitous, encoding complex relationships <br/>ranging from chemical bonds to social interactions. Hidden in these<br/>networks are the answers to many important questions in biology,<br/>business, and sociology. In order to analyze complex networks, users <br/>have to master sophisticated computing and programming skills. It <br/>indeed becomes a pain point for many scientists and engineers.<br/><br/>This project is to change the state of the art by developing a <br/>general graph information system, which is able to address the needs <br/>of searching and mining complex networks. Real-life networks are <br/>complex, not only having topological structures, but also containing <br/>heterogeneous contents and attributes associated with nodes and <br/>edges. The mixture of structures and contents raises two challenges <br/>that require new solutions for smarter and faster graph analysis. <br/>First, new types of graph search and mining operations, such as graph <br/>aggregation, graph association, and graph pattern mining, are <br/>emerging. Second, when graphs become complex and large, most of <br/>existing graph mining algorithms cannot scale well. <br/><br/>This project addresses these challenges and performs a <br/>comprehensive study of a general graph information system. <br/>The system includes three major components: complex graph search, <br/>graph pattern mining, and graph indexing. <br/>It covers emerging structure queries in social, <br/>biological, and information networks, new graph mining operators <br/>such as graph summarization and association, and innovative indexing<br/>methodologies, e.g., differential graph index.<br/><br/>This research is tightly integrated with education through student <br/>mentoring and curriculum development. Publications, software and <br/>course materials resulted from this project are disseminated on the <br/>project website: http://www.cs.ucsb.edu/~xyan/gis.html."
"0954254","CAREER: Primitives and Policies for Complex Behavior in Human and Robotic Hands","IIS","Cyber-Human Systems","07/15/2010","05/31/2014","Veronica Santos","AZ","Arizona State University","Continuing grant","Ephraim P. Glinert","06/30/2015","$554,349.00","","vjsantos@ucla.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","1045, 7218, 1187, 9102, 9215, HPCC","$0.00","Each human fingertip has approximately 2000 tactile sensors. Stimulation of these sensors triggers reactive grip responses that are mediated by the spine. In comparison to the dexterous capabilities of the human hand, robotic manipulation capabilities in unstructured environments are crude. When controlled by a human operator, robotic manipulators are further limited by restricted information flow (command and sensing) at the human-machine interface. All human-machine systems, from telesurgery robots to neuroprostheses, must address the critical issue of communication delays which can range, depending upon the distance between the human and the machine, from less than a second to hours. For artificial manipulation, even delays of one second can result in adverse events such as increased bleeding from an open incision or increased frustration and eventual disuse of an advanced prosthesis. Taking a cue from biology, autonomous low-level reflexes that detect stimuli and implement a corrective response in robotic hands without a human in the loop could buy time for communication, information processing, and decision-making in human-machine systems. A long-term research objective of the PI is to advance robotic manipulation with grip reflex algorithm primitives, artificial tactile sensors, and generalizable grasp policy algorithms inspired by the human hand. In this project, she will focus on understanding what drives low-level reactive grip responses, how human-machine performance can benefit from the implementation of similar autonomous primitives, and what grasp policies can be learned by a robotic hand. Contributions of this work will include characterization of the reactive grip responses in human hands, development of human-inspired grip reflex algorithm primitives and tactile sensors for robotic hands, and development of learning algorithms that autonomously extract general grasp policies for robotic hands. Research outcomes will enhance our fundamental understanding of grasp primitives in human hands that provide a foundation for dexterous manipulation, and improve the functionality of robotic hands through grip reflex algorithm primitives and learning algorithms that extract grasp policies.<br/><br/>Broader Impacts: This research will transform artificial manipulation by enabling robotic grasp with dynamic control of adduction/abduction degrees-of-freedom and use of biomimetic tactile sensors, thereby revolutionizing robotic manipulators intended for unstructured, access-limited, or unsafe environments (including space, underwater, military, rescue, surgery, assistive, rehabilitative, and prosthetic) that require robustness in the face of uncertainty, control delays, or limited information flow at the human-machine interface. In conjunction with her research the PI will work to engage students at an early age in the exploration of the rich field of robotics. To that end, she will develop hands-on instructional modules for teaching elementary and middle school students about robotics using low-cost materials and deploy them locally for the benefit of students under-represented in science, technology, engineering, and mathematics fields. She will also develop an interactive exhibit for a science museum on robotic hands deploy it locally for the benefit of school-aged children and the general public in the metropolitan Phoenix area."
"1117303","RI: SMALL: Collabrative Research: Investigations of the Role of Dorsal versus Ventral Place and Grid Cells during Multi-Scale Spatial Navigation in Rats and Robots","IIS","ROBUST INTELLIGENCE","09/01/2011","06/06/2013","Alfredo Weitzenfeld","FL","University of South Florida","Standard Grant","Kenneth C. Whang","08/31/2015","$264,430.00","Jean-Marc Fellous","aweitzenfeld@usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139745465","CSE","7495","7495, 7923, 9251","$0.00","Spatial navigation is a complex cognitive process that relies on robust and adaptive mechanisms to relate current and future spatial positions to specific locations in the environment. The goal of this project is to provide a better understanding of spatial navigation by integrating information obtained from experimental studies in rats, computational models, and experiments on robots that will test new hypotheses on how these mechanisms work. <br/><br/>The hippocampus and medial entorhinal cortex (MEC) are major brain regions involved in mammalian spatial navigation. While the role of place cells in the hippocampus has been extensively studied, there are still many open questions on the functional role of MEC grid cells and their interaction with the hippocampal place cells. Of interest to this proposal is the recent finding that grid cells are organized in an orderly fashion along the dorso-ventral axis of the MEC, with dorsal grids being much more tightly spaced than ventral ones. The investigators hypothesize that this multiscale organization endows the navigation system with a coding mechanism that will inherently achieve robustness with respect to external perturbations such as obstacles or unexpected changes in visual cues. In order to evaluate this hypothesis the investigators will develop computational and robotic models while systematically performing experiments in rat in which the dorsal or ventral portions of MEC or hippocampus will be inactivated. They will introduce new types of mazes in which the spatial frequency of the trajectories will be controlled. This work will contribute to better spatial navigation in robotics by: (1) providing a robotic testbed to evaluate hypotheses on the role of the entorhinal cortex and (2) providing biologically plausible models for robust spatial navigation under uncertain and dynamic environments. These models will suggest alternatives to classical probabilistic methods commonly used in robot Simultaneous Localization And Mapping paradigms. This work will also contribute to studies of spatial navigation in rats by: (1) showing the usefulness of robots in providing a physical testbed beyond pure computational modeling, and (2) exploiting the shorter cycle of robot experimentation to produce maze configurations that are optimal for testing specific hypotheses in rat experiments."
"1422669","RI: Small: Engineering and Learning Visual Representations","IIS","ROBUST INTELLIGENCE","07/15/2014","07/14/2014","Stefano Soatto","CA","University of California-Los Angeles","Standard Grant","Jie Yang","06/30/2017","$456,617.00","","soatto@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7495, 7923","$0.00","Visual data, including video imagery, conveys ""information"" about objects of interest within the scene: Shape, material, identity, relations, etc. However, it is also highly redundant, and subject to variability that has little to do with the properties of the scene of interest, but instead depend on the sensor, the vantage point, and the nature of the illuminant, etc. This project addresses the question of determining what function of imaging data should be inferred and stored, that is, as ""informative"" as possible for a class of tasks such as object or scene detection, localization, recognition and categorization, and at the same time as ""compressed"" as possible, and insensitive to nuisance variability. Such a function is called a Representation. This research has pedagogical value, by framing seemingly unrelated methods as different approximations of an ideal Representation, thus facilitating the educational process in Computer Vision. This is further expected to facilitate the design of better Representations, and therefore improved algorithms for visual recognition (detection, localization, recognition, and categorization) systems, with impact in a range of applications from autonomy (e.g., robotic navigation and surveillance) to interaction (e.g., assisted surgery and augmented reality).<br/><br/>The project frames the problem of inferring optimal task-specific Representations in terms of the Information Bottleneck Principle, and addresses issues of computability, approximation, and dimensionality reduction within this framework. It also addresses questions of ""learnability,"" to determine whether a generic learning architecture can approximate an optimal representation. The Information Bottleneck is a generalization and relaxation of the notion of minimal sufficient statistic, where complexity constraints and task relevance are explicitly taken into account. The challenge is that modeling the generative process for visual data entails complex geometry (surface shape), topology (occlusions), photometry (material reflection, illumination), and dynamics (motion) with the object of interest living in infinite-dimensional spaces. Thus, the Information Bottleneck is difficult to even formalize, let alone instantiate, compute, and optimize. The project focuses on developing approximations of the Information Bottleneck that are tractable and yet enjoy performance guarantees."
"1302448","III: Medium: Meta-analysis reinterpreted using causal graphs","IIS","INFO INTEGRATION & INFORMATICS","07/15/2013","07/14/2014","Eleazar Eskin","CA","University of California-Los Angeles","Continuing grant","Sylvia J. Spengler","06/30/2017","$832,229.00","Judea Pearl","eeskin@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7364, 7924","$0.00","Statistical conclusions from research studies may often be misleading due to a variety of reasons including small sample sizes for the studies or confounding factors which are unknown to the investigators of the study. One way to reduce the possibility of misleading conclusions is to combine the results of multiple research studies using a technique referred to as ""meta-analysis."" Meta-analysis is one of the most widely used techniques to infer knowledge from data in science. The idea behind meta-analysis studies is that the combined statistical conclusions from multiple research studies reflect the information in all of the studies and are more likely to be accurate. The conclusions from meta-analyses are considered ""better"" or ""more likely to generalize"" than conclusions from single studies. However, this notion is not well formalized and formalizing this question is a goal of this project. In addition, existing meta-analysis methods do not take into account any knowledge of the similarities and differences between the studies. Taking advantage of these similarities and differences can improve the effectiveness of meta-analysis.<br/><br/>This project takes advantage of recent developments in the area of ""causal inference"" which is the study inferring cause and effect relationships from data. These types of inferences utilizes a type of graph called a causal graph which graphically represents cause and effect relationships. This project develops an alternate framework for meta-analysis based on a novel type of causal graph, a selection graph. A selection graph formally represents the similarities and differences between the studies. This project provides a unifying framework and powerful powerful methodology for meta-analysis. The methods developed in this project are applied to genetic studies where meta-analyses have discovered thousands of variants involved in common human disease in the past few years.<br/><br/>Causal graphs have had a major impact on the way causality is taught and understood in cognitive science, statistics, and the health and social sciences. The proposed research promises to have similar impacts by transforming the approach to meta-analysis, one of the work horses of statistical inference in the physical, life and social sciences. The resulting techniques will be used to perform meta-analyses of genetic studies which can lead to the discovery of variation involved in disease. The results of the project, including publications, software, data sets, and course materials will be made freely available through the project web site: http://zarlab.cs.ucla.edu/causal-meta-analysis/."
"1319912","HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative","IIS","Cyber-Human Systems","08/01/2013","07/14/2014","Robert Young","NC","North Carolina State University","Continuing grant","William Bainbridge","07/31/2016","$352,696.00","","young@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","7367, 7923","$0.00","The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments. Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure. The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves. Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br/><br/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br/><br/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines. Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process."
"1320909","HCC: Small: Effective Augmented Reality Depth Representation Methods and Accuracy Evaluations Inspired by Medical Applications","IIS","Cyber-Human Systems","09/15/2013","07/14/2014","J. Edward Swan II","MS","Mississippi State University","Continuing grant","Anthony Hornof","08/31/2016","$498,233.00","","swan@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7367","7367, 7923, 9150","$0.00","Augmented reality (AR) systems, which are computer systems that enhance the viewing of physical objects in the world with computer data, are currently held back from widespread use for many real-world applications because of the unsolved human-computer interaction problem of how to accurately convey to a person how far away from that person a computer-generated object is intended to appear. People using AR systems routinely misjudge the depth of AR-presented objects. This is especially true for AR objects that should appear to be located behind opaque occluding surfaces; in this case AR should produce an ""x-ray vision"" perceptual experience that makes the occluding surface appear to become transparent. The perceptual phenomena that underlie this problem relate to (a) conflicting depth cues that naturally arise with AR technology, especially incorrect occlusion cues in optical ""x-ray vision"" AR, (b) conflicting findings from techniques that have been developed to measure depth perception within reaching distance, and (c) the role of practice and feedback in training to correct these depth misjudgments.<br/><br/>This project will evaluate AR depth representation methods and explain the underlying phenomena, with an emphasis on medical AR tasks and applications. The project will develop and evaluate a head-worn haploscope to allow researchers to study the depth cues of accommodation and vergence AR. The project will create and evaluate vergence-based methods for rendering AR information in depth; that is, techniques in which people can control the appearance of computer data inside of a physical object by rotating their eyes as is needed to look at near and far objects. The researchers on this project will collaborate with experts on the use of AR for medical applications to develop new vergence-based techniques for AR ""x-ray vision"" in the medical domain. <br/><br/>Broader Impacts: Vergence-based AR applications have the potential to improve health outcomes for a broad array of medical procedures, and also to improve human capabilities in task domains such as manufacturing and equipment maintenance. This project will hasten the timeframe for successfully developing and deploying such applications. Students working on this project will be trained in an interdisciplinary context that rigorously studies the intimate interplay between computer graphics and human perception. The interdisciplinary and human-centered aspects of the project will help to recruit students who might otherwise be less likely to gravitate to computer science."
"1017389","III: Small: Collaborative Research: Detection and Presentation of Community and Global Event Content from Social Media Sources","IIS","INFO INTEGRATION & INFORMATICS","09/15/2010","09/15/2010","Luis Gravano","NY","Columbia University","Standard Grant","Sylvia J. Spengler","08/31/2015","$249,551.00","","gravano@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7364","7923","$0.00","Social media sites such as Twitter, Facebook, YouTube, and Flickr host an ever-increasing amount of user content captured or produced in association with real-world events, from presidential inaugurations to community-specific events. Unfortunately, the existing tools to find, organize, and present the social media content associated with events are extremely limited. This project will address critical end-to-end information processing and presentation methods that will transform public access to real-world event information from social media sources. In particular, this work will increase the digital presence of currently underrepresented communities and address their information needs: for these communities, events are often not covered by mainstream media, but are increasingly available on social media services. As a distinctive characteristic, the project will draw on several research areas, namely, information retrieval and databases, human-computer interaction, and social media, thus contributing to educating multidisciplinary students. The PIs will continue to include undergraduate students and students from underrepresented populations in the research.<br/><br/>The project will result in new data analysis and visualization techniques for event-based information tasks, addressing human and computational factors in social media systems to handle vast collections of noisy, user-contributed content of widely varying structure and quality. To enable effective browsing, search, and presentation of event content, this work will use the wealth of social media documents to address several fundamental problems. The first<br/>problem is the detection of events in repositories of social media content. Such content, increasingly posted by users in real time, is noisy and highly heterogeneous, but can help in the early detection of a wide range of events of all sizes. The second problem is the comprehensive identification of content related to detected or known events, currently fragmented across social media sites and often hard to find and collect. The third problem is content presentation, which requires the development of novel presentation and visualization techniques for social media event content. The amount of content<br/>available even for a single event can be overwhelming and hinder data exploration and sense-making. <br/><br/>The project will create new tools that will transform the viewing experience of the event information. These tools will allow users to create and share personalized views of the event data as a story-telling practice. Finally, as a main outcome, the data used in the research will be made available to other researchers whenever possible. Moreover, another main outcome will be a publicly available prototype system based on this research, designed to help connect computing and information science challenges to the activities and natural interests of a diverse set of users."
"1219254","III: Small: Modeling, Querying and Mining of Dynamic Graphs","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/14/2014","Ambuj Singh","CA","University of California-Santa Barbara","Continuing grant","Sylvia J. Spengler","08/31/2015","$514,318.00","","ambuj@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7923, 9251","$0.00","Many applications generate data that can be modeled as graphs: Biological networks, social networks, ecological networks and food-webs, among others. Traditional graph theory and most current research in graph modeling, querying, and mining concentrates on problems where the graph structure is inherently static and does not change with time. But networks in the real world are dynamic in nature with a wide range of temporal changes. While the topology of networks such as social networks and transportation networks undergoes gradual change (or evolution), the content (information flow, annotations) changes more rapidly. <br/><br/>Against this background, this project aims to develop a set of scalable querying and mining tools for dynamic graphs by integrating techniques from databases, data mining, and algorithms. The first research thrust examines inherent properties for characterizing dynamic graphs, specifically the dynamic reachability structure of nodes. It also investigates high-fidelity methods for generating dynamic graphs based on these properties. The second research thrust aims to develop summarization techniques for dynamic graph structures. These techniques can be used to compress large graph datasets, to make predictions about future values, and to query information cascades under partial observation. The third research thrust aims to develop techniques for mining significant dynamic subgraphs under different constraints of connectivity such as fixed subgraph structure, connected subgraphs, and smooth subgraphs. The goal is here to find anomalous patterns in dynamic graph datasets using a statistical characterization of background behavior. The final research thrust reconsiders the first three research thrusts from the point of view of content and topic models in order to understand the relationship between content of a message and its flow in a network. The developed methods will be evaluated using a number of real-world data sets including email datasets such as Enron, re-tweeting activity data sets on Twitter, Facebook wall posts, and transportation networks. <br/><br/>An important result of this work is a theoretically well-founded and empirically verifiable framework for modeling, querying and mining of dynamic graphs. Aspects of dynamic behavior in which both the structure of networks and their content (information flow, annotations, etc.) change will be considered. The study of such dynamic networks and how information flows through them is essential to developing a theory of dynamic networks and their evolution. This work helps answer questions such as power-law applies to dynamic behavior, whether content of a message can predict its flow and vice versa, whether anomalies in a dynamic network can be mined effectively by building either an empirical summary or a generative model. Robust open source tools based on the developed algorithms will be released for research, academic and non-profit endeavors. The research is expected to yield new techniques in graph algorithms, graph databases, and graph mining, and realize a collection of tools that can be used by scientists, and ultimately lead to a theory for dynamic graphs. <br/><br/>Broader Impacts: The proposed project will integrate research and education by introducing the results of the project into a graduate seminar, and a graduate course on information management. The project will support a postdoctoral researcher and train graduate students. The project offers enhanced opportunities for research-based training of graduate and undergraduate students, including members of under-represented groups e.g., females in Computer Science at the University of California at Santa Barbara. For high school students, the CNSI Apprentice Research Program at UCSB brings in high school students every summer. The open source implementations of algorithms resulting from this work will be freely disseminated to the community."
"1218692","RI: Small: Learning Open Domain Semantic Parsers","IIS","ROBUST INTELLIGENCE","08/01/2012","07/30/2012","Alexander Yates","PA","Temple University","Standard Grant","Tatiana D. Korelsky","07/31/2015","$425,821.00","","yates@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7495","7923","$0.00","Supervised semantic parsers, which learn to map language to relational data, perform poorly on texts that differ in vocabulary or style from the training text, and on databases that differ from the database used in training. Today's semantic parsers have only been tested on narrowly-circumscribed domains like geography, but the ideal semantic parser would generalize to the many and incredibly diverse relational databases available on the Web. <br/><br/>This project develops semantic parsers that approach this ideal system. The project divides the overall task into two parts: mapping named-entities in text to database constants in any domain, and mapping full sentences and questions to logical forms written in a variant of the lambda calculus. Techniques for resolving named-entities make use of domain-independent contextual information around the named-entity for disambiguation. To connect words like ""directed"" with a database relation listing directors of movies, the project relies on schema-matching techniques from database integration. The system extracts a relational view of a corpus, and then generates alignments between these extracted alignments and the fixed relational structure of existing databases. The project uses transfer-learning and co-training approaches to estimate parameters for statistical models for named-entity disambiguation and schema matching across domains and databases.<br/><br/>The project is expected to produce new methods and software systems for connecting human language with relational data. It enables language-based queries to the broad array of structured data available on the Web, making it easier to find information than ever before."
"1253538","CAREER: Combinatorial Inference and Learning for Fusing Recognition and Perceptual Grouping","IIS","ROBUST INTELLIGENCE","10/01/2013","07/15/2014","Charless Fowlkes","CA","University of California-Irvine","Continuing grant","Jie Yang","09/30/2018","$193,525.00","","fowlkes@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","1045","$0.00","When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate surfaces while recognition can help resolve ambiguities in grouping based on local image cues. This project is developing a computational framework that fuses top-down information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. This research includes (1) identifying local image features that provide cues to grouping and figure-ground, (2) developing libraries of composable detectors that capture the appearance of objects, parts and their spatial relations, and (3) designing models and efficient inference routines that explicitly reason about occlusion and the binding of image regions and contours into object shapes.<br/><br/>Integrated models of grouping and recognition have direct significance to expand the computer vision capabilities of robotics and assistive technologies that must operate in complex, cluttered environments. The framework being developed also has applications in automating biological image analysis where top-down shape information are useful in resolving noisy local measurements. The computational tools developed by the project along with dissemination and educational efforts are aimed at forming an interdisciplinary bridge between biological imaging and cutting-edge computer vision research."
"1360971","III: Small: Probabilistic Hashing for Efficient Search Learning","IIS","INFO INTEGRATION & INFORMATICS","08/28/2013","07/14/2014","Ping Li","NJ","Rutgers University New Brunswick","Continuing grant","Sylvia J. Spengler","08/31/2016","$475,149.00","","pingli@stat.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7364","7364, 7923","$0.00","Numerous applications involve massive, high-dimensional datasets. For example, the search industry routinely deals with billions of web pages, where each page is often represented as a binary vector in 2^64 dimensions. In computer vision, images are often represented as non-binary vectors in millions of dimensions. Algorithms which are capable of efficiently compressing, retrieving, and mining these datasets are of high practical importance. Mathematically rigorous and computationally efficient hashing methods will be developed to dramatically reduce ultra-high-dimensional datasets. These algorithms will be integrated with a variety of learning techniques including classification, clustering, near-neighbor search, matrix factorizations, etc. <br/><br/>The project builds on and extends minwise hashing, and b-bit minwise hashing which are standard hashing techniques in search applications. The project aims to (i) rigorously analyze b-bit minwise hashing and develop, analyze, and apply significantly more efficient (and more accurate) to problems in search and learning; (ii) develop a unified framework of probabilistic hashing which essentially consists of one permutation followed by (at most) one random projection; (iii) develop a unified theory of summary statistics under a variety of engineering constraints (storage space, computational speed, indexing capability, adaptation to streaming, etc.). <br/><br/>Hashing algorithms developed under this framework are expected to be substantially much more efficient and more accurate than existing popular algorithms such as random projections and minwise hashing. This general framework allows the design algorithms to accommodate many different data types (sparse or dense data, binary or real-valued data, static or streaming data), many different engineering needs (computing inner products or lp distances, kernel learning or linear learning), and different storage requirements. Anticipated results of the proposed research include rigorous and computationally efficient hashing algorithms for dealing with ultra-high-dimensional datasets, the integration of the resulting hashing algorithms into with a variety of learning techniques for classification, clustering, near-neighbor search, singular value decompositions, matrix factorization, etc; and rigorous experimental evaluation of the resulting methods on big (e.g., TeraByte or potentially PetaByte) data of the order of up to 2^64 dimensions. <br/><br/>Broader Impacts: Effective approaches to building predictive models from extremely high dimensional data can impact many areas of science that rely on machine learning as the primary methodology for knowledge acquisition from data. The PI's education and outreach efforts aim to broaden the participation of women and underrepresented groups. The publications, software, and datasets resulting from the project will be freely disseminated to the larger scientific community."
"1332234","Computational Audition Workshop","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE, Science of Learning Activities","06/15/2013","06/06/2013","Barbara Shinn-Cunningham","MA","Trustees of Boston University","Standard Grant","Tatiana D. Korelsky","05/31/2015","$27,000.00","Joshua McDermott, Daniel Ellis","shinn@cns.bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7252, 7495, 7704","7495, 7556","$0.00","This grant will support a two-and-a-half-day long workshop on Computational Audition, bringing together top scientists from a broad range of disciplines. Computational audition, the study of how information can be derived from sound in both biological organisms and in machines, is an emerging field. The topic is broad, encompassing a diverse group of scientists including neuroscientists, psychologists, psychophysicists, speech scientists, computer scientists, and engineers. The field of computational audition has the potential to be a model of interdisciplinary research with a great deal of intrinsic intellectual interest. It is primed to become a hotbed of scientific growth, and this meeting will help the field evolve toward that goal.<br/><br/>Broader Impacts<br/>Computational audition is important both for developing new technological applications as well as for finding new clinical treatments (because understanding the basis of normal hearing will help treat hearing impairment). And yet by comparison to many other related fields, its potential is underexplored. For instance, research on human and machine perception has been dominated to a large extent by vision, with hearing neglected by comparison. This workshop will nurture the development of interdisciplinary research in computational audition that will capitalize on this potential."
"1319551","III: Small: Rapid screening of interacting ligands and proteins","IIS","INFO INTEGRATION & INFORMATICS","08/15/2013","07/14/2014","Daisuke Kihara","IN","Purdue University","Continuing grant","Sylvia J. Spengler","07/31/2016","$327,706.00","","dkihara@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7923, 7364","$0.00","Computational infrastructure for efficient and accurate searching of bio-molecules from various databases is foundation of any modern biology, biochemistry, pharmacology, and biotechnology. The goal of this project is to develop computational methods and databases that allow fast, real-time screening of various types of three dimensional (3D) structural data of proteins and their interacting molecules in a seamless fashion. The structure data to be searched include 3D protein structures and protein complexes, predicted protein structures, low-resolution protein complexes solved by cryo-electron microscopy, small chemical ligand molecules, and drug molecules. The project employs a mathematical representation of biomolecules that can quickly compare and search biomolecules that have similar global and local surface shape and properties with a query molecule. The project will further expand the applicability of the molecule representation for searching interacting molecules by identifying complementarity of shapes and surface properties. The methods to be developed in the project allow biologists to quickly identify potentially interacting proteins to a query protein, which will help generating testable hypothesis of molecular mechanisms of diseases through building molecular networks. Moreover, the methods will also enable quick searching of ligand molecules and potential drug molecules that fit to a target protein.<br/><br/>Biology has entered the informatics era, when combining different types of big omics data are routinely required to reach a systems-level understanding of biological function of molecules and cells. In order to effectively glean useful structural data for biological studies, there is a strong need for computational methods that can quickly and seamlessly search for different types of structural data. Establishing efficient methods for searching biomolecular shape and physicochemical properties is essential for capitalizing on the large number of efforts directed towards determining molecular and cellular structures by structural genomics and other projects. The project will develop computational methods and databases to screen various types of protein structures and their interacting molecules seamlessly and quickly. Using the molecular representation proposed in the project, global and local shapes and surface properties (electrostatic potential, hydrophobicity) of proteins and ligand molecules can be compared ery fast. In contrast to conventional 3D structure search methods for biomolecules that take hours or even more than a day to finish a database search, the methods to be developed will allow real-time searches against large databases. Thus, structural analysis will become as convenient as sequence database searches for biology researchers. The 3D molecule search methods will be applied to identify interacting molecules for a query protein, ligand molecules that would bind to a pocket region of the query protein as well as interacting proteins. Knowing molecular interactions is critical for understanding functions of proteins. The key innovations include 1) finding interacting molecules to proteins, i.e. pocket-ligand interactions and protein-protein interactions; 2) local surface comparisons for functional annotations; Developed methods will be implemented into 3D-Surfer, a one-stop website for biomolecular shape retrieval.<br/><br/>The proposed approach can be applied for other types of rapid shape and property comparisons, such as 2D and 3D medical images, microscope images, geographical landscapes, and face recognition. Graduate and undergraduate students in biological sciences and computer science will be trained in cross-listed courses among several departments. Several existing programs at Purdue for recruiting minority students and undergraduate students will contribute to broad participation in the project. Overall the proposed project leverages Purdue University?s efforts in interdisciplinary computational life science and engineering."
"1353606","CAREER: A Scalable, Declarative, Imprecise Database Management System","IIS","INFO INTEGRATION & INFORMATICS","07/01/2013","07/14/2014","Christopher Re","CA","Stanford University","Continuing grant","Frank Olken","04/30/2016","$268,339.00","","chrismre@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7364","1045, 1187, 7364","$0.00","The unprecedented amounts of data available to individuals, companies, governments, and scientists promises to revolutionize the way entertainment, business, governance, and science operate. And while data are cheap and plentiful, much of this data is lower quality than the precise data that has been managed for the last 30 years. Building an application that processes this imprecise data is difficult: it requires that developers handle both standard data management challenges (e.g., concurrency and scalability), while at the same time coping with imprecise and incomplete data, which is typically done using statistical or machine learning techniques (e.g., interpolation and classification). The Hazy project addresses this challenge by building a system that integrates the paradigms of relational database management systems with statistical machine learning techniques. This project conducts the following major tasks: (I) designing a language to integrate these techniques with standard SQL, (II) proposing an algebra to implement this language along with support for automatic optimization (similar to a standard RDBMS), and (III) discovering techniques to efficiently maintain the statistical models as the underlying data are changed or updated. The end goal is a system that makes it as easy to develop scalable applications that use imprecise data as it is to develop their precise counterparts. Hazy allows users to process larger amounts of data with more sophisticated statistical processing than ever before. In turn, this enables new applications in a divese set of areas, such as life and physical science sensing applications, health-care and environmental monitoring, and enterprise-based and Web-based information extraction.<br/><br/>The research of this project is used to develop the data and infrastructure for new practicum-style courses that are under development at the University of Wisconsin-Madison. In addition, this infrastructure will be used as part of an outreach effort to enable high school students to gain access to data analysis tools. The source code of Hazy is released into open source and the results are disseminated on the project Web site (http://www.cs.wisc.edu/hazy/)."
"1320617","III: Small: Collaborative Research: Conflicts to Harmony: Integrating Massive Data by Trustworthiness Estimation and Truth Discovery","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","07/14/2014","Jiawei Han","IL","University of Illinois at Urbana-Champaign","Continuing grant","Sylvia J. Spengler","07/31/2016","$211,115.00","","hanj@cs.uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364","7923","$0.00","Big data leads to big challenges, not only in the volume of data but also in its dynamics and variety. Multiple descriptions about the same set of objects or events from different sources unavoidably lead to data or information inconsistency. Then, among conflicting pieces of data or information, it is crucial to tell which data source is reliable or which piece of information is correct. Accurate information is referred to as the truth and the chance of a source providing accurate information is denoted as source reliability or trustworthiness. The objective of this project is to detect truths without supervision, by integrating source reliability estimation and truth finding. A unified framework is developed to model complex trustworthiness factors, heterogeneous data types, incremental and parallel computation, and source and data dependencies so that truth and trustworthiness can be inferred from multiple conflicting sources of heterogeneous, disparate, correlated, gigantic, scattered, and streaming data.<br/><br/>This project makes tangible contributions to data integration, information understanding and decision making, and benefits many applications where critical decisions have to be made based on the correct information extracted from diverse sources. Research results of this project are integrated into course materials and projects, and into training students and new generation researchers, especially female and minority students. For further information about this project, please refer to the project website: http://www.cse.buffalo.edu/~jing/truth.htm"
"1319578","III: Small: Integrated Digital Event Archiving and Library (IDEAL)","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/14/2014","Edward Fox","VA","Virginia Polytechnic Institute and State University","Continuing grant","Maria Zemankova","08/31/2016","$500,000.00","Kristine Hanna, Donald Shoemaker, Andrea Kavanaugh, Steven Sheetz","fox@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7364","7923, 7364","$0.00","The Integrated Digital Event Archive and Library (IDEAL) system addresses the need for combining the best of digital library and archive technologies in support of stakeholders who are remembering and/or studying important events. It extends the work at Virginia Tech on the Crisis, Tragedy, and Recovery network (see http://www.ctrnet.net) to handle government and community events, in addition to a range of significant natural or manmade disasters. It addresses needs of those interested in emergency preparedness/response, digital government, and the social sciences. It proves the effectiveness of the 5S (Societies, Scenarios, Spaces, Structures, Streams) approach to intelligent information systems by crawling and archiving events of broad interest. It leverages and extends the capabilities of the Internet Archive to develop spontaneous event collections that can be permanently archived as well as searched and accessed, and of the LucidWorks Big Data software that supports scalable indexing, analyzing, and accessing of very large collections. Through a new model-based approach to intelligent focused crawling, it improves the quality (e.g., accuracy, coverage, and elimination of noise) of collections of webpages so as to ensure comprehensiveness, balance, and low bias, as is needed for scholarly study of historically important events by social scientists. It incorporates a range of visualization capabilities in support of key stakeholder communities, including archivists, librarians, researchers, scholars, and the general public. IDEAL connects the processing of tweets and webpages, combining informal and formal media, to automatically detect important events, as well as to support building collections on chosen general or specific topics. It supports integration of multiple types and at multiple levels, including key models about the event it is crawling (event models), the sources of information about the event (source models), the mechanisms used for disseminating information about the event (publishing venue models), and the entities related to the event (society /organization models). Integrated services include topic identification, categorization (building upon special ontologies being devised), sentiment analysis, and visualization of data, information, and context.<br/><br/>The IDEAL website (http://www.eventsarchive.org) supports searching, browsing, analyzing, and visualizing of event collections (of both tweets and webpages), as well as access to project software, methods, findings, publications, and other results. Usage is encouraged of the integrated system along with a growing number of collections, as well as of particular tools such as for focused crawling, which should aid curators to avoid non-relevant content while including a broader range of sources, improving significantly upon current crawling and archiving methods. Important data and information on events of interest are saved rather than lost, helping preserve our history and culture, in support of public interest, education, policy making, historical analyses, and comparative studies. Students studying sociology, human-computer interaction, digital libraries, information retrieval, computational linguistics, multimedia, and hypertext are gaining experience and contributing in scholarly studies, algorithms, software, interfaces, and big data handling."
"1017362","III-Core:Small: MoveMine: Mining Sophisticated Patterns and Actionable Knowledge from Massive Moving Object Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","07/08/2011","Jiawei Han","IL","University of Illinois at Urbana-Champaign","Continuing grant","Frank Olken","08/31/2015","$500,000.00","","hanj@cs.uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364","7923","$0.00","This research project is to investigate principles and methods for uncovering sophisticated patterns and actionable knowledge from massive moving object data. Thanks to the rapid progress and broad adoption of sensor, GPS, wireless network, and other advanced technologies, moving object data have been accumulating in unprecedented scale. However, moving object data could be dynamic, sparse, scattered, and noisy, and patterns and knowledge to be mined could be deeply hidden, sophisticated, and subtle. The MoveMine project investigates effective and scalable methods for mining various kinds of complex patterns from dynamic and noisy moving object data, finding multiple interleaved periodic patterns, and performing in-depth multidimensional analysis of moving object data. It integrates and extends multiple disciplinary approaches derived from spatiotemporal data analysis, data mining, pattern recognition, statistics, and machine learning. The study takes bird and animal movement data and traffic data as the major sources of data for investigation. However, developed methods can be applied to the analysis of many other kinds of moving object data for environmental study, traffic control, law enforcement, and protection of homeland security. The study also addresses the issue of ensuring privacy and security protection while developing powerful pattern and knowledge discovery mechanisms. The research results are to be published in various research and application forums and be integrated into the educational programs at UIUC. The progress of the project and the research results are also disseminated via the project Web site (http://www.cs.uiuc.edu/homes/hanj/projs/movemine.htm)."
"1065397","RI: Medium: Collaborative Research: Learning Representations of Language for Domain Adaptation","IIS","ROBUST INTELLIGENCE","04/01/2011","02/20/2014","Alexander Yates","PA","Temple University","Continuing grant","Tatiana D. Korelsky","03/31/2015","$705,982.00","Yuhong Guo","yates@temple.edu","3340 N. Broad Street","PHILADELPHIA","PA","191405102","2152048691","CSE","7495","7924, 9251","$0.00","Supervised Natural Language Processing (NLP) systems perform poorly on domains and vocabulary that differ from training texts. A growing body of empirical and theoretical work points to the features used by traditional NLP systems as the culprit for domain-dependence and for the inability to generalize to previously unseen words. <br/><br/>This project is the first to systematically investigate representation-learning as a technique for improving performance on domain adaptation. It explores latent-variable language models ? including Factorial Hidden Markov Models, dependency parsing models, and deep architectures ? as techniques for extracting novel features from text. The resulting representations yield similar features for distributionally-similar words, thereby allowing generalization to words not seen during training of a classifier. The project also explores novel procedures for training a language model, which incorporate Web-scale ngram statistics as substitutes for standard statistics used in unsupervised training.<br/><br/>Language users are extraordinarily inventive, and new domains of discourse appear constantly, such as in specialized areas of science and technology. By building on top of the representations produced by this project, NLP systems can improve in accuracy on new domains and on Web text, bringing applications like the Semantic Web closer to reality. For resource-poor languages and domains, the project can help reduce the cost of annotating texts by reducing the need for broad coverage in the training texts. By involving the diverse student bodies at Temple University and Philadelphia-area high schools, the project helps to broaden participation in computer science research by underrepresented groups."
"0905381","RI: Medium: Collaborative Research: The Effect of Subglottal Resonances on Machine and Human Speaker Normalization","IIS","ROBUST INTELLIGENCE, PERCEPTION, ACTION & COGNITION","09/01/2009","03/18/2014","Abeer Alwan","CA","University of California-Los Angeles","Standard Grant","Tatiana D. Korelsky","09/30/2015","$639,694.00","","alwan@ee.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495, 7252","7495, 7924, 9102, 9215, HPCC, 6890","$639,694.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>Despite large acoustic differences in the speech of various talkers, humans are generally able to understand each other quickly and easily. The mechanisms by which humans map such variability onto a set of phonemes has been the subject of research for more than 50 years. This ""speaker normalization"" problem has generally been thought of in terms of normalizing the formant frequencies of a particular speaker with a reference set of formants. In this project, a novel approach to speaker normalization is explored, in which not formants but subglottal resonances<br/>(SGRs) are normalized. SGRs have previously been shown to define a set of frequency bands within which formants may vary, yet retaining the same phonemic vowel quality. Normalizing SGRs (and associated frequency bands) therefore reduces formant variability in an effective way. In this project, effects of SGR normalization on automatic speech recognition<br/>(ASR) performance are evaluated for both adult and child speakers of English and Spanish. In parallel, effects on human speech perception in multi-talker conditions are explored. Results are expected to improve ASR performance and shed light on human speech production and perception. The project will result in speech databases (including direct recordings of SGR acoustics) and ASR tools, which are critically useful for research in speech production, perception, speaker identification, and speech processing algorithms for cochlear implants and multi-lingual ASR. The collaboration in Engineering, Linguistics, Speech & Hearing, and Psychology facilitates a multidisciplinary learning environment.<br/>Publications, results, databases, and tools will be disseminated to the research community."
"1420894","RI: Small: Global, Stable Descriptors of Visual Motion","IIS","ROBUST INTELLIGENCE","07/15/2014","07/11/2014","Carlo Tomasi","NC","Duke University","Standard Grant","Jie Yang","06/30/2017","$450,044.00","","tomasi@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7923","$0.00","This project studies the fundamental mathematics of how to describe the motions visible in a video recording. The developed techniques allow accurately delineating the boundaries between image regions that move differently from each other. The resulting description of motion can be used as input for recognizing activities in video. Applications include surveillance, traffic monitoring, video retrieval, robot navigation, assistance to human vehicle drivers, medical diagnosis of movement pathology, assessment of performance in sports or other activities, sign language recognition, and automatic video annotation.<br/><br/>Current approaches define visual motion as a point-to-point mapping across video frames. However, image data in poorly textured areas constrain point motion weakly if at all. Since these areas are pervasive, computing point-to-point motion requires strong and often arbitrary assumptions about the scene. This project redefines image motion as a curve-to-curve mapping. The curves in question are iso-contours, that is, the curves in each video frame along which image brightness is constant. Techniques from computational topology are used and extended to describe how iso-contours in one frame connect to those in the next, forming surfaces in spacetime. The concept of persistence from computational topology, together with a new notion of feature longevity, allow separating ephemeral changes caused by image noise or lighting artifacts from features that reoccur consistently over time. The research can provide a global, topological, stable description of image motion. The research team evaluates the techniques on both existing video and on sequences newly recorded with specialized cameras to isolate different technical challenges in turn. Other researchers can use these sequences for further experimentation when they are ready to be published."
"0914868","RI:Small Time-Based Language Modeling","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC","10/01/2009","02/18/2014","Nigel Ward","TX","University of Texas at El Paso","Continuing grant","Tatiana D. Korelsky","09/30/2014","$505,999.00","David Novick, Olac Fuentes","nigel@utep.edu","ADMIN BLDG RM 209","ElPaso","TX","799680587","9157475680","CSE","7495, 1640","7495, 7923, 9215, HPCC, 9251, 1640, 9102","$0.00","Speech recognizers all include a component for predicting, based on the past context, what words are likely to appear next. Today these components, known as language models, operate at the symbol level, abstracted away from the details of how and when the words are spoken. Spoken language, however, is not just a symbolic or mathematical object, but is produced and understood by human brains, with specific processing constraints, and these can directly affect what happens when in dialog.<br/><br/>This project is developing language models and ``dialog models'' that explicitly use the information in the timings of words. Inspired by psychological research suggesting that dialog and language behaviors are the result of multiple simultaneously active cognitive processes, the working assumption is that the words likely to be spoken at a given time depend, probabilistically, on the elapsed time since various reference points: for example since the speaker began talking, since the speaker's last disfluency, since the listener's last back-channel, etc. Statistical analyses of large corpora of human-human spoken dialogs, with machine learning methods, are revealing patterns and regularities which are being used to build language models with improved predictive power.<br/><br/>These language models implicitly represent some aspects of dialog dynamics, with the potential to lead to an integrated understanding of the nature of dialog as a human ability. These improved language models are also likely to improve speech recognition accuracy, enabling the development of spoken language systems that are more accurate, more efficient, and more useful."
"1117829","III: Small: Efficient Query Processing in Large Search Engines","IIS","INFO INTEGRATION & INFORMATICS","08/15/2011","08/16/2011","Torsten Suel","NY","New York University","Standard Grant","Maria Zemankova","07/31/2015","$499,852.00","","torsten.suel@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7364","7923","$0.00","The largest web search engines now receive hundreds of millions of queries per day that need to be answered in fractions of a second on collections of tens of billions of web documents. In order to process all these queries, search engines consume increasing amounts of hardware and energy resources. This project focuses on developing new algorithms, index structures, and other software techniques for scaling query processing in search engines, that is, techniques that allow queries to be executed faster and on larger data sets using fewer hardware and energy resources. <br/><br/> Research activities in this project focus on three main approaches. First, the project studies how index size and access time can be reduced through improved index compression techniques. Second, work on new early termination techniques considers how the top results for a query can be computed without exhaustive traversal of the index structures for the query terms, for simple ranking functions such as BM25 or Cosine, and for the more complex functions with many features used by current web search engines. Finally, the project explores general techniques for query optimization in information retrieval (IR) systems, inspired by the significant body of work on query optimizers in database systems. <br/><br/> Web search engines are a multi-billion dollar industry and a crucial component of the internet. Techniques resulting from this project are expected to benefit this industry by reducing the hardware cost and energy consumption of large-scale search services. Results will be disseminated through publications in major conferences and journals, tutorials at conferences, distribution of software libraries, contributions to existing software tools such as Lucene. This project provides research and educational opportunities for graduate and undergraduate students and prepare them for later work at companies, research labs, or universities. Web site (http://cis.poly.edu/westlab/queryproc/) provides more information about this project."
"1409003","RI: Medium: The Foundations of a Manipulation Repertoire","IIS","ROBUST INTELLIGENCE","07/15/2014","07/11/2014","Matthew Mason","PA","Carnegie-Mellon University","Continuing grant","Satyandra Gupta","06/30/2018","$253,562.00","Michael Erdmann, Siddhartha Srinivasa","matt.mason@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7924","$0.00","This project is based on two theses: (1) autonomous robotic manipulation requires a large repertoire of actions; and (2) autonomous manipulation does not decouple into separate arm and hand functions. The project's goal is to establish the principles and techniques to endow a robot with a large repertoire of manipulative actions, many of them involving an intimate coordination of arm and hand. The approach is to develop these principles and techniques using physics-based models as well as machine learning of empirical models. The project is developing and testing these principles and techniques by attacking several challenge tasks. The work is organized to address three primary challenges: (1) identifying actions; (2) modeling actions; and (3) orchestrating actions. For the first challenge, identifying actions, the project is adapting previous physics-based manipulation research, along with ordinary robotic engineering of behaviors inspired by humans and existing robotic systems. For the second challenge, modeling actions, the project is augmenting physics-based models work with empirical stochastic modeling drawn from previous applications of machine learning. For the third challenge, orchestrating actions, the project is adapting previous work on sensor-based planning and control. The project's expected broader impacts includes more capable robots, which will simplify deployment, enable new applications and improve existing applications, which ultimately serves to improve productivity, services, and national economic competitiveness."
"1322406","CAREER: Analyzing and Exploiting Meta-information for Keyword Search on Semi-structured Data","IIS","INFO INTEGRATION & INFORMATICS","12/25/2012","08/07/2013","Yi Chen","NJ","New Jersey Institute of Technology","Continuing grant","Maria Zemankova","02/28/2015","$305,001.00","","yi.chen@njit.edu","323 DOCTOR MARTIN LUTHER","Newark","NJ","071021982","9735965275","CSE","7364","1045, 7364, 9216, 9251, HPCC","$0.00","The goal of this research project is to provide high-quality keyword search results on semi-structured data in XML format. To address the challenge of handling inherent ambiguity in keyword search, fundamental techniques and an effective search engine are developed that exploit the meta-information in the data in order to infer user search intention and to achieve high search quality. The project includes novel research on the following key areas: (1) Query Result Generation: identifying relevant nodes in XML data and composing atomic and intact query results, each of which represents an object of the inferred user search goal; (2) Query Result Presentation: developing techniques for result ranking, snippet generation, and result clustering, in order to help users quickly find the most relevant results; (3) Advanced Queries and Data Models: supporting expressive search options and handling XML data with rich constraints; and (4) Efficiency: developing techniques for performance optimization, including indexes, materialized views, and top-k query processing. Furthermore, an axiomatic evaluation framework is initiated for formally reasoning about XML keyword search strategies.<br/><br/>The success of the project will advance the state-of-the-art of keyword search on XML data, enhance the research and education infrastructure in this area, and have broader impacts on both general public as well as scientific communities for information discovery. This research is intergrated with education through curriculum enhancement, student advising, workshops as well as outreach programs. Publications, software and course materials that are resulted from this project will be disseminated via the project website (http://web.njit.edu/~ychen/xseek.htm)."
"1115417","III: Small: RUI: Improving Data Quality and Data Mining Using Noisy Micro-Outsourcing","IIS","INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","08/01/2011","03/25/2014","Shengli Sheng","AR","University of Central Arkansas","Continuing grant","Sylvia J. Spengler","07/31/2015","$308,628.00","","ssheng@uca.edu","201 Donaghey Avenue","Conway","AR","720350001","5014505061","CSE","7364, 9150","7364, 7923, 9150, 9229, 9251","$0.00","Machine learning currently offers one of the most cost-effective approaches to building predictive models (e.g., classifiers for categorizing the millions of messages, news articles, and blogs that are generated every day). However, the effective use of machine learning methods in such settings is limited by the availability of a training corpus (i.e., a representative set of instances that have been labeled with the correponding categories). In domains where labeled data are scarce or expensive to acquire, there is an urgent need for cost-effective approaches to selectively acquiring labels for data samples used to train predictive models using machine learning. <br/><br/>This project explores novel techniques that take advantage of the low cost of micro-outsourcing using systems such as Amazon's mechanical Turk, to engage a large number of workers from around the world for acquiring the labels of instances to be used to construct the training corpus. There is currently little understanding of how to utilize the multiple noisy labels obtained using micro-outsourcing. There is a need for advanced techniques for taking advantage of the low cost of micro-outsourcing in order to improve data quality and the quality of models built from the available data. It explores novel approaches for utilizing multiple labels given to an instance by different labelers. It also extends active learning techniques for active selection of samples to be labeled to take into account the multi-sets of labels that have been already obtained from a pool of labelers. <br/><br/>Advances in techniques for active selection of data instances to be labeled in a micro-outsourcing setting can significantly improve the quality of data used to build predictive models in a broad range of applications, including gene annotation, image annotation, text classification, sentiment analysis, and recommender systems, where unlabeled data are plentiful yet labeled data are sparse. The project will provide research opportunities for students at University of Central Arkansas, a primarily undergraduate institution and help expand the STEM pipeline. Additional information about the project can be found at: http://sun0.cs.uca.edu/~ssheng/."
"1443033","ABI: Toward Advanced Understanding in Biological Systems - Support for Training at the Intelligent Systems for Molecular Biology Conference, Boston, MA, July 11-15, 2014","DBI","ADVANCES IN BIO INFORMATICS, INFO INTEGRATION & INFORMATICS","07/15/2014","07/10/2014","Theresa Gaasterland","CA","International Society for Computational Biology","Standard Grant","Anne Maglia","06/30/2015","$40,000.00","","gaasterland@ucsd.edu","SDSC/UCSD MC0505","La Jolla","CA","920930505","8588220852","BIO","1165, 7364","7556","$0.00","Funds will support student training at the 2014 Intelligent Systems for Molecular Biology (ISMB) conference, which will be held in Boston, Massachusetts, July 11-15, 2014. The ISMB conference is the largest and most high profile annual meeting of scientists working in computational biology and bioinformatics. The program presents the latest research methods and results developed through the application of computer programming to the study of biological sciences. A broad range of sub-disciplines covering the field is represented at the meeting. Each year novel research output using cutting-edge technologies is presented. The conference serves as a forum for the presentation of novel algorithmic methods and new ways to apply bioinformatics tools to the most important current challenges in biology and the biomedical sciences.The conference has a rigorous focus on computation and methodology coupled with outstanding biology. Leading experts conduct training sessions at ISMB and provide participants with opportunities to learn new tools and techniques not easily gained elsewhere. Students have opportunities to interact with senior scientists on the forefront of technology development. Students and scientists return to their labs from ISMB equipped to apply what they have learned, advance their own research efforts, and initiate investigations in new areas.<br/><br/>Students will gain the latest skills in bioinformatics and computational biology. Individuals trained in the latest techniques in these fields are in extremely high demand in a diverse range of research centers and industries including pharmaceutical, agricultural, environmental, consumer products, biotech, software, hardware, and service companies. Bioinformatics skills have become integral to the analysis of the large volumes of biomedical and agricultural data currently being generated in the life sciences, and to understanding complex biological systems. ISMB has become a forum for reviewing the state-of-the-art advances in the many fields of the growing discipline of computational biology, for introducing new directions, and for announcing technological breakthroughs. ISMB and ISCB continue to contribute to the advancement of biology and build the bridges necessary to support research developments in life sciences. For more information about the conference, visit http://www.iscb.org/ismb2014."
"1320538","RI: Small: Bayesian Thinking on Your Feet---Embedding Generative Models in Reinforcement Learning for Sequentially Revealed Data","IIS","ROBUST INTELLIGENCE","08/01/2013","07/10/2014","Jordan Boyd-Graber","MD","University of Maryland College Park","Continuing grant","Tatiana D. Korelsky","07/31/2016","$317,050.00","Hal Daume","jbg@umiacs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7923","$0.00","Machine learning algorithms cannot ""think on their feet"". When applied in practice, most approaches developed using traditional machine learning techniques wait for an entire input to arrive before they are able to provide an answer or react. While sufficient for some tasks, this is inappropriate for a large class of problems that require more immediate or incremental responses. This project develops new algorithms to address machine learning problems that require an algorithm to ""think on its feet"". These algorithms combine guesses about what input is likely appear in the future with actions that the algorithm should take now to provide useful, effective output in a timely fashion.<br/><br/>One application of these new methods is simultaneous translation. This is the problem of taking problem of ""observing"" a sentence one word at a time in a foreign language, such as German, and providing a real-time running translation in a target language (like English). This is particularly difficult for language pairs that have significant syntactic divergences, such as object-verb order differences between foreign languages like German or Japanese (verb final) and target languages like English (verb medial). Like human simultaneous translators, machine learning algorithms must learn to predict the words that will appear at the end of a sentence. The project facilitates this prediction using a framework that combined word prediction and machine translation system.<br/><br/>The project also uses the newly developed algorithms in academic settings to provide significant outreach to high school students and undergraduates, particularly in underrepresented communities."
"0910908","HCC: Large: Intelligent Tracking Systems that Reason about Group Behavior","IIS","INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","09/01/2009","03/05/2014","Margrit Betke","MA","Trustees of Boston University","Standard Grant","Ephraim P. Glinert","08/31/2015","$2,858,292.00","Thomas Kunz, Stan Sclaroff, Joyce Wong","betke@cs.bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364, 7367","6890, 7925, 9215, 9216, HPCC","$2,858,292.00","""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).""<br/><br/>The ability to reason about the complexity of living organisms in diverse environments is one of the hallmarks of intelligence. In this project the PI and her interdisciplinary team of investigators will design computer vision algorithms for intelligent tracking of large groups of living individuals in three-dimensional space. She will develop specific systems for tracking groups of microorganisms, bats, birds, and humans. And she will formulate machine learning methods for analyzing group behavior, specifically the conditions for formation and dispersal of groups, and the interactions of individuals within a group. An important innovative aspect of this research is the systematic and comprehensive approach to reasoning about the motion of large groups of living organisms observed in video data, independently of whether they happen to be humans, animals, or cells. Previous efforts in this area have typically focused on studying the behavior of a single type of organism, and on testing theories of behavior based predominately on simulations, without the appropriate analytical tools to automatically explore and quantify the vast number of visual data sets. This project, on the other hand, will base research findings on the analysis of thousands of trajectories of individual group members moving in 3D space. To this end, the PI and her team will collect video data in the field and in public spaces to ensure optimal data capture conditions. They will use these data to develop robust solutions for the problem of matching hundreds of individual bats, birds, or people from frame to frame. They will generate stereoscopic reconstructions of movement trajectories based on multiple calibrated cameras, and use machine learning to model group behavior and mine the trajectory data. Finally, they will compare the findings of their reasoning system against current theories about the formation of groups and the interactions of individuals within a group. A similar, systematic research strategy will be employed to address understanding of the behavior of single cells. The team will design microscope imaging protocols, develop solutions for the segmentation and tracking of individual cells, and use statistical learning techniques to discover patterns and correlations in the behavior of the cells on physiologically relevant substrates.<br/><br/>Broader Impacts: Understanding the processes by which groups of animals and microorganisms behave is crucial to the effective conservation of populations and ecosystems and the management of cellular environments. Project outcomes will advance knowledge across the fields of computer vision, artificial intelligence, behavioral ecology, and biological engineering, and will provide new tools for answering urgent economic and ethical questions, for example about the mortality of birds and bats in wind energy facilities."
"1116414","III: Small: Scalable Integration and Analysis of the Provenance of Diverse Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","08/08/2011","Ashish Gehani","CA","SRI International","Standard Grant","Frank Olken","07/31/2015","$485,868.00","","ashish.gehani@sri.com","333 RAVENSWOOD AVE","MENLO PARK","CA","940253493","6508592651","CSE","7364","7923","$0.00","As scientists begin to get access to data sets that are accompanied by automatically generated provenance records, they are faced with the challenge of integrating and analyzing this metadata. Independent sources are likely to have captured provenance at distinct levels of abstraction, have different levels of completeness, used separate sets of identifiers to refer to the same artifacts, processes, and agents, and introduced dissimilar semantics in the annotations.<br/><br/>This research studies the problem of semi-automatically integrating and analyzing the provenance of scientific data that originates from diverse sources, with independent annotation schema, semantics that may overlap only partially, representations at different granularity, and incomplete characterizations of the activity being recorded. In particular, (i) it develops a formal framework for combining provenance, (ii) provides an extensible software system for provenance ingestion, integration, and analysis, and (iii) creates canonical provenance data sets of various sizes, granularity, and domains, that can be utilized for comparison of provenance integration and analysis algorithms.<br/><br/>Maintaining a record of all the transformations the data undergoes becomes increasingly critical as the length of the analysis grows and the age and diversity of sources of the data grow. Such provenance metadata can address a range of queries. For example, in situations where only derivative data is preserved, a provenance record can help validate claims about the procedures used to obtain the final results. Concerns about whether privacy-sensitive data (such as information from patient records) has been used in contravention to legal or security policies can be alleviated by checking for violations in the provenance records.<br/><br/>More information about the project can be found at: http://spade.csl.sri.com"
"0964197","RI: Medium: Quantifying Causality in Distributed Spatial Temporal Brain Networks","IIS","ROBUST INTELLIGENCE","09/15/2010","09/15/2010","Jose Principe","FL","University of Florida","Standard Grant","Kenneth C. Whang","08/31/2015","$550,000.00","Panagote Pardalos, Andreas Keil","principe@cnel.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7495","7495","$0.00","A key hurdle in studies of brain function is to be able to measure not only what signals are correlated with one another, but also how they are causally related. Correlation quantifies linear dependence, while causality is capable of distinguishing which brain area is leading the correlated counterparts; causality puts an arrow into correlation. Causality is a difficult problem in data analysis and here a novel measure of conditional statistical dependence to evaluate causality is proposed. The ultimate practical goal is to elucidate the principles of cognitive processing and provide online cognitive feedback to human subjects performing complex tasks. <br/><br/>The objective of this project is to use a recently developed paradigm for electroencephalogram (EEG) quantification based on periodic visual stimulation to improve the signal to noise ratio of visual stimulation on a pre-determined EEG frequency band (here around 10 Hz). The goal is to develop advanced signal processing techniques based on instantaneous frequency (Hilbert transform) to quantify the instantaneous amplitude of a visual stimulus in 32 channels over the scalp. <br/><br/>A recently developed measure of local statistical dependence in the joint space called correntropy will be utilized to evaluate the dependency among instantaneous amplitude time series collected over the scalp. The maximum value of correntropy is a measure of statistical dependence, which is the first step towards causality. To achieve a causality measure, conditional dependence will be evaluated by extending correntropy to conditional correntropy, first for triplets of variables and them to subspaces of arbitrary dimensions. Correntropy is a nonparametric measure of dependence; hence, the new method will be compared to linear and nonlinear Granger causality methods implemented in reproducing kernel Hilbert spaces.<br/><br/>These algorithms will be tested on data collected from human subjects in a study of affective visual perception. The goal is to study and quantify the re-entry hypothesis of emotional perception -- that re-entrant modulation originating from higher-order cortices is responsible for enhanced activation in the occipital cortex when emotionally arousing stimuli are perceived. The signal processing and statistical methods developed here will provide a way to identify dependent EEG channels and causal relationships amongst them during the presentation of the stimulus, effectively tracing the flow of neural activity from the stimulated visual areas to frontal areas and back to the visual cortex."
"1216758","III: Small: Advancing the Scientific Understanding of Bullying Through the Lens of Social Media","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/22/2012","Xiaojin Zhu","WI","University of Wisconsin-Madison","Standard Grant","Sylvia J. Spengler","08/31/2015","$499,866.00","Amy Bellmore","jerryzhu@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7364","7923","$0.00","Bullying has been recognized as a serious national health issue. Traditional approaches to the scientific study of bullying are hindered by data acquisition. For example, the standard approach has been to conduct personal surveys in schools. Due to its relatively small sample size and low temporal resolution, neither the true frequency of bullying over the population nor the evolution of bullying roles can be satisfactorily studied. The traditional approaches are also very labor intensive. <br/><br/>Social media has developed to the point where it contains enough signal about bullying. This project develops novel machine learning models that automatically monitor and analyze publicly available social media data to understand bullying. These machine learning models reconstruct hidden bullying episodes from a sequence of social media posts. They automatically determine who participated in which bullying episode as what role. In addition, this project conducts human studies on bullying in school and in social media in parallel, by collecting self-report surveys by school-aged children and their social media posts simultaneously. Such studies correlate the traditional psychological approach and social media data on bullying. Taken together, the project will provide significant new scientific data toward understanding, intervention, and helping policy-making regarding bullying."
"1349837","EAGER: Exploring Adapting Language Technology Across a Network of Domains","IIS","ROBUST INTELLIGENCE","09/01/2013","08/19/2013","Jacob Eisenstein","GA","Georgia Tech Research Corporation","Standard Grant","Tatiana D. Korelsky","08/31/2015","$100,000.00","","jacobe@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7916","$0.00","Much of the most successful software for processing and understanding natural language is based on learning from labeled examples. However, applications to diverse genres such as social media and historical documents have demonstrated the limitations of this approach since the application data differs dramatically from the training examples. Labeling training datasets for each new genre is prohibitively expensive. Methods that adapt the software between the original source domain and the target --- for example, from 20th century newspapers to Shakespearean drama --- are an attractive alternative and an active research area. However, language does not naturally fall into a few source and target domains; rather, documents exist in a multidimensional field of similarity and difference, based on metadata attributes such as the date of publication. In addition, binary source/target adaptation ignores vast amounts of unlabeled data that may bridge the gap between, say, the 20th and 17th centuries, or between text from the Wall Street Journal and text entered on Twitter.<br/><br/>This EAGER award explores a new approach to adapting language technology to new application domains. Using explicit document metadata such as date of authorship (for historical documents) or product type (for online reviews), documents are situated in a network of fine-grained domains. Micro-adaptation is then performed between adjacent nodes in the network, which are expected to be more similar to each other than (distant) the source and target domains. These micro-adaptations can then be propagated across the domain graph, yielding an adaptation path from source to target. Empirical evaluations will compare this approach to the current state-of-the-art practices: adapting directly from source to target, and adapting from the source to a broader set of non-source documents. In addition, a theoretical analysis will identify conditions under which this approach is likely to succeed.<br/><br/>Language technology already impacts society by facilitating the retrieval, organization, and summarization of information, but its inability to transcend a small set of training domains is one of the most critical obstacles to more widespread adoption. Key application domains such as social media, patient medical records, and legal documents differ substantially from available training corpora, and the development of effective technology for these areas depends on bridging the domain gap. In addition, the sociocultural variation found in online language dramatically reduces the performance of state-of-the-art systems, creating a ""language gap"" between standard and minority dialects. This research is not tied to any specific language processing task; rather, it promises to build a more robust foundation that can apply across many tasks, bringing the benefits of language technology to new users and settings."
"1117707","RI: Small: Algebraic and Spectral Structure of Data in High Dimension","IIS","ROBUST INTELLIGENCE","07/01/2011","06/29/2011","Mikhail Belkin","OH","Ohio State University","Standard Grant","Todd Leen","06/30/2015","$450,000.00","","mbelkin@cse.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7495","7923","$0.00","Obtaining information from data is one of the most fundamental problems of modern science and technology. The aim of machine learning is to develop algorithms to automatically extract useful information from complex, high-dimensional data. Making progress toward this aim requires developing an understanding of the aspects of data, which are amenable to analysis and can be learned using computationally efficient methods. In particular, modeling non-linear structures in high-dimensional data has become one of the very challenging and active lines of research, which has seen significant progress over the last ten years.<br/><br/>The goal of this project is to develop and analyze new mathematical representations for data, based on spectral and algebraic methods. We will explore how different structures in the data, such as cluster, manifold or parametric model structures, are reflected in their spectral and algebraic properties and how they can be extracted algorithmically from data, paying particular attention to the issues of high dimensionality and non-linearity. These insights will be used to build better and more adaptive algorithms for inference and data analysis tasks. <br/><br/>We will also analyze experimentally and theoretically properties of these algorithms, when data deviates from the posited model structure. This is a key issue in practical applications, which nearly always involve uncertainty and noise."
"1344024","INSPIRE Track 1: Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES)","AST","OFFICE OF MULTIDISCIPLINARY AC, INFORMATION TECHNOLOGY RESEARC, , INFO INTEGRATION & INFORMATICS, INSPIRE","09/01/2013","07/09/2014","Richard Snodgrass","AZ","University of Arizona","Continuing grant","Nigel Sharp","08/31/2016","$733,334.00","John Kececioglu, Abhijit Saha, Thomas Matheson","rts@cs.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","MPS","1253, 1640, 1798, 7364, 8078","1798, 8653","$0.00","This INSPIRE award is partially funded by the Special Projects program of the Division of Astronomical Sciences and the Office of Multidisciplinary Activities, both in the Directorate for Mathematical and Physical Sciences, and by the Information Technology Research and Information Integration and Informatics programs in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering.<br/><br/>This project will construct a software infrastructure for filtering and annotating alerts generated by astronomical time-domain surveys, where an alert is a change in an astronomical source when compared with a reference image. Current and future surveys are capable of producing enormous numbers of such alerts: in particular, the planned Large Synoptic Survey Telescope project could produce a million or more every single night for a decade. Within this veritable flood will be a small number of rare and unusual sources with short lifetimes that must be recognized in real time, or else the opportunity for thorough study will be lost.<br/><br/>This research will meet that need: the system will include a core flow that quickly annotates alerts with already known details, creating a useful database in its very first pass, followed by a method to derive broad characteristic features that can be used to filter out and divert those events not in need of rapid follow-up. Advanced, more computationally intensive processing can be applied to those that pass the filters, including multiple paths that allow users to select for their particular interests. The final product for this prototype is those alerts that are the most unusual. The system is designed to be flexible, so no alerts are lost and the stream can be tapped by external users at any point for their own processing. Use of the Arizona Machine Experimentation Lab allows for model construction and testing, and for creation of novel, perhaps more efficient, filtering processes. Throughout, decisions are completely driven by astronomical expertise.<br/><br/>The study of known but rare objects will transform fields ranging from stellar evolution to growth of active galactic nuclei to the fundamental structure of the Universe, while the discovery and characterization of previously unknown objects could create entirely new fields. Although the prototype will focus on the rarest of objects, ultimately the built-in flexibility and community-generated filtering processes will enable finding items of specific interest to any user. In addition, a system that can take alerts, aggregate ancillary information, and filter to identify specific cases, will be of general use in many fields, from epidemiology to network protection to homeland security and beyond, wherever rapid analysis of new events properly associated with existing information is critical."
"0844890","CAREER: Passivity-Based Distributed Frameworks for Multiuser Shared Haptic Collaboration over the Internet","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","03/15/2009","07/24/2013","Dongjun Lee","TN","University of Tennessee Knoxville","Continuing grant","Satyandra Gupta","02/28/2015","$455,889.00","","djlee@utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","CSE","7495, 9150","1045, 1187, 9150, 9215, HPCC","$0.00","The main goal of this project is to develop theoretical foundations for robustly-stable and high-fidelity shared haptic collaboration among geographically-distributed multiple users over the Internet. For this, the project utilizes: 1) distributed architecture for real-time responsiveness of each user?s haptic feedback regardless of Internet?s latency; and 2) passivity (of total distributed architecture) as a means for robust-stability of haptic interaction with a wide-range of heterogeneous human users. More specifically, the project focuses and investigates the following three key research tasks: 1) discrete-time passive haptic simulation algorithms for consistent/scalable deployment of the shared virtual environment, particularly among (computationally) heterogeneous users; 2) haptically-convincing physics-based passive hierarchical model reduction frameworks to mitigate communication/computing burdens, particularly when the shared virtual environment is of large-scale; and 3) high-performance passive local replica synchronization frameworks over the Internet for crisp/stable shared haptic experience, and fundamental performance limitation given communication imperfectness.<br/><br/>By providing systematic and theoretical frameworks, this project will significantly advance the current state of the art, which is largely heuristic, ad-hoc and qualitative. This project is also expected to produce new results/perspectives/frameworks for general haptics/telerobotics as well as for adjacent research fields. <br/><br/>The theoretical foundations laid by this project will make many powerful applications closer to reality (e.g. virtual collaborative surgical training, pre-manufacturing product evaluation, virtual collaborative sculpting, haptically-enabled networked games, etc). Perhaps more importantly, this project may fundamentally change how we interact with each other in the cyberspace. <br/><br/>Education/dissemination activities of this project will include: development of new hands-on and research-level robotics courses; student advising/mentoring, particularly for minority students; haptics summer camp for K-12, particularly for female students; seminars in local high schools and public demonstrations; project web site, international collaboration, and book writing."
"1344296","INSPIRE Track 1: Aurorasaurus - Citizen Scientists Experiencing the Extremes of Space Weather","AGS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, INSPIRE, Space Weather Research","09/15/2013","07/08/2014","Elizabeth MacDonald","NM","New Mexico Consortium","Continuing grant","Robert M. Robinson","08/31/2015","$998,957.00","Michelle Hall, Andrea Tapia","eliz.macdonald@gmail.com","4200 West Jemez Road, Suite 301","Los Alamos","NM","875442587","5054124177","GEO","1640, 7367, 8078, 8089","4444, 8653, 9150","$0.00","This INSPIRE award is partially funded by the Space Weather Research Program in the Division of Atmospheric and Geospace Sciences in the Directorate for Geoscience; the Human Centered Computing Program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering; and the Advancing Informal STEM Learning Program in the Division of Research on Learning in Formal and Informal Settings in the Directorate for Education and Human Resources. <br/><br/>This is a two-year inter-disciplinary project pursuing tightly coupled goals within human centered computing, citizen science, and space weather research. The aurora borealis of the northern hemisphere and its twin, the aurora australis of the southern hemisphere, are among the most beautiful and awe-inspiring of natural phenomena. They are a manifestation of the interaction of solar plasma with the Earth's atmosphere, magnetic field, and surface, the combined effect of which is termed space weather. As the aurora is a visible manifestation of space weather, observations of aurora are potentially a means of forecasting its catastrophic extremes. Capitalizing on public curiosity of normally intangible plasma physics, the objective of this project is to create a system for collecting, analyzing, interpreting, and redistributing data on the dynamics and evolution of auroral events using crowd-sourced ad hoc Tweets and more purposeful postings from citizen scientists. The current solar maximum is the first since the emergence of the ubiquitous use of social media that has changed - and will continue to change - our interactions with computers and the world. Building on a demonstrated prototype system, the project is poised to take advantage of the approach in 2013-2014 of the maximum in the current 11-year solar activity cycle, with several high activity years following. <br/><br/>The team combines expertise in space weather science, human-computer interface design, and informal science education to realize each of its intertwined goals. <br/>1) For space science, the contribution will be a totally new data source for auroral observations and the potential for real-time, higher-resolution space weather forecasts that are a critical step towards transforming our ability to protect and manage critical infrastructure susceptible to interruption and damage. With crowd-sourced data and user contributions, it is possible to achieve the increased density of high quality data needed for improved predictions. State of the art human-computer interfaces, for data upload, analysis, and interpretation that make participation easy, intuitive, and rewarding, will be developed to ensure the high quality data critical to forecasting.<br/>2) For the field of human-centered computing, the creation of new frameworks will transform our understanding of how the emergent processes of crowd-sourced knowledge and labor come together for scientific discovery under the structures of networked computer platforms. Specifically, the stickiest problem in making crowd-sourced media actionable is the verification of the messages received at a high enough tolerance level for organizational decision-making. A transformative approach will be adopted, employing verification techniques within a community of active participants who will also engage the data, offering human intelligence in collaboration with machine intelligence.<br/>3) The education approach is innovative and potentially transformative in its use of social media to explore the beautiful and mysterious aurora, through which participants in a dynamic social network will come to understand the relevance of space weather to their lives. Intellectually engaging resources, research projects, and motivational incentives for participation will help build a community of citizen scientists committed to advancing knowledge of space weather.<br/><br/>This low-cost, citizen science system for improved forecasting of geomagnetic storms has the potential to transform the way space weather prediction is done and considering the enormous potential cost to society of damage due to such storms would be cost-effective. The project will help enhance public understanding of this little known phenomenon so that citizens are aware and prepared to respond to the effects of space weather. Resulting new understanding of effective approaches to citizen science and the impact of human computer interactions on motivations and success at learning will have value to a wealth of other ongoing citizen science programs."
"1319749","III: Small: Effective Convex Solvers for Machine Learning","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","09/01/2013","07/08/2014","Daniel Boley","MN","University of Minnesota-Twin Cities","Continuing grant","Sylvia J. Spengler","08/31/2016","$453,466.00","","boley@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364, 7495","7364, 7495, 7923, 9251","$0.00","Many large scale machine learning problems are formulated as optimization problems, in which some measure of error or loss is to be minimized over a suitable training corpus. Real problems have too many data points to fit in a single computer. Hence the data and/or computation must be distributed over a network of computers. Often the only practical methods for extremely large problems are so-called splitting methods, but their convergence properties are extremely variable: sometimes very fast, sometimes very slow, in ways that can be hard to predict. The goal of this project is to gain a better understanding of the convergence behavior and to use this understanding to construct accelerated algorithms with more consistent convergence properties. This will allow the application of machine learning techniques to a much wider class of problems.<br/><br/>Splitting methods (or more precisely alternating direction methods) are based on the idea that a general convex optimization problem can be split into two or more parts, each of which can be solved much more easily compared to the problem as a whole. The methods cycle through all the variables in turn, optimizing over each subset of variables leaving the rest fixed. The proposed work builds on a preliminary analysis of a simple model problem using the eigen-structure of certain matrix operators. The project is devoted to extending this analysis to more general problems, as well as developing faster solvers using well-established computational technologies for the matrix eigenvalue problem. Success will be measured in terms of the generality of the theory developed and the improvements in the observed convergence behavior on real problems.<br/><br/>With faster solvers, discovery of major regions of influence in a global-scale social network (e.g. Facebook or Twitter) could become practical on modest computer platforms. The same holds for tracking disease propagation and people in video sequences. With efficient solvers, tracking software could be deployed on local hardware without the need for high-powered central servers. This will lead to advances in countless areas such data mining, compressive sensing, recommender systems, signal processing, missing data imputation, analysis of large scale social, biological or computer networks, image reconstruction, denoising and classification.<br/><br/>The results of this research are to be disseminated in papers in the principal journals and conferences in machine learning, data mining, and optimization as well as in the form of software packages via the WWW (http://www-users.cs.umn.edu/~boley/ML-Optimization).<br/><br/>The project depends on the interaction between different disciplines and applications areas, which will attract students from a variety of backgrounds at both the graduate and undergraduate level. Some research tasks are suitable as projects in classes on linear algebra, optimization, data mining, machine learning and are to be developed for both undergraduate and graduate students. Undergraduate students, including women and members of underrepresented groups, will see the value of mathematical algorithms to solve real problems of interest to them."
"1319600","III: Small: QUEST: An Integrated Query and Event System on Noisy Streams and Tables","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","07/08/2014","Tingjian Ge","MA","University of Massachusetts Lowell","Continuing grant","Frank Olken","08/31/2016","$390,897.00","","ge@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7364","7923, 7364","$0.00","Sequence and order are prevalent in data. In particular, time, as often perceived as the ""fourth dimension"", plays a pivotal role in data streams as well as in stored time series data. The ability to define events, detect and query complex events over noisy sequence data is a much needed addition to the standard data management systems and SQL. This is because complex event detection is about discovering the correlation and co-occurrence of many tuples in the same relation - different from the cursor model in SQL, and because it is sensitive to sequence errors. The goal of this research is to tightly integrate SQL queries and complex event detection over noisy streams and stored tables in a high-performing system. Specific techniques include: (1) Using a query suite to encapsulate the interactions between SQL queries and complex event detection, and proposing a comprehensive semantics for complex events; (2) Incorporating correlated error models into a novel complex event matching algorithm; (3) Designing more efficient algorithms that only get the top-k highest probability matching paths, as well as algorithms that handle other variants of semantics; and (4) Devising several indexing mechanisms for stored sequence tables, and performing overall system optimization for both streams and tables.<br/><br/>The QUEST project has applications in dietary and exercise monitoring/analysis, ECG monitoring, shopping behavior study, security monitoring, and travel pattern discovery, among many others. These applications play a key role in the nation's economy (business intelligence), health, and security. The project greatly enriches the course contents of the undergraduate directed research course in addition to a new graduate course. Further information on the project can be found on the project web page: <br/>http://www.cs.uml.edu/~ge/projects/quest/ ."
"1010363","CRCNS: US-German Collaboration: Role of Astrocytes in Cortical Information Processing","IIS","COLLABORATIVE RESEARCH, CRCNS, ROBUST INTELLIGENCE","10/01/2010","09/20/2010","Mriganka Sur","MA","Massachusetts Institute of Technology","Standard Grant","Kenneth C. Whang","09/30/2014","$574,999.00","","msur@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7298, 7327, 7495","5936, 5979, 7327","$0.00","The cortex consists of two major cell types: neurons and glia. Most research in cortical function has focused primarily on the role of neurons in signal processing. Glial cells, including astrocytes, have been considered as secondary actors in brain function, providing physical and metabolic support to neurons. In primary visual cortex (V1), precise neuronal responses and representations are considered to anchor visual processing. However, astrocytes contact synapses as well as blood vessels, and recent evidence suggests that astrocytes receive synaptic inputs and influence neuronal as well as vascular responses. The accumulated results of the past decade have led to the ?tripartite synapse? concept, in which excitatory synapses in cortex are composed of a presynaptic, a postsynaptic, and an astrocytic element. An over-arching and novel theme of this proposal is that astrocytes partner with neurons in synaptic transmission and plasticity. Any complete framework for understanding and modeling the network basis of cortical responses must account for both astrocytic and neuronal contributions. The goal of this proposal is to combine experimental and computational modeling approaches to understand the role astrocytes play in the generation, development and plasticity of neuronal responses in visual cortex.<br/><br/>Many aspects of astrocyte biology and physiology have been described in vitro, but little is known about the role of astrocytes in the context of intact functional circuits. This project will utilize novel experimental approaches, including specific cellular markers, optical probes of cellular function, and genetically engineered mice with optical reporters, that provide new ways to examine the cooperative roles of neurons and astrocytes in visual cortex responses and representations. The US laboratory of Mriganka Sur has pioneered the use of these approaches, in combination with in vivo two-photon calcium imaging of cells, optical imaging of intrinsic signals, and electrophysiological recording, to study the influence of astrocytes on visual processing. The modeling portion of this project will develop the first network models of visual cortex to include astrocyte influences on synaptic transmission, in addition to neuronal excitation and inhibition. The German laboratory of Klaus Obermayer has made seminal contributions to a computational understanding of how visual cortex networks generate, develop and alter emergent responses. Previous joint efforts of the Sur and Obermayer groups have been influential in revealing operating regimes of visual cortex networks, the influence of map structure on cortical network function, and the dynamics of feature-selective responses. In each instance, computational models influenced experiments, and vice versa.<br/><br/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF)."
"0964560","III: Medium:Simplifying Database Management with Automated Experimentation","IIS","INFO INTEGRATION & INFORMATICS","08/01/2010","07/10/2013","Shivnath Babu","NC","Duke University","Continuing grant","Sylvia J. Spengler","07/31/2015","$783,002.00","Kameshwar Munagala","shivnath@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7364","9251, 7364, 9215, HPCC","$0.00","Despite a number of recent efforts, current solutions for database administration tasks like tuning, troubleshooting, benchmarking, and capacity-planning remain far from satisfactory. Database systems have many configuration parameters to control memory distribution, I/O optimization, costing of query plans, and other behavior. Regular users and even expert database administrators struggle to tune these parameters for good performance. The inherent complexity makes it hard for these systems to gracefully handle uncertain and dynamically-changing workloads and diverse query mixes. The .eX project addresses these challenges through a novel methodology called automated experiment-driven management which encapsulates key building blocks to automatically generate knowledge of system behavior for simplified administration and self-tuning. These building blocks include techniques to: (i) characterize good system performance models, (ii) plan experiments that generate data to learn and maintain these models efficiently under system and workload changes, and (iii) make robust decisions using these models given the inherent uncertainty in how accurately the models capture the true underlying system behavior. Apart from system administration, .eX's automated experiment-driven management can benefit applications like MapReduce computations, large-scale computational simulations, and keyword auctions in online advertising. Two new courses for graduate and undergraduate students at Duke cover principles of automated experiment-driven management. A fully-functional prototype of .eX is being developed and deployed in multiple settings to simplify database administration. The source code of .eX will be released publicly and the technology will be migrated potentially to industrial-strength system administration products. Results from .eX will be disseminated via the project Web site (http://www.cs.duke.edu/~shivnath/dotex.html)."
"1252835","CAREER: Learning Scalable Models for Grounded Semantic Parsing","IIS","ROBUST INTELLIGENCE","09/01/2013","07/08/2014","Luke Zettlemoyer","WA","University of Washington","Continuing grant","Tatiana D. Korelsky","08/31/2018","$187,915.00","","lsz@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","1045","$0.00","One core challenge in natural language research is to do robust, wide coverage semantic analysis. Recently, there has been progress towards solving this problem by developing algorithms for learning semantic parsers that map sentences to rich, logical representations of their meaning. State-of-the-art approaches have reached the level where they can, with sufficient training data, be used to learn highly accurate parsers for many different natural languages on a number of benchmark problems. However, the general applicability of this work has been limited by the focus on somewhat idealized conditions, where the application domain is of limited size, sentences are analyzed in isolation, and there is an exclusive focus on database query applications.<br/><br/>This CAREER project aims to build a framework for grounded semantic parsing that solves these challenges by reasoning about a sentence's possible meanings given its linguistic and situated context. This type of reasoning is necessary for extending existing learning approaches to fundamentally new applications, such as conversational understanding. However, it is also be crucial for the next generation of semantic parsers that learn from easily gathered data and scale to domains that are several orders of magnitude more complex than previously considered.<br/><br/>The project will extend the PI's educational and outreach efforts, including the creation of freely shared online content for introductory and advanced semantics topics. It will also enable new initiatives by the PI to increase diversity in computer science study and research, by supporting efforts to motivate students through early exposure to exciting language understanding problems."
"1117940","HCC: Small: Programming by Voice: Extending Initial Programming Environments for Children with Disabilities","IIS","Cyber-Human Systems","09/01/2011","05/07/2013","Jeffrey Gray","AL","University of Alabama Tuscaloosa","Standard Grant","Ephraim P. Glinert","08/31/2015","$331,524.00","Sandra Nichols","gray@cs.ua.edu","801 University Blvd.","TUSCALOOSA","AL","354870104","2053485152","CSE","7367","7367, 7923, 9251, 9150","$0.00","The PI's objective in this research is to empower children with certain kinds of disabilities so they can participate fully in initial programming environments (IPEs) that are used to teach computer science. Specifically, the PI will investigate the science and necessary tool construction to support speech-enabled adaptation of IPEs such as Scratch, Lego LabVIEW for Mindstorms, and Alice, which were originally designed for manual input with a keyboard and mouse, in order to allow children with limited use of their limbs to interact via alternative interfaces. The aforementioned IPEs traditionally rely on user interfaces involving windows, icons, and other graphical widgets, and require a mode of program input that can pose a barrier to those with upper limb motor impairments, who may lack the dexterity and mobility needed to control a mouse or keyboard with their hands. The PI's approach will be to imitate the common mouse and keyboard interactions with a voice-driven interface that is customized for each IPE. To these ends, the PI will develop a speech-aware application that runs in parallel to the IPE, listens to the voice commands from the user, interprets the commands according to a grammar influenced by the IPE concepts, and imitates appropriate actions similar to mouse and keyboard operation within the IPE. Core research questions will include how such assistive customizations can be added with automation using reverse engineering and model-driven engineering.<br/><br/>During the first year of the project, the PI will extended a previously developed proof-of-concept to cover the entire Scratch interface. The result will be a robust tool that enables Programming by Voice in Scratch, and which will serve as the evaluation instrument for a target group of children with disabilities. The lessons learned from the first phase of the project will drive a generalization of the steps needed to customize a speech interface for an existing application. Techniques involving screen scraping and reverse engineering, as well as model-driven engineering, will be investigated to automate the process of adapting IPEs to Programming by Voice. The resulting tools will be applied to a new IPE, the Lego LabVIEW for Mindstorms, to allow children with disabilities to program robots. The design and evaluation of the project will be performed in collaboration with United Cerebral Palsy of Birmingham, who will recruit participants into the project and provide resources for training, evaluation, and feedback on the project design.<br/><br/>Broader Impacts: This project unites ideas of human-computer interaction with computer science education to provide customized assistive environments for teaching computational thinking to children with disabilities (targeting grades 6-12). The work will advance our ability to automate the generation of software development environments that support Programming by Voice, resulting in advanced capabilities to enable children with upper limb motor impairments to participate fully in computer science education opportunities. The PI will involve graduate students in the research; he will supervision undergraduate Honors projects, and he will also mentor high school students from underrepresented groups with science fair projects related to this work. The results of the research will be disseminated through a project web page that will include open source software, teaching materials, video demonstrations and publications."
"1302231","III: Medium: Mining petabytes of data using cloud computing and a massively parallel cyberinstrument","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","07/07/2014","Petros Drineas","NY","Rensselaer Polytechnic Institute","Continuing grant","Sylvia J. Spengler","08/31/2016","$759,237.00","Bulent Yener, Mohammed Zaki, Angel Garcia, Christopher Carothers","drinep@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7364","7364, 7924","$0.00","There is a growing need for effective approaches to mining very large, i.e., petabyte scale data sets in many areas of science, engineering, and business.<br/><br/>The project aims to design, analyze, and implement a number of fundamental matrix-mining and graph-mining operations that are scalable to petabyte-sized inputs. Such efforts guarantee the continuation of the phenomenal growth in analyzing, visualizing, and extracting information from massive matrices and graphs. Project leverages Rensselaer's unique computing platform in the form of a massively parallel machine (a Blue Gene/Q) with access to approximately 1.2 petabytes of storage, as well as a data-staging layer, named the RAM Storage Accelerator (RSA) with 512 computational nodes and a a total of 8TBs of fast RAM. The platform is configurable to allow the computational nodes at the RSA level to be used to pre-process data from the secondary storage in a cloud-like fashion. The project aims design and analyze approximation algorithms for matrix and graph mining tasks that follow an iterative, two-step approach: given petabytescale data, first, using computationally inexpensive approaches to obtain compact data sketches using the RSA layer as a ""cloud"" in order to reduce their size from the petabyte scale to the terabyte scale. The resulting data sketches are processed using computationally demanding approaches on the Blue Gene/Q. This process is iterated using the approximate solutions in order to improve the quality of the sketches and the approximation guarantees. <br/><br/>The research team expects to release software and libraries for matrix and graph mining algorithms that implement our two-phase approaches for PB-scale matrices and graphs. The resulting tools will be applied to the analysis of petabytes of data from computer simulations of the dynamics of biomolecular systems. The investigators plan to involve students and researchers from other institutions in the design, analysis, and development of the proposed methods through an internship program. The project also offers increased opportunities for research-based training in Data Analytics and High Performance Computing to graduate and undergraduate students at RPI. The results of the research will be made available to the academic community through the project web site."
"1018055","HCC: Small: Enabling and Exploring Natural Interaction","IIS","Cyber-Human Systems","09/01/2010","08/04/2010","Randall Davis","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","08/31/2015","$499,541.00","Mary Cummings","davis@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7923","$0.00","Advances in technology are making it feasible to explore novel approaches to human-computer interaction in a wide variety of devices and settings, in an effort to achieve interaction that feels more natural. While valuable from both a user and commercial perspective, use of new technology is not well understood from a more principled system design or cognitive science perspective. Establishing even the basic elements of a set of design principles would both produce better designs and increase our confidence in using the technology in high-risk/high-reward domains, such as first responder planning and control. The PI's long-term goal is to develop a set of principles specifying how to design systems that both enable natural human-computer interaction and are informed by an understanding of human factors. Natural interaction refers to the cognitively transparent, effortless multimodal communication that can happen between people; this work aims to make that possible in human-computer interaction. Designs informed by human factors take into account an understanding of human capabilities (e.g., attention, use of multiple information channels, etc.), so that the final system is a good impedance match to human information processing. This research will involve building systems designed in this spirit and articulating principles for their design that, in turn, will facilitate future designs by making explicit both the task conditions under which one or another modality is appropriate (e.g., when to draw, when to talk), and the ways in which multiple modalities can effectively be used simultaneously in human-computer communication. The project is set in the context of a tabletop-based system that assists with planning and coordination in the command center of an urban search and rescue (USAR) operation. The work will proceed by leveraging and combining the team's experience in building novel interaction technologies and in human factors. They will extend the current version of the PI's tabletop system, which permits basic pen-based interaction, so as to give it the ability to handle the kinds of sketching, freehand gestures and speech used in real-world USAR work, thereby providing a far more natural style of interaction. The additional interaction modalities will make the system more powerful, while the real-world, time-pressured character of the task offers a good platform for studying the human factors aspects. This will allow the team to understand how, when and why various modalities are useful, providing the data from which system design principles can be articulated. To help ensure breadth of applicability of project outcomes, the PI will explore the same issues in a second domain, software design with UML diagrams.<br/><br/>Intellectual Merit: This research will provide insight into a model of multimodal interaction by producing empirical data about modality selection, and by articulating a widely useful set of principles for interface design that make explicit the conditions for both modality selection and cognitively effective modality combination. Such principles offer the possibility of transformative change to multimodal interface design, changing it from the current largely ad hoc practice to a design process guided by testable principles. Pursuing the research in two task domains will help to ensure a useful degree of generality to the principles derived. The work will provide benefit to society to the extent it can improve the effectiveness of first responder teams. The ability to handle non-traditional interaction modalities (e.g., gesture) will ultimately make computer interaction more accessible to physically disadvantaged users. The PI will take care, to the extent possible, to use and build upon open source tools, so that he can make available to the community all of the research software produced during the course of the project, thereby adding to the supply of next-generation research and education platforms."
"1118114","III: Small: Query and Goal Driven Entity Resolution Framework","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","04/16/2014","Sharad Mehrotra","CA","University of California-Irvine","Continuing grant","Frank Olken","07/31/2015","$553,406.00","Dmitri Kalashnikov","sharad@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7364","7364, 7923","$0.00","Data cleaning technologies, traditionally designed to improve quality of data in back-end data warehouses, are fast emerging as a vital component of real-time information access. As the Web evolves towards supporting interactive analytics and basic search migrates from simple keyword retrieval to retrieval based on semantically richer concepts (e.g., entities) extracted from web pages, the need for ""on-the-fly"" cleaning techniques that can help alleviate data quality challenges is rapidly increasing. This project explores three new innovations that will help advance data cleaning towards becoming an embedded enabling technology for real-time information access. The first innovation is ""query-aware data cleaning"" which is based on the observation that the specificity of the real-time task such as a query can be exploited significantly to bring new optimizations to the data cleaning process. The second innovation is a data cleaning framework that migrates from the ""best-effort"" adhoc setup of today's systems into a principled approach that exposes and exploits a fundamental tradeoff between the cost of cleaning and quality of results achieved. Finally, since results of cleaning need to be fed to the end-user or analysis code, the proposal postulates and addresses approaches towards how results processed through data cleaning code can be presented to the end-recipient. The primary contribution is mechanisms to hide the uncertainty in the data and determinize the results while maximizing the end application goals. <br/><br/>The proposed research is intended to bring transformative improvements in interactive analytics and search on the web by facilitating real-time data cleaning and data quality enhancements. The project also aims to benefit the research community by incorporating mechanisms developed as part of this research into the Web People Search Technology (WEST), enabling WEST to become a real-time on-the-fly web people search tool. The goal is to support WEST as a plug-and-play system wherein other researchers could embed and test their data cleaning algorithms and tools. Finally, the planned research, system development, and educational activities are going to significantly enhance the educational experience of students, preparing them for a brighter future in the today's knowledge driven society.<br/><br/>For further information see the project web site at the URL: http://sherlock.ics.uci.edu"
"1302423","III: Medium: Collaborative Research: Spatial Data and Trajectory Data Management on GPUs","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","07/07/2014","Jianting Zhang","NY","CUNY City College","Continuing grant","Sylvia J. Spengler","07/31/2017","$238,267.00","Camille Kamga","jzhang@cs.ccny.cuny.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","CSE","7364","7924, 7364","$0.00","Although locating and navigation devices embedded in smartphones have already generated large volumes of location and trajectory data, the next generation of consumer electronics are likely to generate even larger volumes of location-dependent data where spatial and trajectory data management techniques will play critical roles in understanding the data to facilitate decision making. Modern Graphics Processing Units (GPUs) are capable of general computing. Current generation of commodity GPUs have large numbers of processing cores, support even larger numbers of current threads and provide high memory bandwidth, yet are available at affordable prices. The massively data parallel computing power of GPUs makes the hardware ideal for spatial and trajectory data management which is both data and computing intensive.<br/><br/>This project develops parallel indexing structures and query processing algorithms for spatial and trajectory data on GPUs to provide high performance which is crucial in speeding up existing applications and enabling new scientific and business inquiries. The project achieves its goals by developing: 1) novel spatial indexing techniques on GPUs; 2) novel spatial joins on GPUs; 3) novel trajectory segmentation and indexing techniques and trajectory similarity query processing techniques on GPUs; and 4) an end-to-end prototype system incorporated with open source database and GIS systems for performance evaluations and real world applications. Compared with existing spatial and trajectory data management systems that are mostly disk-resident and adopt a serial CPU computing model, the performance of GPU accelerated main-memory based systems is expected to achieve several orders of magnitude speedup and brings the performance of spatial and trajectory queries to a new level. The research results are beneficial to many applications, such as transportation, urban planning, wild bird ecology, and epidemiology of infectious diseases. Collaboration is carried out with transportation engineers at the University Transportation Research Center in New York City and ecology scientists at the University of Oklahoma?s Earth Observing and Modelling Facility. The project also makes important impacts on education as it provides training for students in the areas of national critical needs: database research, high performance computing, GPU programming, GIS, transportation, mobile and ecology applications. The developed algorithms and prototype system, real datasets and performance evaluation results are made available to the public at the Website: http://www.cs.ou.edu/~database."
"1153617","EAGER: An Exploration in Enabling Community-driven Collaboration","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","09/08/2011","John Wooley","CA","University of California-San Diego","Standard Grant","Sylvia J. Spengler","08/31/2015","$120,114.00","","jwooley@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7916, 7364","$0.00","Contemporary information technology is ever more central to science and society in the midst of the deluge of complex data. The impact on bioscience is notable, where the pace of production and the data complexity means that a large amount of data is often not adequately analyzed by the data producers, yet researchers expect rapid dissemination of such types of data. To ensure effective impact, a solution promising to be transformational is to open ""big data"" analysis to the broader community. An avenue is provided by modern IT and the explosive growth and democratizing impact of the Internet, which, following the digitization of information and communication, has changed the pace of information exchange and opens up new channels for disseminating data and for engaging disparate disciplines in extended, productive collaborations. The result of this will be a platform with a customized pre-build interface that will significantly reduce the downside of the form-based data input approach. The input interface will be small, easy to use and readily accepted by users but still relevant to what a user might want to input. The interface will provide strong search ability to the controlled vocabulary and provide users with this information through ""input hint"", dropdown lists or auto-completion, according to what is most efficient for the specific extension and provides an effective, readily followed and precise process. Sustaining the free text input section will provide users with maximum freedom of data input. By enabling community collaboration via Web access and implementing a database resource linked with the knowledge collection interface together with free text entry format, this system will provide a venue for researchers among many communities, including those located at non-research intensive universities, community colleges and minority-serving institutions, in this Nation and worldwide, to contribute their insight to experimental research observations that currently requires expensive specialized equipment only available in a few centers around the world."
"1321146","RI: Small: Flexible Turn-Taking for Mixed-Initiative Spoken Dialogue System","IIS","ROBUST INTELLIGENCE","09/01/2013","07/04/2014","Peter Heeman","OR","Oregon Health and Science University","Continuing grant","Tatiana D. Korelsky","08/31/2015","$249,999.00","","heemanp@ohsu.edu","3181 S W Sam Jackson Park Rd","Portland","OR","972393098","5034947784","CSE","7495","7495, 7923","$0.00","The goal of this project is to determine how turn-taking in human-human dialogue works, and use this as a basis for developing a flexible model of turn-taking for use in spoken dialogue systems. The first two aims focus on determining whether turn-taking is solely determined by the current speaker or is negotiated by both conversants. The first aim measures how well human subjects, listening to excerpts of speech, can predict whether the current speaker will continue the turn or release it. The second aim analyzes timing lags at turn transitions. Many turn transitions have short lags, which favors a speaker-control model; however this might be an artifact of common speech act sequences, back channels, early onsets, and provisional turns. The third aim, using the findings of the first two aims, is to determine the cues and mechanisms that are used by conversants in taking the turn.<br/><br/>Better understanding of turn-taking in human-human dialogues is important as it will help in building more efficient and natural spoken dialogue systems, allowing the user and system to better collaborate to solve complex tasks. It should also allow spoken dialogue systems to deal with a broad range of users, from experts to novices: for experts, letting them take the initiative (and the turn), in order to efficiently complete the task, while guiding novices with more directions and examples. Furthermore, understanding human-human turn-taking might have biomedical applications. For example, Autism, which is a disorder that affects social communication, might impact how people engage in turn-taking, and so turn-taking biomarkers might help in diagnosing it."
"1434919","WORKSHOP: Doctoral Symposium at the Eighth International Conference on the Theory and Application of Diagrams (DIAGRAMS 2014)","IIS","Cyber-Human Systems","03/01/2014","03/04/2014","Stephanie Schwartz","PA","Millersville University","Standard Grant","Ephraim P. Glinert","02/28/2015","$20,000.00","","stephanie.schwartz@millersville.edu","PO Box 1002","Millersville","PA","175510302","7178723820","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) for approximately 15 graduate students, along with a panel of 4 distinguished research faculty mentors (but only those students enrolled in U.S. educational institutions, about 8, will be eligible for funding through this grant). The event will take place in conjunction with (and on the first day of) the Eighth International Conference on the Theory and Application of Diagrams (DIAGRAMS 2014), to be held July 28-August 1, 2014, in Melbourne, Australia, and co-located with the IEEE Symposium on Visual Languages and Human-Centric Computing, as was the case in 2008. Diagrams are wide-ranging and open-ended representations that include sketches, drawings, charts, pictures, 2D and 3D geometric models, and maps. They are a vital tool in human communication in areas such as art and science, as well as commerce and industry. A better understanding of how effective diagrams can be generated and used has the potential to produce transformative advances in these areas. DIAGRAMS is the only conference series that provides a united forum for all aspects of research on the theory and application of diagrams. It is a bi-annual, international and interdisciplinary event whose goals are to present and discuss (a) state-of-the-art research on computational, cognitive and socio-cultural theories, models and techniques of reasoning with diagrammatic representations, and (b) cutting-edge intelligent and interactive information technologies for using diagrammatic representations in supporting human reasoning. Research topics include understanding diagrammatic reasoning in humans, understanding the use of diagrammatic representation for communication, developing techniques for automated diagrammatic reasoning, and designing tools for use of diagrammatic representations. The conference series is overseen by the DIAGRAMS Steering Committee with a rotating membership; more information is available at the conference website http://www.diagrams-conference.org/2014. <br/><br/>The primary goal of the DIAGRAMS 2014 Doctoral Consortium is to increase the exposure and visibility of young graduate student researchers in these areas. The workshop will be a research-focused day-long meeting that affords participants an opportunity to present their work and get feedback from established researchers in the field, who will be present to comment on the young researchers' presentations in an informal and constructive environment. Each invited participant will be asked to give a short talk, which will be followed by discussion and critiquing. For some students, this may be their first opportunity to give a research talk outside their home institutions, which will help prepare them for future scholarly discussions. The Doctoral Consortium is open for attendance to all conference registrants, and summaries of the presentations will be available on the conference website.<br/><br/>Broader Impacts: DIAGRAMS 2014 will significantly increase our understanding of diagrammatic reasoning in humans and machines, and will add momentum to the development of new information technologies for the use of diagrammatic representations in support of human reasoning. The conference will help develop human research capital by enabling interactions between senior and junior researchers and by catalyzing new collaborations. The Doctoral Consortium will increase the exposure and visibility of young graduate student researchers in these areas, and help train them by providing early input from senior researchers in the field in an interactive and constructive environment. The social network among this next generation of researchers, and the relationships with senior researchers, created by the workshop will play a critical role in their enculturation into the profession. Diversity of the selected students is a goal of the organizers, who will be proactive in an effort to ensure that both students and faculty are a diverse group across multiple dimensions including nationality, scientific discipline and gender. To further assure diversity, only one student will be selected from each educational institution, with preference given to students from underrepresented populations."
"1349906","CAREER: BCSP: Methods for analyzing sequencing data from repetitive genomes","IIS","INFO INTEGRATION & INFORMATICS","05/15/2014","05/19/2014","Benjamin Langmead","MD","Johns Hopkins University","Continuing grant","Sylvia J. Spengler","04/30/2019","$425,546.00","","langmea@cs.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7364","1045, 7364","$0.00","Our understanding of how biological systems work is increasingly fueled by data from DNA sequencers. Sequencing has improved dramatically over the past several years, but the datasets produced by sequencers are unwieldy and difficult to interpret. This is especially true when the genome being studied contains many repeated stretches of DNA, as is the case for most mammals and plants. The goal of this project is to develop improved computational and statistical methods for analyzing DNA sequencing data, providing faster, more accurate, and more interpretable results to scientists studying organisms with repetitive genomes. These methods will be implemented as open source software tools made freely available to the research community. A successful project will result in these tools being widely adopted in the biological research community. Repetitive sequences are implicated in cellular regulation processes and associated with human disease. The integrated education plan also seeks to improve software for analyzing sequencing data by teaching computer science students the complete set of skills needed to make usable genomics software in the era of big data genomics. The PI will develop an undergraduate minor in computational biology, a graduate class covering methods for analyzing large sequencing datasets, and a competitive class project. A successful effort will result in more trained computer scientists joining and contributing to the study of computational biology and genomics.<br/><br/>The genomes of plants, mammals and other higher eukaryotes contain many repeated DNA sequences. 80% of the maize genome, for example, is covered by repetitive stretches of DNA. At the same time, computational tools typically model DNA as a string. This has advantages; it allows these tools to borrow methods developed for other strings, such as books and web pages, and apply them to DNA. But for repetitive genomes, the string abstraction fails to capture the prevalence of repeated DNA sequences related to each other through evolution. The PI proposes a broad research agenda based on the idea that analyzing sequencing data derived from repetitive genomes requires special, repeat-aware computational methods. The first project explores accurate and efficient methods for aligning sequence reads to repeat families. The PI proposes methods that exploit similarities between alignment problems to yield solutions that are more accurate than current approaches. The second project explores novel methods for predicting the probability that an alignment reported by a read aligner is correct, i.e., that the aligner correctly identified the read's point of origin. Downstream analysis tools use this quantity to weigh their confidence in evidence derived from the alignment. But estimating this quantity accurately is difficult, and there are no widely applicable approaches available now. The PI proposes a tandem simulation approach, whereby a simulator mimicking properties of a real dataset can provide training examples that in turn allows us to accurately predict these probabilities for real data. These methods address major deficiencies in everyday common genomics analyses, which are made slower and less accurate by repetitive DNA.<br/><br/>The PI will also conduct an integrated set of curriculum building and outreach efforts. These have the goal of bringing computational biology to the attention of more students earlier in their training, and to provide graduate and upper undergraduate students with a strong computational biology curriculum. Specifically, the PI will develop and implement an undergraduate minor in computational biology at Johns Hopkins University. Second, the PI will design a new graduate-level course covering contemporary methods for analyzing very large collections of sequence data. Finally, the PI will develop a competitive project called the Big Sequence Data Pentathlon that tests students' ability to design scalable, usable genomics analysis tools on a parallel computer system."
"1065092","International: A US-Germany Research Collaboration on Systems for Computer-Integrated Healthcare","IIA","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE, IRES","05/01/2011","04/06/2011","Gregory Hager","MD","Johns Hopkins University","Standard Grant","Maija M Kukla","04/30/2015","$147,320.00","","hager@cs.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","O/D","1640, 7495, 7727","5936, 5979, 7639","$0.00","Computer-Integrated Medicine (CIM) is a new and rapidly growing area with high global appeal. Work in CIM is multi-national and inter-disciplinary. International research exchange is thus essential in creating state-of-the-art CIM systems, and in supporting CIM research programs.<br/><br/>The goal of this International Research Experiences for Students project is to create a bilateral international research exchange program on computer-integrated medicine (CIM) between the Technical University of Munich (TUM) Graduate School in Information Science and Health (GSISH) and the Johns Hopkins University (JHU) Center for Computer-Integrated Surgical Systems and Technology (CISST-ERC). Our vision is to develop a joint research and education activity that merges team research projects with cohort-focused education and organized cultural and socialization experiences, thereby creating a wide-ranging and long-term collaborative research program between our institutions. Both the TUM and JHU are national leaders in CIM, with networks of research collaborations that span their respective continents. The proposed IRES support will provide the ?missing link? in our existing faculty interactions and unilateral student exchange, to bind the networks of the two institutions into one larger transatlantic network on a more systematic and sustainable level. <br/><br/>We have developed the exchange to focus on the development of a cohort experience for students with an innovative educational and research mentoring environment. Our collaboration will focus on four research projects that exploit the inherent synergies of JHU and TUM. They are: 1) Automated surgical skill modeling and workflow analysis; 2) Video reconstruction and registration for advanced surgical visualization; 3) Software systems for information-enhanced surgery; and 4) Medical robotics devices and systems for microsurgery. Each of these projects is led by both TUM and JHU faculty, and takes advantage of complementary skills at each institution. <br/><br/>Our project will emphasize the development of research networks that the students will be able to take advantage of after the exchange ends, leading to long-term international cooperation. The focus on graduate students in the exchange provides a longer time horizon for the networks, and the eventual inclusion of undergraduates in the exchange will cement the transatlantic research community in this growing area of important interdisciplinary research.<br/><br/>This project is supported by NSF's Office of International Science and Engineering (OISE) and the NSF Directorate for Computer & Information Science and Engineering (CISE), Divisions of Information and Intelligent Systems (IIS) and Robust Intelligence (RI)."
"1005411","Cross-Cutting Research Workshops on Intelligent Information Systems","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","09/15/2010","03/28/2014","Frederick Jelinek","MD","Johns Hopkins University","Continuing grant","Tatiana D. Korelsky","09/30/2015","$599,972.00","Gregory Hager, David Yarowsky, Rene Vidal, Sanjeev Khudanpur","jelinek@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7364, 7495","7364, 7495, 7556","$0.00","A series of annual research workshops on Intelligent Information Systems, centered on machine learning for speech, language and vision technologies, are being organized at Johns Hopkins University to bring together diverse ?dream teams? of leading professionals, graduate students, and undergraduates, in a truly cooperative, intensive, and substantive effort to advance the state of the science.<br/>The primary goals of the proposed workshop series are to develop machine learning principles applicable to a broad spectrum of intelligent systems, to attract students to the field and to prepare them for research by putting them to work on exciting problems alongside senior researchers in a highly collaborative environment. Creation of research infrastructure and lasting collaborations are secondary goals.<br/>An open call for workshop project proposals is being issued each year to researchers in the worldwide IIS community. Received proposals are competitively evaluated and cooperatively refined at interactive peer review meetings, where project proponents, government representatives, and experts from related fields meet to assess their scientific merit, viability and potential impact. The graduate students attending the workshop are familiar with the field and are selected in accordance with their demonstrated performance. The undergraduates are entering seniors who are new to the field and who have shown outstanding academic promise; they are selected through a national search. The participation of undergraduates in these research programs encourages talented young scholars to pursue graduate studies in IIS.<br/>By the end of this 3-year workshop series (beginning 2010), more than a hundred individuals will have conducted intensive collaborative research: about 30 academic and industry researchers, 20 researchers from government and national laboratories, 30 graduate students, and 20 undergraduates. Additional benefits of the workshops will be the collection or creation, and dissemination of valuable tools and data for IIS research, the establishment of fruitful and long-lasting collaborations, and the cross-fertilization of ideas among the participants."
"0846112","Career: Cognitive Auditory Systems for Processing of Complex Acoustic Scenes","IIS","ROBUST INTELLIGENCE","07/01/2009","03/19/2014","Mounya Elhilali","MD","Johns Hopkins University","Standard Grant","Kenneth C. Whang","06/30/2015","$556,421.00","","mounya@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","1045, 9102, 9215, HPCC, 6890","$556,421.00","Performance of hearing systems and speech technologies can benefit greatly from a deeper appreciation and knowledge of how the brain processes and perceives sounds. While most current systems invoke operations akin to the peripheral auditory system, they stop shy of incorporating promising capabilities of the central auditory system, most importantly its ability to adapt to the demands of an ever-changing acoustic environment. Recent physiological findings are amending existing dogmas of processing in auditory cortex; replacing conventional views of ""static"" processing in sensory cortex with a more ""active"" and malleable mapping that rapidly adapts to behavioral tasks and listening conditions. Hence, a new architecture for sound processing based on cognitive and adaptive processes promises to open a revolutionary frontier for hearing and speech technologies.<br/><br/>The PI will conduct a five year CAREER award study aimed at developing effective algorithmic implementations to tackle challenging sound and speech processing problems in real ecological environments. This research aims at providing a rigorous framework for designing experiments that test the role and mechanisms of active and cognitive adaptation in the auditory system. This interdisciplinary effort will integrate techniques from neurophysiology, psychophysics, computational neuroscience and engineering. The planned research will focus on: (i) developing a computational model for adaptive and cognitive auditory processing using dynamic systems techniques such as adaptive and kalman filtering; (ii) furthering understanding of the role of cortical plasticity in auditory perception with a series of experiments with human subjects (using psychoacoustics and Magnetoencephalography -MEG-) aimed at<br/>exploring the neural correlates, time course and role of these adaptive processes; (iii) assessing the computational and experimental findings in a range of engineering applications; and (iv) exploring the integration of higher cortical processing capabilities in hearing prostheses.<br/><br/>This research effort is complemented by an educational plan aimed at promoting education in the field of adaptive and cognitive audition, through the development of new undergraduate and graduate curricula, introduction of new educational and assessment tools for improving and monitoring student achievements, as well as outreach activities to attract talented individuals to the field of cognitive engineering.<br/><br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."
"0530118","PIRE: Investigation of Meaning Representations in Language Understanding for Machine Translation Systems","IIA","HUMAN LANGUAGE & COMMUNICATION, COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE, PIRE","10/01/2005","02/11/2014","Frederick Jelinek","MD","Johns Hopkins University","Continuing grant","John Tsapogas","09/30/2015","$2,498,407.00","Martha Palmer, Jason Eisner, Hynek Hermansky, Sanjeev Khudanpur, John Godfrey, Eugene Charniak, Mark Johnson","jelinek@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","O/D","7274, 7298, 7495, 7742","0000, 5930, 5936, 5979, 7566, OTHR","$0.00","----<br/>This Partnership for International Research and Education (PIRE) links senior and junior researchers from Johns Hopkins University and Brown University with counterparts from Charles University in the Czech Republic and Saarland University in Germany. The international team, led by Frederick Jelinek at Johns Hopkins, will investigate formal representations of linguistic meaning for use in speech recognition/reconstruction and machine translation (MT) systems. Their goal is to augment current speech recognition systems by applying a variety of formal models for deep syntactic/semantic representation so that output of their refined MT system becomes coherent, grammatical text.<br/><br/>The projects complementary education component involves introducing participating U.S. graduate students to European-developed linguistic formalisms and training them to apply those formalisms to problems in natural language processing. Students will have language training in Czech or German and will spend at least one semester abroad where they will further their linguistic training in tectogrammatical representation at Charles University or head-driven phrase structure grammar at Saarland University. In the final stages of their Ph.D. program, each will return to the Czech Republic or Germany to work with European mentors on research that incorporates these state-of-the art language processing techniques. <br/><br/>Results from the collaborative research, annual workshops and cross-training should advance the field of computational linguistics by integrating formal meaning representations and statistical methods for natural language processing so that modern computer resources can be exploited to more rapidly translate verbal communications from other languages into English. If successful, this work could revolutionize language modeling for automatic speech recognition so that even spontaneous speech may be translated into fluent, reconstructed text that efficiently captures the intended meaning of the original. <br/><br/>This interdisciplinary PIRE in computational linguistics fulfills the program objective of advancing scientific knowledge by enabling experts in the United States and Europe to combine complementary talents and share research resources in areas of strong mutual interest and competence. Broader impacts include early career introduction of U.S. graduate students to an international professional network of leading linguists, computational theorists, and experts in human language technology."
"1319667","RI: Small: Fast, Cheap, and In Control: New Methods for Precision Navigation of Low-Cost Autonomous Underwater Vehicles for Ocean Science","IIS","ROBUST INTELLIGENCE","08/01/2013","06/24/2014","Louis Whitcomb","MD","Johns Hopkins University","Continuing grant","Satyandra Gupta","07/31/2016","$335,624.00","","llw@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7495, 7923","$0.00","A novel class of small low-cost unmanned underwater vehicles (UUVs) is beginning to perform oceanographic, environmental assessment, and national security missions that are faster and less expensive than previous methods such as large high-cost UUVs, human-piloted vehicles, and human divers. A significant limitation of small low-cost UUVs is their low-cost navigation systems which presently limit them to missions requiring comparatively low-precision navigation. This project is developing new methods for high-accuracy navigation with low-cost sensors to provide dramatically improved navigation accuracy for low-cost UUVs. The three-part approach (1) employs Doppler sonar velocity measurement and low-cost low-power inertial measurement units to estimate attitude; (2) develops nonlinear model-based state estimators employing a full nonlinear model of the vehicle's second order plant dynamics; and (3) utilizes underwater acoustic modem networks to provide simultaneous acoustic communication and acoustic range and range-rate data, and employ these data for improved underwater vehicle navigation. Experimental validation of these methods includes full-scale experimental trials with two disparate testbed underwater vehicles. Dissemination of the results includes research publications and more general public outreach. This project involves hands-on training and mentoring of undergraduate students and graduate students. The undergraduates will be involved in the research, and will also serve as mentors in a program which provides introductory engineering experiences for middle school girls in the Baltimore area through half-day weekend programs on the Johns Hopkins University campus. This research will enable UUVs to perform missions requiring high navigation accuracy that are presently considered either impractical or infeasible with existing low-cost UUVs."
"1349902","EAGER: Formal and Empirical Foundations of Semantics-Preserving Machine Translation","IIS","ROBUST INTELLIGENCE","08/15/2013","08/15/2013","Adam Lopez","MD","Johns Hopkins University","Standard Grant","Tatiana D. Korelsky","07/31/2015","$149,896.00","","alopez@cs.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7495, 7916","$0.00","Statistical machine translation has been enormously successful over the last two decades, resulting in what is today a thriving industry highlighted by offerings such as Google Translate. Yet translation systems still often fail to preserve the semantics of sentences -- the ""who did what to whom"" relationships that they express. This is because they model translation as simple substitution and permutation of words, or at best as the reordering of syntactic units, such as nouns and adjectives. To preserve semantics, they must model semantics. At the same time, computational linguists have developed rigorous, expressive mathematical models of language that exhibit high empirical coverage of semantically annotated linguistic data, correctly predict a variety of important linguistic phenomena in many languages, and can be processed with highly efficient algorithms. However, these models are untested as the basis of statistical translation models. <br/><br/>This EArly Grant for Exploratory Research aims to close the gap, building the foundations of empirical semantics-preserving transduction models based on modern, linguistically-informed mathematical models of language. The project derives new mathematical functions that map linguistically expressive representations from one language to another, and implement them to align translated documents and translate new documents. Though high-risk, this exploratory project has the potential to unify and transform the disparate fields of empirical machine translation and theoretical computational linguistics."
"0963898","RI: Medium: Collaborative Research: Semi-Supervised Discriminative Training of Language Models","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","06/01/2010","06/03/2014","Sanjeev Khudanpur","MD","Johns Hopkins University","Continuing grant","Tatiana D. Korelsky","08/31/2015","$518,250.00","Damianos Karakos, Chris Callison-Burch","khudanpur@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7298, 7495","5940, 7495, 7924","$0.00","This project is conducting fundamental research in statistical language modeling to improve human language technologies, including automatic speech recognition (ASR) and machine translation (MT). <br/><br/>A language model (LM) is conventionally optimized, using text in the target language, to assign high probability to well-formed sentences. This method has a fundamental shortcoming: the optimization does not explicitly target the kinds of distinctions necessary to accomplish the task at hand, such as discriminating (for ASR) between different words that are acoustically confusable or (for MT) between different target-language words that express the multiple meanings of a polysemous source-language word. <br/><br/>Discriminative optimization of the LM, which would overcome this shortcoming, requires large quantities of paired input-output sequences: speech and its reference transcription for ASR or source-language (e.g. Chinese) sentences and their translations into the target language (say, English) for MT. Such resources are expensive, and limit the efficacy of discriminative training methods. <br/><br/>In a radical departure from convention, this project is investigating discriminative training using easily available, *unpaired* input and output sequences: un-transcribed speech or monolingual source-language text and unpaired target-language text. Two key ideas are being pursued: (i) unlabeled input sequences (e.g. speech or Chinese text) are processed to learn likely confusions encountered by the ASR or MT system; (ii) unpaired output sequences (English text) are leveraged to discriminate between these well-formed sentences from the (supposed) ill-formed sentences the system could potentially confuse them with. <br/><br/>This self-supervised discriminative training, if successful, will advance machine intelligence in fundamental ways that impact many other applications."
"1218709","RI: Small: Structured Sparse Conditional Random Fields Models for Joint Categorization and Segmentation of Objects.","IIS","ROBUST INTELLIGENCE","09/01/2012","08/31/2012","Rene Vidal","MD","Johns Hopkins University","Standard Grant","Jie Yang","08/31/2015","$449,794.00","","rvidal@cis.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7923","$0.00","Object categorization and segmentation are arguably among the most important and challenging problems in computer vision. While these two problems are clearly related, most of the existing literature treats these tasks separately. This project bridges this gap by developing algorithms for joint categorization and segmentation of objects, which simultaneously use category-level information (top-down) and pixel-level information (bottom-up). This project develops a novel graph-theoretic paradigm that combines principles from conditional random fields and sparse representation theory. In this framework, each semantic region is represented in terms of an over-complete dictionary of objects, object parts, subparts and superpixels. To simultaneously estimate both the segmentation and a sparse representation for each region, the research team defines an energy function for the random field, which includes new higher order potentials obtained as the output of a classifier applied to the sparse representation of a segmented region. The research team also explores methods based on structured-sparse dictionary learning and latent support vector machines for learning the dictionaries and the classifier parameters. Furthermore, the research team investigates efficient discrete optimization techniques for minimizing the new energies resulting from the combination of structured-sparse models with different classifiers.<br/><br/>Applications of this research include image search, autonomous navigation (localization and identification of the road, street signs, pedestrians and vehicles), medical diagnostic tools (detection, localization and classification of lesions and tumors in medical images), surveillance (localization of suspicious people, weapons and vehicles) and robotics (identifying the boundaries and extent of objects to be interacted with). The project involves students of different levels."
"1111507","RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","09/01/2011","02/27/2014","Andreas Terzis","MD","Johns Hopkins University","Standard Grant","Satyandra Gupta","08/31/2015","$485,716.00","","terzis@cs.jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","1640, 7495","7925","$0.00","This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br/><br/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering."
"1449211","EAGER: Collaborative Research: Wireless Sensing of Speech Kinematics and Acoustics for Remediation","IIS","Cyber-Human Systems","09/01/2014","07/03/2014","Maysam Ghovanloo","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","08/31/2016","$150,000.00","","mghovan@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7916","$0.00","Speech is a complex and intricately timed task that requires the coordination of numerous muscle groups and physiological systems. While most children acquire speech with relative ease, it is one of the most complex patterned movements accomplished by humans and thus susceptible to impairment. Approximately 2% of Americans have imprecise speech either due to mislearning during development (articulation disorder) or as a result of neuromotor conditions such as stroke, brain injury, Parkinson's disease, cerebral palsy, etc. An equally sizeable group of Americans have difficulty with English pronunciation because it is their second language. Both of these user groups would benefit from tools that provide explicit feedback on speech production clarity. Traditional speech remediation relies on viewing a trained clinician's accurate articulation and repeated practice with visual feedback via a mirror. While these interventions are effective for readily viewable speech sounds (visemes such as /b/p/m/), they are largely unsuccessful for sounds produced inside the mouth. The tongue is the primary articulator for these obstructed sounds and its movements are difficult to capture. Thus, clinicians use diagrams and other low-tech means (such as placing edible substances on the palate or physically manipulating the oral articulators) to show clients where to place their tongue. While sophisticated research tools exist for measuring and tracking tongue movements during speech, they are prohibitively expensive, obtrusive, and impractical for clinical and/or home use. The PIs' goal in this exploratory project, which represents a collaboration across two institutions, is to lay the groundwork for a Lingual-Kinematic and Acoustic sensor technology (LinKa) that is lightweight, low-cost, wireless and easy to deploy both clinically and at home for speech remediation.<br/><br/>PI Ghovanloo's lab has developed a low-cost, wireless, and wearable magnetic sensing system, known as the Tongue Drive System (TDS). An array of electromagnetic sensors embedded within a headset detects the position of a small magnet that is adhered to the tongue. Clinical trials have demonstrated the feasibility of using the TDS for computer access and wheelchair control by sensing tongue movements in up to 6 discrete locations within the oral cavity. This research will leverage the sensing capabilities of the TDS system and PI Patel's expertise in spoken interaction technologies for individuals with speech impairment, as well as Co-PI Fu's work on machine learning and multimodal data fusion, to develop a prototype clinically viable tool for enhancing speech clarity by coupling lingual-kinematic and acoustic data. To this end, the team will extend the TDS to track tongue movements during running speech, which are quick, compacted within a small area of the oral cavity, and often overlap for several phonemes, so the challenge will be to accurately classify movements for different sound classes. To complement this effort, pattern recognition of sensor spatiotemporal dynamics will be embedded into an interactive game to offer a motivating, personalized context for speech motor (re)learning by enabling audiovisual biofeedback, which is critical for speech modification. To benchmark the feasibility of the approach, the system will be evaluated on six individuals with neuromotor speech impairment and six healthy age-matched controls."
"1449266","EAGER: Collaborative Research: Wireless Sensing of Speech Kinematics and Acoustics for Remediation","IIS","Cyber-Human Systems","09/01/2014","07/03/2014","Rupal Patel","MA","Northeastern University","Standard Grant","Ephraim P. Glinert","08/31/2016","$149,994.00","Yun Fu","r.patel@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7367, 7916","$0.00","Speech is a complex and intricately timed task that requires the coordination of numerous muscle groups and physiological systems. While most children acquire speech with relative ease, it is one of the most complex patterned movements accomplished by humans and thus susceptible to impairment. Approximately 2% of Americans have imprecise speech either due to mislearning during development (articulation disorder) or as a result of neuromotor conditions such as stroke, brain injury, Parkinson's disease, cerebral palsy, etc. An equally sizeable group of Americans have difficulty with English pronunciation because it is their second language. Both of these user groups would benefit from tools that provide explicit feedback on speech production clarity. Traditional speech remediation relies on viewing a trained clinician's accurate articulation and repeated practice with visual feedback via a mirror. While these interventions are effective for readily viewable speech sounds (visemes such as /b/p/m/), they are largely unsuccessful for sounds produced inside the mouth. The tongue is the primary articulator for these obstructed sounds and its movements are difficult to capture. Thus, clinicians use diagrams and other low-tech means (such as placing edible substances on the palate or physically manipulating the oral articulators) to show clients where to place their tongue. While sophisticated research tools exist for measuring and tracking tongue movements during speech, they are prohibitively expensive, obtrusive, and impractical for clinical and/or home use. The PIs' goal in this exploratory project, which represents a collaboration across two institutions, is to lay the groundwork for a Lingual-Kinematic and Acoustic sensor technology (LinKa) that is lightweight, low-cost, wireless and easy to deploy both clinically and at home for speech remediation.<br/><br/>PI Ghovanloo's lab has developed a low-cost, wireless, and wearable magnetic sensing system, known as the Tongue Drive System (TDS). An array of electromagnetic sensors embedded within a headset detects the position of a small magnet that is adhered to the tongue. Clinical trials have demonstrated the feasibility of using the TDS for computer access and wheelchair control by sensing tongue movements in up to 6 discrete locations within the oral cavity. This research will leverage the sensing capabilities of the TDS system and PI Patel's expertise in spoken interaction technologies for individuals with speech impairment, as well as Co-PI Fu's work on machine learning and multimodal data fusion, to develop a prototype clinically viable tool for enhancing speech clarity by coupling lingual-kinematic and acoustic data. To this end, the team will extend the TDS to track tongue movements during running speech, which are quick, compacted within a small area of the oral cavity, and often overlap for several phonemes, so the challenge will be to accurately classify movements for different sound classes. To complement this effort, pattern recognition of sensor spatiotemporal dynamics will be embedded into an interactive game to offer a motivating, personalized context for speech motor (re)learning by enabling audiovisual biofeedback, which is critical for speech modification. To benchmark the feasibility of the approach, the system will be evaluated on six individuals with neuromotor speech impairment and six healthy age-matched controls."
"1302360","RI: Medium: Collaborative Research: Decision-Making on Uncertain Spatial-Temporal Fields: Modeling, Planning and Control with Applications to Adaptive Sampling","IIS","ROBUST INTELLIGENCE","06/01/2013","04/24/2014","Marin Kobilarov","MD","Johns Hopkins University","Continuing grant","Satyandra Gupta","05/31/2017","$135,051.00","","marin@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","7495","7495, 7924","$0.00","Inland bodies of freshwater are a resource that is critical for the Nation's health and safety. This project is developing a new spatio-temporal field representation suitable for modeling, planning and control under uncertainty in order to improve monitoring of such water systems. The project's focus is on a reconfigurable aquatic sensor-actuator network designed to capture data from coupled physical, chemical, and biological processes that occur across space and time-scales. The key advantages of this sensor-actuator network in its application to this domain include synoptic volume coverage, adaptive sampling, flexible control and robustness to component failure. The research objective is to build models of dynamic processes for which high resolution sampling is necessary at special locations. Toward this end, this project is contributing new methods, data-structures, algorithms, and implementations validated by field testing a heterogeneous system consisting of stationary and mobile (robotic) underwater node. <br/><br/>This project provides unique interdisciplinary opportunities for education of both graduate and undergraduate students via new course work that blends projects and research topics directly into courses and newly developed seminars. It provides a multi-disciplinary experience for students while developing their engineering skills. Relevant components of computer science, computer engineering, and mechanical engineering are integrated together by using the project's aquatic platform and experimental scenarios as a focal point. <br/><br/>The project advances the state-of-the-art for such systems because it integrates low-level dynamic processes with high-level planning and distributed optimization. The research represents a change in the scale of robotic aquatic sampling away from immense bodies of<br/>water in oceanographic research, toward bodies of water that have a more immediate affect on our well-being as they are sources and stores of drinking water. The impact of datasets which lead to better understanding of managed and natural inlets, differing topography including dam walls and man-made structures, regions of turbulence, and seasonal algal growth are immense."
"1302709","HCC: Medium: Multi-lifespan Information System Research and Design","IIS","Cyber-Human Systems","09/01/2013","07/03/2014","Batya Friedman","WA","University of Washington","Continuing grant","William Bainbridge","08/31/2016","$800,192.00","Tadayoshi Kohno","batya@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7924","$0.00","This project seeks to identify principles by which information and computer scientists can design solutions for systems that will span periods extending beyond a single human lifespan. The challenge is not simply that hardware, software, and information infrastructure change, but also that culture and social institutions change. Thus the research will develop information systems that can adapt to shifting socio-technical conditions as they unfold; provide a delicate balance among remembering, forgetting, and speaking sensitive to different generations; support public discourse; and link distributed digital heritage across technology, institutions, and time. To achieve these goals, the project will leverage the existing Tribunal Voices testbed within four research strands: (1) multi-lifespan envisioning; (2) tagging and meaning making across generations; (3) supporting public discourse in shifting socio-technical conditions; and (4) constructing multi-lifespan policy and infrastructure.<br/><br/>Multi-lifespan systems must be resilient to shifting societal, political, and technological conditions over an extended period of time. A fundamental challenge is to understand what those shifts might be, and how to support such future shifts from a technical perspective in today's designs. This project will explore conceptual, technical, and policy-oriented mechanisms for adapting and supporting such shifts. Another fundamental challenge is determining how to involve the public in interacting with deployed multi-lifespan systems, with sensitivity to multi-generations. This project will develop innovative methods to support public discourse for digital forums and public exhibits with attention to generational perspectives and secure participation. Multi-lifespan systems will need mechanisms for supporting the permanence of data, even as technologies change, as well as the intended impermanence of data. This project will develop integrated technical mechanisms and interaction designs to support a balance among remembering, forgetting, and speaking about difficult topics. <br/><br/>This will be the first large-scale research and design investigation from a multi-lifespan design approach. The goals are two-fold: First, achieving technical progress by generating general design knowledge and methods for multi-lifespan information system design. Second, achieving social progress by contributing meaningful information system designs in support of advancing international justice and reconciliation between groups that had been in conflict with each other. In its broadest framing, through the development and refining of the core theory and methods of multi-lifespan information system design, this project seeks to shape the future of human-centered computing such that the next generation of scientists is well positioned to frame and address problems on a longer-term societal level."
"1016900","III: Small: RUI: Collaborative Research: Exploiting Information Graphics in a Digital Library","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","05/03/2012","Stephanie Schwartz","PA","Millersville University","Standard Grant","Maria Zemankova","08/31/2015","$120,857.00","","stephanie.schwartz@millersville.edu","PO Box 1002","Millersville","PA","175510302","7178723820","CSE","7364","7923, 9229, 9251","$0.00","This project is a collaborative effort between the University of Delaware and Millersville University. Information graphics (non-pictorial graphics such as bar charts and line graphs) occur frequently in popular media such as newspapers and magazines. Not only is the knowledge conveyed by these graphics very often not included in the article's text, but (in contrast with scientific documents) the article's text most often does not even explicitly refer to the graphics. Information retrieval research has focused on the text of documents, and their information graphics have largely been ignored. Yet, the graphic designer considered the graphic's message important enough to warrant designing a graphic to convey it. This project's goal is a novel methodology for retrieving relevant information graphics from a digital library in response to user queries.<br/><br/>Information graphics in popular media generally have a communicative goal or message that they are intended to convey. This message encapsulates the high-level knowledge contained in the graphic. The approach of the project is a language model that treats the relevance of a graphic to a query as a mixture of three components: a graphic's intended message, other textual components of the graphic such as its caption and additional textual description augmenting the caption, and the text of the document containing the graphic. Challenges that are being addressed include identifying the portion of the article that is relevant to the graphic, associating query terms with the intended messages of graphics in the document library, expanding the abbreviated captions and additional textual descriptions of graphics to more fully capture their content, and appropriately weighting the contribution of individual components of the mixture model. In addition, some kinds of graphics, such as grouped bar charts, have both a primary intended message and a secondary message. The impact of the secondary message on retrieval when an ideal graphic is unavailable is also being addressed. Evaluation of the graph retrieval methodology consists of experiments in which human subjects rate the relevance of retrieved graphics to user queries.<br/><br/>The goal of this project is to produce a system for retrieving relevant information graphics, thereby expanding the utility of digital libraries. Together with the SIGHT system, which conveys the content of information graphics via speech, the project will extend the information resources available to individuals with sight-impairments. The project will also produce a corpus of information graphics and their XML representations that can be used by other researchers. Corpora and research results will be disseminated on the project web site (http://www.cis.udel.edu/~carberry/Graph-Retrieval). In addition to significantly increasing the resources accessible from a digital library, the research will lay the foundation for expanding research on question-answering to take into account information graphics. The project will contribute to the development of future scientists by educating graduate students, providing research opportunities for undergraduates at a predominantly undergraduate institution, and enhancing the mentoring skills of graduate students as they work on a team that includes undergraduates."
"1150115","CAREER: Social Multimedia as Volunteered Geographic Information: Crowdsourcing What-Is-Where on the Surface of the Earth Through Proximate Sensing","IIS","INFO INTEGRATION & INFORMATICS","07/01/2012","07/02/2014","Shawn Newsam","CA","University of California - Merced","Continuing grant","Maria Zemankova","06/30/2017","$316,313.00","","snewsam@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2092284318","CSE","7364","1045, 7364, 9251","$0.00","This project investigates social multimedia for geographic discovery. Specifically, community-contributed ground-level images and videos are used to map what-is-where on the surface of the Earth in much the same way that overhead images taken from air- or space-borne platforms have been used for decades in the traditional field of remote sensing. The overarching premise is that georeferenced social multimedia data can be considered a form of volunteered geographic information. Further, it can enable geographic discovery not possible through traditional means. The framework, termed proximate sensing, is applied to two challenging geographic discovery problems: 1) land-use classification, and 2) mapping public sentiment such as how scenic a particular geographic location is. Land-use classification is an important problem but is often not possible using overhead images since remote sensing does not record activities. This project instead applies and extends state-of-the-art techniques in image understanding to ground-level images and videos to map land-use. The motivation is similar for mapping public sentiment.<br/><br/>The broader impacts include developing K-12 spatial literacy curricula through an Engineering Projects in Community Service team whose client is the Merced County Office of Education. University of California-Merced was recently classified as an Hispanic Serving Institution, making it one of only a handful of research universities with this designation nationwide. Undergraduate students from underrepresented groups will be involved in developing a GeographUSA project whereby volunteers can upload geographically representative photos of the United States. Results, datasets, and other project artifacts will be made available through the project website (http://vision.ucmerced.edu/projects/socialmultimedia/)."
"1420146","CHS: Small: Collaborative Research: Sampling and Reconstruction for Computer Graphics Rendering and Imaging","IIS","Cyber-Human Systems","09/01/2014","06/25/2014","Ravi Ramamoorthi","CA","University of California-Berkeley","Standard Grant","Ephraim P. Glinert","08/31/2017","$250,000.00","","ravir@cs.ucsd.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367","7367, 7453, 7923","$0.00","Sampling of high-dimensional signals is at the heart of graphical rendering and computational photography, but current approaches unfortunately still tend to be brute-force and require large numbers of samples, which is time-consuming and costly. In this project, which involves researchers at two institutions, the Principal Investigators will build on their prior work to develop a comprehensive theoretical, algorithmic and systems foundation for sampling and reconstruction in computer graphics rendering and imaging. A key goal is a unified sampling theory that considers the type of coherence in the visual signal (such as low rank, locally low rank, low frequency, sparsity) and the type of measurement (such as point samples in rendering or projection of generic patterns for light transport acquisition, or acquisition of full light field imagery). This will provide a unified framework for choosing the best sampling strategy, and for comparing different approaches. It will also enable the establishment of rigorous lower bounds and optimality results. The work has immediate connections to signal-processing, applied mathematics and photography, and will have broad impact in connecting these domains with computer graphics. The Principal Investigators will disseminate project outcomes in part by incorporating the findings into their online courses that have large enrolments. They will also make datasets and software available, and will work to include them in industrial applications by exploiting their strong ties with a number of high-tech companies. <br/><br/>Physically-based rendering algorithms are now widespread in production, but photorealistic rendering is still inefficient since it involves the evaluation of a high-dimensional 4D-8D Monte Carlo integral for each pixel considering antialiasing, lens effects, motion blur, soft shadows and global illumination. Typically, each pixel is treated separately, with many samples needed for each integral dimension. Similar challenges arise in other areas of computer graphics, such as precomputed rendering (explicit tabulation of a 4D-8D light transport operator), light transport acquisition (measurement of high-dimensional 4D-8D functions like the BRDF or BSSRDF), and computational photography or imaging that acquires higher-dimensional 4D functions in consumer light field cameras. The traditional approach is to (pre)compute or measure the data by brute force, followed by compression. However, this incurs unacceptable costs given the size and dimensionality of current visual appearance datasets. In this work the Principal Investigators will leverage the sparsity in the continuous (rather than discrete Fourier) domain, coherence and structure of light transport to sample, reconstruct and integrate, reducing the amount of data needed by orders of magnitude, while developing new reconstruction schemes for computational imaging. Within rendering, the PIs will explore a novel method that combines motion blur, depth of field, and global illumination in a single algorithm for real-time rendering based on adaptive Monte Carlo sampling and filtering of different effects. A key challenge in such approaches is robust sampling of difficult paths; the Principal Investigators will address this issue with conservative adaptive sampling and Graduated Metropolis. Finally, new systems-level software will be developed that enables easy integration and implementation of light transport simulation methods for rendering and imaging."
"1351034","EAGER: ATAROS: Automatic Tagging and Recognition of Stance","IIS","LINGUISTICS, ROBUST INTELLIGENCE","09/15/2013","05/14/2014","Gina-Anne Levow","WA","University of Washington","Standard Grant","Tatiana D. Korelsky","08/31/2015","$257,836.00","Mari Ostendorf, Richard Wright","levow@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","1311, 7495","7495, 7916, 9251","$0.00","From activities as simple as scheduling a meeting to those as complex as balancing a national budget, people take stances in negotiations and decision making. While the related areas of subjectivity and sentiment analysis have received significant attention, work has focused almost exclusively on text, whereas much stance-taking activity is carried out verbally. Early experiments suggest that people alter their speaking style when engaged in stance-taking, and listeners can much more readily detect negative attitudes by listening to the original speech than by reading transcripts. However, due to the diversity of factors that influence speech production, from individual differences to social context, isolating the signals of stance-taking in speech for automatic recognition presents substantial challenges.<br/><br/>This Early Grant for Exploratory Research project represents a focused exploration of spoken interactions to provide a characterization of linguistic factors associated with stance-taking and develop computational methods that exploit these features to automatically detect stance-taking behavior. Robust linguistic markers of stance-taking are identified through analysis of both controlled elicitations and archived recordings of Congressional hearings on the financial crisis. The former allow experimental comparisons to highlight sometimes subtle contrasts, while the latter enable validation and extension of those findings in real-world, high-stakes discussions. The analysis includes novel acoustic-phonetic measures of dynamic patterns in speech, such as vowel space scaling and pitch/energy velocity, with sophisticated visualization techniques developed to support feature exploration. Findings are validated via stance recognition experiments combining acoustic and lexical cues, which lay the foundation for automatic tracking of trends and shifts in attitudes."
"1111107","SOCS: Socially Intelligent Computing for Coding of Qualitative Data","IIS","Cyber-Human Systems, VIRTUAL ORGANIZATIONS, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2011","05/15/2014","Kevin Crowston","NY","Syracuse University","Continuing grant","Tatiana D. Korelsky","08/31/2015","$779,831.00","Nancy McCracken","crowston@syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","7367, 7642, 7953","7367, 7642, 7953, 9251","$0.00","This project will develop and evaluate an innovative research tool, based on Natural Language Processing (NLP) and Machine Learning (ML), to support qualitative social science research, specifically content analysis. Content analysis is a qualitative research technique for finding evidence of concepts of theoretical interest using text rather than numbers as its raw data. The process of identifying and labeling significant features in text is referred to as ""coding,"" and the result of such an analysis is a text annotated with codes for the concepts exhibited. This technique has become increasingly popular and more applicable as the volume of available ""born-digital"" text has exploded. However, the reliance on manual analysis of the text limits the scale and scope of content analysis research.<br/><br/>In this project, the problem of coding qualitative data is conceptualized as an information extraction problem amenable to automation using NLP. However, rather than seeking to automate the process, the technologies will be used in a supporting role, creating a human-computer partnership. ML will be used to induce NLP rules from examples of coded text, avoiding the need to develop rules manually. To reduce the amount of training data needed from the human participants, an active learning process will be employed, in which a few hand-coded examples are used to create an initial model that can be further evolved through interaction with the user. These approaches will be combined in a prototype tool to support qualitative content analysis. As a demonstration and test of the tool, it will be applied to current and novel studies of cyber-infrastructure-supported distributed groups, specifically free/libre open source software development teams, and then to a broad range of social science research problems. This broad usage will also provide a test of the generalizability of a socio-computational approach to this problem.<br/><br/>The intellectual merit of the research is four-fold. First, the proposal seeks to develop a novel socio-computational system that supports a human-computer partnership through the integration of information extraction and active learning. Second, a validation study will apply the tool to a diverse set of codes, providing evidence of the generality and limits of a socio-computational approach. Third, the demonstration studies using the tool will contribute to research on distributed groups. Finally, the project addresses a fundamental methodological problem in the broad domain of qualitative research, namely dealing with large quantities of unstructured qualitative data, by applying innovative computer-support. By avoiding the need for hand-written rules and reducing the required amount of hand-annotated training data, this partnership will make practical the use of a system for coding large quantities of qualitative data in various domains.<br/><br/>The project has numerous broader impacts. It will benefit society by providing useful infrastructure for research in the form of a content analysis tool for scientific research and in for the form of corpora of annotated data for use in future Natural Language Processing research. The demonstration studies will provide generalizable knowledge to improve the effectiveness of distributed groups, an increasingly important mode of organization. Finally, the project contributes to the education and training, of women and minority group members in particular."
"1344272","INSPIRE Track 1: The Age of Water and Carbon in Hydroecological Systems: A New Paradigm for Science Innovation and Collaboration through Organic Team Science","IIS","INFORMATION TECHNOLOGY RESEARC, GEOBIOLOGY & LOW TEMP GEOCHEM, Cyber-Human Systems, SURFACE EARTH PROCESS SECTION, VIRTUAL ORGANIZATIONS, INSPIRE","10/01/2013","07/02/2014","Christopher Duffy","PA","Pennsylvania State Univ University Park","Continuing grant","Kevin Crowston","09/30/2016","$1,000,000.00","Yolanda Gil, Paul Hanson","cxd11@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","1640, 7295, 7367, 7570, 7642, 8078","8653, 7367","$0.00","This INSPIRE award is partially funded by the Geobiology & Low Temperature Geochemistry Program in the Division of Earth Sciences in the Directorate for Geoscience; the Human Centered Computing Program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering; and the Virtual Organizations as Socio-technical Systems Program in the Division of Advanced Cyber-Infrastructure in the Directorate for Computer & Information Science & Engineering.<br/><br/>This project will develop new scientific work practices and cyberinfrastructure tools to advance the fields of hydrology and limnology (lake ecology). The project will develop a socio-technical model of ""organic team science"" in which scientists are motivated to collaborate across diverse scientific communities and to share and normalize data to solve scientific problems through an open framework. potentially creating new cross-disciplinary collaborations around the modelling problems. The project will advance hydrology by making already-collected geospatial data more usable for analysis and simulations. It will advance limnology by developing an integrated hydrodynamic model of lakes as connected to the broader hydrologic network to quantify water, material, nutrient and energy fluxes, which is potentially transformative for limnology. The project will be carried out with collaborators including the NSF Susquehanna/Shale Hills Critical Zone Observatory and the GLEON projects.<br/><br/>The project will provide benefits by developing cyberinfrastructure to provide access for limnology to climate and geospatial data and models as well as novel practices for supporting organic team science. The later is potentially a significant and transformative contribution to the infrastructure for science. The hydro-dynamic model could be useful for those managing lakes. The proposal includes plans for outreach to the scientific community to share these findings."
"0964697","HCC: Medium: Collaborative Research: Guiding Folksonomy Development to Enable Novel Tagging Applications","IIS","Cyber-Human Systems","04/15/2010","02/06/2014","Shilad Sen","MN","Macalester College","Continuing grant","William Bainbridge","03/31/2015","$249,646.00","","ssen@macalester.edu","1600 Grand Avenue","Saint Paul","MN","551051801","6516966000","CSE","7367","7367, 7924, 9215, HPCC","$0.00","This is a study of tagging, the assignment of labels to information objects by users, and the ""folksonomy"" categorization systems that can result. By the 19th Century, increasing amounts of information were being published, and it was clear that efficient methods of organization were needed for the information to be accessible. In response, categorization schemes like the Library of Congress Classification and the Dewey Decimal System were invented. The overall information dissemination system contained clear roles and divisions of labor: editors decided what got published, information professionals categorized published works, and most people simply consumed the results. The Internet has toppled this traditional approach. There is no publication barrier, so orders of magnitude more information is available online and information professionals cannot keep up. However, new technologies have arisen that work in this context, notably tagging. Any user can associate tags with items such as documents, movies, or photos, and the tags serve as keys for retrieval. Since tags can be created by any user, the number of tags contributed scales with a community's size: thus, tagging works at Internet scale. Tagging lets users represent their own perspectives, which aids retrieval.<br/><br/>However, tagging is a young technology, with significant challenges and unmet potential. Individual tags are often of poor quality, and many tagging systems are globally incoherent. Empirical evaluations of tagging systems in use are few, and formal comparisons to traditional approaches have not been done. Tagging applications have been limited mainly to search. This project addresses these challenges. It will develop a firmer scientific understanding of the strengths and weaknesses of tagging as a categorization method. It will explore the potential of tagging to enable powerful applications beyond information retrieval. The project consists of three main research activities: (1) Creating a set of metrics to quantify the value of a categorization structure; using these metrics in formal and empirical comparisons of tagging systems to traditional categorizations; (2) Designing mixed-initiative interaction techniques for computational agents and people to detect, evaluate and resolve problems in tagging systems; (3) Developing novel tag-based applications for users to express their preferences and navigate complex information spaces.<br/><br/>This research will create both information-theoretic and usage-based metrics to measure the value of a categorization structure. Studies will be done to show relations between the two types of metric, letting designers predict, for example, how many tags per item are required for effective user search. Systematic cost-benefit comparisons of tagging systems to traditional expert categorizations will be done, thus providing empirical data to a debate that has been characterized by heated conjecture. The utility and generality of a set of mixed-initiative interaction techniques and novel applications will be established by (a) implementing them in multiple platforms, and (b) evaluating them in careful field experiments.<br/><br/>Improving the effectiveness of tagging will help millions of users find the information, products, and services they seek. More directly, the techniques of this project will be implemented in four working online communities, for movie viewers, cyclists, ethics researchers, and politically interested citizens. Collectively these sites have tens of thousands of users, all of whom will benefit directly. Many students will be trained, learning multiple research methods and gaining valuable experience with real online communities. Finally, the software will be developed under an open source license and datasets will be published, thus facilitating other researchers and web site developers in their work."
"1219258","RI: Small: Integrating Learning and Search for Structured Prediction","IIS","ROBUST INTELLIGENCE","08/01/2012","05/22/2013","Prasad Tadepalli","OR","Oregon State University","Standard Grant","James Donlon","07/31/2015","$463,437.00","Alan Fern","tadepall@eecs.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7495, 7923, 9251","$0.00","The field of machine learning is extremely successful in solving classification problems where the inputs are fixed size feature vectors and the outputs are a small fixed number of classes. However, many applications such as natural language understanding and visual scene interpretation involve inputs and outputs of variable size that have rich internal structure. This project will study new approaches for such structured prediction problems. For example, the inputs may be natural language documents or visual scenes and the outputs may be formal representations of their semantic content, such as entities inferred or observed and the relationships between them. Most approaches to structured prediction learn a cost function to score potential structured outputs. Finding the correct output for the given structured input then consists of inferring the least cost output. Unfortunately, the computational cost of this inference is prohibitive for expressive cost functions; this forces the use of either simpler cost functions or approximate inference. In either case, prediction accuracy can suffer.<br/><br/>The current project aims to address this issue by integrating learning and search in a new framework that allows for the development of novel algorithms for structured prediction. In particular, this project will address three topics: (1) A generic framework will be developed for cost function learning by imitating the decisions of an optimal time-bounded search procedure on the training data. This will allow for a wide range of state-of-the-art search algorithms to be leveraged for structured prediction. (2) A theory and framework will be developed to learn to speed up the search for a global optimum by compressing the search into a shorter time-frame. This will allow for learning to address not only accuracy but also the computational efficiency of the predictor. (3) Both the cost function learning and speedup learning will be instantiated in multiple search algorithms and evaluated in different applications.<br/><br/>The project seeks to make contributions to a variety of applications of broad impact including natural language understanding, tracking objects in video, and personalized scheduling. The frameworks, algorithms and testbeds for learning to search and structured prediction will be integrated into the Weka tool-box so that they can be easily combined with different supervised learning algorithms and used in further research. The results and benchmark domains will be publicly distributed through the project's web pages. A special topics graduate course will be taught on the topic of this proposal at Oregon State University."
"1149799","CAREER: Advancing End-User Programming with Expertise Sharing Tools","IIS","Cyber-Human Systems","06/01/2012","07/01/2014","Bjoern Hartmann","CA","University of California-Berkeley","Continuing grant","Janet L. Kolodner","05/31/2017","$302,107.00","","bjoern@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367","1045, 7367","$0.00","The objective of this research is to investigate how to improve end-user programmer productivity and learning through user interfaces and algorithms for capturing, sharing, and accessing programming expertise. Focus is on the needs of end-user programmers who create graphical user interfaces and build physical computing systems. Fieldwork and data analyese will be conducted to understand current practices around seeking and providing advice online. Informed by this framework, tools will be developind for creating and sharing high-quality examples and tutorials, finding and recommending relevant examples, and integrating found code into new projects. Success of the methods will be evaluated through laboratory experiments and deployment of instrumented software. This work draws on methodology from computer-supported cooperative work, end-user programming, the design of authoring tools, project-based learning, and design of computer-realized scaffolding. Four types of results will be produced: 1) knowledge about the types of problems end-user programmers seek help on; 2) analysis how current systems help and hinder the sharing of expertise; 3) novel techniques to improve expertise sharing within programming environments; and 4) evaluations that quantify the benefits of such techniques. <br/><br/><br/>Programmers increasingly rely on Web resources such as question answering sites, forums, and example repositories to help them prototype, implement, and debug software. This trend is especially prevalent in end-user programmers, who write code but are not professionally trained in Computer Science. They vastly outnumber professional programmers in the United States. Current development tools are largely ignorant of the social exchange of programming advice online: program editors and Web applications are isolated from each other. This lack of specific applications for describing and sharing programming expertise limits the effectiveness of both production and use of knowledge. This work will lower the threshold for programming digital media. The research will increase the quality, scope, and utility of online reference materials. Access to these materials can accelerate learning, improve productivity, increase self-efficacy of programmers, and democratize the production and sharing of programming knowledge."
"1117705","III: Small: Collaborative Research: Probabilistic Models using Generalized Exponential Families","IIS","INFO INTEGRATION & INFORMATICS","07/01/2011","06/03/2011","Vishwanathan Swaminathan","IN","Purdue University","Standard Grant","Sylvia J. Spengler","06/30/2015","$248,221.00","","vishy@stat.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7923","$0.00","III: Small: Collaborative Research: Probabilistic Models using Generalized Exponential Families<br/>Swaminathan Vishwanathan, Purdue University; Manfred Warmuth, University of California, Santa Cruz<br/><br/>Machine learning is currently indispensible for building predictive models from massive data sets. A large majority of widely used machine learning algorithms are based on minimizing a convex loss function. A fundamental problem with all such models is that they are not robust to outliers. To address this limitation, this project develops probabilistic models based on a parametric family of distributions, namely, the t-exponential family, that lead to quasi-convex loss functions and yield models that are robust to outliers. <br/><br/>The key challenge when working with the t-exponential family of distributions, as in the case of the exponential family, is to compute the log-partition function and perform inference efficiently. The project addresses this challenge in two specific cases. For problems with small number of classes exact iterative schemes are being developed. For problems where the number of classes is exponentially large, approximate inference techniques are being developed by extending variational methods. <br/><br/>In partnership with Google, some of the data mining algorithms resulting from this project are being applied to a challenging real-world problem of recognizing text in photos (the PhotoOCR problem). The project offers opportunities for research-based advanced training of graduate students as well as research opportuinities for undergraduates in machine learning and data mining. Algorithms for constructing predictive models from data that are robust in the presence of outliers are likely to find use in a broad range of applications. Open source implementions of algorithms, publications, and data sets resulting from the project are being made available through the project web page at: http://learning.stat.purdue.edu/wiki/tentropy/start"
"1409886","RI: Medium: Collaborative Research: Models of Handshape Articulatory Phonology for Recognition and Analysis of American Sign Language","IIS","ROBUST INTELLIGENCE","06/01/2014","06/09/2014","Diane Brentari","IL","University of Chicago","Standard Grant","Tatiana D. Korelsky","05/31/2017","$275,546.00","Jason Riggle","dbrentari@uchicago.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","CSE","7495","7495, 7924","$0.00","Sign languages are the primary means of communication for millions of Deaf people in the world, including about 350,000-500,000 American Sign Language (ASL) users in the US. While the hearing population has benefited from advances in speech technologies such as speech recognition and spoken web search, much less progress has been made for sign language interfaces. Advances depend on improved technology for analyzing sign language from video. In addition, the linguistics of sign language is less well-understood than that of spoken language. This project addresses both of these needs, with an interdisciplinary approach that will contribute to research in linguistics, language processing, computer vision, and machine learning. Applications of the work include better access to ASL social media video archives, interactive recognition and search applications for Deaf individuals, and ASL-English interpretation assistance.<br/><br/>This project focuses on handshape in ASL, in particular on one constrained but very practical component: fingerspelling, or the spelling out of a word as a sequence of handshapes and trajectories between them. Fingerspelling comprises up to 35% of ASL, depending on the context, and includes 72% of ASL handshapes, making it an excellent testing ground. The project addresses gaps in existing work by focusing on handshape in various conditions, including fast, highly coarticulated signing. The main project activities include development of (1) robust automatic detection and recognition of fingerspelled words using new handshape models, including segmental and ""multi-segmental"" graphical models of ASL phonological features; (2) techniques for generalizing across signers, styles, and recording conditions; (3) improved phonetics and phonology of handshape, in particular contributing to an articulatory phonology of sign; and (4) publicly released multi-speaker, multi-style fingerspelling data and associated semi-automatic annotation."
"1302700","RI: Medium: Collaborative Research: Object and Activity Recognition as the Maximum Weight Subgraph Problem with Mutual Exclusion Constraints","IIS","ROBUST INTELLIGENCE","09/01/2013","06/16/2014","Sinisa Todorovic","OR","Oregon State University","Continuing grant","Jie Yang","08/31/2017","$252,813.00","","sinisa@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7495, 7924","$0.00","It has been widely acknowledged that recognizing objects in images, and human activities in video - the basic problems in computer vision - can be significantly improved by accounting for object (activity) parts, context, and their spatiotemporal relationships. This is because these constraints facilitate resolving ambiguous hypotheses in the face of uncertainty. Since parts and contexts can be efficiently modeled by graphical models (e.g., Conditional Random Field), object and activity recognition are often formulated as probabilistic inference of graphical models. The project develops a new theoretical framework of graphical models that explicitly encodes high-order, spatiotemporal, hierarchical, and contextual interactions among objects (activities) as Quadratic Mutual-Exclusion Constraints (QMCs), for the purposes of object and activity recognition in images and video.<br/><br/>The key contributions of the project work include: 1) Approaches to view-invariant object and activity recognition; 2) Formulations of learning and inference of graphical models representing objects and human activities, as finding a maximum weight subgraph (MWS) under the QMCs; 3) Polynomial-time algorithms for solving the MWS problem subject to QMCs; and 4) Explicit performance bounds and theoretical guarantees of tightness and convergence of the proposed learning and inference algorithms. <br/><br/>The project framework encodes hard constraints from the domain of interest that have never been used in prior work, and uses principled, polynomial-time algorithms for learning and inference. The research of this project advances the state of the art in object and activity recognition, and enables new applications including video surveillance, retrieval from large datasets, and perception of mobile robots."
"1331932","CyberSEES: Type 2: Computing and Visualizing Optimal Policies for Ecosystem Management","CCF","INFORMATION TECHNOLOGY RESEARC, CYBERINFRASTRUCTURE, ROBUST INTELLIGENCE, CyberSEES","09/15/2013","09/08/2013","Thomas Dietterich","OR","Oregon State University","Standard Grant","Todd Leen","08/31/2016","$1,200,000.00","Claire Montgomery, Ronald Metoyer, Heidi Albers, Mark Crowley","tgd@cs.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","1640, 7231, 7495, 8211","8060","$0.00","Intellectual Merit<br/><br/>Many ecosystems exhibit spatially spreading processes that we would like to manage to either promote or prevent. For example, we seek to prevent the spread of invasive species while promoting the spread of endangered species. For wildland fire, we seek to promote the spread of low-intensity ground fires that prevent the buildup of dangerous fuels while preventing the spread of high-intensity crown fires that destroy endangered species habitat and valuable timber. These management problems can be formulated mathematically as Markov Decision Problems (MDPs) defined over spatial regions. However, because of the spatial nature of these problems, the MDPs are immense and cannot be solved by any existing algorithms. This project develops new MDP solution algorithms for spatial MDPs. These algorithms will work with ecosystem simulators (rather than requiring explicit models) and they will also address the risk of catastrophic outcomes such as species extinction or catastrophic wildfires. <br/><br/>To bridge the gap between the computational solution of an MDP and the actual adoption of such solutions by policymakers, this research develops visualization and interaction methods that will allow stakeholders (e.g., policymakers, land owners, timber industry representatives, conservation biologists) to understand and critique both the problem formulations and the resulting solutions. <br/><br/><br/>Broader Impacts<br/><br/>The new methods will be tested on five management problems: (a) Tamarisk spread in river networks, (b) Cheatgrass spread in Western US range lands, (c) Sudden Oak Death spread in California and Oregon, (d) deciding when to let a wildfire burn versus suppressing it, and (e) deciding where to place fuel reduction treatments in the landscape to reduce fire risk. The Tamarisk, Cheatgrass, and Sudden Oak Death problems will be studied in stylized settings where the relevant environmental properties and costs can be varied. The goal of these studies is to understand how the different spatial spreading processes (exhibited by these different invasive species) determine the structure of the optimal management policy. The results will be published in the literature on natural resource economics and discussed with policymakers in these areas. The wildfire problems (""let burn,"" and ""fuel treatment"") will be studied in a real landscape-a publicly-owned site in the Deschutes National Forest containing a mix of Ponderosa and Lodgepole pine. A collaborating fire manager with the US Forest Service will recruit a panel of stakeholders to analyze and critique the proposed management policies using the visualization and interaction tools that we will develop.<br/><br/>Problems and techniques developed in this project will form the core of the first Summer School in Computational Sustainability, which will be organized by the research team. The results will also be integrated into the OSU Summer Institute in Eco-Informatics (an NSF REU Site) and the OSU Spring Break Course in Monte Carlo AI for junior undergraduates. Four Ph.D. students and one Postdoc will be trained during this project."
"1016394","HCC: Small: Culture,Technology and Wellness: Approaches to Improving the Health and Wellness of US Americans","IIS","Cyber-Human Systems","09/01/2010","08/26/2010","Rebecca Grinter","GA","Georgia Tech Research Corporation","Standard Grant","William Bainbridge","08/31/2015","$496,694.00","","rebecca.grinter@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7923","$0.00","The goal of this research is to examine how the incorporation of culturally specific values into health-related ICTs might increase the likelihood of their adoption, as well as how those culturally specific values bear on their practical use. This research sits at the intersection of two research thrusts that are gaining momentum within Human Centered Computing, and contribute to the intellectual development of both. First, this proposed research contributes to the human-centered health ICT research domain by explicitly accounting for culturally specific values in the design of applications. Medical evidence in the U.S. shows that health interventions will likely not succeed unless they are culturally relevant. And yet, little research to date has attempted to explicitly incorporate culturally specific values into design, or has evaluated value-sensitive systems in use. Results of this research will show how different values can be designed into health ICTs, and how that affects their usage. It will also surface the values implicit in current health ICTs. Second, there is a body of research (largely in Human Computer Interaction for Development (HCI4D)) that argues that culture must be explicitly taken into account in the design of ICTs for them to succeed. When it is accounted for, significant innovations can result. This literature makes a compelling case for explicitly accounting for cultures outside the United States, but simultaneously points to a surprising omission: knowledge about the ICT implications of cultural diversity within the United States. This research addresses that gap by showing how explicit attention to cultural values can lead to transformative socio-technical systems for health and wellness. Further, as has been reported within the HCI4D literature, focus on culturally specific values also provides opportunities to reflect on assumptions embedded within the methods, frameworks and systems that guide human-centered research. <br/><br/>The project will focus on three areas, each answering different research questions. 1) Impact of value discovery and the design and evaluation of ICTs that incorporate those values. The idea that systems have values is an established research finding within HCC. Value Sensitive Design (VSD) explicitly argues for accounting for values in the design of systems. The proposed work will bring research on values in design into the health domain by empirically identifying values and designing them into ICTs that provide culturally relevant health information. Evaluations of each intervention will focus on adoption and rejection patterns with particular focus on use (or not) as related to the values designed into the system. 2) Impact of culturally distinct patterns of collaboration. Collaboration is an essential component of health; support of friends and family complements an individual?s health management. However, public health researchers find that collaboration, particularly cooperation, extends beyond the family to the community in various sub-cultures. These results suggest that opportunities exist to refine our understanding of collaboration, by asking questions about the nature and patterns of interactions surrounding health practices. Questions focus on what is being shared, who is communicating with whom and how, and where ICTs have the most promise for supporting existing modes of collaboration as well as developing entirely new ones.3) How infrastructure differences present an opportunity for transformative solutions. Public health research suggests that culturally tailored health innovations are particularly important in low-income minority communities. But reports suggest that ICT adoption is increasing among these communities, and also that different types of systems are being appropriated because of the differences in infrastructure."
"1148867","CAREER: Scientific Computing for a New Generation of Ecologists","DEB","POP & COMMUNITY ECOL PROG, INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY, INFO INTEGRATION & INFORMATICS, MSPA-INTERDISCIPLINARY, ALGORITHMIC FOUNDATIONS","09/01/2012","07/30/2012","Stefano Allesina","IL","University of Chicago","Standard Grant","Douglas Levey","08/31/2017","$599,244.00","","sallesina@uchicago.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","BIO","1182, 1640, 1714, 7275, 7334, 7364, 7454, 7796","1045, 7931, 8007, 8750, 9169, ","$0.00","Ecology is about to face the data deluge that other biological disciplines have already experienced. With ecological data increasing rapidly in quality and size, new methods are needed to extract the most relevant biological information from massive data-sets. The objective of this project is to develop new mathematical, computational and statistical tools for the analysis of three ecological problems. First, when a species goes extinct, the impact reverberates through the ecological network, possibly causing the extinction of other species. A new method to predict such ""secondary extinctions"" will be developed. Second, the number and size of published ecological networks is increasing rapidly, making it possible to answer one of the oldest questions in ecology: how many species traits (e.g., body size, swimming speed, metabolic rate) does one need to measure to predict whether two species will interact? A new computational method, coupled with a large dataset will attempt to answer this question. Knowing which are the critical traits determining the possibility of interactions could find application in the study of invasive species. Third, the spatial structure of ecosystems mediates many ecological processes. A new method will be developed to measure the impact of spatial heterogeneity on the structure of ecological networks.<br/><br/>The development of these new tools require sophisticated methods, which are not typically included in the curriculum of biologists. The educational goal of the project is to train ecologists in the computational methods that will be needed to advance the discipline in the decades to come. Graduate students will learn how to automate the analysis of biological data, distribute computation over large computer clusters, organize data into relational databases, program in different languages, collaborate on data, code and manuscripts, automatically managing versions and conflicts, and pick the right tool for each task. Outreach activities will be provided through lectures and media interviews and with activities carried out in collaboration with local elementary schools and the Museum of Science and Industry."
"1125228","Collaborative Research: CDI-Type II: BirdCast: Novel Machine Learning Methods for Understanding Continent-Scale Bird Migration","IIS","INFO INTEGRATION & INFORMATICS, CDI TYPE II","09/01/2011","09/09/2012","Thomas Dietterich","OR","Oregon State University","Standard Grant","Sylvia J. Spengler","08/31/2015","$1,000,865.00","","tgd@cs.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7364, 7751","7721, 7751, 9251","$0.00","An interdisciplinary team of computer scientists, statisticians, and ornithologists will develop novel computer science methods and apply them to the challenge of understanding the annual migration of birds across North America, which is one of the most complex and dynamic natural phenomena on the planet. While direct observation of migrating birds is limited to a handful of birds wearing tracking devices, other sources of data provide partial information about migration that, when appropriately combined, will provide insight into migration at a scale previously unimaginable. These sources include a continent-wide network of volunteer bird watchers, night flight calls captured by a network of acoustic monitoring stations, continent-scale weather patterns gathered by a network of weather stations, and clouds of migrating birds detected at night by WSR-88D weather radar stations. To analyze these data, the team will develop two innovative machine learning techniques-Collective Graphical Models (CGMs) and Semi-Parametric Latent Process Models (SLPMs). The resulting model will be able to identify the complex conditions governing the dynamics of migration behavior including the choice of migratory pathways, the factors that influence when birds migrate, and the speed and duration of each night's movements. CGMs greatly extend the scope of phenomena that can be captured with graphical models. Under suitable conditions, a CGM is able to recover a model of the behavior of individuals using only collective observations.<br/><br/>For BirdCast, it will construct a model of individual bird dynamics from the collective observations provided by birders, acoustic and weather stations, and weather radar. Once the model is constructed, it will be applied to live data feeds (bird sightings, acoustic detections, radar detections, and weather forecasts) to predict bird migration in real time. SLPMs are an extension of latent process models, such as the CGM for bird migration, in which the dynamics of a process is represented by latent variables that are observed only indirectly. In an SLPM, the conditional probability distribution of each variable is modeled using flexible, non-parametric methods from machine learning, such as boosted regression trees. Introducing such flexible methods such as CGMs and SLPMs into latent variable models raises difficult challenges for model fitting and validation. Preventing over-fitting will require the creation of novel information regularization and latent model cross-validation methods to enforce latent variable semantics.<br/><br/>The proposed work will allow, for the first time, real-time predictions of bird migrations: when they migrate, where they migrate, and how far they will be flying. Accurate models of migration have broad application for basic research by allowing researchers to understand behavioral aspects of migration, how migration timing and pathways respond to variation in climatic conditions, and whether linkages exist between annual variation in migration timing and subsequent inter-annual changes in population size.<br/><br/>BirdCast will expand opportunities for the public to participate in the gathering of data and its analysis. The existing data set has more than 60 million observations, and the size is growing exponentially. Last year, volunteers contributed more than 1.3 million hours observing birds. Student engagement in the research is significant as well."
"0964705","RI: Medium: Collaborative Research: Optimizing Policies for Service Organizations in Complex Structured Domains","IIS","ROBUST INTELLIGENCE","07/01/2010","06/15/2013","Prasad Tadepalli","OR","Oregon State University","Continuing grant","Todd Leen","06/30/2015","$588,401.00","Alan Fern","tadepall@eecs.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7495, 7924, 9251","$0.00","This project studies an important class of complex structured planning <br/>domains called ``service domains'' using simulators and probabilistic<br/>action models. Examples of service domains include optimizing emergency <br/>response in a typical city, scheduling doctors and nurses in a <br/>hospital, administering tasks in a typical office, optimally delivering <br/>products to shops from distribution centers. These domains <br/>share many characteristics such as relational structure, parallel actions, <br/>multi-time-scale decision making, exogenous events, and the need for <br/>human interpretable solutions that make them highly challenging.<br/>The project develops scalable and principled planning algorithms for <br/>service domains through a variety of techniques including a novel<br/>hierarchical framework of multi-time-scale optimization, new<br/>model-free simulation-based planning algorithms, and model-based <br/>planning via composition of first-order decision diagrams. These <br/>techniques are applied to the real-world problem of optimizing <br/>the fire and emergency response in cities through a collaboration<br/>with the fire department of Corvallis, Oregon. <br/><br/><br/>The results of the project include new algorithms and frameworks to solve <br/>service domains, prototype implementations of the algorithms<br/>in the emeregency response domain, and new testbeds of service domains <br/>for research. The broader impact of the work includes more cost-effective <br/>emergency response systems, and development of new research-oriented courses, <br/>tutorials and special workshops on the next generation decision support <br/>systems for service domains."
"1414600","Doctoral Mentoring Consortium at the Thirteenth International Conference on Autonomous Agents and Multi-Agent Systems","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","05/01/2014","04/30/2014","Kagan Tumer","OR","Oregon State University","Standard Grant","James Donlon","04/30/2015","$25,000.00","","kagan.tumer@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","1640, 7495","7495, 7556","$0.00","This grant supports student travel for select students participating in the Doctoral Mentoring Consortium (DMC) at the Thirteenth International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), Paris, France, May 5-9, 2014. This is the premier international conference for researchers in agents and multi-agent systems (MAS) across a fully international research community. <br/><br/>This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research. The central activities for the DMC include opportunities for students to present and discuss their work with their peers; interaction with an identified group of senior researchers for advice on Ph.D. research, a ""careers panel"" to discuss career choices in industry and academia, small group activities led by assigned mentors, and a great deal of opportunity for interactions with the international research community in AAMAS, which might lead to future collaborative activity. In addition, the DMC includes a Tutorial Program with full-day and half-day tutorials that will provide detailed overviews of specific subfields by leading researchers in the field. <br/><br/>Sponsoring student travel to AAMAS conveys many benefits beyond the DMC program. The sponsored students have full access to a well-developed AAMAS workshop and conference program covering a diverse range of research areas in this community. This is an opportunity for students to engage in discussion with scientists from around the world and to explore new research directions and topics. This year AAMAS also includes unique conference activities in Robotics, Virtual Agents, Innovative Applications and Special Challenges and Visions. Students also have the opportunity to attend the Demonstrations track. Such demonstrations of agent technologies and agent-related software and hardware are a significant source of motivation and inspiration to budding researchers. <br/><br/>The broader impact of supporting this student participation is clear. AAMAS is the major international conference that will figure prominently in the research careers of students who remain involved in agents and MAS. Students gain valuable research insights from the exchange of technical ideas in this broader venue. In the process, they make valuable connections with potential collaborators from around the world. As intelligent software and embodies systems become more prevalent, it is clear that advances in intelligent agent technology will have significant impact in virtually any domain imaginable, including such national priorities as health and well-being, e-commerce, and national defense."
"1314384","HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","IIS","Cyber-Human Systems","08/01/2013","08/07/2013","Martin Erwig","OR","Oregon State University","Standard Grant","Ephraim P. Glinert","07/31/2017","$857,141.00","Margaret Burnett","erwig@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7367","7367, 7925","$0.00","In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br/><br/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask ""why"" questions to understand the differences among variations of a system. For novices, an ""Idea Garden"" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br/><br/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students."
"1320943","RI: Small: Automated Planning of Experiments for Design Optimization","IIS","ROBUST INTELLIGENCE","08/01/2013","06/13/2014","Alan Fern","OR","Oregon State University","Continuing grant","James Donlon","07/31/2016","$456,000.00","Xiaoli Fern","afern@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7495, 7923, 9251","$0.00","Many engineering and scientific projects require planning experimental activities in order to optimize an objective. Such planning involves jointly reasoning about both the budget-limited resource constraints among activities along with the utility of potential information that they may provide. Unfortunately, for many real-world planning problems, with rich structure among potential activities, tools from classic experimental design are not directly applicable due to their simplifying assumptions and poor scalability. This project aims to transform the practice of experimental planning by developing new algorithms that account for the complexities exhibited in a wide range of domains.<br/><br/>The project involves three key activities. First, the experimental design description language (EDDL) is being created for formally modeling complex real-world experimental domains. Second, novel planning algorithms are being developed for efficiently computing high-quality solutions to problems expressed in EDDL. Third, work with bioengineers is assessing and improving the usability of the tools and producing benchmark problems based on real and simulated bioengineering data. The creation of the language and benchmarks will help facilitate algorithm comparisons for continued progress by the wider research community.<br/><br/>The broader impact of the project is to facilitate experiment planning in a wide range of experimental domains for which there are currently no available computational tools. Currently, in such domains, planning is largely ad-hoc and often done without computer support. Our research has broad economic impact potential by helping engineers and scientists to get the most value out of limited experimental resources. The project also advances high school, undergraduate, and graduate education in the areas of computer science and bio-engineering, with an emphasis on recruiting female students. The students will get the unique experience of working across disciplines and research labs."
"1445796","EAGER: Collaborative Research: Articulate: Augmenting Data Visualization With Natural Language Interaction","IIS","Cyber-Human Systems","08/15/2014","06/30/2014","Jason Leigh","HI","University of Hawaii","Standard Grant","Ephraim P. Glinert","07/31/2015","$58,479.00","","leighj@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","CSE","7367","7367, 7453, 7916, 9150","$0.00","Nearly one third of the human brain is devoted to processing visual information. Vision is the dominant sense for the acquisition of information from our everyday world. It is therefore no surprise that visualization, even in its simplest forms, remains the most effective means for converting large volumes of raw data into insight, a process that can support scientific discovery. However a key challenge hindering scientific users from adopting the latest visualization tools and techniques is the steep learning curve that has to be overcome in order to make use of them. The tendency then is to resort to the simplest tools, such as bar charts and line graphs, even though they may lack the expressive power necessary to bring scientific data into focus.<br/><br/>The notion that scientists would ideally like to simply speak with a computer to ask questions about their data, and have the computer automatically generate visualizations that answer their queries, has been well known since at least the NSF 2007 report ""Enabling Science Discoveries through Visual Exploration."" This is the motivation for the current project, which involves a collaboration among researchers at two institutions, given that scientists still are unable to do so. The PIs' ultimate goal is to implement a Virtual Visualization Expert to translate the language of science into the language of visualization. To demonstrate the concept is indeed viable, the PIs previously developed and evaluated a small prototype, which supported their argument that by relieving the user of the burden of having to learn how to use a complex interface one could enable them to focus on articulating better scientific questions.<br/><br/>Given this initial success, the focus of this exploratory research is to establish the foundations of a more generalizable approach that can encompass techniques used in scientific visualization. To this end, the PIs will research the steps needed for mapping natural language requests, which may be accompanied by gestures, into meaningful visualizations and for enabling incremental creation and modifications of visualizations. They will develop innovative models to understand the intent of the user and the objects s/he is referring to, and they will explore how best to design user interfaces for creating and modifying visualizations using language and direct manipulation. The PIs' initial study showed that all these capabilities are crucial to enabling users to make the best use of a dialogic interface for data visualization. Although project outcomes will be geared in the short term to serving the scientific community, the techniques should be applicable more broadly to consumers of information, such as citizen scientists, public policy decision makers, and students."
"1055113","CAREER: Active Learning for Exploratory Clustering","IIS","INFO INTEGRATION & INFORMATICS","01/15/2011","02/19/2014","Xiaoli Fern","OR","Oregon State University","Continuing grant","Sylvia J. Spengler","12/31/2015","$490,846.00","","xfern@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7364","1045, 9251, 1187, 7364","$0.00","Data clustering is a widely used tool for organizing data into coherent groups that correspond to the underlying structure in data. In many applications, incorporating domain knowledge into clustering can help enhance both the quality and the utility of the results of clustering. Unfortunately, users who are not data mining experts currently lack effective means of providing such input to guide clustering. Against this background, Dr. Xiaoli Fern of Oregon State University seeks to develop a novel class of algorithms that take advantage of active learning strategies to interactively elicit information from users to drive clustering. <br/><br/>An important aim of this work is the identification of types of input e.g., in the form of must-link and cannot-link constraints, that are both informative and easy to interactively elicit from users to improve the quality and utility of the results of clustering. The study is driven by and evaluated using exploratory data analysis tasks that arise in several application domains (1) ecosystem informatics e.g. exploratory analysis of in-field bird recordings; (2) human-computer interaction (HCI) e.g., analysis of HCI data to understand user behavior; and (3) plant genomics in collaboration with scientists with expertise in each of these domains. <br/><br/>Improved tools for interactive exploratory data analysis benefit a broad range of applications including most areas of science in which such analysis is beginning to play an increasingly important role in extracting knowledge from data. For example, in ecological informatics, such tools can help scientists to better understand the impact of environmental changes on bird species which in turn can help develop better methods for managing ecosystems. Research-based education and training opportunities offered by this project help prepare a new generation of researchers and practitioners in exploratory data analysis as well as the emerging area of Ecosystem Informatics at Oregon State University. Dr. Fern's outreach efforts are aimed at helping draw female undergraduates and K-12 students from under-represented groups to careers in computer science and engineering. Further information on this project can be found at http://web.engr.oregonstate.edu/~xfern/CAREER"
"0917308","HCC: Small: Collaborative Research: Graph and Pattern Design on Surfaces","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","08/01/2009","06/10/2014","Eugene Zhang","OR","Oregon State University","Standard Grant","Ephraim P. Glinert","07/31/2015","$264,976.00","","zhange@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7367, 7453","7367, 7453, 7923, 9215, 9251, HPCC","$0.00","Abstract ? Zhang/Wonka<br/><br/>The research investigates theory and efficient algorithms for pattern design on surfaces. Patterns on surfaces appear in many natural phenomena such as leaves, animal textures, and terrains as well as man-made objects such as origami, glass ornaments, and facades. Patterns can also be used to describe networks, such as street layouts, power grids, aqueducts, and sensor networks. Pattern design has a wide range of applications in art and entertainment, architecture, engineering, medicine, and city planning. In addition, theory and techniques developed in the research can benefit domains such as computational geometry and vector and tensor field visualization.<br/><br/>There are several fundamental challenges when it comes to pattern design on surfaces. First, there is a lack of unified mathematical formulations of patterns in terms of both symmetries and orientations contained in the patterns. Consequently, the aforementioned applications are typically addressed as being unrelated despite the intrinsic links between them. Second, many past approaches to these problems lack hierarchical control. This is required so that the user can design high level information down to occasionally low level specifics and the layout algorithms fill in the rest procedurally. In this research, the investigators explore a unified framework that allows hierarchical design of patterns on surfaces. In this framework, orientation and symmetry information is specified everywhere in the domain through tensor field design. Next, the tensor field which contains desired orientation and symmetry information is used to generate a complex which can be a point set, a graph, a tiling, or any combination of them. Finally, additional details are added onto the complex through texture and geometry synthesis, or sub-patterns are added inside the cells of the complex. Ideas from various mathematical domains such as dynamical systems, tensor calculus, differential geometry, and algebraic topology are borrowed and applied in this research."
"1422455","RI: Small: Mathematical Analysis of an Answer Set Programming Language","IIS","ROBUST INTELLIGENCE","07/01/2014","07/01/2014","Vladimir Lifschitz","TX","University of Texas at Austin","Standard Grant","James Donlon","06/30/2017","$404,037.00","","vl@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7495, 7923","$0.00","Answer Set Programming (ASP) is a programming methodology designed for solving combinatorial search problems, where the goal is to find a solution among a finite but very large number of possibilities. Such problems are common in science and technology. In safety-critical applications of ASP it is important to have a higher level of confidence in the correctness of software than can be achieved by merely applying it to many test cases; mathematical methods must be used to prove with complete certainty that the program finds the correct answer in every possible case. This project develops such mathematical methods.<br/><br/>In the early days of ASP, the input languages of answer set solvers had a simple semantics based on the concept of a stable model. But many constructs added over the years to the language of ASP because programmers found them useful cannot be explained in terms of stable models in the sense of the original definition of that concept or its straightforward generalizations. Manuals written by the designers of answer set solvers explain the meaning of these programming constructs using examples and informal comments that appeal to the user's intuition, without references to any precise semantics. The first goal of this project is to characterize the semantics of ASP in a mathematically precise way using an extension of stable models to logical formulas with infinite conjunctions and disjunctions. Second, this semantics is used for verifying the correctness of ASP programs and optimization methods. The broader impacts of this work include collaboration with other research groups for dissemination, validation and adoption of the research results, and integration of the research into graduate education."
"1302439","III: Medium: Collaborative Research: Spatial Data and Trajectory Data Management on GPUs","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","07/01/2014","Le Gruenwald","OK","University of Oklahoma Norman Campus","Continuing grant","Sylvia J. Spengler","07/31/2017","$232,119.00","","ggruenwald@ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7364","7924, 7364, 9150","$0.00","Although locating and navigation devices embedded in smartphones have already generated large volumes of location and trajectory data, the next generation of consumer electronics are likely to generate even larger volumes of location-dependent data where spatial and trajectory data management techniques will play critical roles in understanding the data to facilitate decision making. Modern Graphics Processing Units (GPUs) are capable of general computing. Current generation of commodity GPUs have large numbers of processing cores, support even larger numbers of current threads and provide high memory bandwidth, yet are available at affordable prices. The massively data parallel computing power of GPUs makes the hardware ideal for spatial and trajectory data management which is both data and computing intensive.<br/><br/>This project develops parallel indexing structures and query processing algorithms for spatial and trajectory data on GPUs to provide high performance which is crucial in speeding up existing applications and enabling new scientific and business inquiries. The project achieves its goals by developing: 1) novel spatial indexing techniques on GPUs; 2) novel spatial joins on GPUs; 3) novel trajectory segmentation and indexing techniques and trajectory similarity query processing techniques on GPUs; and 4) an end-to-end prototype system incorporated with open source database and GIS systems for performance evaluations and real world applications. Compared with existing spatial and trajectory data management systems that are mostly disk-resident and adopt a serial CPU computing model, the performance of GPU accelerated main-memory based systems is expected to achieve several orders of magnitude speedup and brings the performance of spatial and trajectory queries to a new level. The research results are beneficial to many applications, such as transportation, urban planning, wild bird ecology, and epidemiology of infectious diseases. Collaboration is carried out with transportation engineers at the University Transportation Research Center in New York City and ecology scientists at the University of Oklahoma?s Earth Observing and Modelling Facility. The project also makes important impacts on education as it provides training for students in the areas of national critical needs: database research, high performance computing, GPU programming, GIS, transportation, mobile and ecology applications. The developed algorithms and prototype system, real datasets and performance evaluation results are made available to the public at the Website: http://www.cs.ou.edu/~database."
"1319829","HCC: Small: Activity-Enriched Computing","IIS","Cyber-Human Systems","09/15/2013","07/01/2014","James Hollan","CA","University of California-San Diego","Continuing grant","Anthony Hornof","08/31/2016","$355,035.00","","hollan@cogsci.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367","7367, 7923","$0.00","Although myriad extraordinary benefits have resulted from the web and expanding network connectivity, the intertwining of computers with virtually every aspect of life also brings a growing stream of interruptions. These interruptions and the fragmenting of activity they produce are increasingly accepted parts of modern life. A critical research challenge for human-centered computing is how to smooth and mitigate the impact of interruptions as well as assist in resuming interrupted activities. Meeting this challenge will require moving beyond the traditional document-centric view of information to address the complexity of real activity, its often fragmented history, and the need to access information arrayed across digital and paper media.<br/><br/>This project will explore the design of systems that will allow people to exploit visual and episodic memory to benefit from the capture of the history and context of their computer-mediated activities. The heart of the project is rethinking the nature of data as stored in computers from being a state to being an inspectable activity history of interaction that can be presented to users. Activity-enriched computing has the potential to reshape how we use computers by creating systems that react to and are augmented by the history of past events, changing the computer environment to one in which history is always available to assist if needed. The primary scientific contributions will be to (a) develop an activity-enriched computing framework for designing a new class of systems in which history is a first-class element, (b) prototype and evaluate activity-enriched applications, and (c) extend theory and methods for representing, visualizing, and analyzing activity histories. Scientific contributions will include a novel activity-enriched computing framework that will (a) capture the rich detail of computer-mediated activity, (b) identify and make meaningful and useful episodes available, (c) link the worlds of paper and digital documents, and (d) exploit summarization and visual access mechanisms to support navigation of activity histories and ease resuming interrupted activities. The overarching objective is to lessen the impact of interruptions and aid reestablishment of context.<br/><br/>Broader Impacts: The broader impacts of the proposed activity include the potential to radically improve the efficacy of all computer-mediated activities. The results of the project and the software developed will be widely disseminated and made available on the project website. Additional impact will result from training students in the interdisciplinary approach required to design activity-enriched computing applications, providing research opportunities for both graduate and undergraduate students. A long-term impact will be to crystallize a research community to further develop and evolve activity-enriched computing."
"1018490","RI: Small: Grounding Probabilistic Event Logic in a Hierarchy of Video Segmentation Tubes","IIS","ROBUST INTELLIGENCE","09/15/2010","03/13/2012","Sinisa Todorovic","OR","Oregon State University","Standard Grant","Jie Yang","08/31/2014","$465,984.00","Alan Fern","sinisa@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7923, 9251","$0.00","The project addresses the fundamental challenge of grounding high-level semantic concepts about events into low-level video data. The key innovations include: (1) Representing events via probabilistic event logic (PEL) along with corresponding inference and learning algorithms, (2) Video segmentation into a hierarchy of space-time tubes, and (3) Robustly grounding PEL into space-time tubes via AND-OR grammars. Space-time tubes are extracted by tracking candidate object boundaries across frames, where both boundary detection and tracking are learned from training videos. PEL allows for arbitrary, probabilistic, spatiotemporal constraints among events, including the traditional compositional rules, Allen relations between time intervals, and correlations among different events. Unlike existing work, the logical nature of PEL allows humans, even non-experts, to easily inject their own knowledge into the system. PEL conducts joint, holistic inference to find the globally best parse over all events, which is grounded in an AND-OR grammar of primitive events. The AND-OR grammar uses robust graph matching of video tubes for handling uncertainty in low-level visual processing. <br/>For evaluation, two video datasets of American football and a building?s atrium are compiled, with fully annotated event labels, object tracks, and spatiotemporal segmentations. <br/><br/>Training is provided for graduate and undergraduate students, including those from under-represented groups. The project is expected to: (a) advance the state of the art which typically focuses only on video classification; (b) make the two datasets public; (c) generate workshops/tutorials on the related topics; and (d) produce publications in the highest-impact journals/conferences."
"1160995","III: CCF: Medium: Collaborative Research: Combinatorial Analysis of Biological and Social Networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","06/29/2014","Bhaskar DasGupta","IL","University of Illinois at Chicago","Continuing grant","Sylvia J. Spengler","08/31/2015","$356,222.00","","dasgupta@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364","7924","$0.00","In this collaborative interdisciplinary proposal involving a researcher at the University of Illinois at Chicago (UIC) and one at the Pennsylvania State University (Penn State), the investigators will design and apply novel algorithmic tools to explore several fundamental graph-theoretic problems that have significant applications in biological and social interaction networks. The research problems addressed in the proposal can be broadly classified into graph partitioning type of problems and graph sparsification type of problems. For example, one such problem in the context of social interaction networks is to partition the nodes into so-called ""communities of statistically significant interactions"" to study the behavioral patterns of a group of individuals in a society. The PIs will formulate precise computational problems, study their properties, use novel algorithmic tools to design efficient algorithms, and implement the resulting algorithms to test their accuracy and efficiency. The proposed research will leverage further development of novel combinatorial tools previously developed by the PIs, in addition to developing new techniques, to design efficient algorithms for complex optimization problems. The algorithms developed in the course of this project will be implemented for validation on simulated and real data, and will lead to open-source software for the life science and social science communities.<br/><br/>On a broader level, since this proposal deals with fundamental combinatorial optimization problems that arise in diverse scientific fields, the proposed research will have a strong impact on research areas beyond the primary research area, such as in stability analysis of computer networks and in social network visualization. A central component of the proposal is the creation of meaningful educational activities that leverage the proposed interdisciplinary research and build on the PIs' substantial past experience in teaching, mentoring and outreach and on the diverse communities in Chicago . Additionally, the PIs plan to integrate research and education via course and curriculum development, involvement of undergraduates, minorities and under-represented groups, effective dissemination of research, mentoring of undergraduate and graduate students, outreach and community involvement, and promoting diversity in research and educational activities.<br/><br/>The outcomes of the project will be made freely available through the following websites of the investigators and their labs: http://www.cs.uic.edu/~dasgupta; http://www.cs.uic.edu/~dasgupta/professional/algo-lab.html; and http://www.phys.psu.edu/~ralbert."
"1445751","EAGER: Collaborative Research: Articulate: Augmenting Data Visualization With Natural Language Interaction","IIS","Cyber-Human Systems","08/15/2014","06/30/2014","Barbara DiEugenio","IL","University of Illinois at Chicago","Standard Grant","Ephraim P. Glinert","07/31/2015","$241,521.00","Leland Wilkinson, Andrew Johnson","bdieugen@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7367","7367, 7453, 7916","$0.00","Nearly one third of the human brain is devoted to processing visual information. Vision is the dominant sense for the acquisition of information from our everyday world. It is therefore no surprise that visualization, even in its simplest forms, remains the most effective means for converting large volumes of raw data into insight, a process that can support scientific discovery. However a key challenge hindering scientific users from adopting the latest visualization tools and techniques is the steep learning curve that has to be overcome in order to make use of them. The tendency then is to resort to the simplest tools, such as bar charts and line graphs, even though they may lack the expressive power necessary to bring scientific data into focus.<br/><br/>The notion that scientists would ideally like to simply speak with a computer to ask questions about their data, and have the computer automatically generate visualizations that answer their queries, has been well known since at least the NSF 2007 report ""Enabling Science Discoveries through Visual Exploration."" This is the motivation for the current project, which involves a collaboration among researchers at two institutions, given that scientists still are unable to do so. The PIs' ultimate goal is to implement a Virtual Visualization Expert to translate the language of science into the language of visualization. To demonstrate the concept is indeed viable, the PIs previously developed and evaluated a small prototype, which supported their argument that by relieving the user of the burden of having to learn how to use a complex interface one could enable them to focus on articulating better scientific questions.<br/><br/>Given this initial success, the focus of this exploratory research is to establish the foundations of a more generalizable approach that can encompass techniques used in scientific visualization. To this end, the PIs will research the steps needed for mapping natural language requests, which may be accompanied by gestures, into meaningful visualizations and for enabling incremental creation and modifications of visualizations. They will develop innovative models to understand the intent of the user and the objects s/he is referring to, and they will explore how best to design user interfaces for creating and modifying visualizations using language and direct manipulation. The PIs' initial study showed that all these capabilities are crucial to enabling users to make the best use of a dialogic interface for data visualization. Although project outcomes will be geared in the short term to serving the scientific community, the techniques should be applicable more broadly to consumers of information, such as citizen scientists, public policy decision makers, and students."
"1219200","HCC: Small: Towards more natural and interactive brain-computer interfaces","IIS","Cyber-Human Systems","09/01/2012","08/01/2013","Virginia de Sa","CA","University of California-San Diego","Continuing grant","Ephraim P. Glinert","08/31/2015","$422,396.00","Scott Makeig","vdesa@cogsci.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367","7367, 7923","$0.00","Brain computer interfaces (BCIs) translate basic mental commands into computer-mediated actions. BCIs allow the user to bypass the peripheral motor system and to interact with the world directly via brain activity. These systems are being developed to aid users with motor deficits stemming from neurodegenerative disease, injury, or even environmental restrictions which make movement difficult or impossible. One popular class of EEG-driven BCI systems is based on imagined movement. In these systems the user interacts with a computer through motor imagery such as the imagination of hand vs. tongue movement. But the ability of users to control such a BCI is very variable, and all the factors involved are not fully understood. For example, EEG signals can change drastically from offline training to online use. Unfortunately, drift in EEG can lead to loss of control of the BCI, which leads to user frustration and further drift of EEG signals from their training baselines.<br/><br/>The PI's goal in this project is to create a more robust BCI system by specifically addressing loss of control and system drift. Her hypothesis is that explicitly training on a signal that incorporates a user's satisfaction and, more importantly, dissatisfaction with the current performance may result in a more natural interface, and thereby lead to a reduction in loss of control and improved system usability and performance. The research will be carried out in three stages. First, active and passive EEG signals of dissatisfaction and satisfaction will be analyzed in a simulated online setting. Next, a real-time online system that recognizes dissatisfaction vs. satisfaction to control 1-D cursor movement will be constructed and system performance compared to that of a standard left/right motor imagery system. Finally, the best working parts of the dissatisfaction/satisfaction system will be integrated with the more standard left/right system, to create a better hybrid system. The (dis)satisfaction signals will be based on actively controlled motor imagery signals, interpreted emotion, and detection of error-like signals.<br/><br/>Broader Impacts: This project has the potential to vastly improve the robustness of EEG-based BCI systems, by responding to natural signals of satisfaction and dissatisfaction, by being resistant to drift, and by naturally taking advantage of frustration which is a common cause of loss of control. By training the BCI to recognize frustration the PI expects to turn this typically negative trait into a positive. The project will support and train an under-represented minority graduate student and a post-doc in this important interdisciplinary area, and it will create projects for under-represented REU participants as well as for high school students through the PI's partnerships with the NSF Temporal Dynamics of Learning Center (TDLC, where she is a member of the faculty governing and admissions committee for the REU program) and the Preuss School (a charter school for low income students with no college educated parent). All software written for EEG signal processing and analysis, as well as data from the experiments, will be made available as add-ons to EEGLAB which is distributed by co-PI Makeig."
"1446810","WORKSHOP: Doctoral Consortium at the 2014 ACM International Conference on Collaboration Across Boundaries (CABS 2014)","IIS","Cyber-Human Systems","07/01/2014","06/30/2014","Scott Robertson","HI","University of Hawaii","Standard Grant","Ephraim P. Glinert","06/30/2015","$23,408.00","","scott.robertson@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","CSE","7367","7367, 7556, 9150","$0.00","This is funding to support participation by students and faculty based in U.S. educational institutions in a Doctoral Consortium (workshop) that will bring together promising doctoral students and distinguished researchers from academia and industry, to be held in conjunction with the 5th International ACM Conference on Collaboration Across Boundaries: Culture, Distance and Technology (CABS 2014), which will take place in Kyoto, Japan, on August 20-22. Sponsored by the Association for Computing Machinery's Special Interest Group on Computer-Human Interaction (SIGCHI), the annual CABS conference is a growing international forum for the presentation and discussion of research and practice focused on understanding and supporting intercultural communication and global teams. CABS serves as a gathering point for researchers who share a common interest in understanding how technology can be used to bridge people from multiple cultures. A fundamental premise of the conference is that the difficult problems of language and culture that arise in cross-cultural communication and collaboration can only be adequately addressed by multidisciplinary efforts. Thus, attendees come from diverse academic disciplines including computer science, engineering, management science, information science, communication, psychology, sociology, and anthropology. Attendees also span the globe, with participation from the United States, China, Japan, Korea, Israel, France, Denmark, Germany, the UK, and other countries. The conference solicits competitive paper, panel, demo and other submissions; peer-reviewed, archival papers and notes appear in the ACM Digital Library. More information about the conference may be found online at http://cabs.acm.org/2014/.<br/><br/>The CABS Doctoral Consortium is a research-focused meeting of a group of 10-12 selected PhD candidates and a panel of 4-5 distinguished researchers from academia and industry. The event, whose goal is to help launch the careers of outstanding researchers in the area of intercultural collaboration, will take place on August 20, with follow-up events during the conference's technical program on August 21-22. NSF funds will support participation by one senior researcher from the United States (the PI) and 8 students based in U.S. educational institutions. The full-day Doctoral Consortium will provide students with exposure to their research community, with an opportunity to present their work and receive constructive feedback from peers and senior researchers in the field, and with ample time to start building a professional support network of peers and mentors (e.g., during the organizational and working dinners). The feedback is geared toward helping student participants understand and articulate how their work is positioned relative to other CABS research, whether their topics are adequately focused for dissertation research projects, whether their methods are correctly chosen and applied, whether their results are being appropriately analyzed and presented, etc. The student participants will also present their work as posters, which they have prepared before arrival, during the CABS technical program. During the interactive poster session the students will be present to discuss their work with interested attendees, but the posters will be available for viewing throughout the entire three days of the conference. The students' work is thus showcased for conference attendees, and the students have the opportunity to get feedback from a larger audience. In addition, abstracts for all Doctoral Consortium attendee presentations will be printed as a packet to be distributed to all CABS attendees, and the full extended abstract for each presentation will be made available on the CABS 2014 website. The event organizers will make special efforts to promote participation from U.S. institutions and ethnic groups that have been traditionally underrepresented at CABS. They will also consider equitable gender balance in the mix of accepted students. To further increase diversity among the student participants, the organizers have committed to accepting no more than 1 student from any particular institution, except in the case that 2 qualified students of different genders apply in which case both may be accepted."
"1344257","INSPIRE Track 1: Language-Based Computational Methods for Analyzing Worldviews","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, ROBUST INTELLIGENCE, INSPIRE","10/01/2013","06/30/2014","Rada Mihalcea","MI","University of Michigan Ann Arbor","Continuing grant","William Bainbridge","09/30/2016","$793,206.00","James Pennebaker","mihalcea@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","1640, 7367, 7495, 8078","1332, 8653","$0.00","This INSPIRE award is partially funded by the Cyber-Human Systems Program in the Directorate for Computer and Information Science and Engineering, the Robust Intelligence Program in the Directorate for Computer and Information Science and Engineering, and the Social Psychology Program in the Directorate for Social, Behavioral and Economic Sciences. The goal of this project is to gather new insights into the ways people organize and understand their worlds within and across different cultures by means of innovative methodologies and tools from the fields of psychology and computational linguistics. The findings from this project will provide a better understanding of people on the individual psychological level as well as the cultures themselves, while developing and demonstrating new research techniques that can be used in future by many disciplines to exploit the vast troves of scientifically valuable textual data currently available online. Specifically, the project targets the following three main research objectives: 1) Construct a very large multicultural database of writings from English-speaking cultures, covering several styles and genres, including: social media (e.g., blogs, tweets); news articles; literary works; student writings. 2) Build computational linguistic models that can automatically identify differences in concept usage for different cultures, and apply these models on a large scale. 3) Validate the findings of these computational models through psychological qualitative and quantitative methods in laboratory studies. <br/><br/>The ways people use words can provide insights into the ways they see and understand their worlds. Everyday language can also tell us about people's social, emotional, and psychological states and even the ways they think about themselves and others. Particularly interesting is that many of the social and psychological insights we find with the language of individuals can be extrapolated to groups, communities, and entire cultures. This project seeks to analyze the written language of people across several cultures in a way that will allow us to better understand the ways groups of people understand their worlds. In short, it will use advances in computational linguistics and social psychology to track the underlying values, beliefs, and concerns of very large groups of people by analyzing the ways they use words. Unlike previous studies, which have been limited to relatively small self-report surveys targeting a handful of concepts across cultures, this project will help us understand the differences in perception for thousands of concepts, by several cultures representing hundreds of thousands of people.<br/><br/>This project promises to shed new light on cultural differences by analyzing the ways people understand their worlds through their everyday language use. The approach will inform applications in communication, threat control, tracking of cultural values, and others. The project will also provide educational opportunities, in the form of training for students in both computer science and psychology, who will be directly exposed to interdisciplinary research, cultural diversity, and international experiences. Finally, the large multicultural dataset that will be created as part of this project, along with the tools to process it, will be made publicly available, thus enabling future research, as well as educational projects concerned with the analysis and understanding of cultural diversity and worldview."
"1012733","HCC: Large: SSCI-MISR: Symbiotic, Spatial, Coordinated human-robot Interaction for Multiple Indoor Service Robots","IIS","INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","08/01/2010","06/30/2014","Manuela Veloso","PA","Carnegie-Mellon University","Continuing grant","Ephraim P. Glinert","07/31/2015","$3,006,152.00","Reid Simmons, Illah Reza Nourbakhsh, Aaron Steinfeld","veloso@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, 7367","7367, 7925, 9251","$0.00","Despite the significant advances in robotics research and development over the years, there are still no pervasive intelligent mobile robots coexisting with humans in daily environments. Among the many possible reasons as to why this is the case, this project addresses the challenge of an effective concrete interaction of mobile robots with humans, focusing on tasks which enable joint human and robot performance and require spatial interaction. The PI's vision is that project outcomes will make it possible to have multiple robots in, say, an office building available for different navigational and informational tasks, including accompanying daylong visitors through their schedule of meetings, giving tours to occasional visitors, fetching objects for and taking them to people in offices, and delivering the daily mail. To achieve this goal, she plans to transform the state of the art in robot technology for social service robotics, by introducing a novel symbiotic human-robot and robot-robot interaction paradigm that allows robots to help and be helped by humans and each other. A robot will ask humans for assistance based on self awareness of its own limitations and a utility analysis of the estimated cost and benefits of the assistance. The PI and her team will develop and evaluate a robot platform-independent and building-independent problem environment representation, along with algorithms for incremental map learning, localization and navigation, and asynchronous (multi-robot) task partitioning and planning under uncertainty with a utility analysis that includes human availability for robot helping. They will explore effective spatial interaction between mobile robots in spaces with humans, utilizing social conventions, so that people are not just obstacles from the robot's perspective. The robot science and development research will be seamlessly integrated with educational and outreach activities, as well as with principled evaluation which will include fielding a team of robots in campus buildings.<br/><br/>Broader Impacts: Aside from dramatically advancing the state of the art in robot technology, enabling multiple mobile robots to be part of the workspace of an office building environment will have significant educational impact relating both to robot technology and interaction with robots. Continuous, openly available robot presence in the computer science and robotics research spaces will change the nature of the relationship between researchers and their classroom research projects, by triggering synergistic collaborations and new, higher-risk experiments with lower setup cost. C Campus outreach tours will be transformed from a narrow view of the future of technology in laboratory settings to a sweeping exposure to the reality and implications of humans and robots coexisting throughout the built environment, significantly broadening inquiry and discussion about the role of interactive technology in our lives. Disseminated curricula incorporating low-cost mobile robots in the secondary school classroom will lift the robot-classroom relationship from one of build kits for very low-capability robots to one of high-level interaction design, industrial design, and discussions of human-robot relationships."
"1065489","RI: Medium: Dynamical Coordination and Sequencing of Multifunctionality in Animals and Robots","IIS","ROBUST INTELLIGENCE","07/01/2011","06/30/2014","Roger Quinn","OH","Case Western Reserve University","Continuing grant","Kenneth C. Whang","06/30/2015","$1,115,993.00","Hillel Chiel","rdq@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7495","7495, 7924, 9251","$0.00","How can intelligent control be created for autonomous robots that will allow them to respond flexibly and adaptively to changing environments? In the animal world, relatively simple animals such as soft-bodied invertebrates, are capable of coordinating their many possible movements, flexibly shifting and sequencing multiple behaviors as conditions change, and learning to alter their behavior based on experience. For robots, however, this remains a challenge, which is addressed in this project using a novel control architecture that can produce sensory driven or cyclic movements.<br/><br/>Traditional control architectures for robotics have three layers: high level deliberative planning, low-level reactive control, and an intermediate level for sequencing and simple decision-making. Creating intermediate level controllers for intelligent behavior is particularly challenging, and a major obstacle to progress in autonomous robotics. This problem will be addressed using a novel neural-inspired control architecture, stable heteroclinic channels (SHCs) that can flexibly and robustly orchestrate multiple degrees of freedom for multifunctionality, and can readily handle behavioral hierarchies, temporal decision-making, and learning. Their properties also allow them to incorporate some of the best aspects of the two traditional approaches to robotic control: finite state machines and central pattern generator (limit cycle) controllers. SHC-based dynamical architectures underlying multifunctionality will be analyzed in a soft-bodied animal that is tractable to experimentation, and principles from these neurobiological architectures will be used to implement multifunctional behavior in a novel hyper-redundant, soft-bodied robot platform.<br/><br/>There are many possible applications for adaptive, flexibly-controlled soft-bodied, or hyper-redundant, robots that are able to coordinate their many degrees of freedom in varying ways to accomplish multiple functions. A multifunctional worm-like robot could crawl through pipes of varying diameter and at any angle with respect to gravity and make sharp turns at intersections. A hollow hyper-redundant robot could inspect water mains from the inside, without interrupting water flow. Such a robot could be used for oil and gas pipeline inspections to avoid costly and environmentally disastrous leaks. Smaller versions could be developed for endoscopic diagnosis of the gastrointestinal tract. The proposed work will lead to a single controller framework that can robustly coordinate multiple coupled actuated mechanisms within a robot, and describe the sequencing of distinct behaviors in both animals and robots."
"1016324","RI: III: Small: IInterlinking Image Collections","IIS","ROBUST INTELLIGENCE","09/01/2010","08/16/2010","Leonidas Guibas","CA","Stanford University","Standard Grant","Jie Yang","08/31/2015","$448,678.00","","guibas@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7923","$0.00","The availability of digital cameras, improved networking, and the diminishing cost of memory has made it easy to capture, share, and store large image collections. With dense sampling, there are many connections and correlations among these captured images, as they effectively record the same or visually similar objects. This project aims to build such networks of linked images on a large scale, store the inter-image relationships in the form of a graph or simplicial complexes called Image Webs, study the properties of these networks, and exploit them for a variety of applications.<br/><br/>Establishing links between parts of images based on image content analysis, and doing so on the scale of millions of images, is a computationally demanding task. Since it is impractical to do this for all image pairs, techniques are developed for attempting to establish links only between pairs for which (1) a link is likely to exist and, (2) the link adds substantially to what is already known about the connectivity of a particular Web. A deeper understanding of the global structure of image webs as topological complexes can aid this link prediction process. Methods are developed for effectively navigating these large structures and for constructing useful maps over them. Integration with more symbolic information associated with images is possible by transferring information around in this vast network.<br/><br/>The project is of a highly interdisciplinary nature, combining techniques from continuous applied mathematics, traditionally used in signal processing and image analysis, with methods from discrete mathematics and network theory."
"1162617","HCC: Medium: Collaborative Research: Haptic Display of Terrain Characteristics and its Application in Virtual and Physical Worlds","IIS","Cyber-Human Systems","10/01/2012","06/27/2014","Mark Minor","UT","University of Utah","Continuing grant","Ephraim P. Glinert","09/30/2016","$826,385.00","John Hollerbach, Kenneth Foreman, Andrew Merryweather","mark.minor@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7367","7367, 7924, 9251, 9150","$0.00","The PIs' goal in this research is to realistically display terrain in an immersive Virtual Reality (VR) locomotion interface, based upon modification of the foot/terrain interaction coupled with graphical and auditory display of the terrain and user interaction. Project outcomes will include novel ""smart shoe"" technology capable of sensing and modifying the terrain perceived by the wearer at each step so that terrain slope, surface stiffness, height variations, slip and balance can be actively controlled. The approach is based upon an instrumented shoe sole with a directionally compliant structure using controllable bladders and embedded sensors to regulate terrain effects as the user walks. The design and control of the shoe will be based upon dynamic biomechanical and terrain interaction models. Subject data will provide a baseline for design, verification, and validation of the system. A robotic test-bed will validate shoe response characteristics prior to subject evaluations.<br/><br/>The platform for this work will be the existing TreadPort Active Wind Tunnel (TPAWT), which is capable of realistically displaying locomotion environments on varying slopes as well as providing controllable wind, heat, and odor display. The cave-like display of the TPAWT will be converted to a three dimensional stereo graphics system with seamless floor projection in order to present local terrain features such as shape, height variations, and surface texture. Combined representation, interpretation, and coordination of the graphical and physical artifacts will be considered with the aim of creating an immersive and realistic locomotion experience with the end goal of achieving practical application. This combined system is termed the TPAWT Terrain Display System (TPAWT-TDS).<br/><br/>The target test group for the new technology will be patients with Parkinson's Disease, (PD), for whom VR training has already shown some promising results for improving gait characteristics and reducing the likelihood of falls. Survey data from PD patients will motivate selection of the specific terrain. Regular and PD users will first be evaluated on physical mockups of the terrain, which will then be recreated and evaluated in follow-up trials in the VR environment. Once validated, the VR terrain display will be used for PD training. Users will again be evaluated on the physical mockups to evaluate gait and balance performance, which will also be compared to untrained subjects.<br/><br/>Broader Impacts: The ""smart shoe"" technology to be created in this project will allow exploration of new and sophisticated methods for combining 3D graphical terrain cues with an actively changing physical terrain in a novel VR interface. The resulting environment will have myriad potential applications as a rehabilitation and training tool, not the least of which is improved locomotion and fall prevention (since falls are the single most costly form of injury today). Development of the new technology will be combined with rigorous human participant studies. Research findings will be disseminated via websites and at major conferences, and also integrated into the robotics, virtual reality, ergonomics, and physical therapy curricula."
"1439616","HCC: Small: STAAR: Spatial Touch Audio Annotator and Reader for Individuals with Blindness or Severe Visual Impairment","IIS","Cyber-Human Systems","11/20/2013","06/05/2014","Francis Quek","TX","Texas A&M University Main Campus","Standard Grant","Ephraim P. Glinert","07/31/2015","$302,067.00","","quek@tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","CSE","7367","7923, 7367","$0.00","The PI's goal in this research is to develop tools on a state-of-the-art platform (the Apple iPad) that will afford access to textual information for individuals who are blind or who suffer from severe visual impairments (IBSVI). The PI's approach is to use an embossed screen overlay to provide spatial and tactile correlates to text read aloud, and to engage the spatial cognition and memory resources of the target population for navigating through a document and annotating it if/as desired. The PI argues that from the invention of print media forward, information has been formulated and optimized for consumption by beings (people) with a dominant visual capability. This visuo-spatial bias is not well-understood or studied in the context of information access by and delivery to the IBSVI community; most technological information aids funnel information to them as sequential aural streams, obviating the use of broader spatial cognitive resources. In this project the PI will develop a Spatial Touch Audio Annotator and Reader (STAAR) testbed to explore a multimodal alternative that enables the user to fuse spatial layout and informational content through touch location on a slate-type device and audio rendering of text to speech, respectively. STAAR will enable self-paced reading using a tactile overlay pattern on an iPad surface, which will be designed to provide tactile landmarks to help the user navigate the ""page."" STAAR will render the text chunk touched audibly. The use of touch gestures to enable contextualized highlighting and note-taking will also be investigated. The PI will study how the target population may employ spatial strategies and exploration to re-find and re-access information both in the act of reading and for recall after some time interval. <br/><br/>Broader Impacts: A new generation of slate-type devices exemplified by the Apple iPad threatens to widen the accessibility gap between the IBSVI community and the majority of the population. By supporting the use of spatial cognitive and memory resource for both reading and contextualized annotation, the PI hopes to ameliorate this endemic barrier to participation. Project outcomes will contribute to our understanding of the role of space in information design and representation, and the spatial cognition and memory resources needed for uptake of such information. And they will contribute to the domain of mobile computing, for the IBSVI community in particular but ultimately for the population in general, through the STAAR system, which will be designed and implemented from the ground up as a portable device on a state-of-art interaction form-factor. The multimodal fusion of haptics and speech in STAAR will have implications for the designs of such things as navigational aids and service delivery systems for the non-sighted as well as the sighted. The project will in addition provide unique cross-disciplinary educational and learning opportunities for undergraduate and graduate students. All software developed in this project will be placed in open source."
"1319974","HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative","IIS","Cyber-Human Systems","08/01/2013","06/27/2014","Joseph Magliano","IL","Northern Illinois University","Continuing grant","William Bainbridge","07/31/2016","$146,950.00","","jmagliano@niu.edu","301 Lowden Hall","De Kalb","IL","601152860","8157531581","CSE","7367","7367, 7923","$0.00","The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments. Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure. The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves. Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br/><br/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br/><br/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines. Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process."
"1360035","HCC: Small: Exploring the Emergent Dynamics Between Nonprofit Organizations and a Technologically-Enabled, Innovative Public","IIS","Cyber-Human Systems","08/01/2013","06/27/2014","Amy Voida","IN","Indiana University","Continuing grant","William Bainbridge","09/30/2015","$477,848.00","","amyvoida@iupui.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7367","7367, 7923, 9251","$0.00","This research examines how and why members of the public are using technology to work with nonprofit organizations and begins to explore how new technologies might be designed to foster more productive partnerships between nonprofit organizations and the public. Mobile information and communication technologies have fundamentally changed the nature of grassroots organizing, enabling members of the public to rapidly and flexibly organize themselves in order to accomplish a variety of goals. However, nonprofit organizations have often failed to leverage the public's innovative and civically-engaged uses of technology for their benefit. This research will undertake two synergistic lines of inquiry to address such issues, one consisting of empirical research, and the other developing design principles.<br/><br/>A three-phase empirical study will examine the role of technologies in fostering partnerships between the public and nonprofits. The first phase will explore the use of social media, a technology foregrounding social context, for online advocacy. The second will examine distributed work technologies, predominantly foregrounding temporal context, for virtual volunteering. The third will investigate the use of mobile technologies, foregrounding physical context, for mobile giving. Each phase will be motivated by the same high-level research questions, allowing synthesis across phases and generalization about the role of technology in bridging between the public and nonprofit organizations.<br/><br/>In the design inquiry, a series of low-fidelity and medium-fidelity prototypes will be developed that embody design recommendations derived from the empirical inquiry, taking advantage of new permutations of social, physical and temporal contexts. A series of focus groups and design workshops will provide feedback to help guide iteration on the design of the prototypes.<br/><br/>This research will provide empirical evidence of how technologies used for online advocacy, virtual volunteering and mobile giving influence the dynamics between nonprofit organizations and members of the public. It will advance theoretical knowledge about the role of nonprofits in a changing technological landscape of public civic engagement. This research will also derive theory about the roles of social, physical, and temporal contexts in civically-engaged technology use. <br/><br/>Understanding the way that members of the public are using technology to work with nonprofit organizations is critical for fostering and designing technologies to support productive partnerships moving forward. This research also provides an opportunity for students to participate in civically engaged scholarship, the kind of scholarship that has been shown to attract the participation of minorities in computing disciplines."
"1352915","EAGER: Identifying Barriers and Opportunities for Building SocioTechnical Capital","IIS","Cyber-Human Systems","09/15/2013","09/04/2013","Tawanna Dillahunt","MI","University of Michigan Ann Arbor","Standard Grant","Anthony Hornof","08/31/2015","$149,942.00","","tdillahu@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7367, 7916","$0.00","This project advances a scientific understanding of how ""socio-technical capital"" - ties that are created, maintained, or exploited through the use of information and communication technologies - is developed and used across different socioeconomic groups and populations. It is hypothesized that, like other valuable resources, the benefits of computer-mediated opportunities for building socio-technical capital are unequally distributed in society. For example, it appears as if far more effort has gone into building social networking tools and online markets for highly paid professionals (such as LinkedIn) than for handymen or day laborers. And online labor markets that exist for low-skill, low-commitment jobs (such as Amazon Mechanical Turk) do not appear to offer a path toward building socio-technical capital that might lead to more-stable, higher-wage jobs.<br/><br/>This project seeks to understand the prospects of tailoring the technologies of social networking tools and online labor markets to meet the needs of specific socio-economic populations, such as populations in Detroit, Michigan, and other cities in economic decline. The project will follow a human-centered approach of contextual inquiry, conducting interviews and focus groups employing a range of ""design probes"". These probes will examine technologies that currently support the employment process (such as LinkedIn, CareerBuilder, ODesk, TaskRabbit, and Angie's List) as a springboard to identify fundamental barriers to usage, and also to generate ideas for features that might be especially useful. In later sessions, design probes will include low-fidelity prototypes embodying features generated in earlier sessions. The end result will be an articulation of the special needs, barriers, and opportunities for using technology to help people in economically vulnerable communities to build, maintain, and use social capital to start moving up the economic ladder. The project will investigate how information and communication technology can help to create and maintain of social and economic bridges between individuals within specific economic communities and people who can provide access to employment opportunities outside of those communities.<br/><br/>Broader Impacts: The project will have broad social impact by informing approaches to cultivating pathways to upward mobility in communities hit hardest by economic decline. If the research finds promising opportunities and surmountable barriers to the use of social networking tools and online labor markets, it will inform the design of future technologies and computer-mediated approaches to help these populations better prosper. If the research finds limited opportunities or insurmountable barriers, practitioners will know to look elsewhere to help vulnerable populations find essential socio-technical capital."
"0953149","CAREER: Cross-Document Cross-Lingual Event Extraction and Tracking","IIS","INFO INTEGRATION & INFORMATICS","03/01/2010","06/27/2014","Heng Ji","NY","CUNY Queens College","Continuing grant","Maria Zemankova","02/28/2015","$543,384.00","","jih@rpi.edu","65 30 Kissena Blvd","Flushing","NY","113671575","7189975400","CSE","7364","1045, 7364, 9251, 9102, 9215, HPCC","$0.00","The goal of this research project is advance the Information Extraction (IE) paradigm beyond ""slot filling"", and achieve more accurate, salient, complete, concise and coherent extraction results by exploiting dynamic background knowledge and cross-document cross-lingual event ranking and tracking. The approach consists of cross-document inference, unknown implicit event time prediction and reasoning, cross-document entity coreference resolution with global contexts, centroid entity detection, event attribute extraction and graph-based clustering algorithms for redundancy and contradiction detection, automatic new event clustering and active learning, abstractive summary generation based on extraction results, name translations with comparable corpora and cross-lingual co-training.<br/><br/>The experimental research is integrated with educational activities, including project-related curriculum development. The project involves PhD students as well as undergraduate students, engages non-Computer Science undergraduate students in utility evaluation and corpus annotation, and attracts elementary school and high school students by tutorials, regular research seminars and an extensive summer workshop. The results of this project will also have a benefit in E-Science and E-Learning by extracting and tracking the related knowledge from scientific literature and learning materials used in elementary schools and high schools.<br/><br/>Project results, including open source software, task definition guidelines, annotated corpora, scoring metrics will be disseminated via project Web site<br/>(http://nlp.cs.qc.cuny.edu/blendeet.html)."
"1131883","US-German Collaboration: Towards a Neural Theory of 3D Shape Perception","IIS","PERCEPTION, ACTION & COGNITION, COLLABORATIVE RESEARCH, CRCNS, ROBUST INTELLIGENCE","11/01/2011","07/24/2013","Steven Zucker","CT","Yale University","Continuing grant","Kenneth C. Whang","10/31/2015","$460,004.00","","steven.zucker@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7252, 7298, 7327, 7495","5936, 5979, 7327","$0.00","How the brain estimates the 3D shape of objects in our surroundings remains one of the most significant challenges in visual neuroscience. The information provided by the retina is fundamentally ambiguous, because many different combinations of 3D shape, illumination and surface reflectance are consistent with any given image. Despite this ambiguity, the visual system is extremely adept at estimating 3D shape across a wide range of viewing conditions, something that no extant machine vision system can do. The long-term goal of the project is to develop a computational model in neural terms to explain how 3D shape is estimated in the primate visual system. It will build upon the responses of cells early in visual cortex (V1) and develop models of how they can be organized into mid-level configurations that specify 3D shape properties. Importantly, the project will also measure human perception of 3D shape in a series of psychophysical experiments designed to test specific predictions, bringing together the complementary expertise of Roland W. Fleming (Giessen University: human perception, psychophysics) and Steven W. Zucker (Yale University: computational vision, computational neuroscience). The results should provide a deeper understanding of visual circuit properties in the ventral processing stream; they should provide models for 3D computer vision and graphics; and they may pave the way for the development of rehabilitation strategies for patients with visual deficits.<br/><br/>The basic approach starts with populations of neurons tuned to different orientations and seeks to understand how these provide basic information about local shape properties according to the principles of differential geometry. Specifically, when 3D surfaces are projected onto the retina, the distorted gradients of shading and texture lead to highly structured patterns of local image orientation, or orientation fields, which can be inferred via circuits involving long-range horizontal connections. The investigators seek to derive formal models showing how these networks can be organized to infer 3D surface properties. The specific approach is involves four stages: (i) modeling how the visual system obtains clean and reliable orientation fields from the outputs of model V1 cells through lateral interactions and feedback; (ii) establishing how local measurements are grouped into specific ""mid-level"" configurations to support the recovery of 3D shape properties (modeling V2 to V4); (iii) modeling how these low- and mid-level 2D measurements can be mapped into representations of 3D shape properties (V4 to IT); and (iv) modeling how grouping and global constraints can convert these shape estimates into global shape reconstructions (again V4 to IT). Targeted psychophysical experiments will complement all of the modeling and test specific predictions from it. The resulting stimuli will support next generation neurophysiological experiments. Although the above stages define a working strategy, dependencies among these stages should also provide a model of the feedforward/feedback projections that link different areas of cortex. The ultimate goal is a model that can correctly predict the errors, the successes, and the limits of human shape perception. <br/><br/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF)."
"1115199","III: Small: Robust and Scalable Reputation Management and Recommender Systems Using Belief Propagation","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","06/26/2012","Faramarz Fekri","GA","Georgia Tech Research Corporation","Continuing grant","Maria Zemankova","08/31/2015","$398,388.00","","fekri@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7364","7923","$0.00","Reputation and recommender systems have widespread use in online marketing, web services, P2P computing, e-commerce, social settings, and education. The objective of this research is to develop reliable, scalable and dependable schemes that are also resilient to malicious behaviors. <br/><br/>The approach is based on viewing both reputation and recommender systems as solving for marginal probability distribution functions from complicated global (joint-distribution) functions of many variables (users, items or service providers, and ratings). These marginal probability distributions are functions of the variables representing the reputation values (in reputation systems) and the ratings to be predicted to the users (in recommender systems). However, computing these marginal distributions are computationally prohibitive (i.e., exponential with the number of variables) for large scale reputation and recommender systems. Therefore, this research represents the reputation and recommender systems using factor graphs or Pairwise Markov Random Fields, and utilizes the Belief Propagation (BP) algorithm to efficiently (in linear complexity) solve for these marginal distributions. In particular, the project includes research to: (1) study the general theories of BP-based reputation management and recommender systems on various graphical models and develop novel algorithms; (2) study the convergence, scalability, and robustness of the developed algorithms via mathematical analysis and intensive simulations; (3) develop a Belief Propagation based Iterative Trust and Reputation Management (BP-ITRM) system and compare it with the current state of the art using real-life datasets and conducting user studies; and (4) adaptively learn various attack strategies against the reputation and recommender systems, determine the impacts of such attacks, and decrease their impact. <br/><br/>The project is expected to make contributions to both theory and practice by developing a new reputation management framework for recommender systems, and algorithms that provide effective ways to deal with information overload and access to relevant information. It is anticipated that the work will drive the technology for effective online products and information services. Technologies resulting from this research will bring a broad range of benefits in many areas including online services, P2P and distributed computing systems, e-commerce, business, social settings, education, national security and the economy. The research results are expected to make theoretical contributions relevant to computer science, information theory and statistical inference. This project offers a unique opportunity to train graduate students and expose undergraduate students to cross-cutting research in different fields (computer science, information theory, statistical inference). The project website (http://www.ece.gatech.edu/research/labs/WCCL/Security6.html) is used to disseminate resulting publications, datasets (obtained from user studies and mathematical models), and course materials to broad communities of researchers, students and industry practitioners."
"1161491","HCC: Medium: Plug and Train: Mixed Reality Humans for Team Training","IIS","Cyber-Human Systems","07/01/2012","06/27/2014","Benjamin Lok","FL","University of Florida","Continuing grant","William Bainbridge","06/30/2016","$807,895.00","Casey White, Samsun Lampotang, Adam Wendling","lok@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7367","7367, 7924","$0.00","There are an estimated 45 million inpatient surgical procedures per year in the U.S., where critical incidents account for 832,500 deaths and between 1,350,000 and 7,650,000 cases of significant harm to the patient. Of these errors, teamwork failures (e.g. misunderstanding procedural instructions and not acknowledging and repeating back drug dosage levels) are a significant factor - up to 70% for medical operations such as surgery. Reducing teamwork failures requires team training using effective protocols; however, few team training opportunities on these protocols exist. <br/><br/>Intellectual merit: To address this deficiency in training, the project will substitute unavailable human team members with mixed reality humans (MRH). MRHs will plug into roles of unavailable human team members to facilitate training in multi-party scenarios. The research team will first develop systems capable of having MRH inhabit training environments alongside human trainees. Then, they will develop novel conversational modeling techniques to support a training experience to be conducted with any combination of human trainees and virtual human teammates. Finally, the team will conduct a set of user studies with the system to explore the effect of mixed reality humans, the impact of mixed reality humans on team dynamics, and the efficacy of team training with mixed reality humans. The result of this work will be effective self-contained, portable MRH systems that integrate into clinical training environments.<br/><br/>Broader impacts: The project will result in important educational tools for team training that will ultimately lower the high social and financial costs of team errors in medicine. Better trained teams make fewer and less serious mistakes, thereby improving patient outcomes. The tools and findings will be integrated into the curriculum of continuing medical education and new hire orientation at the University of Florida. While initially applied and evaluated in a clinical setting, the investigators anticipate that mixed reality human team training will be applicable to other multiparty scenarios in aviation, the military, education, and crisis response."
"1439613","EAGER: Multimodal Corpus for Vision-Based Meeting Analysis","IIS","ROBUST INTELLIGENCE","11/19/2013","06/20/2014","Francis Quek","TX","Texas A&M University Main Campus","Standard Grant","Jie Yang","08/31/2015","$9,566.00","","quek@tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","CSE","7495","7495, 7916","$0.00","This project explores a multimodal corpus for vision-based meeting analysis. The research team is working on: (1) extracting the data from tapes and organizing them into multimedia databases; (2) developing a database visualization and analysis tool to support model development; and (3) developing an agent-based algorithm to extract hand and head tracking information so that higher level models may be built onto the data. <br/><br/>The project provides datasets that are organized into a usable corpus with many unique properties, such as the ground truth at the psycholinguistic/psycho-social level of the social roles status, purpose of each meeting, and at the video level in the form of motion tracking data collected co-temporally with the video, for developing and testing new algorithms. The developed tools improve the access to the multimedia database of multi-view group human behavior. The agent-based approach provides a novel way in video annotation. The developed tools and algorithms from this project can be applied to many other applications. For example, the tools may be applied to analyze classroom behavior and in learning scenarios. The project provides research opportunities for undergraduate and graduate students including women and individuals from underrepresented populations. The project outreaches to the user communities through publications, presentations, web presence, and broader collaborative interactions."
"1250702","EAGER: Automatic Classification of Programming Difficulties by Mining Programming Events","IIS","Cyber-Human Systems, SOFTWARE & HARDWARE FOUNDATION, SOCIAL-COMPUTATIONAL SYSTEMS, Cyberlearning&FutureLearn Tech","09/01/2012","04/25/2014","Prasun Dewan","NC","University of North Carolina at Chapel Hill","Standard Grant","William Bainbridge","08/31/2015","$124,960.00","","dewan@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7367, 7798, 7953, 8020","7367, 7916, 7944, 7953, 8045, 9251","$0.00","Today, when a student or industrial programmer faces difficulty in some task assigned to him/her, this event often goes unrecorded and unobserved by others. As a result, it is not possible to use mechanisms to ameliorate the effect of the difficulty. In this project, the researchers will address this problem by automatically detecting and classifying programming difficulties by mining programmers' interaction with the computer. Specifically, they will investigate (a) whether it is possible to automatically identify the barrier causing a difficulty and (b) whether it is possible to determine the severity of the difficulty. The project will start a new area of research exploring how difficulty-detection mechanisms should be designed, implemented, evaluated, and applied.<br/><br/>Broader impacts: If successful this research will lead to future work on a variety of difficulty amelioration mechanisms, including (a) allowing industrial workers and teachers to synchronously push help to developers facing difficulties; (b) informing developers facing difficulties about actions taken by others who overcame similar difficulties, so that they can take similar actions; (c) allowing assignment doers to anticipate the kind of difficulties they will encounter and thus be better prepared for the assignment; and (d) giving assignment definers an understanding of the inherent difficulty level of the assignment, which can lead to redefinition or better explanation of the assignment. These amelioration mechanisms can substantially reduce the high costs associated with software development and quality teaching, and transform collaborative software engineering and education. Such mechanisms can lead to significant productivity gains in industry, especially in distributed software development. An educational setting provides an even more compelling motivation because shyness of students and/or lack of instructor time prevents student difficulties from being addressed in a timely manner. In computer science this is particularly a problem as a small mistake can prove to be very costly. The difficulty amelioration mechanisms will reduce this problem and thus attract a larger variety of students to computer science and empower those who are already committed to it."
"0808772","III-CXT-Large: Working with Uncertain Data in Exploring Scientific Images","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2008","06/26/2014","Bangalore Manjunath","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","08/31/2015","$3,197,882.00","Tobias Hollerer, Ambuj Singh, Kenneth Rose","manj@ece.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","1640, 7364","7364, 7925, 9216, 9251, HPCC, 9215","$0.00","Elements of uncertainty are inherent to management and analysis of complex image data for scientific and engineering applications. The work builds on previous multidisciplinary work for storage, management, and analysis of biological images of cellular architectures in the vertebrate central nervous system and sub-cellular environments, but the techniques are general and target other areas, such as environmental management, geographical information science, remote sensing and interactive digital multimedia. Imaging is at the cores of many scientific discoveries, with information captured in terms of raw pixel intensities and in multiple channels for color or hyperspectral imagery. The work includes generation of probabilistic measurements and quantified uncertainties from image analysis methods, pattern classification methods generating information that can be stored as probabilistic feature tables and new approaches to visualization of probabilistic information. The proposed work will be integrated within the UCSB BioImage Search and Query environment, part of the campus data infrastructure, and the software developed will be made available as open source."
"1400802","CHS: Medium: Collaborative Research: Immediate Feedback to Support Learning American Sign Language through Multisensory Recognition","IIS","Cyber-Human Systems","09/01/2014","06/26/2014","YingLi Tian","NY","CUNY City College","Standard Grant","Ephraim P. Glinert","08/31/2018","$557,918.00","","ytian@ccny.cuny.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","CSE","7367","7367, 7924","$0.00","American Sign Language (ASL) is a primary means of communication for 500,000 people in the United States and a distinct language from English, conveyed through hands, facial expressions, and body movements. Studies indicate that deaf children of deaf parents read better than deaf children of hearing parents, mainly due to better communication when both children and parents are deaf. However, more than 80% of children who are deaf or hard of hearing are born to hearing parents. It is challenging for parents, teachers, and other people in the life of a deaf child to learn ASL rapidly enough to support the visual language acquisition of the child. Technology that can automatically recognize aspects of ASL signing and provide instant feedback to these students of ASL would give them a time-flexible way to practice and improve their signing skills. The goal of this project, which involves an interdisciplinary team of researchers at three colleges within the City University of New York (CUNY) with expertise in computer vision, human-computer interaction, and Deaf and Hard of Hearing education, is to discover the most effective underlying technologies, user-interface design, and pedagogical use for an interactive tool to provide such immediate, automatic feedback for students of ASL.<br/><br/>Most prior work on ASL recognition has focused on identifying a small set of simple signs performed, but current technology is not sufficiently accurate on continuous signing of sentences with an unrestricted vocabulary. The PIs will develop technologies to fundamentally advance ASL partial recognition, that is to identify linguistic/performance attributes of ASL without necessarily identifying the entire sequence of signs, and automatically determine if a performance is fluent or contains errors. The research will include five thrusts: (1) based on ASL linguistics and pedagogy, to identify a set of observable attributes indicating ASL fluency; (2) to discover new technologies for automatic detection of the ASL fluency attributes through fusion of multimodality (facial expression, hand gesture, and body pose) and multisensory information (RGB and Depth videos); (3) to collect and annotate a dataset of RGBD videos of ASL, performed at varied levels of fluency, by students and native signers; (4) to develop an interactive ASL learning tool that provides ASL students immediate feedback about whether their signing is fluent or not; and (5) to evaluate the robustness of the new algorithms and the effectiveness of the ASL learning tool, including its educational benefits. The work will lead to advances in computer vision technologies for human behavior perception, to new understanding of user-interface design with ASL video, and to a revolutionary and cost-effective educational tool to assist ASL learners achieve fluency, using recognition technologies that are robust and accurate in the near-term. Project outcomes will include a dataset of videos at varied fluency levels, which will be valuable for future ASL linguists or instructors, students learning ASL, and computer vision researchers."
"1354297","Innovations in Electroacoustics and Computing: Print Disablity and as a Model for Technology Innovation and Transfer","SES","Cyber-Human Systems, SCIENCE, TECH & SOCIETY","05/15/2014","05/05/2014","Mara Mills","NY","New York University","Standard Grant","Linda Layne","04/30/2016","$239,138.00","","mmills@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","SBE","7367, 7603","1353, 7603","$0.00","Through archival research and interviews with innovators, the PI will produce a history of electronic reading technologies for blind and print-disabled people, and their co-evolution with mainstream reading practices. Beyond the introduction of new formats such as audiobooks and electronic books, print access efforts in the twentieth century gave rise to numerous technical innovations that transferred to other branches of electroacoustics and computing. Innovations in long-playing records,pitch-shifting with magnetic tape, scanning, optical character recognition (OCR), and synthetic speech ultimately retooled reading for both humans and machines. The project will contribute to the history of computing through attention to the overlooked topics of optical character recognition (OCR) as a mode of data input, and pattern-matching as a technique for artificial intelligence.<br/><br/><br/>Based on these historical examples, this communications scholar develops new tools for understanding and stimulating innovative technology design and transfer. The work will contribute to the subfield of disability and STS, will train two disabled students, and will help destigmatize the category of assistive technology by tracing the ways these devices intervene into media policy, are repurposed for broad use, or in fact are marketed to multiple audiences. In addition to a monograph, the project will result in a website that will preserve and make publicly-available examples from several historical reading formats (e.g. Talking Books, text-to-tone, and text-to-speech systems). The website will model best practices of electronic accessibility."
"0916607","RI: Small: Computational Models of Context-awareness and Selective Attention for Persistent Visual Target Tracking","IIS","ROBUST INTELLIGENCE","09/01/2009","06/26/2014","Ying Wu","IL","Northwestern University","Standard Grant","Jie Yang","08/31/2015","$391,986.00","","yingwu@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495","7495, 7923, 9215, HPCC, 9251","$0.00","Although persistent and long-duration tracking of general targets is a basic function in the human vision system, this task is quite challenging for computer vision algorithms, because the visual appearances of real world targets vary greatly and the environments are heavily cluttered and distractive. This large gap has been a bottleneck in many video analysis applications. This project aims to bridge this gap and to overcome the challenges that confront the design of long-duration tracking systems, by developing new computational models to integrate and represent some important aspects in the human visual perception of dynamics, including selective attention and context-awareness that have been largely ignored in existing computer vision algorithms. <br/><br/>This project performs in-depth investigations of a new computational paradigm, called the synergetic selective attention model that integrates four processes: the early selection process that extracts informative attentional regions (ARs), the synergetic tracking process that estimates the target motion based on these ARs, the robust integration process that resolves the inconsistency among the motion estimates of these ARs for robust information fusion, and the context-aware learning process that performs late selection and learning on-the-fly to discover contextual associations and to learn discriminative-ARs for adaptation. <br/><br/>This research enriches the study of visual motion analysis by accommodating aspects from the human visual perception and leads to significant improvements for video analysis. It benefits many important areas including intelligent video surveillance, human-computer interaction and video information management. The project is linked to educational activities to promote learning and innovation through curriculum development, research opportunities, knowledge dissemination through conferences and the internet as well as other outreach activities, and the involvements of underrepresented groups."
"1405550","RI: Medium: Computational Models, Interaction Mechanisms, and Planning Algorithms for Semi-Autonomous Systems","IIS","ROBUST INTELLIGENCE","06/01/2014","06/26/2014","Shlomo Zilberstein","MA","University of Massachusetts Amherst","Continuing grant","James Donlon","05/31/2018","$313,715.00","Claudia Goldman, Donald Fisher","shlomo@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7495","7495, 7924","$0.00","Autonomous systems offer transformational impacts on society as they help reduce human labor, decrease risks and costs, and improve productivity and efficiency. They have been deployed in a wide range of domains from household products to space exploration vehicles. In many areas, however, there are still considerable barriers to the deployment of fully autonomous systems. These barriers range from technological to ethical and legal issues. Examples include driving a car, robot deployment in search and rescue operations, automated farming, and robotic surgery. When full autonomy is not feasible, it is often desirable to automate parts of the entire process. This project offers a comprehensive study of planning for semi-autonomous systems -- systems that are capable of autonomous operation under some conditions, but may require manual control in order to complete the task at hand. Planning for semi-autonomous systems is challenging because it must account for the different skills of the human operator and the automated system, the communication between them required to facilitate smooth transfer of control, the uncertainty about human responsiveness, engagement level and readiness to take over control, and the possibility of human error in interpreting or following the plan. <br/><br/>The project takes an interdisciplinary approach that addresses the computational challenges together with the challenges that rise whenever the human is in the loop. With a focus on semi-autonomous driving as the primary domain, research activities include: designing general-purpose graphical models to represent the problem of collaborative control of semi-autonomous systems; developing effective methods to represent and earn competence models of the actors; developing efficient decision-theoretic planning algorithms that exploit heuristic search and reachability analysis to create the shared plan; developing algorithms to compute vital statistics and runtime feedback about the shared plan; developing ways to capture models of situation awareness and human errors, and factor them into the planning process; and creating a set of challenging scenarios and test problems for planning in semi-autonomous systems. Evaluation of the approach is conducted using several testbeds including two realistic driving simulators."
"1422441","CHS: Small: Generative models of shapes","IIS","Cyber-Human Systems","07/01/2014","06/26/2014","Evangelos Kalogerakis","MA","University of Massachusetts Amherst","Standard Grant","Ephraim P. Glinert","06/30/2017","$499,997.00","","kalo@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7367","7367, 7453, 7923","$0.00","This research will advance the state of the art in three-dimensional (3D) shape synthesis by developing generative probabilistic models that will enable the automatic understanding of semantics from shape geometry, and which will lead to the development of new computational modeling algorithms that allow anybody to easily create compelling and highly detailed 3D content. Users will be able to create shapes by simply providing high-level specifications, shape types, parts, semantic shape attributes, landmark points, or sketches based on simple and intuitive user interfaces. These models will also enable the computer to infer complete geometry from partial geometric data acquired by range cameras and to fill in any missing shape parts, or to robustly recognize objects in a scene acquired by 3D sensors. Project outcomes will advance the state of the art in 3D modeling, providing users with intuitive tools that significantly lower the barrier of rapid and easy creation of detailed shapes. Such tools are becoming increasingly important, since there is a growing interest in 3D models in scientific and engineering fields such as collaborative virtual environments, augmented reality, simulation, computer-aided design, and architecture. In particular, this work will significantly benefit 3D printing; where despite hardware advances, the main bottleneck remains the creation of shapes to be supplied to the printer. The research will also advance the state of the art in shape understanding and object recognition, which are important for computer vision and robotics applications.<br/><br/>The key idea behind these generative models is that they represent complex hierarchical compositions, correlations and variations of detailed geometric shape features, as well as their relationships with high-level semantic shape attributes. The models will be automatically learned from large shape repositories available on the Web, after the input shapes are pre-processed by new algorithms the Principal Investigator will develop for simultaneous shape segmentation and landmark localization so that their parts and points are consistently labeled. Existing shape synthesis algorithms are limited to re-use and re-combine shape parts from a repository, or synthesize shapes in specific classes (such as human bodies or faces), with limited geometric variability and no structural or semantic variability. The Principal Investigator's generative models, on the other hand, will instead learn how to densely place points and patches to create new plausible shapes in complex domains, such as furniture, vehicles, tools, creatures, etc. Inference algorithms built upon the generative models will be able to synthesize shapes given linguistic terms or sparse geometric input. As a result, the research will lead to the development of new 3D content creation tools that will transform the field of computational modeling: instead of executing a series of painstaking low-level geometric editing and manipulation commands, users will perform simple, easy, and intuitive interactions to achieve their design goals."
"1400810","CHS: Medium: Collaborative Research: Immediate Feedback to Support Learning American Sign Language through Multisensory Recognition","IIS","Cyber-Human Systems","09/01/2014","06/26/2014","Elaine Gale","NY","CUNY Hunter College","Standard Grant","Ephraim P. Glinert","08/31/2018","$120,000.00","","egale@hunter.cuny.edu","695 Park Avenue","New York","NY","100655024","2127724020","CSE","7367","7367, 7924","$0.00","American Sign Language (ASL) is a primary means of communication for 500,000 people in the United States and a distinct language from English, conveyed through hands, facial expressions, and body movements. Studies indicate that deaf children of deaf parents read better than deaf children of hearing parents, mainly due to better communication when both children and parents are deaf. However, more than 80% of children who are deaf or hard of hearing are born to hearing parents. It is challenging for parents, teachers, and other people in the life of a deaf child to learn ASL rapidly enough to support the visual language acquisition of the child. Technology that can automatically recognize aspects of ASL signing and provide instant feedback to these students of ASL would give them a time-flexible way to practice and improve their signing skills. The goal of this project, which involves an interdisciplinary team of researchers at three colleges within the City University of New York (CUNY) with expertise in computer vision, human-computer interaction, and Deaf and Hard of Hearing education, is to discover the most effective underlying technologies, user-interface design, and pedagogical use for an interactive tool to provide such immediate, automatic feedback for students of ASL.<br/><br/>Most prior work on ASL recognition has focused on identifying a small set of simple signs performed, but current technology is not sufficiently accurate on continuous signing of sentences with an unrestricted vocabulary. The PIs will develop technologies to fundamentally advance ASL partial recognition, that is to identify linguistic/performance attributes of ASL without necessarily identifying the entire sequence of signs, and automatically determine if a performance is fluent or contains errors. The research will include five thrusts: (1) based on ASL linguistics and pedagogy, to identify a set of observable attributes indicating ASL fluency; (2) to discover new technologies for automatic detection of the ASL fluency attributes through fusion of multimodality (facial expression, hand gesture, and body pose) and multisensory information (RGB and Depth videos); (3) to collect and annotate a dataset of RGBD videos of ASL, performed at varied levels of fluency, by students and native signers; (4) to develop an interactive ASL learning tool that provides ASL students immediate feedback about whether their signing is fluent or not; and (5) to evaluate the robustness of the new algorithms and the effectiveness of the ASL learning tool, including its educational benefits. The work will lead to advances in computer vision technologies for human behavior perception, to new understanding of user-interface design with ASL video, and to a revolutionary and cost-effective educational tool to assist ASL learners achieve fluency, using recognition technologies that are robust and accurate in the near-term. Project outcomes will include a dataset of videos at varied fluency levels, which will be valuable for future ASL linguists or instructors, students learning ASL, and computer vision researchers."
"1400906","CHS: Medium: Collaborative Research: Immediate Feedback to Support Learning American Sign Language through Multisensory Recognition","IIS","Cyber-Human Systems","09/01/2014","06/26/2014","Matt Huenerfauth","NY","CUNY Queens College","Standard Grant","Ephraim P. Glinert","08/31/2018","$537,997.00","","matt@cs.qc.cuny.edu","65 30 Kissena Blvd","Flushing","NY","113671575","7189975400","CSE","7367","7367, 7924","$0.00","American Sign Language (ASL) is a primary means of communication for 500,000 people in the United States and a distinct language from English, conveyed through hands, facial expressions, and body movements. Studies indicate that deaf children of deaf parents read better than deaf children of hearing parents, mainly due to better communication when both children and parents are deaf. However, more than 80% of children who are deaf or hard of hearing are born to hearing parents. It is challenging for parents, teachers, and other people in the life of a deaf child to learn ASL rapidly enough to support the visual language acquisition of the child. Technology that can automatically recognize aspects of ASL signing and provide instant feedback to these students of ASL would give them a time-flexible way to practice and improve their signing skills. The goal of this project, which involves an interdisciplinary team of researchers at three colleges within the City University of New York (CUNY) with expertise in computer vision, human-computer interaction, and Deaf and Hard of Hearing education, is to discover the most effective underlying technologies, user-interface design, and pedagogical use for an interactive tool to provide such immediate, automatic feedback for students of ASL.<br/><br/>Most prior work on ASL recognition has focused on identifying a small set of simple signs performed, but current technology is not sufficiently accurate on continuous signing of sentences with an unrestricted vocabulary. The PIs will develop technologies to fundamentally advance ASL partial recognition, that is to identify linguistic/performance attributes of ASL without necessarily identifying the entire sequence of signs, and automatically determine if a performance is fluent or contains errors. The research will include five thrusts: (1) based on ASL linguistics and pedagogy, to identify a set of observable attributes indicating ASL fluency; (2) to discover new technologies for automatic detection of the ASL fluency attributes through fusion of multimodality (facial expression, hand gesture, and body pose) and multisensory information (RGB and Depth videos); (3) to collect and annotate a dataset of RGBD videos of ASL, performed at varied levels of fluency, by students and native signers; (4) to develop an interactive ASL learning tool that provides ASL students immediate feedback about whether their signing is fluent or not; and (5) to evaluate the robustness of the new algorithms and the effectiveness of the ASL learning tool, including its educational benefits. The work will lead to advances in computer vision technologies for human behavior perception, to new understanding of user-interface design with ASL video, and to a revolutionary and cost-effective educational tool to assist ASL learners achieve fluency, using recognition technologies that are robust and accurate in the near-term. Project outcomes will include a dataset of videos at varied fluency levels, which will be valuable for future ASL linguists or instructors, students learning ASL, and computer vision researchers."
"1064681","III: Medium: Collaborative Research: Scalable Kinship Inference in Wild Populations Across Years and Generations","IIS","ADVANCES IN BIO INFORMATICS, INFO INTEGRATION & INFORMATICS","08/01/2011","06/12/2013","Tanya Berger-Wolf","IL","University of Illinois at Chicago","Continuing grant","Sylvia J. Spengler","07/31/2015","$954,730.00","Ashfaq Khokhar, Mary Ashley, Bhaskar DasGupta","tanyabw@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","1165, 7364","1165, 7924, 9179","$0.00","Scalable kinship inference in wild populations across years and generations<br/><br/>A cornerstone of research in molecular ecology is the reconstruction of family groups (kinship analysis).<br/>Understanding how individuals in free-living populations are related to each other provides the best<br/>opportunity to study many important biological processes, ranging from sexual selection to patterns<br/>of dispersal and recruitment. Recent advances in molecular DNA technologies and computational<br/>methods have made these studies possible. However, many conceptual and computational challenges<br/>remain and need to be addressed in order to advance these studies. To date, existing research work<br/>on kinship analysis has primarily focused on computational methods that address a single relationship, such as parentage assignment or reconstruction of full sib groups. Inclusion of multiple objectives, such as half-sib reconstruction with minimum parentage assignment, or hierarchy over multiple generations, makes formulation of the underlying computational problem extremely challenging, and simple extensions of previous methods do not address in a practical, scalable, and robust manner the problem of kinship reconstruction for data sets that include multiple generations of species or involve multiple optimization functions.<br/><br/>The goal of the proposed research is to design robust, parsimonious, and versatile computational<br/>approaches for inferring multi-generation kinship relationships in wild populations from multiallelic<br/>markers. Parsimony assumption is fundamental to these approaches as it requires no prior knowledge,<br/>assumptions about sampling methodology, or existence of models, which is the case for most free-living<br/>populations. The diverse tasks of this project include formulating computational kinship inference<br/>problems based on existing biological studies, analyzing computational complexity of and providing<br/>solutions to the resulting combinatorial optimization problems, and designing robust, scalable and<br/>efficient high performance implementations. The resulting computational methods will be evaluated<br/>on datasets collected from existing biological studies and will be deployed to the biological community<br/>through the Kinalyzer web-based service, currently actively used for sibship inference only.<br/><br/>The research proposed in this project will greatly impact diverse application areas including funda-<br/>mental research in combinatorial optimization and data mining, and within biology, areas as diverse as<br/>behavioral ecology, evolutionary genetics, conservation, forensics, and epidemiology. The multidisci-<br/>plinary nature of the project and the research team will enhance curriculum design of related areas and<br/>introduce new cross-disciplinary courses. This cohesive, multidisciplinary project will provide training<br/>opportunities in biology, operation research, algorithms analysis, bioinformatics and high performance<br/>computing, within a single application framework. The project will leverage the diverse scientific ex-<br/>pertise and extensive mentoring experience of the team to foster a true interdisciplinary collaboration<br/>and to provide a thriving environment for a new generation of interdisciplinary scientists."
"0905460","HCC: Medium: Collaborative Configuration: Supporting End-User Control of Complex Computing","IIS","Cyber-Human Systems","09/01/2009","07/19/2012","Mark Newman","MI","University of Michigan Ann Arbor","Continuing grant","William Bainbridge","08/31/2015","$1,185,194.00","Mark Ackerman","mwnewman@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7655, 7924, 9215, HPCC","$0.00","This project will develop techniques that will allow users to help each other create and maintain configurations of complex, pervasive computing and communication environments. As personal computing environments become ever more complex, growing to include not just desktop and laptop computers, but also mobile phones, media devices, sensors, and more, configuration tasks grow in importance and difficulty. In particular, it becomes challenging for end-users to create, understand, and maintain the hardware and software configurations that allow them to carry out the activities that matter to them. Moreover, this problem will only get worse with time as computing environments grow to include the hundreds or even thousands of different devices and software services that have been forecast by computer scientists. <br/><br/>The approach taken in this project derives from the observation that, even as each user may have specific devices, services, and preferences that make it difficult for her to find information relevant to their particular needs, there frequently exists some other user, somewhere, who has experienced and solved a similar problem. This other user's knowledge would doubtless be of great benefit to the first user, but existing tools for seeking help and modifying configurations do not make it easy for such information exchange to take place. An important goal, then, is to match each user with the knowledge she needs in order to accomplish the configuration tasks facing her, on the assumption that such knowledge resides with some other user with a similar system. <br/><br/>This project will address a number of challenges, including: 1) How can ""configuration knowledge"" be identified and made available without placing undue burden on the individuals who possess it? 2) How can help-seekers be presented with information in a way that allows them to act on it with minimal effort and likelihood of error? 3) How can the complexity of large spaces of possible configurations be reduced to only the dimensions that matter for users' decision-making? In order to address these challenges, this project will develop the Collaborative Configuration Service (CCS) - a general service that collects configuration information from various users of a particular system and matches similar users with each other for the purpose of providing help. Through an iterative study-build-evaluate process, research will construct and refine CCS by adapting it successively to three different user communities: users of an ambient information device (Chumby), users of an open source software-based home media system (MythTV), and people representing the ""early majority"" of home media networking users. <br/><br/>Supporting users to gain control and receive help with the configuration and operation of open, evolving pervasive computing environments will lower the barrier to the adoption of those environments. This will lead to benefits to both the end-users themselves and to the companies for whom an open marketplace for pervasive computing services and components will present opportunities for competition and technological innovation."
"1245947","INSPIRE: Automating Reasoning in Interpreting Climate Records of the Past","IIS","PALEOCLIMATE PROGRAM, MARINE GEOLOGY AND GEOPHYSICS, INFORMATION TECHNOLOGY RESEARC, ANTARCTIC GLACIOLOGY, ARCTIC NATURAL SCIENCES, POLAR CYBERINFRASTRUCTURE, CI REUSE, CYBERINFRASTRUCTURE, INFO INTEGRATION & INFORMATICS, INSPIRE","08/15/2012","06/25/2014","Elizabeth Bradley","CO","University of Colorado at Boulder","Standard Grant","Maria Zemankova","07/31/2015","$642,815.00","Kenneth Anderson, James White, Thomas Marchitto","lizb@cs.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","1530, 1620, 1640, 5116, 5280, 5407, 6892, 7231, 7364, 8078","1079, 4444, 7364, 7433, 7754, 8653, 9251, 1620, 1640, 5116, 5280, 7231","$0.00","This INSPIRE award is jointly funded by the Information Integration and Informatics Program in the Information and Intelligent Systems Division of the Computer and Information Sciences Directorate, the Marine Geology and Geophysics Program in the Ocean Sciences Division of the Geosciences Directorate, the Arctic Natural Sciences Program in the Arctic Sciences Division and the Antarctic Glaciology Program in the Antarctic Sciences Division in the Office of Polar Programs, and the Office of Cyberinfrastructure. <br/><br/>The critical first step in the analysis of paleoclimate records like ice or sediment cores is the construction of an age model, which relates the depth in a core to the calendar age of the material at that point. The reasoning involved in age-model construction is complex, subtle, and scientifically demanding because the processes that control the rate of material accumulation over time, and that affect the core between formation and sampling, are unknown. Geoscientists approach this problem by treating the core like a crime scene and asking the question: ""What physical and chemical processes could have produced this situation, and what does that say about the timeline?"" However, the sheer number of possibilities, coupled with the volume and complexity of the climatology data that is currently available and is continually collected, severely limit the scope of these investigations. The goal of this project is to remove this roadblock. This research will lead to an integrated software tool called CScibox, that uses automated reasoning techniques to help scientists analyze ice and sediment cores. It employs a cyberinfrastructure that provides powerful, intuitive tools on a scientist's desktop while taking full advantage of modern data- and computation-intensive computing and networking infrastructure -- including workflow-based computation, parallel execution, distributed systems, cluster machines and the cloud. <br/><br/>CScibox will not only improve the ability of individual geoscientists analyze single cores; it has the potential to transform the field of paleoclimatology by facilitating rapid, reproducible analysis and synthesis of the information in the diverse collections of raw data available in data archives to foster understanding and improved scientific decision making. This will have broad impacts for society by allowing scientists to develop deeper insights into the roles of various factors in the complex relationships that give rise to geological records of the earth's climate that are used in today's models of environmental change. This project also has a broad educational impact. Students involved in the development and implementation of CScibox will develop skills in interdisciplinary research and will learn how to apply computational methodology in a challenging scientific context that has not yet significantly benefitted from developments in information technology. CScibox is designed to be easy to install and use; see the project web site (http://www.cs.colorado.edu/~lizb/cscience.html) for source code, documentation, and examples of its use. Future steps include extending the work to other paleoclimate data, working with geoscientists to make the user interface as intuitive as possible, and holding demos and workshops at geosciences conferences to educate that community about what the tool can do and how to use it."
"1421925","RI: Small: Neuroevolution of Brain-Inspired Computational Models Over Vast Timescales","IIS","ROBUST INTELLIGENCE","07/01/2014","06/24/2014","Kenneth Stanley","FL","University of Central Florida","Standard Grant","James Donlon","06/30/2017","$472,542.00","","kstanley@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7495","7495, 7923","$0.00","For many years researchers inspired by the idea of natural selection have experimented with computer programs called evolutionary algorithms. These algorithms simulate a kind of artificial breeding process in which a set of candidates generated by the computer are evaluated for their ability to perform a desired task. The best performers are then allowed to reproduce with slight variation to form a new and hopefully improved generation. In recent years evolutionary algorithms have exhibited the ability to evolve brain-like structures called artificial neural networks in an approach called neuroevolution. These evolved networks perform tasks often critical to technological progress and artificial intelligence like controlling robots or recognizing images. However, unlike evolution in nature, which yields dramatic changes over hundreds of thousands of generations, evolutionary algorithms have rarely been run for more than a few thousand. This project for the first time is applying new evolutionary techniques that reward continual novelty and diversification to experiments evolving over hundreds of thousands of generations, on the scale of nature. The driving hypothesis is that modern evolutionary algorithms run on this scale can yield robotic behaviors, agent morphologies, and decision-making capabilities significantly beyond the current state of the art.<br/><br/>To investigate long-term evolution in practice, artificial neural networks are being evolved in a variety of domains through new kinds of novelty-driven neuroevolution algorithms designed to avoid the convergence seen in typical evolutionary experiments. Because this new class of algorithms tends to avoid convergence, the long-term dynamics and ultimate potential for discovery of such algorithms over vast time scales (i.e. hundreds of thousands of generations) is almost entirely unknown. The idea of running neuroevolution at unprecedented timescales mirrors recent results in related areas like deep learning where massive computation has proven capable of fundamentally altering the kinds of problems that can be solved. Because evolutionary runs over hundreds of thousands of generations yield enormous troves of evolutionary data, an important component of the project is the development visualization techniques for exploring and characterizing the results of such runs. The project overall is producing a new set of tools, a new set of evolved capabilities for autonomous control and decision-making, and an increased understanding of the implications of big data and big computation for simulated evolution in computers."
"1343544","INSPIRE Track 1: Action, Vision and Language, and their Brain Mechanisms in Evolutionary Relationship","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE, IIS SPECIAL PROJECTS, INSPIRE","09/15/2013","06/24/2014","Michael Arbib","CA","University of Southern California","Continuing grant","Betty H. Tuller","08/31/2016","$800,000.00","","arbib@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","SBE","7252, 7495, 7484, 8078","7252, 8089, 8653","$0.00","This INSPIRE award is partially funded by the Perception, Action, and Cognition Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral, and Economic Sciences and the Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate of Computer and Information Science and Engineering.<br/><br/>This research will address and bridge two grand challenges: (1) To understand how action, perception, and social interaction were supported by the brain of the last common ancestor of macaque and human, complementing modeling elsewhere on great apes, and (2) To build on evolutionary insights to better understand how different parts of the human brain work together when we use language. Key entry points will be signed and spoken languages and the use of hand gestures (e.g., novel hand gestures by apes) to convey meaning. Going further, a particular focus will be on systems that link the brain's capacities to generate as well as recognize actions, and their interactions with other brain systems. <br/><br/>An international group of scientists in linguistics, primatology, neuroanatomy, neurophysiology, and neurocomputational modeling of motor, cognitive and language processes will pool data on the anatomy, physiology, behavior and communication of the various primate species. To support this extended collaboration, the researchers will build a novel online collaborative environment (""Collaboratory Workspaces"") to test, make predictions, and challenge both the modeling and experimentation. This infrastructure may catalyze a new style of collaboration between modelers, experimentalists, and clinicians. <br/><br/>The research also has the potential to support modeling of the damage that results in the clinical disorders of apraxia and aphasia. Integration of models of vision, action and language is also important for creating robots that can flexibly and usefully interact with individual people and for ""neuromorphic architecture,"" in which a building's sensors and action systems adaptively adjust to the human inhabitants."
"1338054","CAREER: Computation and Approximation in Structured Learning","IIS","ROBUST INTELLIGENCE","01/01/2013","06/24/2014","Ali Farhadi","WA","University of Washington","Standard Grant","Todd Leen","05/31/2016","$419,879.00","Emily Fox","ali@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","1045, 1187, 7495","$0.00","Machine learning is transforming the way many fields make sense of data, from engineering and science to medicine and business. Machine learning has vastly improved speech recognition, machine translation, robotic navigation and many other prediction tasks. A crucial goal of machine learning is automating intelligent processing of information: this project will focus on automatically describing videos by detecting objects, people, actions and interactions between them, and parsing documents by extracting entities, events and relationships between them. All these prediction tasks require more than just true-false or multiple-choice answers, but have an exponential number of possible answers to consider. Breaking these joint predictions up into independent decisions (for example, translating each word on its own, recognizing a phoneme at a time, detecting each object separately) ignores critical correlations and leads to poor accuracy.<br/><br/>Structured models, such as grammars and graphical models, can capture strong dependencies but at considerable computational costs. The barrier to improving accuracy in such structured prediction problems is the prohibitive cost of inference. Structured prediction problems present a fundamental trade-off between approximation error and inference error due to computational constraints as we consider models of increasing complexity. This trade-off is poorly understood but is constantly encountered in machine learning applications.<br/><br/>The primary outcome of this project will be a framework for addressing very large scale structured prediction using a novel coarse-to-fine architecture. This architecture will enable explicit, data-driven control of the approximation/computation trade-off. It promises to drastically advance state-of-the-art accuracy in computer vision and natural language applications and greatly enhance search and organization of documents, images, and video. The PI's plan includes an active role in the machine learning community, disseminating results through tutorials, code and data and organizing workshops."
"1343720","INSPIRE Track 1: The Mathematics of Balance in Mechanical Systems with Impacts, Unilateral Constraints, Underactuation and Hyper-sensing: Application to Agile bipedal Locomotion","ECCS","Engy, Pwr, Ctrl, Ntwks (EPCN), ROBUST INTELLIGENCE, INSPIRE, IIS SPECIAL PROJECTS, CONTROL SYSTEMS, APPLIED MATHEMATICS, SPECIAL STUDIES AND ANALYSES","09/01/2013","06/24/2014","Jessy Grizzle","MI","University of Michigan Ann Arbor","Continuing grant","Radhakisan S. Baheti","08/31/2016","$800,000.00","Anthony Bloch","grizzle@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","ENG","7607, 7495, 8078, 7484, 1632, 1266, 1385","092E, 8653","$0.00","This INSPIRE award is partially funded by Energy,Power and Adaptive Systems Program in the Division of Electrical, Communications and Cyber Systems in the Directorate For Engineering, Control Systems Program in the Division of Civil, Mechanical, and Manufacturing Innovations, in the Directorate for Engineering, Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering, Applied Mathematics Program in the Division of Mathematical Sciences in the Directorate for Mathematical and Physical Sciences. <br/><br/>While we are witnessing a veritable revolution in bipedal robot construction technology, the science of balance, as embodied in the feedback control algorithms that allow these robots to stand, walk, and step over obstacles is still in its infancy. Current feedback algorithms demand laborious, time consuming trial-and-error tuning specific to each machine and each gait. If bipedal robots are ever to fulfill their potential roles from assisting the elderly or infirm in their homes to disaster and rescue response, their control software development process must be founded on better science.<br/> Intellectual Merit: The project draws upon mechanics, MEMS devices, mathematics, and feedback systems to make a sea change in the practice of modeling and feedback control design in bipedal robots. The work seeks to advance scientific understanding of legged locomotion so that performance objectives can be tested mathematically for feasibility on reliable models and principled methods exist for model-based feedback controller design. The theoretical results of the project are being evaluated experimentally on a 3D bipedal robot at the University of Michigan.<br/>Broader Impacts: Important medical applications of bipedal locomotion research include lower-limb prostheses and devices for the rehabilitation of walking and balance after injury. The PIs use their interdisciplinary work in mathematics, sensing, feedback systems, and robotics to promote STEM subjects. The researchers are actively involved in rapid dissemination including videos posted on YouTube channels, television programs, and weekly tour of their robotics laboratory."
"1320402","RI: Small: Large-scale Probabilistic Forecasting for Energy Systems","IIS","ROBUST INTELLIGENCE","08/01/2013","06/24/2014","Zico Kolter","PA","Carnegie-Mellon University","Continuing grant","Todd Leen","07/31/2015","$236,946.00","","zkolter@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","How much power is a set of wind farms likely to generate over the next 24 hours? How will occupants in a commercial building interact to consume energy? Being able to answer prediction questions like these is vital to developing a more sustainable energy infrastructure: If we can predict renewable energy production and demand ahead of time, we can schedule energy resources more efficiently and reliably, leading to significant reductions in greenhouse gas emissions. Unfortunately, these are also inherently uncertain quantities we need to predict; for example, no matter how good our algorithms are, we can't predict human behavior with perfect accuracy. In order to use such predictions, we need to be able to properly model the uncertainty inherent in these domains. We need to make predictions that are not only correct on average, but which capture the complex random fluctuations and correlations between predicted quantities. Only then can we schedule energy resources in a way that accounts for these uncertainties.<br/><br/>This project develops and uses a recently-proposed framework for modeling --- sparse Gaussian conditional random fields --- a generalization of the commonly used Markov random field. This framework efficiently models high-dimensional distributions by exploiting sparsity in the inverse covariance matrix. The project extends the state of the art by greatly accelerating model learning, by extending existing theory to understand when these models can effectively learn high-dimensional predictors, and by generalizing the predictions to the non-Gaussian setting through copula methods. The project uses these algorithms to build forecasting models in four crucial domains in the energy sector: energy demand, wind power, user occupancy in homes and commercial buildings, and personal energy consumption from smart meters.<br/><br/>The project has exemplary broader impacts. First, the research deals directly with application domains crucial to efficient energy management, where even small advances can have a sizable impact on sustainability. Second, the PI leverages the research to bring the power systems and machine learning communities closer together, disseminating the results at both machine learning and power systems venues, and releasing material and video lectures to practitioners in energy. Finally, the project harnesses the research to increase diversity within STEM fields by advising under-represented minorities at the graduate and undergraduate level, and by engaging High School students and teachers with talks illustrating how computation can be used to address problems in sustainability."
"1247126","EAGER: Embodying Visual Semantic Information Composition to Stimulate Sensemaking and Ideation","IIS","Cyber-Human Systems","09/01/2012","04/25/2014","Andruid Kerne","TX","Texas Engineering Experiment Station","Standard Grant","William Bainbridge","08/31/2015","$324,000.00","","andruid@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7367","7367, 7916, 9251","$0.00","This project synthesizes techniques from interaction design, creative cognition, visual design, programming languages, and information retrieval and visualization to help people draw on big data to stimulate innovation. Sensemaking is the process of understanding a collection of information resources. Ideation means the process of generating new ideas. In performing information-based ideation tasks, people use information for developing new ideas, such as planning a paper, thesis, or invention. This project will provide new tools for presenting information visually. ""Information composition"" is a medium for representing each information collection as a connected whole. To better support innovation and creative visual thinking, this research brings diagramming, along with collection curation, to information composition. Pen, touch, and in-air sensing will transform interaction into an extension of the body, helping people express, understand, and remember. Embodied interaction will be based on the Interface Ecology Lab's ZeroTouch, a novel multi-finger sensing technology.<br/><br/>Intellectual merit: The objective of this proposal is to develop ""Embodied InfoComposer"", a toolset that uses pen, touch, and other modalities for authoring visual semantic information collections. The principal hypothesis is that embodying interaction, making representations visual, and connecting rich metadata semantics will stimulate sensemaking and ideation, helping people collect, reflect, create, and invent. This research will result in significant outcomes in important areas of human centered computing, including: (1) new understanding of how integrated diagramming and information composition promotes creative visual thinking; (2) new fluid embodied interaction techniques; (3) new methods for measuring reflection, ideation, and sensemaking; and (4) new implications for design of embodied creativity support environments.<br/><br/>Broader impacts: This research will transform how people work with information, leading to greater innovation in a variety of domains including business and education. The work is likely to have broad societal impact because innovation is a key factor leading to job creation and economic success. The project will also have educational impact through the training of graduate students and by the use of Embodied InfoComposer to foster creative visual thinking by undergraduate students from diverse majors in a design process course. Undergraduate computer science students in capstone senior design will use resulting technologies as building blocks in innovative projects. Recruitment of female and minority student researchers at the graduate and undergraduate levels will be sought."
"1422869","CHS: Small: Fast simulation of geometrically complex multibody systems in contact and self-contact","IIS","Cyber-Human Systems","09/01/2014","06/25/2014","Jernej Barbic","CA","University of Southern California","Standard Grant","Ephraim P. Glinert","08/31/2017","$484,210.00","","jnb@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7367, 7453, 7923","$0.00","The ability to simulate complex machinery in contact is broadly applicable to engineering practice. It can be used for virtual training, say in the operation of heavy machinery. Perhaps most importantly, it can be used to assemble and test complex mechanical structures in virtual reality (using a human-computer interface that includes haptic feedback). Such virtual prototyping, as it is commonly called, greatly shortens design cycles, decreases errors, improves product safety and saves millions of dollars in R&D costs. Applications can be found anywhere a complex structure must be designed and manufactured out of many component parts: airplanes, cars, trains, spaceships, power plants, buildings, tools, heavy equipment, etc. In this project the PI will develop computationally efficient collision detection and contact resolution methods that can accommodate complex systems consisting of many objects that are connected by joints and undergoing contact and self-contact. His goal is to devise algorithms that are sufficiently fast to accommodate high update rates (1,000 simulation steps per second for haptics, or more), and that scale to complex real-world mechanisms typically represented by millions of triangles, such as an internal combustion engine or an entire car engine compartment, an airplane landing gear or airplane doors, or excavator machines. Furthermore, whereas previous fast successful industrial penalty-based methods have typically been limited to pairs of objects in contact, in this research the PI's objective is to deal with more complex and realistic situations including rigid objects, joints, friction and self-contact.<br/><br/>Fast simulation of multi-body systems in contact is challenging due to the severe computational and stability requirements imposed by complex geometry. Such simulations frequently involve distributed contact, that is to say contact involving many collision sites of varying surface areas and normal orientations that change rapidly over time. Because it is challenging for constraint-based methods to resolve such contact stably at high update rates, the Principal Investigator will exploit industry-proven penalty methods between points and implicit functions (distance fields or voxmaps), and he will extend the approach, which has to date been limited to pairs of objects in contact, to accommodate N >= 2 objects in arbitrary contact, as well as objects connected with joints and undergoing active control. The technical challenges include how to stably resolve and time-step distributed contact between N >= 2 objects, how to stably simulate and render 6-DOF distributed contact in the presence of constraints (joints), and how to handle self-contact and incorporate friction, all the while maintaining high update rates (or gracefully degrading them in case of extreme contact). Because the Principal Investigator's preliminary experience suggests that the discrete nature of current algorithms is an important limitation in practice, he will also investigate continuous collision detection between points and distance fields. Project outcomes will be transitioned to engineering practice via the PI's ongoing collaborations with a number of industrical leaders in high-tech virtual prototyping, and will advance the state of the art in computer graphics, haptics, robotics and virtual reality."
"1420122","CHS: Small: Collaborative Research: Sampling and Reconstruction for Computer Graphics Rendering and Imaging","IIS","Cyber-Human Systems","09/01/2014","06/25/2014","Fredo Durand","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","08/31/2017","$249,999.00","","fredo@graphics.lcs.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7367, 7453, 7923","$0.00","Sampling of high-dimensional signals is at the heart of graphical rendering and computational photography, but current approaches unfortunately still tend to be brute-force and require large numbers of samples, which is time-consuming and costly. In this project, which involves researchers at two institutions, the Principal Investigators will build on their prior work to develop a comprehensive theoretical, algorithmic and systems foundation for sampling and reconstruction in computer graphics rendering and imaging. A key goal is a unified sampling theory that considers the type of coherence in the visual signal (such as low rank, locally low rank, low frequency, sparsity) and the type of measurement (such as point samples in rendering or projection of generic patterns for light transport acquisition, or acquisition of full light field imagery). This will provide a unified framework for choosing the best sampling strategy, and for comparing different approaches. It will also enable the establishment of rigorous lower bounds and optimality results. The work has immediate connections to signal-processing, applied mathematics and photography, and will have broad impact in connecting these domains with computer graphics. The Principal Investigators will disseminate project outcomes in part by incorporating the findings into their online courses that have large enrolments. They will also make datasets and software available, and will work to include them in industrial applications by exploiting their strong ties with a number of high-tech companies. <br/><br/>Physically-based rendering algorithms are now widespread in production, but photorealistic rendering is still inefficient since it involves the evaluation of a high-dimensional 4D-8D Monte Carlo integral for each pixel considering antialiasing, lens effects, motion blur, soft shadows and global illumination. Typically, each pixel is treated separately, with many samples needed for each integral dimension. Similar challenges arise in other areas of computer graphics, such as precomputed rendering (explicit tabulation of a 4D-8D light transport operator), light transport acquisition (measurement of high-dimensional 4D-8D functions like the BRDF or BSSRDF), and computational photography or imaging that acquires higher-dimensional 4D functions in consumer light field cameras. The traditional approach is to (pre)compute or measure the data by brute force, followed by compression. However, this incurs unacceptable costs given the size and dimensionality of current visual appearance datasets. In this work the Principal Investigators will leverage the sparsity in the continuous (rather than discrete Fourier) domain, coherence and structure of light transport to sample, reconstruct and integrate, reducing the amount of data needed by orders of magnitude, while developing new reconstruction schemes for computational imaging. Within rendering, the PIs will explore a novel method that combines motion blur, depth of field, and global illumination in a single algorithm for real-time rendering based on adaptive Monte Carlo sampling and filtering of different effects. A key challenge in such approaches is robust sampling of difficult paths; the Principal Investigators will address this issue with conservative adaptive sampling and Graduated Metropolis. Finally, new systems-level software will be developed that enables easy integration and implementation of light transport simulation methods for rendering and imaging."
"1017134","RI: Small: Vision-Based Mobile Manipulation and Navigation","IIS","ROBUST INTELLIGENCE","08/15/2010","08/19/2010","Gaurav Sukhatme","CA","University of Southern California","Standard Grant","Jie Yang","07/31/2015","$449,271.00","Stefan Schaal","gaurav@cs.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7923","$0.00","This project focuses on tackling a critical barrier to long-term autonomy for robotic systems, namely the lack of theoretically well-founded self-calibration methods for inertial and vision-based sensors, commonly found on sophisticated robots. The project is motivated by the vision of power-up-and-go robotic systems that are able to operate autonomously for long periods without requiring tedious manual sensor calibration. The research team addresses this problem in the context of vision-based mobile manipulation and navigation. The core foci of the work are: 1. the development of a unified mathematical theory of anytime, automatic calibration for visual-inertial systems, and 2. an experimental characterization of the resulting algorithms with state-of-the-art, sophisticated robots of significant diversity (humanoids performing mobile manipulation and autonomous ground vehicles navigating outdoors). Inertial sensing is critically important for humanoid balance control, while visual sensing relates the 3D world to the robot's body coordinates thereby enabling manipulation. In the case of autonomous ground vehicles, monocular and stereo camera calibration is still commonly performed manually using a known calibration target. The project obviates the need for this requirement. The expected outcomes of the project are: 1. a theoretical foundation for humanoid robots to function autonomously in unstructured environments over significant periods of time, and 2. new navigation algorithms for ground vehicles allowing them to see further with greater acuity. The project explicitly incorporates undergraduate research in cooperation with an REU site currently operational at the USC Computer Science Department."
"0911036","III: Large: Causal Databases","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2009","06/25/2014","Joseph Halpern","NY","Cornell University","Continuing grant","Maria Zemankova","08/31/2015","$2,353,128.00","Johannes Gehrke, David Lifka, Joseph Halpern, Dan Suciu","halpern@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","1640, 7364","7364, 7925, 9216, HPCC","$0.00","The commercial success of data mining, and the great research interest<br/>that this area attracts, prove that there is a need for analyzing and<br/>understanding data that goes well beyond classical database queries.<br/>Users are often particularly interested in understanding the causal<br/>relationship between data items and the reasons for observations.<br/><br/>Current database systems cannot explicitly model the causal structure<br/>within data (although it is often implicit in the data), and thus offer<br/>no specific support for causal queries. In the absence of information<br/>about causal relationships, users have to rely on techniques for mining<br/>for statistically significant patterns in data. Causal relationships<br/>are often simply concluded from statistical dependencies. This can lead<br/>to inaccurate conclusions; correlation does not necessarily imply<br/>causation.<br/><br/>This project creates the foundations for a new breed of databases<br/>called causal databases. Causal databases can model causal information,<br/>and allow for queries regarding causality and explanations, which are<br/>beyond the scope of current databases. They can also take advantage of<br/>causal information that is implicit, but unexploited, in some current<br/>databases, such as those for large engineering projects. In the<br/>project, new database models and query languages for representing and<br/>transforming causal information are developed, with particular focus on<br/>large engineering databases and scientific databases. In addition,<br/>efficient and scalable techniques for processing causality and<br/>computing explanations in large causal databases are developed. This<br/>involves both work on integrating causality processing into traditional<br/>database query processing architectures and the development of special<br/>datastream techniques for scaling up to the most data-intensive<br/>applications.<br/><br/>Further information on the project can be found at the project web<br/>page: http://www.cs.cornell.edu/databases/causality/"
"1117527","III: Small: Personalized Inconsistency Resolution in Online Databases","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/21/2011","Alin Deutsch","CA","University of California-San Diego","Standard Grant","Frank Olken","07/31/2015","$500,000.00","Yannis Papakonstantinou","deutsch@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7923","$0.00","The RICOLLA project manages inconsistencies in structured databases maintained collaboratively by an online community. RICOLLA remains fully functional in the presence of inconsistencies, enabling ""resolve-as-you-go"" consistency. RICOLLA allows users to collaboratively resolve certain conflicts while disagreeing on others. Building Ricolla involves the following technical contributions: a) a novel architecture that tolerates inconsistency, allows data query and update, while aiding inconsistency resolution by community members; b) a data model and interface for explaining the inconsistencies to the users; c) a set of resolution actions that allow each user to resolve individual data inconsistencies; d) a resolution policy language for summarizing a set of resolution actions based on high level criteria; and e) a set of algorithms for implementing the system on top of a relational database management system.<br/><br/><br/>The resulting techniques and prototype contribute to the infrastructure for the next generation of online databases. This benefits a variety of online communities who need to collaboratively edit structured data, ranging from the scientific domain to digital government and social networks. RICOLLA's evaluation includes as use cases two scientific communities (biologists and geoscientists) and UCSD students taking database classes. Direct deployment in teaching serves to both improve students' online collaboration and collect their feedback for RICOLLA's evaluation and tuning purposes. Publications, technical reports, software and experimental data resulting from this research are available at the project web site http://db.ucsd.edu/ricolla."
"1423419","RI: Small: Design and Implementation of Goal-directed Solvers for Answer Set Programming","IIS","ROBUST INTELLIGENCE","07/01/2014","06/24/2014","Gopal Gupta","TX","University of Texas at Dallas","Standard Grant","James Donlon","06/30/2017","$495,109.00","","gupta@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7495, 7923","$0.00","This project is focused on the development of an efficient Answer Set Programming (ASP) solver, advancing the state-of-the-art in logic based knowledge representation, logic programming and artificial intelligence. ASP is an elegant way to represent knowledge and perform advanced reasoning (common sense reasoning, non-monotonic reasoning, planning, constraint satisfaction, etc.). ASP is based on the stable model semantics proposed by Gelfond and Lifschitz. It has gained wide acceptance in the last fifteen years in the knowledge representation (KR) and artificial intelligence (AI) research communities due to its incorporation of negation, its expressiveness and simple, intuitive syntax. Considerable past research has been done in developing the ASP paradigm as well as its implementations and applications. Implementation techniques for realizing answer set solvers range from simple guess-and-check based methods to those based on SAT solvers and complex heuristics. Applicability of current ASP systems is limited due to (i) the current implementation methods not being goal-directed (i.e., not being query-driven), (ii) need for grounding the answer set program if predicates are present, (iii) being forced to find the model of the entire program (even though to answer a given query only a small subset of the model needs to be computed), and (iv) no answer being produced even if a minor inconsistency (unrelated to the query) is present in the knowledge base. This project addresses these problems by developing a query-driven implementation of answer set programs containing predicates. Current systems have to process the entire knowledge base (expressed as an answer set program) to compute an answer. In contrast, the query-driven method developed in this project only accesses and processes parts of the knowledge base that are involved in answering the query. Query-driven execution allows predicates to be directly included in answer set programs. It also leads to efficiency in execution. <br/><br/>The query-driven method is based on PI's group's recent discovery of coinductive logic programming. Coinductive logic programming imparts operational semantics to greatest fixed point-based computations. Given a query and an answer set program, this coinduction-based operational semantics is used to compute (partial) answer sets that contain the query goal(s). With query-driven execution, predicates can be supported directly, i.e., answer set programs containing predicates no longer have to be grounded first. The main tasks of this project are the following: (i) develop an efficient query-driven, top-down execution strategy for propositional answer set programs; (ii) extend this query-driven execution strategy to handle Datalog ASP (without grounding the program first); (iii) further extend this query-driven execution strategy to handle Predicate ASP (without grounding the program first); (iv) develop coinductive extension of ASP and its implementation; (v) develop a query-driven abductive reasoning engine based on ASP; and, (vi) further extend the engine to incorporate constraints over reals. The key intellectual contributions of the research is the investigation of techniques for query-driven execution of answer set programs and advanced reasoning systems that employ negation. The research tests the claim that a query-driven implementation can more elegantly (and efficiently) support constraints and abduction in ASP. The broader impacts of this work include the availability of more powerful applications of knowledge representation; mechanisms for common sense reasoning; integration of advanced ASP systems into education and research venues; and the development of the research careers of graduate and undergraduate students, including those from under-represented groups."
"1320149","III: Small: GeoCrowd - A Generic Framework for Trustworthy Spatial Crowdsourcing","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","06/23/2014","Cyrus Shahabi","CA","University of Southern California","Standard Grant","Sylvia J. Spengler","08/31/2016","$516,000.00","","shahabi@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7364","7364, 7923, 9251","$0.00","Many studies foresee significant growth in the number of smart phone users, the phone's hardware and software features, and the broadband bandwidth. Therefore, a transformative area of research is to utilize this new platform for various tasks, among which the most promising is spatial crowdsourcing. Spatial crowdsourcing engages individuals, groups, and communities in the act of collecting, analyzing, and disseminating urban, social, and other spatiotemporal information. <br/><br/>Two major impediments to the success of spatial crowdsourcing in real-world applications are scalability and trust issues. Therefore, the first objective of this project is to study the issue of scale in spatial crowdsourcing. In particular, given that the task assignment is the main bottleneck of the system, the spatial aspects of the tasks are exploited to reduce the complexity of assignment. In addition, a cloud-based distributed approach to the problem is investigated for better scale-out. The second objective is to extend the framework to incorporate trust by maintaining a reputation score per worker and a confidence level for every spatial task. Consequently, multiple workers can perform a task redundantly in order to satisfy its confidence level. The spatial task assignment solutions are extended to take redundant task assignments and confidence satisfaction into consideration.<br/><br/>Spatial crowdsourcing has applications in disaster-response, urban planning, intelligent transportation, journalism and intelligence. As part of this project a spatial crowdsourcing system is being developed that can be used for real-world data collection and evaluation as well as for social studies and educational purposes.<br/>Results are disseminated through the web: http://infolab.usc.edu/projects/GeoCrowd/"
"1110970","SoCS: Studying the Computability of Emotions by Harnessing Massive Online Social Data","IIS","SOCIAL-COMPUTATIONAL SYSTEMS, Cyber-Human Systems","08/01/2011","05/14/2014","James Wang","PA","Pennsylvania State Univ University Park","Continuing grant","Kevin Crowston","07/31/2015","$768,821.00","Jia Li, Michelle Newman, Reginald Adams","jwang@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7953, 7367","7367, 7953, 9251","$0.00","The emergence of massive human-rated and commented visual data has opened avenues for exploring fundamental questions in artificial intelligence beyond the horizon. This project tackles the challenge of automatically inferring visual aesthetics and emotions and inventing new systems that assist creative and decision-making activities of the general public. An interdisciplinary team, with expertise in visual modeling, data mining, psychology, and computational sciences will build tools to distill information from a combination of visual, textual, and numerical data. Visual features, selected based on published literature and consultation with domain experts, will be extracted for discriminating types of emotions. The resulting systems can select and rank visual information based on aesthetics and emotions.<br/><br/>Intellectual Merits: This project will allow computer scientists to gain understanding of next-generation computerized visual aesthetics and emotion assessment systems. The complex inter-relationship among content, context, and subjectivity in aesthetics and emotion assessment makes the corresponding learning problems especially challenging, which is likely to trigger innovation in machine learning and statistical modeling. Such capabilities will fundamentally change the way visual information is analyzed, processed, and managed. The project will advance our understanding of the computability of emotions, and lead to new applications that can be used in a variety of settings.<br/><br/>Broader Impacts: The research will have a transformative impact in the fields of information retrieval, human-computer interaction, information processing, consumer electronics, and design. The technology can also be used to refine multimedia content that serves as education resources. The project will disseminate research findings, generate new software implementations and collected datasets, and provide online services that can be used by researchers, educators, and industry. Education efforts include developing an interdisciplinary curriculum, training cross-disciplinary scientists, and involving underrepresented groups in research."
"1115670","TC: Small: Integrating Privacy Preserving Biometric Templates and Efficient Indexing Methods","CNS","TRUSTWORTHY COMPUTING, FED CYBER SERV: SCHLAR FOR SER, INFO INTEGRATION & INFORMATICS","09/01/2011","06/21/2012","Venugopal Govindaraju","NY","SUNY at Buffalo","Standard Grant","Christopher Clifton","08/31/2015","$514,788.00","Atri Rudra","govind@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7795, 1668, 7364","7795, 7923, 9178, 9251","$0.00","Biometrics, such as fingerprints, provide a great tool for personalized authentication. While people are usually willing to submit their biometric information to government agencies, they are less likely to do so for commercial companies without a guarantee of privacy protection. This project will have significant societal impact by triggering wide acceptability of large-scale biometrics enabled applications.<br/>The primary technological hurdle faced by large scale biometric systems today is the ability to address two competing objectives: (1) provide fast matching of a biometric against a large database of stored biometric readings and (2) provide privacy of the biometrics in the database such that it can withstand malicious attacks. Existing solutions tackle either of the two problem but not both simultaneously.<br/>Tackling the two problems in an integrated fashion is non-trivial as any solution to conceal the biometric data to ensure privacy involves breaking down the structure inherent in the biometric template, thus making it extremely challenging to index the records efficiently. This project presents a unified approach by developing ""cryptographically hidden"" biometric templates which will lend themselves to fast searches. This effort will draw upon new research in the fields of biometrics, databases, and coding theory."
"1118106","III: Small: Parallel Similarity Comparison and Duplicate Detection with Incremental Computing","IIS","INFO INTEGRATION & INFORMATICS","08/15/2011","03/20/2012","Tao Yang","CA","University of California-Santa Barbara","Standard Grant","Maria Zemankova","07/31/2015","$515,732.00","","tyang@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7923, 9251","$0.00","All-pairs similarity comparison is one of the core algorithms in many data-intensive mining and search applications such as near duplicate detection among web pages, spam detection, advertisement click analysis, similar news/fresh content grouping, and recommendation for similar product purchases and search queries. Conducting similarity search on large datasets is time consuming and becomes more challenging when data are being updated continuously. It is important to develop high performance algorithms and software to meet the increasing speed demands in many consumer and business applications using similarity computation. <br/><br/>This project studies efficient and cost-effective parallel algorithms when data are being updated periodically or dynamically. Techniques for partitioning data and balancing computation on a cluster of machines are developed to optimize input/output operations, communication, and computing resource usage. As data are often updated continuously, leveraging previously computed results to handle updated data can eliminate a large amount of unnecessary operations and speedup the entire computation process by an order of magnitude. The project develops efficient software on a cluster of machines. The project starts with incremental duplicate detection for web data analysis and search, and continues to work on similarity comparison in several other applications. Performance of developed software is evaluated in those applications.<br/><br/>This research has the potential to develop fully-optimized solutions with significantly reduced cost and increased speed for a variety of big data applications that perform similarity analysis. Developed software will be made available for application developers or data engineers to conduct large-scale computation without involving the complexity of managing parallelism. The project web site (http://www.cs.ucsb.edu/projects/psc/) is used for dissemination of results. The educational plan contains research mentoring, undergraduate and graduate instruction improvement, and outreach activities such as working with high school students."
"1016916","III: Small: Collaborative Research: Exploiting Information Graphics in a Digital Library","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","05/13/2013","Mary Carberry","DE","University of Delaware","Standard Grant","Maria Zemankova","08/31/2015","$419,056.00","","carberry@cis.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7364","7364, 7923, 9150, 9251","$0.00","This project is a collaborative effort between the University of Delaware and Millersville University. Information graphics (non-pictorial graphics such as bar charts and line graphs) occur frequently in popular media such as newspapers and magazines. Not only is the knowledge conveyed by these graphics very often not included in the article's text, but (in contrast with scientific documents) the article's text most often does not even explicitly refer to the graphics. Information retrieval research has focused on the text of documents, and their information graphics have largely been ignored. Yet, the graphic designer considered the graphic's message important enough to warrant designing a graphic to convey it. This project's goal is a novel methodology for retrieving relevant information graphics from a digital library in response to user queries.<br/><br/>Information graphics in popular media generally have a communicative goal or message that they are intended to convey. This message encapsulates the high-level knowledge contained in the graphic. The approach of the project is a language model that treats the relevance of a graphic to a query as a mixture of three components: a graphic's intended message, other textual components of the graphic such as its caption and additional textual description augmenting the caption, and the text of the document containing the graphic. Challenges that are being addressed include identifying the portion of the article that is relevant to the graphic, associating query terms with the intended messages of graphics in the document library, expanding the abbreviated captions and additional textual descriptions of graphics to more fully capture their content, and appropriately weighting the contribution of individual components of the mixture model. In addition, some kinds of graphics, such as grouped bar charts, have both a primary intended message and a secondary message. The impact of the secondary message on retrieval when an ideal graphic is unavailable is also being addressed. Evaluation of the graph retrieval methodology consists of experiments in which human subjects rate the relevance of retrieved graphics to user queries.<br/><br/>The goal of this project is to produce a system for retrieving relevant information graphics, thereby expanding the utility of digital libraries. Together with the SIGHT system, which conveys the content of information graphics via speech, the project will extend the information resources available to individuals with sight-impairments. The project will also produce a corpus of information graphics and their XML representations that can be used by other researchers. Corpora and research results will be disseminated on the project web site (http://www.cis.udel.edu/~carberry/Graph-Retrieval). In addition to significantly increasing the resources accessible from a digital library, the research will lay the foundation for expanding research on question-answering to take into account information graphics. The project will contribute to the development of future scientists by educating graduate students, providing research opportunities for undergraduates at a predominantly undergraduate institution, and enhancing the mentoring skills of graduate students as they work on a team that includes undergraduates."
"1023853","Collaborative Research: Integrating Shape, Scaling, and Alignment in a Global Approach to F0 Events in Intonation Systems","BCS","LINGUISTICS, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","10/01/2010","09/21/2010","Jonathan Barnes","MA","Trustees of Boston University","Standard Grant","William J. Badecker","09/30/2014","$252,555.00","","jabarnes@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","SBE","1311, 7252, 7495","0000, 1311, 6867, 7495, 7969, OTHR","$0.00","Human languages use pitch to convey meaning in a bewildering variety of ways. In all languages, pitch (as one aspect of speech prosody) can express attitude or emotion. In some languages, like English, pitch patterns, usually called intonation contours, also express distinctions such as that between a question and a statement. In languages like Mandarin Chinese, pitch patterns usually called tones go still further to signal differences between words that are otherwise identical. Despite significant advances in recent decades, a unified theoretical account of such linguistic phenomena remains elusive. What is missing is a common acoustic or articulatory vocabulary for expressing the relevant distinctions---a single measurable dimension within which spoken pitch contours (rises and falls) can be reliably distinguished regardless of the language under investigation. In recent work, the research team developed a new mathematical approach to tone and intonation, based on the notion of Tonal Center of Gravity. TCoG is a gestalt or global approach to tone perception and production that reconciles seemingly contradictory results from different strands of the experimental literature, moving toward a model that incorporates the best aspects of past theories, while avoiding their characteristic weaknesses. That earlier work has established that the TCoG approach accounts well for production and perception data involving two contrasting English intonation contours. This project aims to expand the empirical range of the approach in three crucial ways: First it extends the model to additional English intonation patterns. Second, it moves beyond English to look at other intonation languages (e.g., German), as well as so-called ""tone languages"" (e.g., Serbian). Lastly, whereas the previous work concentrated primarily on the timing of tonal events in speech, this project goes further, to investigate the interaction of tonal timing patterns with the scaling of tonal events in the pitch domain. The experimental work will be of two primary kinds: automatic classification of pitch contours recorded from native speakers in an experimental setting, and direct manipulation (through speech synthesis) of pitch contours in perception studies designed to determine which aspects of the acoustic signal have the greatest effect on listeners' judgments of utterance meaning.<br/><br/>Given the central role of intonation patterns in speech communication, one major contribution of the Tonal Center of Gravity approach is its potential to transform methods for speech synthesis and speech understanding. Synthetic speech is typically described as repetitive, detached, and often unhelpfully neutral; listeners recognize that they are talking with a machine that 'doesn't get it'. By providing a more detailed understanding of how intonational patterns help to convey a message, TCoG could be used to devise algorithms for the synthesis of more natural and appropriate-sounding speech. Likewise, for automatic understanding of the aspects of meaning that depend on intonational patterns, TCoG could allow an automatic system to detect levels of nuance beyond simply whether a word is emphasized or not, or whether an utterance is a statement or a question. A final application of this work could be in the development of software tools for second language learning, in which automated instruction and feedback on the subtleties of second language intonation patterns could help learners master important aspects of communication that are typically ignored in current approaches to language pedagogy."
"1319810","RI: Small: Collaborative Research: Statistical ranking theory without a canonical loss","IIS","ROBUST INTELLIGENCE","08/01/2013","08/08/2013","Ambuj Tewari","MI","University of Michigan Ann Arbor","Standard Grant","Todd Leen","07/31/2016","$245,594.00","","tewaria@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7495, 7923","$0.00","The problem of ranking objects occupies a central place in key technologies such as web search and recommendation systems. These technologies have a tremendous daily impact on the lives of millions of people. Moreover, the enormous scale of data on the web makes the use of machine learning especially attractive in constructing ranking algorithms. A huge amount of research effort has been devoted to developing efficient ranking algorithms that can deal with a variety of data sets encountered in web search and recommendation systems.<br/><br/>This project develops unifying mathematical theory that will provide a basis for understanding and categorizing existing algorithms and, more importantly, lead to deeper insights and new algorithms for the problem of learning to rank. The investigators also apply ranking algorithms to new domains. For example, ranking chemical reactions based on their plausibility will help chemists discover much-needed reaction bases for technologies such as carbon dioxide reduction, and conversion of natural gas into gasoline. <br/><br/>Fundamental advances in the statistical theory of ranking will be incorporated into undergraduate and graduate courses. Data sets and software developed will be made freely available to the scientific community. The investigators will also organize a workshop with a focus on interdisciplinary participation and involvement of under-represented groups in computer science and statistics.<br/><br/>The primary technical challenge in developing statistical ranking theory is the absence of a universally agreed-upon loss functions for ranking. This is in contrast to classic machine learning problems such as classification and regression, where there are only a few natural possibilities for the loss function and these are well-understood theoretically. The project addresses this gap by investigating how different loss functions for ranking affect fundamental theoretical properties such as learnability, and by creating a theory of convex surrogates that is applicable when loss functions abound. The project re-examines existing statistical literature on ranking with a computational lens. This will enable development of flexible and efficient plug-in decision rules that model the conditional probability of labels given inputs.<br/><br/>By incorporating the results of this research into courses and survey articles, the PIs help train a new generation of machine learning researchers and practitioners who will view ranking as a learning problem on par with classification and regression in mathematical depth as well as practical importance. Theoretical guidance for practitioners formulating new algorithms for ranking will improve the most common applications on the web."
"1318392","RI: Small: Robust and Long-Term Visual Mapping and Localization","IIS","ROBUST INTELLIGENCE","09/01/2013","06/21/2014","John Leonard","MA","Massachusetts Institute of Technology","Continuing grant","Satyandra Gupta","08/31/2016","$373,293.00","","jleonard@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7495, 7923","$0.00","This project develops robust and persistent algorithms for mapping and localization using low-cost visual/depth cameras and inertial sensors. New map representations and algorithms are developed to provide computationally efficient long-term 3D mapping and navigation. Topics of investigation include incremental non-Gaussian inference techniques, dense mapping, change detection in dynamic environments, and semantic understanding. A lack of robustness has been a key shortcoming of previous techniques for localization, and thwarted the development of persistently autonomous mobile robot systems. Extension to multimodal distributions poses significant intellectual difficulties. Dense methods are transforming robotic perception, enabling sophisticated physical interaction with objects, traversal of stairs, and safe maneuvering in cluttered and confined spaces. Whereas most past research in robotic mapping has assumed a static world, the approach being developed in this grant exploits the dynamics of the world to discover information about objects and places. These advances are being tested for robotic and man-portable sensing systems operating in indoor, outdoor, and underwater environments. The expected impacts span a broad range of applications, from robotic manufacturing, medical robotics, agriculture, and space and underwater exploration, in which perception is a key requirement. Other potential spin-offs include human-portable mapping applications in real estate, construction, and facility maintenance, health and safety. MIT Online Robotics Education provides a set of online course materials for core topics in robotics, targeted to a broad audience for high school and college education. Open source software modules provide positioning capabilities for low-cost robots for education and service robotics applications."
"1319602","RI: Small: Collaborative Research: Bio-inspired Collaborative Sensing with Novel Gliding Robotic Fish","IIS","ROBUST INTELLIGENCE","08/01/2013","06/21/2014","Xiaobo Tan","MI","Michigan State University","Continuing grant","Satyandra Gupta","07/31/2016","$164,219.00","","xbtan@msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7495","7495, 7923","$0.00","Monitoring and understanding aquatic environments is critical to water sustainability. The goal of this award is to establish a theoretical framework and provide an enabling technology for robust underwater collaborative sensing with small, inexpensive robots. Inspired by the source-seeking behavior of live fish, computationally efficient algorithms are developed for cooperative tracing of the gradients of environmental fields, and their robustness is analyzed in the presence of localization error and changing communication topology. The algorithms are experimentally validated in thermal source seeking and tracing with a group of energy-efficient and highly maneuverable gliding robotic fish, which are enhanced in this project with optical communication and localization capabilities. Advanced controllers are developed for these robots to realize three-dimensional maneuvering and to track reference paths planned through collaborative sensing algorithms. This award offers fundamental understanding of limits and robustness properties of collaborative sensing by resource-limited robots, and contributes to the knowledge base in underwater communication and ranging for small robots. It enables technological advances for persistent sampling of versatile aquatic environments including coastal waters, lakes, and rivers, with a myriad of applications such as oil spill response, ecological monitoring, and port and drinking water security. The findings from this project are disseminated through publications, software sharing, and technology commercialization. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Outreach activities, including museum/aquarium exhibits and teacher training, are developed to pique the interest of K-12 students, teachers, and the public in science and engineering."
"1253413","CAREER: Achieving Quality Crowdsourcing across Tasks, Data Scales, and Operational Settings","IIS","INFO INTEGRATION & INFORMATICS","03/15/2013","06/20/2014","Matthew Lease","TX","University of Texas at Austin","Continuing grant","Maria Zemankova","02/28/2018","$237,219.00","","ml@ischool.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7364","1045, 7364, 9251","$0.00","While crowdsourcing and human computation methods are rapidly transforming the practice of data collection in research and industry, ensuring quality of the collected data remains difficult in practice and exposes projects relaying on quality of crowdsourced data to significant risk. This reduces the benefits of crowdsourcing for both current adopters and a wider community of potential beneficiaries. Although diverse communities have developed statistical algorithms for quality assurance, the splintered nature of these communities has led to relatively little comparative benchmarking and/or integration of alternative techniques. Dearth of reference implementations and shared datasets has further abated progress, as have evaluations based on tightly-coupled systems, domain specific tasks, and synthetic data. This project investigates, integrates, and rigorously benchmarks diverse quality assurance algorithms across a range of tasks, data scales, and operational settings. Overall, technical findings are expected to transform current understanding of quality assurance methods for crowdsourcing, including identifying key limitations of the current state-of-the-art in order to focus ongoing research and innovation where it can have the greatest impact. Reference implementations of key algorithms are designed to support reuse, reproducible findings, continual benchmarking, and ongoing progress. Project will yield new, sanitized public datasets to support ongoing community benchmarking and shared-task evaluations.<br/><br/>Technical contributions from the project are expected to offset risk of growing social inequity as online, distributed work becomes increasingly prevalent. Assumptions that crowdsourcing workers are unreliable or interchangeable limit the complexity and scope of work which can be successfully accomplished with online crowdsourcing. By limiting the amount of work available online and opportunities for skilled work, this further restricts the range of upward economic mobility achievable via crowd work. By developing effective methods to measure work quality over time and identify trusted workers, it will be possible to differentiate, recognize, and reward quality work to promote merit-based economic mobility. Educational activities include a new crowdsourcing course designed for college freshman from diverse backgrounds, a graduate seminar integrating the project's research software, presentations to the student chapter of a professional society, and tutorials and short courses benefiting industry practitioners and researchers. This project will inform the principal investigator's community advisory and organizational activities, including Advisory Board service for an annual industrial conference and organizing workshops bringing the industry and research communities together. Information and results will be disseminated via the project web site (http://ir.ischool.utexas.edu/career/)."
"1212806","CGV: Large: Collaborative Research: Modeling, Display, and Understanding Uncertainty in Simulations for Policy Decision Making","IIS","INFO INTEGRATION & INFORMATICS, GRAPHICS & VISUALIZATION","10/01/2012","06/20/2014","Ross Whitaker","UT","University of Utah","Standard Grant","Maria Zemankova","09/30/2016","$1,831,124.00","Miriah Meyer, Sarah Creem-Regehr, Robert Kirby, William Thompson","whitaker@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7364, 7453","7364, 7453, 7925, 9150, 9251","$0.00","The goal of this collaborative project (1212806, Ross T. Whitaker, University of Utah; 1212501, Donald H. House, Clemson University; 1212577, Mary Hegarty, University of California-Santa Barbara; 1212790, Michael K. Lindell, Texas A&M University Main Campus) is to establish the computational and cognitive foundations for capturing and conveying the uncertainty associated with predictive simulations, so that software tools for visualizing these forecasts can accurately and effectively present this information about to a wide range of users. Three demonstration applications are closely integrated into the research plan: one in air quality management, a second in wildfire hazard management, and a third in hurricane evacuation management. This project is the first large-scale effort to consider the visualization of uncertainty in a systematic, end-to-end manner, with the goal of developing a general set of principles as well as a set of tools for accurately and effectively conveying the appropriate level of uncertainties for a range of decision-making processes of national importance.<br/><br/>The primary impact of this work will be methods and tools for conveying the results of predictive simulations and their associated uncertainties, resulting in better informed public policy decisions in situations that rely on such forecasts. Scientific contributions are expected in the areas of simulation and uncertainty quantification, visualization, perception and cognition, and decision making in the presence of uncertainty. Results will be broadly disseminated in a variety of ways across a wide range of academic disciplines and application areas, and will be available at the project Web site (http://visunc.sci.utah.edu). The multidisciplinary nature of the research and the close integration of the participating research groups will provide a unique educational environment for graduate students and other trainees, while also broadening the participation in computer science beyond traditional boundaries."
"1253432","CAREER: Advancing Interaction Paradigms in Mobile Augmented Reality using Eye Tracking","IIS","Cyber-Human Systems","02/01/2013","06/20/2014","Ann McNamara","TX","Texas A&M University Main Campus","Continuing grant","Anthony Hornof","01/31/2018","$209,129.00","","ann@viz.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","CSE","7367","1045, 7367, 9251","$0.00","In this project the PI will develop the science needed to enhance mobile augmented reality applications with (a) eye tracking and (b) gaze direction. Mobile augmented reality uses a hand-held device to provide a see-through view of the physical world in which an image of the physical world is superimposed with information about the things in that view. It is as if you held a piece of glass up to the world, and text appeared on that piece of glass labeling the things you see through the glass. This project will investigate how mobile eye tracking, which monitors where a person is looking while on the go, can be used to determine what objects in a visual scene a person is interested in, and thus might like to have annotated in their augmented reality view. This project will investigate how to make these scene annotations appear and disappear in a manner that is neither distracting nor obtrusive by conducting experiments that measure a person's ability to accomplish visual tasks while presented with text annotations in different sizes, transparency levels, and distances from the point-of-gaze (the point where a person is looking). The project will develop algorithms to automatically manage the density and placement of these labels to best support human tasks while avoiding the creation of distracting ""visual clutter"".<br/><br/>The project will also develop the science that is needed to direct a person's gaze in the physical world by means of new visualization techniques for use in mobile augmented reality systems. In this case, it is as if the piece of glass through which you are viewing the world periodically changed slightly to unobtrusively motivate you to look more closely at different, specific, task-relevant parts of the scene. This aspect of the project will be conducted in collaboration with the Houston Museum of Fine Arts.<br/><br/>Broader Impacts: The project will advance discovery of visualization techniques to permit mobile applications to enhance the viewing of the physical world, while promoting the teaching and learning of science in multiple contexts. Collaborating with the Houston Museum of Fine Arts, the project will develop a freely-downloadable iPhone application that will enhance museum-goers' learning in the arts, and provide a proof-of-concept of how the techniques developed in this project could be used in other contexts.<br/><br/>The project pursues a number of specific new opportunities in science education, including the development of (a) project-related curriculum for a science-based summer camp for junior high school students at Texas A&M University, (b) new University-level courses on the programming for augmented reality and the human performance aspects of lighting and cinematography, and (c) conference tutorials on experimental design, eye tracking, and perception in computer graphics."
"1111182","SoCS: Collaborative Research: Social Media Enhanced Organizational Sensemaking in Emergency Response","IIS","COLLABORATIVE RESEARCH, INFO INTEGRATION & INFORMATICS, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2011","09/12/2013","Amit Sheth","OH","Wright State University","Standard Grant","Maria Zemankova","08/31/2015","$517,608.00","John Flach, Valerie Shalin","amit.sheth@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7298, 7364, 7953","5914, 5979, 7298, 7364, 7953, 9251","$0.00","This collaborative research leverages expertise of researchers at Wright State University (IIS-1111182) and Ohio State University (IIS-1111118). Online social networks and always-connected mobile devices have created an immense opportunity that empowers citizens and organizations to communicate and coordinate effectively in the wake of critical events. Specifically, there have been many isolated examples of using Twitter to provide timely and situational information about emergencies to relief organizations, and to conduct ad-hoc coordination. However, there are few attempts that try to understand the full ramifications of using social networks in a more concerted manner for effective organizational sensemaking. This project aims to conduct multidisciplinary research involving computer and social scientists fill this gap.<br/><br/>This project seeks to leverage Twitter posts (tweets) as the primary source of citizen inputs and couple relevant content and network information along with microworld simulations involving human role players to measure effectiveness of various organized sensemaking strategies. To arrive at meaningful summaries of citizen input, tweet content is analyzed using a semantic content analysis by combining natural language techniques that are suitably fused with existing knowledge bases (GeoNames, Wikipedia). Content analysis is further enhanced by innovatively combining it with the dynamic analysis of the twitter network to realize concise and trustworthy information nuggets of potential interest to organizations and citizens. The resulting summaries will be fed to a suitably designed microworld simulation involving human actors to derive realistic settings for modeling disaster situations and typical organizational structures.<br/><br/>This project is expected to have a significant impact in the specific context of disaster and emergency response. However, elements of this research are expected to have much wider utility, for example in the domains of e-commerce, and social reform. From a computational perspective, this project introduces the novel paradigm of people-content-network analysis whose application is not just limited to organized sensemaking. For social scientists, it provides a platform that can be used to assess relative efficacy of various organizational structures using microworld simulations and is expected to provide new insights into the types of social network structures (mix of symmetric and asymmetric) that might be better suitable to propagate information in emergent situations. From an educational standpoint, the majority of funds will be used to train the next generation of interdisciplinary researchers drawn from the computational and social sciences. Research activities will also be integrated with graduate course work. Participation of underrepresented groups will be encouraged. Datasets and software developed as part of this project will be made available to the broader research community via the project page (http://knoesis.org/research/semspc/projects/socs)."
"1116360","HCC: Small: Assistive Social Situational Awareness Aids for Individuals with Disabilities","IIS","Cyber-Human Systems","09/01/2011","05/01/2014","Sethuraman Panchanathan","AZ","Arizona State University","Continuing grant","Ephraim P. Glinert","08/31/2015","$515,284.00","Terri Hedgpeth, Vineeth Nallure Balasubramanian, Troy McDaniel, Artemio Ramirez","panch@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","7367, 7923, 9251","$0.00","The PI's goal in this project is to enable a quantum leap towards next-generation social assistive aids that enrich the lived social experiences of individuals with visual impairments. Social interaction is a central component of the human experience. The ability to communicate effectively with fellow individuals is a fundamental necessity for professional success as well as personal fulfillment. But nonverbal cues (including prosody, environment attributes, the appearance of communicators and their physical movements) account for a substantial and important part of the information conveyed during social interactions. As a consequence, the more than 1.3 million individuals in the United States (and 37 million worldwide) who are legally blind have only a limited experience of social interaction. This ""social disability"" often isolates them from their social environments. Existing assistive technologies are focused on problems such as navigation, reading text, and access to everyday appliances as well as to computers and the Internet, whereas little or no work has been devoted to real-time accessibility to social and behavioral cues. Providing real-time access to nonverbal communication cues to visually impaired users poses fundamental challenges in several related fields including affective computing, human communication engineering, behavioral modeling, machine learning, human-machine interaction, multimodal interfaces, usability engineering, multimedia computing, and assistive technology design and development<br/><br/>As a first step towards practical and viable social assistive solutions, the PI will focus in this project on the design and development of a social situational awareness assistive prototype for dyadic (one-on-one) interactions, with an emphasis on head/face-based nonverbal cues. The research will be accomplished through the following specific objectives: (1) Design and development of a dyadic interpersonal mediation interface; (2) Extraction and understanding of nonverbal communication cues; (3) Visuo-haptic sensory substitution for delivering high-bandwidth socio-behavioral data; and (4) Evaluation of the social assistive prototype system in dyadic interaction scenarios representing real-world conditions. The project draws upon intellectual synergies among the team members, who are experts in human-centered multimedia computing, human-computer interfaces and machine intelligence (Panchanathan, Computer Science); assistive technology design and usability engineering (Hedgpeth, Disability Resources Center); and human communication modeling and socio-behavioral analysis (Ramirez, Human Communication). The work will build on the team's past successes in developing assistive technologies that have been designed, prototyped, deployed and tested for individuals who are visually impaired. Project outcomes will be evaluated through the Arizona State University Disability Resource Center and the Arizona Center for the Blind and Visually Impaired.<br/><br/>Broader Impacts: This project will pioneer the development of next-generation social assistive aids for individuals with visual impairments and thus will have a significant impact on their lives. The research to these ends will result in the advancement of computational thinking within and at the confluence of the component disciplines, namely socio-behavioral computing (through the introduction of novel methodologies for computational analysis and evaluation of human communication dynamics in general and social behavior in dyadic interactions, specifically), human-computer interfaces (through the design of novel interfaces that deliver high-bandwidth social data), machine intelligence (through the study of algorithms that elicit various levels of interaction semantics) and assistive technology/usability (through the development and evaluation of social assistive prototypes). The concepts and technologies developed will also provide pathways to technologies for individuals with other disabilities, such as autism, dementia, and (in the most general sense) a very large portion of society. The methodologies developed will provide a wealth of data and information that will be made publicly accessible to promote and catalyze further research in the component disciplines."
"1421065","RI: Small: Enabling robust visual intelligence using propagators to model human competence","IIS","ROBUST INTELLIGENCE","07/01/2014","06/20/2014","Patrick Winston","MA","Massachusetts Institute of Technology","Standard Grant","James Donlon","06/30/2017","$500,000.00","","phw@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7495, 7923","$0.00","The investigators approach the question of robust intelligence by asking what it is that makes humans both intelligent and robustly intelligent. Part of the answer is that humans are uniquely able to see, to report on what they see, and to use visual events--- both real and imagined---to answer questions on demand and to develop a common sense understanding of the physical world. If robust human-level intelligence is to be understood and engineered, then it is necessary to understand human visual competence. To understand human visual competence, it is necessary to understand how the architecture of the brain enables fragmentary and ambiguous perceptions to be brought into alignment with expectations so as to produce an understanding of the visual world.<br/><br/>To take understanding of human vision to the next level, the investigators model the human visual system using the propagator paradigm, a label for a collection of ideas suited to the computational problems faced by vision systems. Propagators themselves are stateless, which makes them appropriate for operation on retinotopic arrays. Also, propagators connect cells in which information monotonically increases, assuring convergence. Most importantly, bi-directonal information flow lies at the core of the propagator paradigm, so when augmented with new capabilities tailored specifically to vision processing, visual information flows not only from the bottom up but also from the top down and, in general, from any module to any other module, just as information flows to and from the many brain centers devoted to vision in the human brain. The investigators note, for example, that the lateral geniculate, a relay station for information flowing from the retina to primary visual cortex, receives most of its input from the primary visual cortex itself.<br/><br/>The investigators are motivated not only by a desire to understand human vision, but also by a desire to build vision applications now far beyond the state of the art. To drive their work, they concentrate on a dynamic scene understanding problem: given an urban scene and one or more stationary cameras, recognize actions such as walk, run, stop, put down, pick up, drop, give, take, follow, enter, and leave."
"1350965","CAREER: Exact Algorithms for Learning Latent Structure","IIS","ROBUST INTELLIGENCE","07/01/2014","06/20/2014","David Sontag","NY","New York University","Standard Grant","Todd Leen","06/30/2019","$499,981.00","","das19@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","1045, 7495","$0.00","One of the fundamental tasks in science is to infer the causal relationships between variables from data, and to discover hidden phenomena that may affect their outcome. We can attempt to automate this scientific process by searching over probabilistic models of how the observed data might be influenced by unobserved (latent) factors or variables. Machine learning of such models provides insight into the underlying domain and a means of predicting the latent factors. However, it is challenging to search over the exponentially many models, and existing algorithms are unable to scale to large amounts of data.<br/><br/>The goal of this CAREER award will provide novel algorithms to circumvent this computational intractability. Based on a classical idea in statistics called the method-of-moments, the new algorithms will be applied in bioinformatics to discover regulatory modules from disease expression profiles, and in health care to predict a patient's clinical state using data from their electronic medical record. A key component of the project is to involve high school students from disadvantaged backgrounds in the research to inspire them to pursue STEM careers.<br/><br/>The project advances machine learning by introducing several new techniques for unsupervised and semi-supervised learning of Bayesian networks. The project overcomes the computational challenges associated with maximum-likelihood estimation by developing new method-of-moment based algorithms for learning latent variable models, focusing on settings where inference itself may be intractable. This includes Bayesian networks of discrete variables where a top layer consists of latent factors and a bottom layer consists of the observed data, a form of discrete factor analysis. The proposed algorithms run in polynomial time and are guaranteed to learn a close approximation to the true model.<br/><br/>The techniques developed as part of this project have the potential to be transformative in the social and natural sciences by enabling the efficient and accurate discovery of latent variables from discrete data. Furthermore, in collaboration with emergency department clinicians, the new algorithms will be applied to learn models relating diseases to symptoms from noisy and incomplete data that is routinely collected as part of electronic medical records. This will advance the field of machine learning in health care by providing algorithms that generalize between institutions without the need for a large amount of labeled training data.<br/><br/>The insights about exploratory data analysis developed as part of this project will be integrated into innovative curriculum in data science, both as part of an undergraduate class and new Master's classes. The project will bring students from nearby high schools to NYU throughout the academic year and during the summer to learn about machine learning through participation in the proposed research, having them use the unsupervised learning algorithms to discover new medical insights. The PI will also develop and deliver tutorials on machine learning to clinicians and the health care industry."
"0952786","CAREER: Advancing Accessible Computing with Tools for Ability-Based Design","IIS","Cyber-Human Systems","06/01/2010","06/20/2014","Jacob Wobbrock","WA","University of Washington","Continuing grant","Ephraim P. Glinert","05/31/2015","$509,359.00","","wobbrock@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","1045, 1187, 9215, HPCC","$0.00","Today's commodity software is ignorant of users' motor abilities. This places the burden of adaptation on people rather than on technology, and forces users either to struggle with off-the-shelf input devices or to procure specialized assistive devices that are expensive, hard to acquire, and infused with social stigmas. Recent approaches like universal design, inclusive design, and design for all acknowledge this problem, but promote an unachievable ""one size fits all"" ideal. Universal solutions are not the answer! Rather, the answer is the opposite, that is to say highly individualized user interfaces aware of and adapted to users' motor abilities. Such interfaces can enable people to use cheap readily-available everyday input devices like mice, touch pads, and trackballs when controlling desktop software. Creating software that matches users' abilities is the focus of the PI's concept of ability-based design, and this research extends the PI's prior work on ability-based design with new software tools for advancing this nascent methodology. These tools will focus on measuring and modeling target acquisition and text entry, two fundamentals of computer input that demand fine motor control, making them key challenges for people with motor impairments. The work will consist of multiple stages. The PI will investigate standard and custom psychomotor movement models for people with motor impairments. He will create and validate a Mouse Perturber tool that injects kinetic noise into an unimpaired movement stream to create simulated motor-impaired performance, making early-stage testing of ability-based prototypes easier. And he will create an Input Observer tool that can rigorously quantify users' performance ""in the wild,"" which requires the inferring of intention outside directed laboratory tasks. He will then develop CAMA, a tool for motor-ability assessment that uses off-the-shelf input devices, and TASK, a tool for quickly creating task models from real user interfaces. Finally, he will integrate CAMA and TASK into a package for assistive technology providers to perform assessment, prediction, and the creation of accessible ""proxy targets."" Project outcomes will include a scientific investigation of standard and custom psychomotor movement models for people with motor disabilities, discovery of how to rigorously measure target acquisition and text entry behavior outside the lab, the invention and validation of a simulation tool for motor-impaired performance, and the creation, validation, and deployment of a low-cost computer-based motor-ability assessment tool for use in a University of Washington assistive technology clinic.<br/><br/>Broader Impacts: This research will enable people with certain types of disabilities to enjoy more usable software matched to their abilities. It will also lead to a new design methodology predicated on a shift in focus from disability to ability, along with four downloadable software tools for improving laboratory, field, and clinical human motor performance evaluations. As an integral part of this research, the PI plans to organize an undergraduate summer workshop that brings informatics and computer science students together with computer users with disabilities to collectively brainstorm new access solutions. He will also develop an educational unit for middle and high school science classes that enables young students to experience simulated disabilities and learn about the roles of scientists and engineers in creating a barrier-free society."
"1217888","RI: Small: Goal-Driven Autonomy","IIS","ROBUST INTELLIGENCE","09/01/2012","06/20/2014","Hector Munoz-Avila","PA","Lehigh University","Standard Grant","James Donlon","08/31/2015","$263,870.00","","hem4@lehigh.edu","Alumni Building 27","Bethlehem","PA","180153005","6107583021","CSE","7495","7923","$0.00","Goal-driven autonomy (GDA) is a reflective model of reasoning about goals to control the focus of an agent's activities by dynamically resolving unexpected discrepancies in the world state, which frequently arise when solving tasks in complex environments. This project is motivated by two observations about GDA agents. First, to perform well, comprehensive GDA agents require substantial domain knowledge; however, few techniques have been investigated for learning this knowledge. Second, while existing GDA agents have demonstrated good performance in a variety of tasks, understanding and generalizing their successes has been hindered by a gap between the kinds of domains that these agents aim to model and the representations that they use; for instance, the bulk of current research on GDA agents assumes STRIPS representations of the agent's goals and actions. <br/><br/>This project aims to study GDA agents that are capable of learning expectations, explanations, and goals. This project aims to develop methods that enable creation of GDA agents that can autonomously act and learn to: (1) identify situations where discrepancies take place between what they expect and what actually has happened; (2) explain the discrepancy; (3) decide which goals to try to achieve as a result of these explanations; and (4) act to accomplish these goals. In this work, the objective of each agent is to maximize its expected return as defined in reinforcement learning. This approach fits naturally with the 4-step GDA cycle, facilitates studying properties about GDA using the well-defined reinforcement learning framework, and enables the adoption of representation formalisms such as stochastic policies (i.e., probability distributions of state-action pairs), which are naturally suited to represent GDA agent's actions in the domains that GDA agents aim to interact with. This project aims to develop representational methods that combine FOL (First Order Logic) literals and actions with probabilities as the basis to represent GDA elements.<br/><br/>The potential Broader Impact of this research is significant due to the potentially large and widespread applications of goal-driven autonomy. With the pervasive presence of autonomous computing devices and software, there is an increasingly pressing need for technology that enables systems to recognize discrepancies in what they expect from their 'worlds', diagnose them, and then adjust themselves. This is a ubiquitous problem in all areas of computer science. For example, in the general area of ambient intelligence, automated systems, such as an air quality control system, must monitor and control a variety of devices; it is very difficult, if not impossible, for a programmer to foresee all potential situations that such a system will encounter. Another example is cyber security where given the openness that characterizes current networks and the continuous integration of new technologies and services into them, it is not feasible to implement counter measures for all potential threats in advance; instead, an agent-based system must continuously monitor the overall network, learn and reason about expectations, and act autonomously when discrepancies are encountered. <br/><br/>This project includes a vigorous educational component. Specifically, it plans to (1) regularly involve undergraduate students in developing and testing carefully scoped components of the project; (2) create a course on adaptive and self-aware GDA agents that transcends traditional boundaries in courses on agents, reinforcement learning, and planning; and (3) create and disseminate testbeds for GDA agents that include not only the project's GDA agents but also simulations and agent-simulation interfaces. Creating and disseminating testbeds will help remediate the lack of systems and agent-simulation interfaces that has been a repeated stumbling block for teaching about GDA agents."
"1216007","CAREER: A Collaborative Adaptive Data Sharing Platform","IIS","INFO INTEGRATION & INFORMATICS","10/31/2011","06/20/2014","Evangelos Christidis","CA","University of California-Riverside","Continuing grant","Frank Olken","03/31/2015","$557,242.00","","evangelos.christidis@ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","7364","1045, 7364, 9251","$0.00","CAREER: A Collaborative Adaptive Data Sharing Platform<br/><br/>The increased popularity of domain social networking and blogs is creating a huge amount of shared data. Properly annotating this data would allow its effective searching and analysis. Consider as a specific motivating application a disaster mitigation collaboration network for businesses. Using keyword search to find open child care locations after a hurricane would require sifting through hundreds of shared documents. Current data sharing platforms provide little help to the users to effectively and effortlessly annotate their data in a way that will benefit the information demand of other users. The long term goal of this project is to leverage the collective knowledge of communities to increase the utility of shared information. The objective of this project is to create the knowledge and techniques to allow the users of an application domain to effectively and effortlessly annotate, share and query data, by exploiting the past user interactions -- i.e., data annotations, query workload and user query relevance feedback. A key novelty of the proposed Collaborative Adaptive Data Sharing Platform (CADS) is that the past user interactions are leveraged to effectively annotate the data at insertion-time. <br/><br/>The intellectual merit of this project is the facilitation of effective annotation, matching and querying of shared data by leveraging the user interactions at insertion and query time. The algorithms for the transformative concept of adaptive insertion form, which will suggest the best attributes, values and matchings to annotate the to-be-inserted data, will estimate the information value and confidence of a candidate annotation and dependencies analysis on the query workload. The adaptive query form algorithms which will guide the user in formulating effective queries, will exploit past user interactions to estimate the user?s affinity to a condition. All algorithms will be evaluated with real users and datasets.<br/><br/>This project is expected to have the following broader impacts: (a) Promote participation of FIU (one of the largest Hispanic institutes in the country) minority students in the research process. This is expected to attract more minority students to pursue MS or Ph.D. in computer science, which is hindered by the lack of exposure to academic opportunities. (b) Facilitate effective collaboration and information sharing among the members of communities -- e.g. disaster management, scientific, news."
"1110947","NetSE:Large: MONACO: Fundamentals of Molecular Nano-Communication Networks","CNS","RES IN NETWORKING TECH & SYS, ROBUST INTELLIGENCE, NETWORK SCIENCE & ENGINEERING, COMM & INFORMATION FOUNDATIONS","09/15/2011","06/20/2014","Ian Akyildiz","GA","Georgia Tech Research Corporation","Continuing grant","Darleen L. Fisher","08/31/2015","$3,000,000.00","Brian Hammer, Craig Forest, Raghupathy Sivakumar, Faramarz Fekri","ian@ee.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7363, 7495, 7794, 7797","7925","$0.00","Nanotechnologies are providing a new set of tools to the engineering community to design and manufacture devices in a scale ranging from one to a few hundred nanometers. At this scale, a nanomachine is defined as the most basic functional unit, which is able to perform only very simple tasks, such as computing, data storing, sensing and actuation. Nanonetworks, i.e., the interconnection of nanomachines in networks, will expand the capabilities of single nano-devices by providing them a way to cooperate and share information. Traditional communication technologies based on electromagnetic waves need to undergo a profound rethinking in order to meet the requirements of these networks. Moreover, there are specific applications of nanonetworks in which the utilization of electromagnetic waves is not feasible, such as in intra-body applications. Alternatively, molecular communication, i.e., the use of molecules to encode and transmit information among nanomachines, represents a radically new communication paradigm that demands novel solutions, including the identification of existing molecular communication mechanisms, the establishment of the foundations of molecular information theory, or the development of architectures and networking protocols for nanomachines. This project will address the above challenges to realize this new communication paradigm.<br/><br/>Intellectual Merit: This project seeks to develop a research area spanning across diverse fields, which include communication and information theory, computer science and biology. Specifically, this project will make contributions along four broad directions. First, the researchers will develop Theoretical Foundations of Molecular Nanonetworks, which include the definition and modeling of the attenuation, delay and noises affecting the emission, propagation, and reception processes in molecular communication. In addition, they will analyze the information capacity of nanonetworks first for a network with only two nodes and then for a network with N nodes, for which the effect of interference and collaborative communication will be taken into account. Second, the researchers will design Protocols for Molecular Nanonetworks based on the development of novel principles, primitives and services. Third, the researchers will implement a Simulation Tool for Molecular Nanonetworks in order to validate the information theoretical results as well as to evaluate the performance of the proposed protocols, by accounting for the interactions in the network molecule by molecule. Finally, the researchers will develop an Experimental Validation Platform for Molecular Nanonetworks by using a concrete testbed based on bacteria communication to verify the correctness of the information theoretical results and the protocols developed within the project.<br/><br/>Broader Impact: The project will pave the way for research in nanoscale communication. The outcomes of this work is expected to have a significant impact on research in nanotechnology, biology and information and communication technologies, since this project will represent the entrance of these three main communities to this converging field and will follow a realistic and integrated approach. The range of potential applications of nanonetworks is astonishingly wide, covering from intra-body networks for health monitoring, cancer detection or drug delivery, amongst others, to chemical attack prevention systems. The principal investigators teach a variety of classes in Georgia Tech spanning information theory, network algorithms, communication protocols and biology. They will immediately incorporate output from the proposed research into their classes. The team will develop an open source simulation tool to test the solutions developed and the tool will be made available for public use. This tool will represent the first simulation tool for molecular nanonetworks and will also be used in class projects as an educational tool to provide insights and deep understanding of nanosensor/actuator networks. Scientific results will be disseminated at international conferences, journals and magazines in the field."
"0968529","SoCS: Explorations on the Effects of Pervasive Networking on Social Relationships and Resource Planning","IIS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","08/01/2010","05/23/2013","Aaron Striegel","IN","University of Notre Dame","Standard Grant","William Bainbridge","07/31/2015","$802,325.00","Omar Lizardo, David Hachen, Christian Poellabauer","striegel@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","1640, 1714, 7367, 7953","7367, 7953, 9251, 9215","$0.00","With the advent of powerful wireless devices over the last several years, the delineation between activities typically reserved for the home computer and the mobile device has blurred considerably. The new opportunities for ""always on"" access have significant sociological impacts with respect to communication between individuals and the communities that they form. The new network access inspires a set of related fascinating research questions. What effect does pervasive, wireless network access have on the social interactions of young adults, in particular college-aged students? Conversely, what impact would a better understanding of these social interactions have on the underlying wireless and wired networks? What is the relationship between the two systems, i.e., does the wireless network truly drive social interactions <br/>or do social interactions drive demand on the wireless network? <br/><br/>The intellectual merit of the proposal will be to gather high quality, long-term social network and behavioral data and then to analyze the data from sociological and technical perspectives. The work will provide two hundred and fifty smart phones to a diverse cohort of first-year University of Notre Dame undergraduate students. The infrastructure will build on lessons from previous efforts at MIT to create a second-generation system for the purpose of tracking the social ties, communication patterns, and behaviors of the cohort over two years. The broader impact of the work will include inter-disciplinary contributions for both computer science and sociology. The work will make available a tremendous body of anonymized data to improve both social and network performance research."
"0917318","RI: Small: Learning Biped Locomotion","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","09/01/2009","06/20/2014","Stefan Schaal","CA","University of Southern California","Standard Grant","Jeffrey Trinkle","08/31/2015","$475,000.00","","sschaal@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7298, 7495","5936, 5979, 7495, 7923, 9215, HPCC","$0.00","In a not too distant future, assistive robots will become a natural part of the human society, in hospitals, schools, elder care facilities, inner city urban areas, and eventually homes. While wheeled robots, e.g., a humanoid torso on a mobile platform, can cover a range of tasks that assistive robots will be needed for, eventually, legged robots will be the most suitable, as legs increase the effective workspace of a robot and allow maneuvering more complex terrains like steps, curbs, and cluttered and rough terrains in general.<br/>This project investigates biped locomotion with a Sarcos humanoid robot. In contrast to most other projects in biped locomotion, it emphasizes walking over uneven and rough terrain, obstacle avoidance, recovery from unexpected perturbation, and learning methods for motor control, as these issues seem to be the most important for working in dynamic and partially unpredictable human environments. Another focus is on dexterous movement control, i.e., control with a maximal amount of compliance and minimal negative feedback gains, using advanced operational space controllers with internal model control. Dexterous, compliant control will increase safety of the robot when accidentally impacting with humans or obstacles, and it will also allow the robot to recover more easily from external perturbation simply by ?giving in?. Such a control approach requires departing from the traditional high-gain position controlled humanoid systems, and focuses on torque control, reactive instantaneous control instead of finite horizon optimization, as well as efficient motion planning and learning methods."
"0964075","HCC: Medium: Collaborative Research: Surface Haptics via Tractive Forces","IIS","Cyber-Human Systems","07/01/2010","06/20/2014","J. Edward Colgate","IL","Northwestern University","Continuing grant","Ephraim P. Glinert","06/30/2015","$995,100.00","Michael Peshkin","colgate@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7924, 9215, 9251, HPCC","$0.00","Surface Haptics, or the creation of virtual haptic effects on physical surfaces, is a topic of rapidly growing importance in human?]computer interaction because of the increasingly widespread use of touch screens. Touch is at once an elegant and maddening interface modality. It is elegant in its simplicity: one can make a selection or tap a button or key with no intervening mouse or joystick. Moreover, touch (especially multi?]finger touch) supports gestures, such as swiping and expanding, which are satisfyingly natural. It is maddening, however, due to the lack of tactile and kinesthetic feedback that are so critical to natural touch. Typing on a virtual keyboard, for instance, is typically an experience of visually guided hunt?]and?]peck with liberal use of the back?]space key.<br/><br/>In this research the PIs will further develop a new class of surface haptic devices, called xPaDs, that promise to enrich the use of touch screen and touchpad interfaces for sighted as well as blind users. xPaDs are notable because they provide controllable shear forces between the fingertips and an ordinary sheet of glass. By controlling shear force in response to a measure of fingertip position (which may be obtained using a variety of existing technologies), it is possible to simulate a huge array of virtual effects; examples include toggle switches that flip from one state to another (each state is a ""potential well"" on the glass surface that pulls the finger to a given location), and contours that can be easily traced.<br/><br/>The heart of the current project lies in the systems engineering that will lead to practical and effective devices capable of controlling a force at one or more fingertips, and in the psychophysical and application?]based studies that will teach us how these capabilities may best be used. xPaDs are sophisticated dynamic systems that employ ultrasonic vibrations to modulate friction synchronized with in?]plane vibrations to produce controllable force vectors. The PIs will address the challenges of controlling force individually at each fingertip, of producing xPaDs with large surface area, and of minimizing energy consumption and audible noise generation. They will use the idea and methodology of ""pop?]out"" experiments to find haptic primitives, that is to say features the human perceptual system can extract with minimal or no perceptual load. The PIs will measure the information transmission capacity of surface haptic devices treated as symbolic channels. And they will explore the ability of the perceptual system to ""bind"" surface haptic features presented to different fingertips into a meaningful, coherent whole. These studies will position the PIs for investigating a set of applications for the blind.<br/><br/>Broader Impacts: Computer interfaces for the blind often rely heavily on speech, which necessarily presents information serially. The PIs argue that a haptic surface can augment a speech?]based interface with critical spatial information. They will study the editing and reading of mathematical expressions, of locating key content on a web page, of navigating intersections, and of planning routes with tools such as Google Maps. In addition, the PIs will develop a low?]cost xPaD development kit, make the plans and code available on the Internet, and develop a high school enrichment unit based upon these materials."
"1217968","III: Small: Collaborative Proposal: Towards Robust Uncertain Data Management","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","06/20/2014","Lisa Hellerstein","NY","New York University","Continuing grant","Frank Olken","09/30/2015","$265,836.00","","lisa.hellerstein@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7364","7364, 7923, 9251","$0.00","The goal of this project is to develop a systematic framework to enable ""robust"" query processing in presence of data uncertainties that arise naturally in a wide variety of application domains. Data uncertainties may take the form of missing or incomplete data, inherent noise in the data, trust or reputation scores assigned to data based on their sources of origin, or confidences in predictions made using automated modeling tools. The input uncertainties naturally lead to uncertainties in the results of any queries or analyses performed on such data. To enable robust and systematic reasoning over such uncertain query results, efficient algorithms and practical tools are developed to: (a) identify the input uncertainties to which query results are most sensitive, (b) decide how to use scarce resources like subject matter experts to resolve uncertainties in query results, and (c) incorporate user feedback to improve the robustness of the input uncertainty parameters themselves. The tools have the potential to make it easy and intuitive to process and analyze uncertain data and extract useful information from it in a wide range of real-world application domains including social media analysis, scientific and biological data management, sensor data management, web data integration, and information extraction. This project provides research opportunities for graduate and undergraduate students, and is aligned with several advanced graduate courses offered by the PIs. The prototype implementation of the framework, publications, and experimental data, will be disseminated via the project web site: http://www.cs.umd.edu/~amol/RPrDB."
"1253935","CAREER: Next Generation Patient Simulators","IIS","Cyber-Human Systems","02/01/2013","05/09/2014","Laurel Riek","IN","University of Notre Dame","Continuing grant","Ephraim P. Glinert","01/31/2018","$268,993.00","","lriek@cse.nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","7367","1045, 7367, 9251","$0.00","It is estimated that in the United States many thousands of people are killed each year and billions of dollars lost due to medical errors. The PI argues that one way to reduce the incidence of such errors is through education involving human patient simulator (HPS) systems. Although perhaps the most commonly used android robots in America, a critical technology gap is that none of the commercially available HPS systems exhibit realistic facial expressions, gaze, or mouth movements, despite the vital importance of these cues in how providers assess and treat patients. The PI's goal in this project is to address this shortcoming by developing novel expression synthesis algorithms and social control methods, thereby advancing the fields of affective computing and human-robot interaction. To these ends the PI will model facial features characteristic of 3 pathologies (stroke, cerebral palsy and dystonia, the latter being a neurological disorder in which the muscles of the trunk, shoulders, and neck go into spasm so that the head and limbs are held in unnatural positions), and 2 affective states (pain and drowsiness). She will synthesize these facial features on a new HPS system and create a model of shared social control for operators of expressive robots, and evaluate their impact on educational and task outcomes. <br/><br/>Broader Impacts: This research will transform the state of the art in HPS technology by enabling educators to run simulations currently impossible with commercially available technology, thereby leading to more realistic training experiences for doctors, nurses, and combat medics, which will ultimately improve healthcare. It will create new facial models of stroke, dystonia and cerebral palsy, which may impact fields such as computer vision and biometrics while also enhancing our understanding of these disorders and providing a means for educating people how to better interact with those suffering from these disabilities and/or to quickly recognize signs of stroke. The PI will also conduct substantial mentoring activities for undergraduates and outreach activities for K-12 students."
"1117153","III: Small: Network Learning for Integrative Cancer Genomics","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","06/18/2013","Rui Kuang","MN","University of Minnesota-Twin Cities","Standard Grant","Sylvia J. Spengler","08/31/2015","$500,000.00","","kuan0009@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","7923","$0.00","New large-scale DNA sequencing and array technologies now provide a promising way to study the molecular mechanisms of cancer by generating enormous information measuring aberrations in cancer genome. The genomic information can potentially guide drug design on targeted molecules, and improve clinical decisions in cancer treatment. One of the main obstacles to further progress is to elucidate multiple complex molecular indicators of cancers from the enormous genomic data. This proposal tackles the problem with network-based machine-learning theoretical frameworks and methods that can model the underlying biological mechanisms for an integrative study of cancer genomic information and relevant biomedical knowledge. As a proof of concept, the developed methods will be applied to study chemoresistance in ovarian cancer treatment. <br/><br/>This proposal aims at creating a general computation-driven approach for guiding cancer genomics research and improving genomics-based clinical decisions in cancer treatment. The research activities described in the proposal will deliver a collection of effective and efficient computational tools to utilize heterogeneous genomic data combined with biomedical knowledge for clinical practices. The study of the ovarian cancer data will help reveal the crucial pathways driving chemoresistance, and provide useful prediction tools and drug targets for ovarian cancer treatment. This proposal will also integrate the latest research development in computational cancer genomics into new courses in several training programs to prepare students for their future professions to meet the need of workforce in the growing biomedical and health informatics industry in the upper midwest region. The education plan will also have a focus on recruiting students in minority and under-represented groups in computer science and information technology.<br/><br/>To achieve the goals, the components of the research plan are 1) to formulate graph kernels and subgraph mining algorithms that can integrate various types of cancer genome aberrations to improve cancer outcome predictions and to discover cancer-causative genome aberration patterns; 2) to formulate semi-supervised matrix factorization methods with Laplacian constraints for predicting novel cancer phenotype and gene associations for identifying potential drug targets, utilizing known relations in phenotype, gene and their association networks; 3) to study the chemoresistance in ovarian cancer treatment to reveal the crucial pathways driving the resistance, and develop useful prediction tools and drug targets for ovarian cancer treatment; 4) to release the developed methods in both software packages and webtools for public use in academia. The two major components of the education plan are: 1) to offer a two-week course, titled Cure Cancer with Computers, in the summer academy of the BioSMART program for Minnesota high school students, and 2) to create a new course Computational Genomics in Biomedical Informatics to support two graduate programs for training students in biomedical/health informatics with knowledge in genomics and computer science."
"1341309","Doctoral Consortium and Student Travel Support for 2013 ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL 2013)","IIS","INFO INTEGRATION & INFORMATICS","06/15/2013","06/19/2014","John Downie","IL","University of Illinois at Urbana-Champaign","Standard Grant","Maria Zemankova","05/31/2015","$18,972.00","","jdownie@uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364","7364, 7556","$0.00","This award supports travel stipends for students to participate in Doctoral Consortium (July 22, 2013) and in the 2013 ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL 2013), to be held in Indianapolis, Indiana, June 23-25, 2013 (http://www.jcdl2013.org). The selected PhD students are in the early stages of their dissertation work and several international students are included in order to provide breadth in exchanging ideas. The goal of the consortium is to help students develop their dissertation proposals and research plans through feedback and guidance from prominent researchers and experienced practitioners from the field of digital library research and development. The JCDL Doctoral Consortium provides a forum for Ph.D. students to interact with major leaders in the digital library community. These international leaders exemplify a broad set of expertise, diversity of perspectives, and wealth of knowledge. The consortium provides students with an opportunity to have broad audience and interact intellectually with professionals who would otherwise be difficult to meet with. Participating students will be selected on the basis of a paper describing their research. At the consortium, participants will have approximately 40 minutes to present their research plans and receive feedback from the panel. After the consortium the students will revise their papers based on the consortium's feedback and then they will be published in the IEEE Technical Committee on Digital Libraries publication ""TCDL Bulletin"" (http://www.ieee-tcdl.org/mediawiki/TCDL/index.php/IEEE-TCDL).<br/><br/>Participation in JCDL 2013 Doctoral Consortium and conference will expose the selected students as well as other attending students to a larger community, extend their opportunities for intellectual engagement, and encourage scholarly discourse and networking among new entrants into the field. The goal is to help shape ongoing and future teaching, research, and development projects in the field of digital libraries by providing wider exposure for the students to innovative ideas which may generate new research questions in the future, and to foster a sense of community among these young researchers at a critical stage in their professional development. The organizers will also take special steps to solicit participation from institutions with underrepresented groups to extend the potential benefits and broaden the horizon of expertise in the field."
"1302422","HCC: Medium: Collaborative Research: Force Feedback for Fingertips","IIS","Cyber-Human Systems","06/01/2013","06/20/2014","J. Edward Colgate","IL","Northwestern University","Continuing grant","Ephraim P. Glinert","05/31/2016","$508,000.00","Michael Peshkin","colgate@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7924, 9251","$0.00","Surface haptics is the creation of programmable haptic effects on physical surfaces such as touch screens and touch pads. Unlike traditional force feedback devices that require the operator to grasp an end effector, surface haptic devices must provide feedback directly to the fingertips. With the dramatic rise of touch screen interfaces in recent years, many approaches to surface haptics have been explored, including vibrotactile, shape morphing, and variable friction. The PI and his team have pioneered an approach in which the surface generates controlled shear forces on each fingertip. Force Feedback for Fingertips (F3), gives fingertips the opportunity to interact with physics-based virtual environments, much like force feedback devices enable the whole hand to do. With F3, fingers can interact with virtual objects that have mass, stiffness and damping as well as more complicated dynamics (e.g., collisions, mechanisms, and force fields). By coordinating haptic effects at multiple fingertips, even more compelling illusions can be generated.<br/><br/>The technology, underlying science, and application of F3 are, however, still in their infancy. F3 works by coupling lateral vibrations to some form of rectification. For example, one approach involves high-frequency lateral vibrations of the surface synchronized with a friction reduction effect, resulting in a slip-push transition at each oscillation. The friction is modulated by means of electrostatic forces or acoustical stimulation. Current approaches work at ultrasonic frequencies, but little is known about the mechanical or electrical behavior of fingertips at these frequencies, or how energy transfer from a surface to the finger can be optimized.<br/><br/>This research will produce new knowledge in three main areas: the physical underpinnings of F3, device design and interaction design. First, both tribological and acoustic measurements will be made to elucidate the mechanisms by which shear forces are generated. A high-bandwidth tribometer and optical imaging system will allow friction to be studied, and a custom-built exciter will allow the propagation of acoustic energy in the fingertip to be studied. Laser Doppler vibrometry will be used to measure surface wave propagation while magnetic resonance elastography will be used to study shear wave propagation within the subcutaneous tissues. Fractional calculus and finite element techniques will then be used to build biologically plausible models of fingertip tribology and mechanics that match the data. Second, a new generation of high-performance F3 devices will be developed. Armed with good models, it will be possible to design impedance-matched devices so that force production is maximized and energy wastage is minimized. Additionally, these new devices will provide control over the force vector at each of multiple fingertip locations. Thirdly, novel multi-finger interactions will be designed. The key idea is that sophisticated percepts, such as ""objects"" that can be grasped and that feel as though they are moving relative to the surface, can emerge from properly coordinated fingertip forces due to Gestalt-like grouping principles.<br/><br/>Broader Impacts: Historically, the PI and his team have had greatest impact when providing technology to and collaborating with colleagues in human-computer interaction. Inspired by this, an open source F3 kit will be developed and shared. In addition, undergraduate and high school students will participate in the research, developing software routines and sample applications for the open source kit. Finally, the kit will be integrated with two pedagogical innovations already implemented by the investigators: flipped classrooms and portable laboratories."
"1350364","EAGER: TEACHER: A Pilot Study on Mining the Web for Customized Curriculum Planning","IIS","INFO INTEGRATION & INFORMATICS, REAL, DISCOVERY RESEARCH K-12","09/15/2013","05/21/2014","Jaime Carbonell","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","08/31/2015","$265,635.00","Yiming Yang","jgc@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, 7625, 7645","7364, 7625, 7645, 7916, 9251","$0.00","With massive quantities of educational materials freely available on the web, the vision of personalized and readily accessible education appears within our grasp. General-purpose search engines are insufficient as they do not focus on educational materials, objectives, pre-requisite relations, etc., nor do they stitch together multiple sources to create customized curricula for students' goals and current knowledge. This exploratory project focuses on establishing fundamental results in: (1) extracting educational units from diverse web sites and representing them in a large directed graph, whose nodes are content descriptors and whose edges encode pre-requisite and other relations; (2) conducting multi-field topic inference via a new family of graphical models to infer relations among educational units; and (3) automated curricular planning, focusing on providing sequences of lessons, courses, exercises and other education units for a student to achieve his or her educational goals, conditioned on current skills. The objective is to develop a data-driven course/curriculum planner on demand, based on a graph traversal that is enriched with alternate paths, reinforcement options, and conditional branches to match the learner's needs.<br/><br/>The broader impact of this research is two-fold: (1) developing methods for mining and traversing web-based educational materials in general, later generalizing to multi-media lessons and courses; and (2) individualized curricular planning, so any student anywhere can be provided with guidance on how to navigate and exploit the vast ocean of massive open online course (MOOC) materials and other educational texts, exercises, etc. in a manner customized to the student's learning objective, capabilities and skills. The resulting system, named TEACHER, can be applied to learning specific job skills, to reinforce classroom instructions, or as stand-alone academic support to address, for instance, the huge percentage of students who attempt taking MOOCs but never complete them due to lack of requisite skills and lack of guidance on how to acquire them. Project web site (http://nyc.lti.cs.cmu.edu/teacher/) will be used to disseminate results."
"0952623","CAREER: Healthy Families: Technology to Support the Health and Wellness of Young Children","IIS","Cyber-Human Systems","07/01/2010","06/19/2014","Julie Kientz","WA","University of Washington","Continuing grant","Ephraim P. Glinert","06/30/2015","$497,182.00","","jkientz@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","1045, 1187, 9215, HPCC","$0.00","This project focuses on the design, development, and evaluation of the effectiveness of computing interventions to assist parents in ensuring the healthy development of their child. As young children undergo rapid development and learn skills that will influence their entire lives, regular visits to a pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. The PI will use a comprehensive human-centered approach to explore and understand the tensions and opportunities for technology to support the health of young children while involving parents and professionals across diverse and underserved populations. The PI will seek to create feasible and effective technologies that motivate and encourage record-keeping by parents. Both qualitative and quantitative research methods will be employed to validate technology designs using a long-term study lasting 18 months in collaboration with Seattle Children's Health and Seattle King-County Public Health. Research outcomes will include: Discovery of design requirements for technologies to support the health of young children, especially for families from diverse and underserved populations; A suite of three new technologies based on the design requirements that leverage mobile and social computing technologies for assisting parents of young children with tracking their child's health information and learning about children's health; Validation of computing technology as a viable means of supporting parent record-keeping, of increasing parent knowledge and confidence in their child's developmental progress, and improving parent-pediatrician communication. <br/><br/>Broader Impacts: This research involves conducting formative studies that further our knowledge of how health technology can be designed for underserved populations so as to minimize anxiety and support the doctor-patient relationship. Thus, the project will address a major public health goal of more closely tracking the health and development of young children, especially those from lower income backgrounds and those with developmental delay. The findings will have implications for domains beyond early childhood development. Project outcomes will expand our knowledge about how mobile and social computing applications can be developed and adapted based on the financial and time constraints of the users. Finally, this work will help refine techniques for evaluating technology applications designed for behavior change and long term outcomes, which in turn will advance the field of Human-Computer Interaction in general."
"0845643","CAREER: Architecting A Database Management System for Semantic Web Data","IIS","INFO INTEGRATION & INFORMATICS","02/15/2009","01/30/2013","Daniel Abadi","CT","Yale University","Continuing grant","Frank Olken","08/31/2014","$400,000.00","","daniel.abadi@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7364","1045, 1187, 7364, 9216, HPCC","$0.00","The goal of the Semantic Web is to free Web data from the applications that control them, so that data can be easily described and exchanged. <br/>This is accomplished by supplementing natural language and other data found on the Web with machine readable metadata in statement form (e.g., X is-a person, X has-name Joe, X has-age 35) and enabling descriptions of data ontologies so that data from different applications can be integrated through ontology mapping. One element of this vision is to turn the Web into a giant database, against which one can issue structured queries and receive structured answers in response.<br/><br/>The SW-Store project is undertaking the clean-slate design of a DBMS specifically architected for this type of Web metadata and the prevalent Semantic Web data model, the Resource Description Framework, or RDF. The management of Semantic Web data presents many difficult challenges. The size of the data is growing rapidly, and in theory could reach the scale of the Web. The types of queries vary greatly in complexity, ranging from keyword search to complicated parameterized subgraph matching. Data integration, inference, and reasoning must be primitive operations that can operate at scale without human intervention. A data management system must not only be a place where data is stored and from which data is accessed; it must use the machine-readable semantics of the data to develop higher level models and help guide a user through the mass of information. In sum, a data management system for the Semantic Web will look very different from a standard, transactional, relational database system.<br/><br/>The SW-store project researches the architecture of such a system. This research is inherently interdisciplinary, bringing in ideas from the data management, Semantic Web, and artificial intelligence communities. The project involves experimenting with partitioning schemes, where data is allocated to different nodes on a shared-nothing cluster so that queries can be run in parallel across multiple machines. It also involves exploring how ontology reasoning can be integrated inside the database system so that it can benefit from the near limitless scalability a shared-nothing cluster can offer. SW-Store further investigates providing iterative query interfaces and integrating complex queries with text search. Finally, the project involves studying the design of the storage layer for a Semantic Web data management system, looking at how data should be laid out, updates should be performed, and what materialized views to create.<br/><br/>Further information about the project can be found at the project Webpage: <br/>http://db.cs.yale.edu/swstore/"
"1009916","III: Large: Collaborative Research: Web Archive Cooperative","IIS","INFO INTEGRATION & INFORMATICS","08/01/2010","08/04/2010","Hector Garcia-Molina","CA","Stanford University","Standard Grant","Sylvia J. Spengler","07/31/2015","$2,350,507.00","","hector@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7364","7925","$0.00","Web Science is an emerging discipline that studies the Web: how human activity is shaped by Web interactions, how the Web can benefit society, and how Web technologies can be improved. Central to Web Science is access to data that records the history of the Web, as well as data that records human activity (e.g., posed queries, tagged pages, Twitter updates). It is currently very difficult for academic researchers to obtain such Web data because it is hard to locate, it is fragmented across diverse sites, and is recorded using inconsistent formats and strategies. This project will build a Web Archive Cooperative (WAC) that will integrate existing archives (repositories of Web data), making it feasible to access large volumes of data in a simplified fashion. The WAC will be a virtual service, providing search facilities and access mechanisms to existing resources. These resources will not just be Web pages, but all types of available Web information, such as query logs, tag annotations, blogs, profiles and Twitter updates. Furthermore, resources will also include the software tools for building and managing Web archives.<br/><br/>The project will explore three goals for a resource discovery service: (1) the manual or automated discovery of entire existing Web related archives; (2) the selection among known archives of the ones that support a specific research question; and (3) the identification of individual resources from within the selected archives. Tools for characterizing discovered archives, especially for the case where the archive does not provide rich descriptive metadata, will also be developed. Characterization of an archive includes elements such as an estimate of the archive's coverage, particulars of the crawling parameters, like dates/frequencies, crawl duration, depth, per-site ceiling on the number of collected pages, content statistics, and link structure. Mechanisms for integrating diverse archives will be developed, and the mechanisms will be applied to site reconstruction (from various archives) and archive views (a logical fusion of resources from multiple sources). Since integration issues are so challenging, an experimental testbed will be set up with small but diverse resources. The testbed will contain several crawls of the same target sites, each obtained with different crawlers and using different parameters. The testbed will also contain related resources. Storage trading schemes will be developed, allowing members to trade local backup space for remote space. A Web archive replication tool will be developed based on existing notions for self-preserving objects. Alternatives for replica synchronization will be studied.<br/><br/>Workshops to bring together key Web Science researchers will be organized to discuss available resources and impediments to sharing. These workshops will drive research and identify needed tools and protocols. With small groups of participants, challenge problems will be established, e.g., combining a set of Web archives. Reports of these results at future workshops can incentivize others to participate in the WAC. In addition, an Advisory Board of industrial, government, and academic experts has been set up to guide the project. A Summer Institute for Web Science graduate students will be held. At this Institute, students will learn to use the latest tools and will learn from each other's experiences in dealing with Web data. In addition, a one-day workshop will be developed, to be offered at Web Science conferences (WWW, SIGIR, etc.) to educate participants about WAC resources. An undergraduate Web Sciences track for computer science majors will be set up, taking advantage of WAC resources. The project will have impact in two ways. First, it will provide tools and services that facilitate access to Web resources. Any researcher, from a computer scientist studying efficient Web search, to a social scientist studying how human beliefs are changing today, to a historian studying how the early Web evolved, to a biologist understanding how disease spreads, will benefit from the work. Second, the project motivates students and young researchers to stay in academia. Currently top talent is flowing to industry because only they have comprehensive Web data, and it is so hard to do significant Web Science at universities. The WAC can provide an alternative, attracting more researchers and teachers to this important area."
"1017718","III: Small: Collaborative Research: Canonical Dependence Analysis for Multi-modal Data Fusion and Source Separation","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","08/07/2010","Tulay Adali","MD","University of Maryland Baltimore County","Standard Grant","Sylvia J. Spengler","07/31/2015","$249,949.00","","adali@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7364","7923","$0.00","Analysis of multiple sets of data, either of the same type as in multi-subject data, or of different type as in multi-modality data, is inherent to many problems in computer science and engineering. Biomedical image analysis figures prominently among these and is particularly challenging because of the rich nature of the data made available by different imaging modalities. Data-driven methods are particularly attractive for the analysis and fusion of such data as they can achieve useful decompositions while minimizing assumptions on the model and underlying processes, and can also incorporate reliable prior information when available. One such approach recently introduced for medical image analysis and fusion is multi-dataset canonical correlation analysis (MCCA) that has proven especially useful for the analysis and fusion of rather disparate data, owing to its high flexibility and extendibility to a wide array of problem settings.<br/><br/>Intellectual Merit: In this proposal, the main aim is twofold. First, a number of powerful methods are developed for multi-subject (multi-set) data analysis and multi-modal data fusion based on canonical dependence analysis by significantly extending the power and flexibility of MCCA. Then, the successful application of the methods are demonstrated on a unique problem that demands these properties, namely the study of brain function and functional associations during simulated driving, a naturalistic task where data-driven methods have proven very useful. The data used in the project are complementary in nature but of very different nature: functional magnetic resonance imaging (fMRI), electroencephalography (EEG), structural MRI (sMRI), genetic array data--single nucleotide polymorphism (SNP)--and behavioral variables. The rich characteristics of the data and the problem at hand thus provide a special challenge for the methods developed and a unique testbed for the evaluation of their performance.<br/><br/>Broader Impacts: The broad impact of the proposed work lies in its potential to substantially impact science and information technology as well as in its educational features. Analysis of multiple datasets of the same type as well as fusion of data from different modalities/sensors is a key problem in many science and engineering disciplines. The new set of methods proposed thus form attractive solutions for many other problems beyond brain function analysis. The fully integrative nature of the proposed work is also an invaluable asset in the ongoing efforts in cross-training of students and researchers as well as increasing the participation of underrepresented groups in science and technology careers.<br/><br/>For further information, see the project web site at the URL:<br/> http://mlsp.umbc.edu/research_projects.html"
"1139078","Collaborative Research: Socially Assistive Robots","IIS","ROBUST INTELLIGENCE","04/01/2012","04/04/2014","Brian Scassellati","CT","Yale University","Continuing grant","Ephraim P. Glinert","03/31/2017","$2,150,000.00","Fred Volkmar, Frederick Shic, Rhea Paul, Aaron Dollar, John Morrell","brian.scassellati@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7495","7723","$0.00","Socially Assistive Robots<br/>Lead PI/Institution: Brian Scassellati, Yale University<br/>This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits. The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians. For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone. In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population. This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does. <br/>To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year. <br/>This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.<br/>For more information visit www.yale.edu/SAR"
"1117801","HCC: Small: Manipulating Perceptions of Robot Agency","IIS","Cyber-Human Systems","09/01/2011","08/05/2011","Brian Scassellati","CT","Yale University","Standard Grant","Ephraim P. Glinert","08/31/2014","$500,000.00","","brian.scassellati@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7367","7923, 7367","$0.00","Robots are increasingly becoming a part of daily human interactions: They vacuum floors, deliver medicine in hospitals, and provide company for elderly and disabled individuals. This project examines one aspect of people's interactions with these robots: how intentional and self-reflective the robot seems to be. Because the perceived agency of a robot affects many dimensions of people's interactions with that robot, it is important to understand how features of robot design, such as its behavior and cognitive abilities, affect perceptions of agency. This question is addressed through a series of laboratory experiments that manipulate behavior and cognitive abilities and measure the degree of agency attributed to socially interactive robots.<br/><br/>Intellectual merit: The project will lead to new measures of perceived robot agency and new knowledge about how people collaborate with robots. The results will inform how engineers construct robots, how artificial intelligence researchers conceptualize behavioral architectures, and how designers craft interactions to produce robots that engage people in simple ways.<br/><br/>Broader impacts: The project will provide a new quantitative measurement of agency that can be used in human-robot interaction and related disciplines and new information that can inform how agency is modeled in the design of human-robot interactions, especially in situations where recognition of agency is a primary factor. The outcomes will be used to improve socially assistive robotics for children with social deficits. The project will also enhance interdisciplinary research offerings for graduate and undergraduate students at the investigators' institution."
"1421391","RI: Small: When Algorithms Trade: Dynamics, Limits, and Economic Implications","IIS","ROBUST INTELLIGENCE","07/01/2014","06/18/2014","Michael Wellman","MI","University of Michigan Ann Arbor","Standard Grant","James Donlon","06/30/2017","$500,000.00","Jacob Abernethy","wellman@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7495, 7923","$0.00","Recent years have seen a dramatic increase in algorithmic trading, to the point that the majority of orders in major equity exchanges today are generated by machines without direct human control. Experience has shown that this automation--particularly at the extremes of high-frequency trading (HFT)--makes a qualitative difference, due to the unprecedented speed and lack of direct human control. The emergence of HFT raises fundamental issues for the efficiency, fairness, and stability of financial markets. The practice is highly controversial, yet the lack of scientific understanding of HFT's implications impedes informed public debate bearing on the question. <br/><br/>Algorithmic trading can also be viewed as herald of a wave of automated behavior with far-reaching effects in a plethora of domains. Methodological improvements from this project advance our ability to anticipate effects of autonomous agents in other areas of major economic and societal impact.<br/><br/>This project conducts a systematic computational study of algorithmic trading. The investigation combines online learning and optimization techniques from the point of view of theoretical machine learning and agent-based modeling (ABM) approaches to develop models of financial trading substantially more comprehensive and robust than heretofore possible. Modeling financial markets as multiagent systems affords heterogeneity: traders differing in objectives, information (access to data and observability of the environment), and response capability (processing and execution speed). Learning and decision-theoretic methods provide a principled basis for defining adaptive strategies that are effective across a broad range of operating conditions and possess guarantees in adversarial environments. Evidence on algorithmic trading implications is derived through systematic computational experimentation.<br/><br/>The project contributes both to scientific knowledge about algorithmic trading, and to agent-based methodology for analyzing complex strategic domains. One particularly novel feature of this study is its emphasis on the effect of temporal structure (e.g., communication latency patterns, adaptive strategies) on the dynamics of algorithm interaction. The agent-based methodology developed here provides a unifying framework for selecting among candidate behaviors based on specified solution concepts, such as game-theoretic or evolutionary equilibria. It exploits ideas from several fields, including simulation modeling, stochastic search, statistical analysis, and machine learning."
"1320519","RI: Small: Mechanics, Manipulation, and Perception of Deformable Objects for Robotic Manufacturing","IIS","ROBUST INTELLIGENCE","08/15/2013","06/18/2014","Timothy Bretl","IL","University of Illinois at Urbana-Champaign","Continuing grant","Satyandra Gupta","07/31/2016","$296,380.00","","tbretl@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","7495, 7923","$0.00","The project is motivated by the need of small-to-medium sized businesses in the United States to automate handling and assembly of compliant parts. As a case study, it focuses on robotic installation of a wire harness (a bundle of wires that terminate in electrical connectors). This manufacturing task is ubiquitous but hard to automate because it requires reasoning about deformation of the wire harness. The project is addressing this challenge with new algorithms for manipulation and perception of deformable objects that are based on novel representations of object shape. It considers first the manipulation of a single wire (one piece of a wire harness). It expresses the shape of this wire as the solution to a geometric optimal control problem, and shows that the set of all solutions to this problem is a smooth manifold that can be parameterized by a single coordinate chart. This result leads to an algorithm for manipulation planning that works well and is easy to implement. Objectives include extending this model to consider variable stiffness, plastic deformation, and branching; making manipulation plans robust to perturbation; estimating material properties and shape from sensor data; and experimentally demonstrating robotic installation of a wire harness. Outreach efforts include co-directing a week-long summer institute for high school students, mentoring undergraduate researchers, and organizing an industrial forum."
"1064412","G&V: Medium: Collaborative Research: A Unified Approach to Material Appearance Modeling","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","06/01/2011","06/06/2014","Holly Rushmeier","CT","Yale University","Continuing grant","Ephraim P. Glinert","05/31/2015","$406,000.00","","rushmeier@cs.yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7367, 7453","7453, 9251, 7924","$0.00","Realistic image synthesis techniques from computer graphics enable the use of simulation in a wide variety of important fields including architecture, industrial design and communication, military, medical, and emergency training, cultural heritage preservation, film production, and gaming. Realistic modeling of material appearance is an essential component of the image synthesis process. Current approaches to material modeling include analytical modeling, numerical simulation, and image-based capture. Each approach has distinct advantages and limitations, and different ranges of applicability. The lack of unity makes material modeling difficult and has limited the useful application of computer graphics image synthesis. This transformative research will change the way materials are modeled in computer graphics systems. Rather than using disparate models as at present, this project will unify these approaches into a common physical and perceptual framework that will serve as the basis for a rich set of tools for material modeling that are physically accurate, phenomenologically expressive, computationally efficient, and easy to use. This work should enable the use of computer-aided material design methods in a wide range of economically and culturally important applications. Creating this framework will involve three subprojects.<br/><br/>Development of a material simulation testbed: In this subproject a suite of tools for material simulation will be developed that includes both Monte Carlo and deterministic algorithms. Different classes of materials (paints, metals, textiles) will be modeled, and different numerical methods will be tested and compared. The resulting simulation tools and a database of the simulated materials will be distributed.<br/><br/>Unification of analytical, simulation, and image-based capture material modeling methods: In this subproject the analytical models that represent general classes of materials will be unified with simulation and image-based capture data that represent specific material instances. In the first part of this subproject simulation and capture data will be fit with a range of analytical models, considering both individual materials and ""families"" of materials generated by progressively changing the parameters of the simulation models. In the second part of this project methods for inferring the microstructures of materials measured using image-based capture methods will be developed. The approach will be to identify the class of a material and then vary the parameters of an appropriate simulation model to best reproduce the captured data. The results of this subproject will be expressive and efficient analytical material models that are physically grounded because they are based on captured data and rigorous simulations.<br/><br/>Development of perceptually-based material design tools: An important criterion for material modeling is usability. Material designers need to be able to easily specify and visualize material appearance properties. This requires consideration of the human factors in material modeling. In this subproject a series of psychophysical experiments on material perception will be conducted and the results will be used to derive perceptually-based material models with meaningful parameters. How image properties affect the visual fidelity of rendered materials will also be investigated. These findings will then be used to develop effective and easy-to-use interfaces for computer-aided material design.<br/><br/>Broader Impacts: Better methods for material modeling and rendering will lead to improved capability and productivity in fields such as architecture, industrial design and communication, training, cultural heritage, and entertainment. The project will build a material appearance community that stretches across academic and commercial boundaries to include computer graphics, computer vision and human vision researchers along with a range of industrial collaborators, and which focuses on developing effective solutions to real-world problems. The research will engage and train groups of students at 3 universities for scientific/technical careers that require working in interdisciplinary teams and partnering with coworkers in remote locations."
"1149662","CAREER: Quantifying diffusion and dynamics on healthcare, innovation and communication networks","IIS","INFO INTEGRATION & INFORMATICS, CLB-Career","07/01/2012","06/18/2014","Edoardo Airoldi","MA","Harvard University","Continuing grant","Sylvia J. Spengler","06/30/2017","$291,673.00","","airoldi@stat.harvard.edu","1350 MASSACHUSETTS AVE","Cambridge","MA","021383846","6174955501","CSE","7364, 9103","1045, 7364, CL10","$0.00","Many modern data collections, gathered for the purpose of providing insights into matters of national interest such as medical and technological innovation, typically measure quickly evolving interactions, in addition to traditional unit-level measurements, in the context of a network. This project develops an integrated research and educational program to enable scientific and quantitative analyses of interactions and other combinatorial measurements as they change over time. Technical problems being addressed include, but are not limited to: an efficient representation that facilitates quantitative analyses of large-scale networks; models of how information and behavior evolve over time as a consequence of the network context they are embedded in; and fast algorithms to perform estimation of critical parameters in these models. These methods will be demonstrated on case studies exploring: the diffusion of medical innovations among physicians and its impact on health; technological innovation dynamics in the United States and the role of non-compete agreements; the estimation of point-to-point communications on a network, from aggregate traffic that is passively monitored.<br/><br/>The presence of interactions and other combinatorial measurements as a source of observed variation in the data creates new statistical and inferential challenges. For instance, generalized linear model theory needs to be extended to responses on a network. The analysis of processes on a network often induces constraints that make the inferential problems ill posed, since they involve a large number of unknown quantities to describe few observations. Estimation may require sampling from, and integrating over, extremely constrained parameter spaces. Importantly, interactions do not necessarily encode statistical dependence. In this sense, dealing with observed interactions requires original thinking; the data settings they entail are not amenable to analysis with classical methods, in which interactions are inferred as a means to encode dependence among unit-level observations. This project tackles technical challenges with a statistical and machine learning approach. Anticipated technical results include, but are not limited to: (1) a new wavelet decomposition of multivariate and dynamic networks; (2) statistical models of diffusion of information on a given network, and models of inhomogeneous network dynamics in continuous time; (3) scalable estimation algorithms for these models; and (4) theoretical foundations of inference with big data. This research will be evaluated qualitatively and quantitatively, at Harvard and in collaboration with industrial partners.<br/><br/>The proposed research is integrated with an interdisciplinary educational program, which will attract undergraduates to research at the intersection of statistics and computer science, in the context of problems of national importance. It will provide opportunities to actively encourage students from underrepresented groups to pursue careers in statistics and computer science. Key elements of the educational program include the development of a statistical machine learning curriculum; lectures on YouTube available to everyone; tutorials at national and international conferences and workshops; and a monograph. Outreach activities include open-source software and webtools for the community at-large, and a collaborative effort with industrial partners to leverage the new computational tools and algorithms for benefiting their pools of users worldwide. Additional details regarding the project can be found at: http://www.fas.harvard.edu/~airoldi/career.html."
"1408672","CHS: Medium: The Use of Robots as Intermediaries to Gather Sensitive Information from Children","IIS","Cyber-Human Systems","07/01/2014","06/18/2014","Cindy Bethel","MS","Mississippi State University","Continuing grant","Ephraim P. Glinert","06/30/2018","$374,351.00","David May, Deborah Eakin, Melinda Pilkinton","cbethel@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7367","7367, 7924, 9150","$0.00","A recent report entitled ""Child Maltreatment 2011"" issued by the U.S. Department of Health & Human Services Administration for Children and Families estimated that more than 3.7 million children were the subjects of at least one report of maltreatment, and that over 681,000 children were found to be unique victims of child maltreatment in the United States. This multidisciplinary research will compare the effectiveness of robot vs. human interviewers for gathering sensitive information from children, using situations in which this would commonly occur: cases of child eyewitness memory and child reports of bullying. The PI argues that the use of a robot as an intermediary during these so-called forensic interviews could reduce or eliminate unintentional cues observed in human interviewers that result in inaccurate reports by children. To validate her hypothesis the PI and her team will develop a systems architecture, an interactive user interface and an interactive robotic toolkit for interviewers, and perform a series of six studies involving children ages 8-11. The interdisciplinary research team is comprised of experts in human-computer interaction, human-robot interaction, robotics, psychology, sociology, and social work, and the project will make contributions to each of these domains. The team further includes a member of the legal profession as a consultant, who will iteratively evaluate the potential for extending the research findings to real-world legal proceedings and investigations. Preliminary research conducted by the PI has attracted attention from the law enforcement and legal communities, so if successful this project has the potential to transform information gathering for investigative purposes. The PI and her colleagues have been actively involved in community outreach in local middle schools and Boys and Girls Clubs with respect to the use of robots for eliciting information related to bullying, and this outreach will be extended to elementary school children involved in the current research. <br/><br/>The research goals for this project will be accomplished through the development of an integrated robotic toolkit based on a novel Interactive Social Engagement Architecture (ISEA) and a unique interactive user interface. ISEA provides a framework for the autonomous generation of robot behaviors for self-preservation and to convey social intelligence. The toolkit will be designed to integrate behavior-based robotics, human behavior models, cognitive architectures, and user input to increase social engagement between a human and system (robot, avatar, etc.). The interactive user interface will provide interviewers with the ability to use the robot as an intermediary for gathering sensitive information. ISEA has three primary parallel paths for processing robot behaviors: (1) verbal behaviors based on expert user input from the interactive user interface; (2) autonomous self-preservation behaviors if the robot is threatened that consist of both verbal and non-verbal responses; and (3) non-verbal autonomous behaviors generated from sensor data coming from the environment, the current internal state of the robot, user input, and prior knowledge from the knowledge base/long-term memory. As part of the research, six human studies will be conducted that use typical situations in which gathering sensitive information from children might occur. Three of these experiments will examine whether child eyewitness memory is more accurate when a robot rather than a human presents misleading information during an interview, while the other three will examine whether children who have been victimized by bullying will be more likely to disclose that victimization to a robot as opposed to a human interviewer. Some of these experiments will examine the role of gender both for humanoid robots and adult interviewers, using established forensic interview protocols, while others will examine whether interviewers high in social intelligence elicit more accurate child eyewitness memory and reports of bullying than those low in social intelligence (where social intelligence is defined by the use of gestural and facial non-verbal behaviors)."
"1441827","Fourth International IEEE Conference on Computational Advances in Bio and medical Sciences (ICCABS) - Travel Awards","CCF","INFO INTEGRATION & INFORMATICS, ALGORITHMIC FOUNDATIONS","07/15/2014","06/18/2014","Sanguthevar Rajasekaran","CT","University of Connecticut","Standard Grant","Mitra Basu","06/30/2015","$12,000.00","","rajasek@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","CSE","7364, 7796","7364, 7556, 7931","$0.00","Broader Significance and Importance<br/>This proposal is to support the travel of students and post-doctoral fellows (PDFs) to attend the 4th International Conference on Advances in Bio and medical Sciences (ICCABS). These students and PDFs will get to meet experts in Bioinformatics and listen to their research results. Not only the attending students and PDFs but also their friends will benefit since when the students and PDFs return to their schools they will communicate their experience with their friends. The conference proceedings will be of great use to students, researchers, and practitioners. Portions of the proceedings could be used in different courses as well.<br/><br/>Technical Description of the Project<br/>Computational techniques are revolutionizing the way in which research is conducted in science and engineering. Unsurpassed advances have been made in various areas. This is particularly true in the domains of biology, medicine, and drug discovery. Given that these areas are of utmost importance to the society at large, it is imperative that every effort be made to enable research advances in them. It is not enough if advances are made in these areas in isolation. These communities have to work together to help each other and come up with the best possible diagnosis tools, treatment procedures, drugs for various diseases, etc. Even though a number of conferences exist today in the general area of bioinformatics, they focus on computational biology to a large extent. The proposed conference has the goal of bringing together scientists in all the three areas and hence serving as a platform for bridging the research efforts in these areas.<br/><br/>The intellectual merit of this project lies in its goal of bringing together scientists in various areas of bio and medical sciences and fostering collaborations among them."
"1353694","EAGER: Diverse M-Best Predictions from Probabilistic Models","IIS","ROBUST INTELLIGENCE","09/15/2013","09/06/2013","Dhruv Batra","VA","Virginia Polytechnic Institute and State University","Standard Grant","Jie Yang","08/31/2015","$184,415.00","","dbatra@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7495","7495, 7916","$0.00","Computer Vision systems must deal with significant levels of ambiguity - from inter- and intra-object occlusion and varying appearance, lighting, and pose. Probabilistic models provide a principled framework for dealing with uncertainty and for converting evidence into a posteriori belief about the world. Typically, a vision system uses this belief to predict the ""most likely"" or maximum a-posteriori hypothesis. Unfortunately, our current models are inaccurate and this single-best hypothesis is often incorrect. <br/><br/>This project explores a novel way to allow vision systems to hedge against uncertainty by producing multiple plausible hypotheses. Specifically, this project develops techniques for finding a diverse set of high-probability solutions from probabilistic models. The project focuses on (a) interactive object cutout (where multiple segmentations are shown to the user to expedite convergence to an acceptable result); (b) semantic segmentation (where multiple plausible scene labelings are propagated to subsequent stages of a cascade for higher-order processing); (c) person/object tracking (where multiple localization hypotheses on each frame reduce the search space of a sequence tracker). <br/><br/>This project is producing new scientific knowledge in the context of probabilistic reasoning and advancing the state of art in computer vision. The techniques developed are useful for other AI domains such as Speech and Natural Language Processing. The PI and his students are broadly disseminating produced work by organizing workshops, tutorials, and journal special issues, and publicly sharing code and results. The project is engaging undergraduate students and women in computer science research."
"1341772","RI: Small: Debugging Machine Visual Recognition via Humans in the Loop","IIS","ROBUST INTELLIGENCE","02/11/2013","05/24/2013","Devi Parikh","VA","Virginia Polytechnic Institute and State University","Standard Grant","Jie Yang","08/31/2015","$30,483.00","","parikh@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7495","7923, 7495","$0.00","The problem of visual recognition is fundamental towards the goal of automatic image understanding. While a large number of efforts have been made in the computer vision community, machine performance at these tasks remains significantly inferior to human ability. <br/>The overarching goal of this project is to leverage the best known visual recognition system - the human visual recognition system. This project employs a ""Human Debugging"" paradigm to replace various components of a machine vision pipeline with human subjects, and examines the resultant effect on recognition performance. Meaningful comparisons provide valuable insights and pinpoint aspects of the machine vision pipeline that are performance bottlenecks and require future research efforts. Specifically, the project considers the problems of image classification and object detection, and explores the roles of local and global information, as well part-detection, spatial modeling and contextual reasoning (including non-maximal suppression) for these problems respectively. <br/>This project touches on a wide range of problems in visual recognition including object recognition, scene recognition and object detection. This novel paradigm of identifying weak links in computational models via humans in the loop is also applicable to other vision problems, as well as other sub-fields in AI. By sharing all collected data and results, and through organized conferences and workshops, this project will initiate and fuel a dialogue with the research community about leveraging humans to advance computer vision. More broadly, this work encourages the involvement of young women and undergraduate students in computer science research."
"1017621","III:Small:Algorithms for Tandem Repeat Variant Discovery Using Next Generation Sequencing Data","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","09/21/2011","Gary Benson","MA","Trustees of Boston University","Continuing grant","Sylvia J. Spengler","07/31/2015","$500,000.00","","gbenson@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364","7364, 7923","$0.00","A tandem repeat (TR) is any pattern of nucleotides which occurs as repeating, consecutive copies along a DNA molecule. Often, the pattern copies are not identical. A TR can be polymorphic, that is, it can be different across individuals in a population: 1) the number of copies may be different, 2) the arrangement of non-identical copies may be dfferent, and 3) the copies may contain different small mutations. TR variants are known to affect important biological processes, such as chromatin structure, gene plasticity, gene expression, and disease states, so their discovery is crucial for correctly understanding complex bio-molecular interactions. While a conservative estimate suggests that 100,000 human TRs may be polymorphic, until recently, genome-wide study of TR polymorphism, in humans and other organisms, has been too difficult and costly, with the result that the true extent of polymorphism and its effects are unknown. New genome sequencing technologies offer the first real opportunity to fill in the details of TR diversity. These technologies sequence millions of high quality, short DNA fragments in a single<br/>experiment. Current sequencing projects are producing many billions of reads rich in TR variant information. Yet, current read mapping algorithms,<br/>which attempt to assign each read to its proper location on the reference genome, are not designed to detect TR variants. <br/><br/>This project has three central goals: 1. Algorithm Development; 2.Genome Studies; 3. Variation Curation in a public database. Strategies will be developed to accurately and efficiently map TR-containing reads to reference genome TR loci. Anticipated algorithmic developments include: 1) Optimization of tree-based alignment, for use when millions of short, disjoint sequences must be aligned to each other. The reads and references can each be merged into separate Patricia tree data structures and alignment computed between tree nodes, thereby eliminating redundant computation in the prefixes of the two sequence sets. 2) Production of space-saving, Burrows Wheeler transforms (BWT) of the most redundant tree parts by employing approximate shortest common superstrings (SCS) for the two sequence sets. 3) Development of an efficient Four-Russians style block computation for edit distance alignment in the trees by exploiting redundancy inherent in the small alphabet and block input scores, 4) Development of a bounding computation for edit-distance based on efficient, bit-register computation of longest common subsequence (LCS) alignment, and 5) Parallelization of all algorithms for further efficiency with multi-core processors, Single Instruction, Multiple Data (SIMD) bit-register computations, and highly parallel graphics processing units (GPUs). Data from six recently published whole human genomes, two human centenarian genomes, and the 1000 genomes project will be analyzed to discover TR variants. An internet-accessible, public database and analysis platform for curation and display of TR variants will be developed.<br/><br/>The TR variant discovery software and all data sets produced will directly enhance the infrastructure for TR diversity research in genome biology, genome evolution, and comparative genomics. The software and data will be freely available to the research community through a high capacity website maintained in the PI's lab at Boston University. The PI will participate in a variety of activities that link research and education and support participation by members of underrepresented groups, including provision of opportunities in research for graduate and undergraduate students, participation in high school enrichment and curriculum development projects, and editorship of an international journal engaged in the dissemination of bioinformatics research."
"1116010","RI: Small: Providing Quality of Information in Robot Sensor Networks","IIS","ROBUST INTELLIGENCE","08/15/2011","08/12/2011","Eric Frew","CO","University of Colorado at Boulder","Standard Grant","Satyandra Gupta","07/31/2015","$499,974.00","","eric.frew@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7495","7923","$0.00","This project develops distributed control algorithms for robot sensor networks using information dynamics to unify network mobility and communication. The new framework moves beyond location-based mobility control algorithms and packet-based communication protocols to a single information-theoretic approach. The framework is developed through: (1) formulation of a new quality of service of information metric and characterization of feasible quality of service demands, (2) adaptive receding horizon control that adjusts planning horizon and sample time based on information dynamics, (3) distributed calculation and optimization of team quality of service, and (4) experimental validation using a heterogeneous indoor robot sensor network and outdoor unmanned aircraft systems.<br/><br/>This research enables the collection of in situ data over large spatiotemporal scales. When deployed in remote or hazardous locations the data collected with these networks leads to a direct improvement to model or understand complex environments, which can help save lives. Students will benefit from the multi-disciplinary activities involved, including embedded computing, miniature sensor devices, wireless networking, and automatic control."
"1018031","RI: Small: Integrating Logic Based Declarative Programming Paradigms","IIS","ROBUST INTELLIGENCE","09/01/2010","04/27/2011","Yuanlin Zhang","TX","Texas Tech University","Standard Grant","James Donlon","08/31/2015","$308,057.00","Michael Gelfond","y.zhang@ttu.edu","349 Administration Bldg","Lubbock","TX","794091035","8067423884","CSE","7495","7923, 9251","$0.00","The project is developing a new, powerful paradigm for declarative programming, capable of solving computational problems that require a large amount of diverse knowledge and use of different reasoning methods. Such problems frequently occur in practice but cannot be solved by more traditional methods of declarative (or procedural) programming. The research includes the development of a language for representing various types of knowledge, algorithms and systems for reasoning about this knowledge, and a methodology of using the language and the systems for solving a large variety of computational problems. Our approach to declarative programming will integrate the ideas from Answer Set Programming (ASP), Constraint Programming (CP), programming methods based on Boolean Satisfiability (SAT) and Satisfiability Modulo Theory (SMT), and with a longer-term goal of including abductive and probabilistic reasoning as well. The approach will be tested on problems in challenging application domains such as a decision support system for space shuttle controllers, secure software systems with complex authorization and obligation policies, and systems capable of planning and scheduling based on non-trivial domain knowledge."
"1444666","Student Travel Support for the 2014 IEEE International Conference on Big Data","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/17/2014","Jimmy Lin","MD","University of Maryland College Park","Standard Grant","Frank Olken","05/31/2015","$20,000.00","","jimmylin@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7364, 7556","$0.00","""Big Data"" has emerged as a new approach to computing that is transforming science, engineering, medicine, health care, finance, business, and ultimately society itself. The IEEE International Conference on Big Data 2014 (IEEE BigData 2014) provides a leadin forum for disseminating the latest research in big data research, development, and applications. The conference will take place in the Washington, D.C. area from October 27-30, 2014 in Washington, D.C. The PC co-chairs are Jimmy Lin (University of Maryland) and Jian Pei (Simon Fraser University). This award will help support travel of Ph.D. students at U.S. universities who are primary authors on full papers that have been accepted to the technical program or are participating in the doctoral student symposium.<br/><br/>This conference solicits high-quality original research papers in any aspect of big data, including infrastructure, management, search and mining, security and privacy, and applications. Contributions will advance the state of the art in techniques, algorithms, and systems.<br/><br/>For further information see the conference homepage: http://cci.drexel.edu/bigdata/bigdata2014/"
"0953856","CAREER: Underactuacted Precision Robotic Grasping and Manipulation","IIS","ROBUST INTELLIGENCE","03/01/2010","02/07/2014","Aaron Dollar","CT","Yale University","Continuing grant","Jeffrey Trinkle","02/28/2015","$498,590.00","","aaron.dollar@yale.edu","Grant & Contract Administration","New Haven","CT","065103209","2037854689","CSE","7495","1045, 1187","$0.00","The vision of robotic assistants for domestic, health care, and workplace applications will not come to fruition without the ability to manipulate typical objects in human environments. However, grasping is challenging in unstructured environments because object models typically required to control the robot are not known beforehand and must be acquired through sensors that are imprecise and incomplete. The majority of research in robotic grasping and manipulation has attempted to address this problem through elaborate multifingered hands combined with tactile sensing and sophisticated planning and control algorithms, often following an anthropomorphic approach. This proposal utilizes an alternative approach involving a focus on the mechanics of the hand itself to accomplish most of the needed ?control.? By appropriately incorporating features such as compliance and underactuation, the uncertainty inherent in unstructured grasping tasks can be more easily accommodated. The proposed work addresses the problem of precision grasping of small objects from the surrounding environment and then begins to address the broader problem of dexterity by examining two-fingered precision manipulation, while investigating the role of compliance, underactuation, and configuration on performance in the presence of uncertainty. This work will be disseminated through publications in scholarly journals and conferences and will contribute to the fundamental understanding of the mechanical interaction of robot hands with small objects and the surrounding environment. These results are expected to lead to the development of low-dimensional hands for precision robotic grasping and manipulation with applications including assistive robots and prosthetics."
"1319645","HCC: Small: Modeling and Supporting Creativity During Collaborative STEM Activities","IIS","Cyber-Human Systems","08/01/2013","04/25/2014","Winslow Burleson","AZ","Arizona State University","Standard Grant","William Bainbridge","07/31/2016","$515,998.00","Danielle McNamara, Kasia Muldner","wb50@nyu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","7367, 7923, 9251","$0.00","This research will advance a novel technological approach that relies on machine learning techniques in general and Natural Language Processing (NLP) in particular to develop models and support for creativity during collaborative science, technology, engineering, and mathematics (STEM) educational activities. We will extend existing educational software with NLP capabilities to automatically assess and subsequently support creativity during collaborative tasks. The research questions are: (1) Which factors influence moment-by-moment creativity during collaborative problem solving activities? (2) How can NLP be used to build student models that detect those factors? (3) How can an ITS use this information to create personalized interventions to support creativity?<br/><br/>The first phase in this research will collect data from students solving problems in pairs with an educational application to identify factors that are relevant to creativity processes and outcomes. These data will be used to derive computational student models for automatically assessing student creativity in terms of both moment-to-moment processes and outcomes through machine learning methodologies focusing on an NLP approach. In addition to providing automatic assessment, the models will also inform factors that influence creativity during collaboration through educational data mining techniques. The final phase of the work will design and test a set of interventions to foster creativity during collaborative activities.<br/><br/>Using data corresponding to pairs of students solving open-ended STEM-based problems, this research will develop a rich and nuanced understanding of creativity processes and outcomes in collaborative contexts, and how these relate to knowledge, affect and creative thinking styles. Relying on that understanding, it will develop and evaluate novel student models that recognize salient, creativity-related events through NLP techniques, as well as personalized support for creativity during collaborative activities and evaluating that support through an experiment with university students. This project will pave the way for a new class of collaborative cyberlearning technologies to both assess and foster creativity, through just-in-time personalized support based on easily deployed NLP-based student models."
"1200792","CAREER: Novel Query Processing Techniques for Distributed Probabilistic Data","IIS","INFO INTEGRATION & INFORMATICS","09/29/2011","06/16/2014","Feifei Li","UT","University of Utah","Continuing grant","Frank Olken","01/31/2016","$422,003.00","","lifeifei@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7364","1045, 1187, 7364, 9251, 9150","$0.00","Data are increasingly generated, stored, and processed distributively. Meanwhile, when large amounts of data are generated, ambiguity, uncertainty, and errors are inherently introduced, especially in a distributed setup. It is best to represent such data in a distributed probabilistic database. In distributed data management, summary queries are useful tools for obtaining the most important answers from massive quantities of data effectively and efficiently, e.g., top-k queries, heavy hitters (aka frequent items), histograms and wavelets, threshold monitoring queries, etc. This project investigates novel query processing techniques for various, important summary queries in distributed probabilistic data.<br/><br/>Broadly classified, this project examines both snapshot summary queries in static (i.e., no updates) distributed probabilistic databases, and continuous summary queries in dynamic (i.e., with updates) distributed probabilistic databases. A number of techniques are explored to design novel, communication and computation efficient algorithms for processing these queries.<br/><br/>A distributed probabilistic data management system (DPDMS) prototype is implemented based on the query processing techniques developed in this project. This DPDMS is released to and used in practice by scientists and engineers from other science disciplines as well as industry.<br/><br/>Graduate and undergraduate students, including those from minority groups, are actively involved in this project. Findings from the project have been integrated into different courses, demos, and educational projects. For further information, such as publications, data sets, source code, and education initiatives, please visit the project website at http://www.cs.fsu.edu/~lifeifei/dpdm."
"1409683","RI: Medium: Collaborative Research: Write A Classifier: Learning Fine-Grained Visual Classifiers from Text and Images","IIS","ROBUST INTELLIGENCE","06/15/2014","06/16/2014","Ahmed Elgammal","NJ","Rutgers University New Brunswick","Continuing grant","Jie Yang","05/31/2017","$166,600.00","","elgammal@cs.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7495","7495, 7924","$0.00","This project develops the learning strategy using textual narrative and images makes the learning effective without a huge number of images that a typical visual learning algorithm would need to learn the class boundaries. The research team investigates computational models for joint learning of visual concepts from images and textual descriptions of fine-grained categories, for example, discriminating between bird species. The research activities have broader impact in three fields: computer vision, natural language processing, and machine learning. There is a huge need to develop algorithms to automatically understand the content of images and videos, with numerous potential applications in web searches, image and video archival and retrieval, surveillance applications, robot navigation and others. There are various applications for developing an intelligent system that can use narrative to define and recognize categories.<br/><br/>This project addresses two research questions: First, given a visual corpus and a textual corpus about a specific domain, how to jointly and effectively learn visual concepts? Second, given these two modalities how to facilitate learning novel visual concepts using only pure textual descriptions of novel categories in the domain? The research team approaches the problem on three integrated fronts: Learning, Natural Language Processing (NLP), and Computer Vision. On the learning front, the project investigates and develops algorithms suitable for learning and predicting visual classifiers with side textual information. On the NLP front, the project aims to develop novel methods for learning global and local discriminative category-level attributes and their values from text, with feedback from human computation and visual signal. The project investigates supervised and unsupervised methods for detecting visual text, and learning methods for deep language understanding to build such rich domain models from the noisy visual text. On the Vision front, the project addresses the tasks of detection and classification with side textual information. The project investigates models for the shape and appearance of a general category that can specialize to different subordinates, in a way that allows interpreting information from text within a proper geometric context, and handle variability in viewpoints and articulation."
"1321053","RI: Small: Deep Learning: Theory, Algorithms, and Applications","IIS","ROBUST INTELLIGENCE","08/15/2013","06/16/2014","Pierre Baldi","CA","University of California-Irvine","Continuing grant","Todd Leen","07/31/2016","$457,999.00","","pfbaldi@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","7495, 7923, 9251","$0.00","The ability to learn is essential to the survival and robustness of biological systems. There is also growing evidence that learning is essential to build robust artificial intelligent systems and solve complex problems in many application domains. However, solutions to complex problems ranging from recognizing faces to understanding speech, cannot be implemented in a single step. Instead they require multiple processing stages, for instance to extract increasingly more abstract and refined features from an input image. <br/><br/>Thus computers and brains are both faced with the problem of deep learning --- how to simultaneously optimize the parameters of a hierarchy of processing stages in order to solve complex tasks and display intelligent behavior. In the past few years there has been remarkable progress in computer science to address the deep learning problem, and deep learning methods now claim state-of-the-art performance in several application areas. The next generation of machine learning methods holds the promise to not only approach human performance in tasks previously impossible for computers, but also to exceed it. However, our theoretical understanding of deep learning remains limited and there are several important areas where deep learning has not yet been applied systematically. This project addresses these challenges and opportunities by furthering formal understanding of the theory and algorithms behind deep learning, and by applying deep learning methods to new problems in the life sciences. Because deep learning can be used in almost any domain, the results have the potential for broadly impacting science, engineering, and technology across multiple areas. <br/><br/>The project has educational and outreach components, ranging from courses to virtual 3D world interactions, for undergraduate and graduate students at UCI, as well as talented students from local high schools, and underrepresented minority students from local colleges. Scientific results, data, and software resulting from the project will be disseminated in scientific journals and over the web.<br/><br/>The project has three main thrusts: theory, algorithms, and applications. From a theoretical standpoint, the project develops better mathematical understanding of deep architectures, including stacks of autoencoder networks, and their properties. These theoretical results will inform the design of deep-learning architectures. From an algorithmic standpoint, the project investigates, formally and through simulations, several deep learning algorithms, including the dropout algorithm and the PI's deep targets algorithm. From an application standpoint, the project uses the new theoretical and algorithmic knowledge in application to the life sciences, for instance for protein structure prediction, and in predicting chemical reactions. Advancing the state-of-the-art for any one of these thrusts will have a significant impact in computer science, artificial intelligence, statistical machine learning, and the corresponding application field."
"1065243","RI: Medium: Collaborative Research: Semantically Discriminative: Guiding Mid-Level Representations for Visual Object Recognition with External Knowledge","IIS","ROBUST INTELLIGENCE","08/01/2011","06/16/2014","Fei Sha","CA","University of Southern California","Continuing grant","Jie Yang","07/31/2015","$491,289.00","","feisha@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7495, 7924","$0.00","This project explores (semi-)automatic ways to create ""semantically discriminative"" mid-level cues for visual object categorization, by introducing external knowledge of object properties into the statistical learning procedures that learn to distinguish them. In particular, the PIs investigate four key ideas: (1) exploiting taxonomies over object categories to inform feature selection algorithms such that they home in on the most abstract description for a given granularity of label predictions; (2) leveraging inter-object relationships conveyed by the same taxonomies to guide context learning, so that it captures more than simple data-driven co-occurrences; (3) exploring the utility of visual attributes drawn from natural language, both as auxiliary learning problems to bias models for object categorization, as well as ordinal properties that must be teased out using non-traditional human supervision strategies; (4) mining attributes that are both distinctive and human-nameable, moving beyond manually constructed semantics.<br/><br/>The project entails original contributions in both computer vision and machine learning, and is an integral step towards semantically-grounded object categorization. Whereas mainstream approaches reduce human knowledge to mere category labels on exemplars, this work leverages semantically rich knowledge more deeply and earlier in the learning pipeline. The approach results in vision systems that are less prone to overfit incidental visual patterns, and representations that are readily extendible to novel visual learning tasks. Beyond the research community, the work has broader impact through inter-disciplinary training of graduate and undergraduate students, and outreach to pre-college educators and students through workshops and summer camps encouraging young students to pursue science and engineering."
"1116584","RI: Small: Endowing Graph-Based Image Segmentation with Global 'Advice': Applications to Diffusion Tensor Images","IIS","ROBUST INTELLIGENCE","09/01/2011","04/16/2012","Vikas Singh","WI","University of Wisconsin-Madison","Standard Grant","Jie Yang","08/31/2014","$363,146.00","","VSINGH@CS.WISC.EDU","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","7923, 9251","$0.00","The primary goal of this project is to enable identification and segmentation of specific structures of interest from imaging data (such as DTI MR brain images). These regions may be small and inconspicuous with poor contrast, therefore, direct application of classical unsupervised segmentation (designed to extract ""salient"" regions) is problematic. The alternative pursued here is a system to leverage expert-like high level advice within the image segmentation process: to do this, the underlying engine is endowed with global constraints encoding (a) effort already expended by the user in segmenting similar images in the past, as well as (b) aggregate knowledge from a cohort of similar images. The key algorithmic component is the design of mechanisms to translate such constraints (as best as possible) to a combinatorial framework so that the resultant models can be optimized efficiently for high resolution 3-D imaging data. This research produces the methodology and accompanying software for this important image analysis task. <br/><br/>The project has broad scientific impact. Wide distribution of code produced from this research can enable improvements in various computer vision and medical imaging problems where image segmentation is a key step. Additionally, the algorithms developed here have applications in other problems such as object recognition and image categorization. The project is also well suited to involve undergraduate and graduate students from a diverse spectrum of backgrounds in cutting edge inter-disciplinary computer vision and image processing research."
"1118018","HCC: Small: Modeling Human Communication Dynamics","IIS","Cyber-Human Systems","08/15/2011","08/11/2011","Louis-Philippe Morency","CA","University of Southern California","Standard Grant","Ephraim P. Glinert","07/31/2015","$490,102.00","Kenji Sagae","morency@ict.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7923, 7367","$0.00","Face-to-face communication is a highly dynamic process where participants mutually exchange and interpret linguistic and gestural signals. Even when only one person speaks at the time, other participants exchange information continuously amongst themselves and with the speaker through gesture, gaze, posture and facial expressions. To correctly interpret the high-level communicative signal, an observer needs to jointly integrate all spoken words, subtle prosodic changes and simultaneous gestures from all participants.<br/><br/>The proposed effort endeavors to create a new generation of computational models for modeling the interdependence between linguistic symbols and nonverbal signals during social interactions. This computational framework has wide applicability, including the recognition of human social behaviors, the synthesis of natural animations for robots and virtual humans, improved multimedia content analysis, and the diagnosis of social and behavioral disorders (e.g., autism spectrum disorder). This research effort is an important milestone, complementary to recent research efforts focusing on only two components (e.g., social signal processing, which focuses on nonverbal and social signals). The proposed unified approach to Social-Symbols-Signals will pave the way for new robust and efficient computational perception algorithms able to recognize high-level communicative behaviors (e.g., intent and sentiments) and will enable new computational tools for researchers in behavioral sciences.<br/><br/>The proposed research will advance this endeavor through the development of new probabilistic models for jointly capturing the interdependence between language, gestures and social signals, and novel computational representations, which integrates data-driven processing and logic rule-based approach (so that prior knowledge from social sciences can be easily included). Four fundamental research goals will be directly addressed: symbol-signal representation (joint representation of language and nonverbal), modeling social interdependence (joint modeling of communicative signals between multiple participants), variability in signal interpretations (variability with annotations of high-level communicative signals), and generalization and validation (generalization over different communicative signals and domains).<br/><br/>The proposed research will enable more natural interaction between users and embodied conversational dialogue systems, impacting the way in which computers are used, for example, in tutoring and in cultural and language training. The potential uses of such software and data go far beyond the scope of this project, making it possible, for example, to perform large scale corpus-based studies about social aspects of human face-to-face (multimodal) communication, or cognitive aspects of human multimodal processing. Following the investigators' past experience with sharing research software open-source, code and corpus annotations will be made available to the research community. These shared research results will be valuable for new researchers as well as important educational material for course development."
"1321015","RI: Small: Multi-View Learning of Acoustic Features for Speech Recognition Using Articulatory Measurements","IIS","ROBUST INTELLIGENCE","09/01/2013","06/16/2014","Karen Livescu","IL","Toyota Technological Institute at Chicago","Continuing grant","Tatiana D. Korelsky","08/31/2016","$371,025.00","","klivescu@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372902","7738340409","CSE","7495","7495, 7923","$0.00","This project explores techniques for learning acoustic features for speech recognition, based on multi-view learning using acoustic and articulatory recordings. Recent work has shown recognition improvements using this strategy via linear and nonlinear canonical correlation analysis, in which transformations of acoustic features are learned so as to maximize correlation with (transformations of) articulatory measurements. Prior work has been limited to a single database and a single language.<br/><br/>The main goals of this project are to learn better universal features for arbitrary speakers and languages and to develop improved multi-view techniques. Project activities include: learning time-varying projections; multi-view techniques based on neural networks; ""many-view"" learning using articulation, video, labels, etc.; efficient implementations; new input features such as spectro-temporal filters; and visualization tools for related research and education.<br/><br/>A critical component of automatic speech recognition is a representation of the audio signal that encapsulates useful information while discarding acoustic noise, speaker identity, and so on. This project aims to automatically learn improved representations using statistical analysis of audio recordings paired with positions of the speech articulators (lips, tongue, etc.) and other measurements. The project starts with basic statistical techniques, and develops new techniques that address challenges and opportunities specific to speech and related signals.<br/><br/>The project's impact extends beyond speech processing. Applications of multi-view representation learning include neurology, meteorology, chemometrics, computer vision, and text processing; all of these can benefit from the improved techniques. The work impacts education by generating materials for a Speech Technologies course and visualization tools for speech and other signals."
"1065228","RI: Medium: Collaborative Research: Teaching Computers to Follow Verbal Instructions","IIS","ROBUST INTELLIGENCE","09/01/2011","04/08/2013","Marie desJardins","MD","University of Maryland Baltimore County","Standard Grant","Todd Leen","08/31/2015","$311,743.00","","mariedj@cs.umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7495","7495, 7924, 9251","$0.00","The goal of this research is to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language on behalf of a user. It will study each of these components in isolation, but a significant focus will be on integrating them into a coherent system. The project will also leverage this technology to provide an entry point to educate non- or pre-computer science students about the capabilities and utility of computers as tools.<br/><br/>Our approach uses three main subcomponents, each of which requires innovative research to solve its portion of the overall problem. In addition, the integrated architecture is a novel contribution of this work. The three components are (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning, (2) translating instructions to task specifications using novel techniques in the area of natural language processing, and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing abstractions.<br/><br/>The goal of the work is develop technology for an improved ability for human users to interact with intelligent agents, the incorporation of novel AI research insights and activities into education and outreach activities, and the development of resources for the AI educator community. In addition to permitting intelligent agents to be developed and trained in the future for a broad range of complex application domains, the interactive agents that we will develop will be used for outreach and student learning."
"1252725","CAREER: Efficient Statistical Inference using Neuroimaging data for Sample Enrichment and Optimizing Power","IIS","STATISTICS, ROBUST INTELLIGENCE","04/15/2013","04/19/2014","Vikas Singh","WI","University of Wisconsin-Madison","Continuing grant","Jie Yang","03/31/2018","$261,421.00","","VSINGH@CS.WISC.EDU","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","1269, 7495","1045","$0.00","Hypothesis testing on neuroimaging data traditionally has made use of classical statistical tests (on uni-variate response variables). This makes sub-optimal use of the structure of images, particularly problematic if the two groups being tested have weak differences to begin with. Failure to detect statistically significant differences may imply failure of the experiment itself. Acquiring more images is expensive but also occasionally infeasible. This project develops technologies to address these problems (particularly those dealing with differential analysis of brain images) via the lens of computer vision and machine learning. The algorithmic component of this project is (1) a suite of convex optimization based multi-modal learning schemes to seamlessly leverage a spectrum of brain imaging data, (2) new multi-resolution representations for inference with surface/network based signals (data derived from structural/functional brain images), and (3) using these mechanisms for boosting statistical power even in experiments with small sample sizes.<br/><br/>The project has broad scientific impact. Extending the operating range of statistical image analysis methods for neuroimaging will foster a new inter-disciplinary area at the interface of computer vision, biostatistics, and machine learning, which is highly intellectually stimulating. The research team brings real neuroimaging research data for undergraduate/graduate students to explore and study. The project goals also include training and mentoring of students, increased involvement of under-represented groups, seminars, and an extensive set of outreach activities. In addition, the resultant software tools drive the analysis of neuroscience studies, which has clear broad societal impact."
"1208118","CRCNS: Collaborative Research: Responses of the Rodent-Vibrissal-Trigeminal System to Air Currents","IIS","CRCNS, ROBUST INTELLIGENCE","10/01/2012","06/16/2014","Mitra Hartmann","IL","Northwestern University","Standard Grant","Kenneth C. Whang","09/30/2015","$498,355.00","Neelesh Patankar","m-hartmann@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7327, 7495","7327, 9251","$0.00","The rodent vibrissal-trigeminal system is one of the most important models in neuroscience for the study of sensorimotor integration. To date, however, research has focused exclusively on direct tactile sensation. Recent results from the Hartmann and Gopal laboratories have demonstrated that rat vibrissae have a robust and repeatable mechanical response to airflow. In addition, neurons in the vibrissal-trigeminal system are known to respond to air puffs. These results suggest that the rat may use its vibrissae to detect air currents and determine wind direction. The Northwestern-Elmhurst team will perform mechanical, behavioral, and computational studies to characterize the role of vibrissae in wind-following behaviors, and the vibrissal-related neural response to air currents. These will constitute some of the first investigations of the underlying mechanisms that permit terrestrial mammals to sense and follow the wind. The team will specifically identify the morphological features of vibrissae and their orientation on the mystacial pad that enable flow sensing behaviors. They will investigate the broad hypothesis that differential mechanical deformations of the vibrissae across the mystacial pad can encode a variety of flow parameters. Finally, behavioral experiments will be performed to determine the extent to which the rat uses its vibrissae to sense airflow, and to quantify the movement strategies used during anemotaxis in the behaving animal. The partnership between Northwestern and Elmhurst will provide significant research opportunities for undergraduates; in addition, videos will be developed to teach the fundamental principles of fluid dynamics and biological sensing that underlie this research. The proposed work has potentially large implications for olfactory localization and the structure of the olfactory system, and is likely to lead to the development of novel flow-sensing technologies."
"0810861","HCC-Small: Collaborative Mixed-Initiative Access Control","IIS","Cyber-Human Systems","09/01/2008","06/16/2014","Prasun Dewan","NC","University of North Carolina at Chapel Hill","Standard Grant","Ephraim P. Glinert","08/31/2015","$491,122.00","","dewan@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7367","7367, 7923, 9215, 9251, HPCC","$0.00","Today, we are faced with three apparently conflicting problems: users are afraid to collaborate unless they have fine-grained control over how their data are accessed by others; many shared environments, especially the new ones, do not offer such controls because of the difficulty of implementing them; those that do offer such controls provide access mechanisms that are difficult to understand and use and result in users being assigned wrong access rights. In this project the PI will investigate the idea of using special-purpose collaborative environments to distribute access, with the goal of developing a general model of access distribution that captures in-use and promising mixed-initiative schemes that have so far been defined only in an application-dependent fashion. The model will be defined using several new kinds of application-independent objects such as access requests and grants that capture the information exchanged in a mixed-initiative system. It will be compatible with existing authorization models including object-based models, in which copies of objects are granted, and rights-based models such as role-based access control, in which (potentially revocable) rights to the object granted. In the PI's approach, the initiative in distributing access rights to shared objects can be taken by information guardians, information consumers, and tools that act as agents of the guardians and the consumers. Information consumers are responsible for sending access requests to information guardians; their agents will (partially or completely) automate this task for them. Information guardians are responsible for authorizing access; their agents will automate this task for them. The PI will identify a general architecture for implementing his model, in which the access-awareness in existing collaboration and communication tools is kept low. In addition, the PI will develop programming abstractions that make it easy to implement the model using the architecture. He will use the abstractions to add mixed-initiative access control in several target systems, which will include both complex widely-used traditional file systems and distributed web services; this experience will help the PI evaluate the programmability of the abstractions. Finally, he will perform field and lab studies to compare alternative approaches to distribute access supported by the general model. <br/><br/>Broader Impacts: If successful, this work will open up a new research area focusing on collaborative mixed-initiative access control, and show that collaborative systems are not only a liability for access control but also an asset. Project outcomes will lead to significant improvement in the usability and programmability of fine-grained authorization mechanisms, thereby facilitating a large number of collaborations that would otherwise not take place. They will also afford a better understanding of the similarities and differences between different access distribution schemes and the consequences of using them. In the short term, the project will develop research and teaching software consisting of two main components: layers on top of widely-used file systems that provide several new access distribution schemes, which can be evaluated by usability researchers and demonstrated in classes on security; and programming abstractions allowing the incorporation of these schemes in new shared environments implemented using web services, which can be used in both class and research projects."
"1409257","RI: Medium: Collaborative Research: Write A Classifier: Learning Fine-Grained Visual Classifiers from Text and Images","IIS","ROBUST INTELLIGENCE","06/15/2014","06/16/2014","Smaranda Muresan","NY","Columbia University","Continuing grant","Jie Yang","05/31/2017","$147,708.00","","smara@ccls.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7495, 7924","$0.00","This project develops the learning strategy using textual narrative and images makes the learning effective without a huge number of images that a typical visual learning algorithm would need to learn the class boundaries. The research team investigates computational models for joint learning of visual concepts from images and textual descriptions of fine-grained categories, for example, discriminating between bird species. The research activities have broader impact in three fields: computer vision, natural language processing, and machine learning. There is a huge need to develop algorithms to automatically understand the content of images and videos, with numerous potential applications in web searches, image and video archival and retrieval, surveillance applications, robot navigation and others. There are various applications for developing an intelligent system that can use narrative to define and recognize categories.<br/><br/>This project addresses two research questions: First, given a visual corpus and a textual corpus about a specific domain, how to jointly and effectively learn visual concepts? Second, given these two modalities how to facilitate learning novel visual concepts using only pure textual descriptions of novel categories in the domain? The research team approaches the problem on three integrated fronts: Learning, Natural Language Processing (NLP), and Computer Vision. On the learning front, the project investigates and develops algorithms suitable for learning and predicting visual classifiers with side textual information. On the NLP front, the project aims to develop novel methods for learning global and local discriminative category-level attributes and their values from text, with feedback from human computation and visual signal. The project investigates supervised and unsupervised methods for detecting visual text, and learning methods for deep language understanding to build such rich domain models from the noisy visual text. On the Vision front, the project addresses the tasks of detection and classification with side textual information. The project investigates models for the shape and appearance of a general category that can specialize to different subordinates, in a way that allows interpreting information from text within a proper geometric context, and handle variability in viewpoints and articulation."
"1353400","EAGER: Collaborative Research: Establishing Trustworthy-Citizen-Created Data for Disaster Response and Humanitarian Action","IIS","Cyber-Human Systems","09/01/2013","09/04/2013","Andrea Tapia","PA","Pennsylvania State Univ University Park","Standard Grant","Kevin Crowston","08/31/2015","$70,000.00","Anna Squicciarini","atapia@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7916","$0.00","Often referred to as microblogging, the practice of average citizens reporting on activities ""on-the-ground"" during a disaster is increasingly common. The contents of these message are potentially valuable to responder organizations and victims, but their volume makes it difficult to separate valuable messages from the stream. This project will examine microblogged messages sent during disasters to determine what aspects of the messages (individually and collectively) indicate that they are relevant, verifiable and actionable. Factors to be considered include the content of the messages, the identity of the sender and the overall pattern and spread of messages. The identified factors will then be used to instruct crowdsourced workers who will label messages to create a large corpus of labelled messages. <br/><br/>The project is important because microblogging data are seen as increasingly important: they are ubiquitous, rapid and accessible, and they are believed to empower average citizens to become more situationally aware during disasters and to coordinate to help themselves. The result of the project, if it is successful, will be evidence that it is possible to identify relevant, verifiable and actionable messages from a stream of microblogged messages and identification of the evidentiary factors. A further outcome will be a disaster-related, labeled dataset of messages, which will be useful to researchers, e.g., those seeking to automatically classify information within a microblogged data stream."
"1018637","III:Small:Transactional Data Stores in the Cloud","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","08/25/2011","Divyakant Agrawal","CA","University of California-Santa Barbara","Continuing grant","Frank Olken","07/31/2015","$515,336.00","Amr El Abbadi","agrawal@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7923, 9251","$0.00","Cloud computing has emerged as a powerful paradigm for hosting Internet scale applications in large computing infrastructures due to their desirable features of unlimited resources and infinite scalability, pay-per-use model requiring no up-front investment, elasticity of resources, and fault-tolerance. Since one of the primary goals of the cloud is to host data-intensive applications, large-scale data management is a crucial component. Traditional relational databases have been extremely successful but lack scalability, elasticity, fault-tolerance, and self-management features that are required in cloud settings. This has led to the emergence of a new storage model referred to as the key-value store model. Although key-value stores have the desired features, they provide minimal consistency and reduced functionality due to their single-key access guarantees thus placing unprecedented burden on application developers. This project explores two alternative scalable data stores designs in the cloud -- ElasTraS: an elastic transactional data store targeted towards enterprise applications requiring a relational storage model; and G-Store: a transactional multi-key value store targeted for applications which favor the data model of key-value stores, but require consistent and scalable access beyond single keys. This project brings forth many novel research solutions for designing and implementing scalable data management systems, and acts as a building block for developing commodity solutions dealing with the growing scale of the Internet. The project enables both graduate and undergraduate students to be trained in the design and development of software and solutions for large-scale distributed systems. The project URL is available at: http://www.cs.ucsb.edu/~dsl/?q=cloud-transactions."
"1053407","CAREER: New Approaches for Ranking in Machine Learning","IIS","ROBUST INTELLIGENCE","09/01/2011","06/16/2014","Cynthia Rudin","MA","Massachusetts Institute of Technology","Continuing grant","Todd Leen","08/31/2016","$407,295.00","","rudin@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","1045, 1187","$0.00","In numerous industries, decisions are based on large amounts of data, where a ranked list of possible actions determines how limited resources will be spent. Over the last decade, machine learning algorithms for ranking have been designed to address prioritization problems. These algorithms rank a set of objects according to the probability to possess a certain attribute; for example, we might rank a set of manholes in order of their probability to catch fire next year. However, current algorithms solve ranking problems approximately rather than exactly, and these approximate algorithms can be slow; furthermore they do not take into account many application-specific problems.<br/><br/>The goals of this project include: <br/><br/>I) Finding exact solutions to ranking problems by developing a toolbox of algorithmic techniques based on mixed-integer optimization technology. <br/><br/>II) Finding solutions faster by showing a fundamental equivalence of ranking problems to easier classification problems that can be solved an order of magnitude faster. <br/><br/>III) Developing frameworks for new structured problems. The first framework pertains to ranking problems that have a graph structure that are relevant to the energy domain. The second framework handles a sequential prediction problem arising from recommender systems, with applications also in the medical domain.<br/><br/>Through collaboration with industry, the proposed methods are being applied in several different areas, including the prevention of serious events (fires and explosions) on NYC's electrical grid."
"1202141","CAREER: Enabling Community-Scale Modeling of Human Behavior and its Application to Healthcare","IIS","ROBUST INTELLIGENCE","10/01/2011","06/13/2014","Tanzeem Choudhury","NY","Cornell University","Continuing grant","James Donlon","02/28/2015","$440,125.00","","tanzeemc@gmail.com","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495","1045, 1187, 9102, 9150, 9215, HPCC, 7495, 9251","$0.00","Research supported by this award is developing community-based methods for sensing, recognizing, and interpreting human activities from body-worn sensors. Specifically, this research is<br/><br/>1) developing systems that learn new classes of activity with minimal human supervision, where the system queries a human user for additional information on an activity being learned, but only when such queries are informationally necessary and behaviorally unobtrusive,<br/><br/>2) developing the paradigm of community-guided learning, which leverages people's social ties and behavioral similarities, in order to define an efficient scheme for sharing various aspects of the underlying activity classes across many individuals, and<br/><br/>3) evaluating the new community-guided learning methods by using them to learn about (a) social isolation and functional independence among elderly persons, and (b) social interaction among high-functioning autistic children.<br/><br/>Speaking generally, the research is advancing machine learning and artificial intelligence, especially in the areas of semi-supervised, active, and relational learning. Beyond these basic scientific contributions, the resulting research has the potential to transform community health assessment by collecting fine-grained clinically-relevant information continuously, cheaply, and unobtrusively, over long periods of time. This research also opens up many opportunities for education and outreach, in part because it is pushing machine learning and artificial intelligence into social and societally-important realms, promising to attract groups, notably women, who are under-represented in computer science."
"1439946","III: Student Travel Fellowships: 2014 Web Reasoning and Rule Systems Conference and Reasoning Web Summer School","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/13/2014","Pascal Hitzler","OH","Wright State University","Standard Grant","Frank Olken","05/31/2015","$12,000.00","Krzysztof Janowicz","pascal.hitzler@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7364","7364, 7556","$0.00","Semantic technologies, Linked Open Data, and knowledge representation formalisms such as the Web Ontology Language OWL are beginning to play increasingly important roles across a broad range of applications. There is an urgent need for the advanced training of graduate students to conduct research in this area and to prepare them for academic or industrial careers. Participation in premier research conferences in the area is an essential element of such training. This project will provide funds to subsidize the travel expenses of 6 students at U.S. universities to attend the 2014 Web Reasoning and Rules Systems conference, RR2014, and the 2014 Reasoning Web Summer School, which will be held September 8-17 in Athens, Greece. Broader impacts of the project include: Enhanced opportunities for training and mentoring of US-based graduate students in Semantic Web and related areas, broadening the participation of students from groups (women and minorities) that are currently under-represented in Computer Science in general, and Semantic Web in particular.<br/><br/>The Web Reasoning and Rule Systems conference series, established in 2007, and the annual Reasoning Web Summer School series, attract the leading researchers in the field of Web Reasoning, and offer a venue for presentation of the latest advances in the field. Covered topics include ontology modeling languages, e.g., RDF, OWL, and RIF, which enable the inference of implicit knowledge from knowledge that is explicitly encoded in the knowledge base. Web Reasoning and related fields focus on the design, analysis, and development of ontology languages, study of their theoretical properties, and the design and implementation of effective inference algorithms. The co-location of the conference and summer school provides for an excellent venue for the training of graduate students. In addition to attending the invited and contributed talks at the conference, and the summer school, the students will benefit from individualized mentoring by established researchers. <br/><br/>For further information see the project webpage: http://pascal-hitzler.de/projects/rr2014.html"
"1441741","Student Travel Grant: 2014 Principles of Knowledge Representation and Reasoning Conference and Doctoral Consortium","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/13/2014","Chitta Baral","AZ","Arizona State University","Standard Grant","Frank Olken","05/31/2015","$15,000.00","Adrian Pearce, Birte Glimm, Marco Maratea","chitta@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7364, 7556","$0.00","This project will support travel grants to students from the US to attend the Doctoral Consortium of the 2014 Principles of Knowledge Representation and Reasoning (KRR) conference to be held in Vienna, Austria. The field of Knowledge Representation and Reasoning is important to build intelligent computer systems and in recent years it has been highlighted with respect to initiatives and successes such as the Semantic Web and the Watson system. However, with respect to some measures (such as percentage of papers submitted), the USA has fallen behind other countries, in this field. Recognizing this and the importance of KRR, a Workshop on Research Challenges and Opportunities in Knowledge Representation was organized by NSF in February 2013. The KRR conference series, established in 1989, is the premiere conference in this field. This award will enable US students to meet and interact with the top researchers in the field of KRR. This will have a long term impact on developing qualified researchers in the USA in this field and this will have further impact on both the academia and industries in the USA.<br/><br/>This award will address a bottleneck in student education in the field of Knowledge Representation and Reasoning (KRR). The PIs are among the main drivers of the conference series. They are established researchers with high visibility and proven track record of successful student mentoring. The KRR conference is a premier event attended by prominent researchers in the area. This award will help the students supported by the award to be better researchers in the field of KRR. This field is not only important to building Intelligent Systems, but has implications in many related areas such as: Event recognition in video analysis, Question answering, Machine reading, and Analysis of big mechanisms. <br/><br/>For further information on the 2014 KRR conference see the conference web page: <br/>http://www.kr.tuwien.ac.at/events/kr2014/"
"1404673","SHB: Medium: Collaborative Research: Crafting a Human-Centric Environment to Support Human Health Needs","IIS","Smart and Connected Health, INFO INTEGRATION & INFORMATICS","08/31/2013","06/13/2014","Sajal Das","MO","Missouri University of Science and Technology","Standard Grant","Sylvia J. Spengler","08/31/2015","$235,919.00","","sdas@mst.edu","300 W 12th Street","Rolla","MO","654096506","5733414134","CSE","8018, 7364","7924, 8018, 7364, 9251, 9150","$0.00","Researchers and providers alike are recognizing that human-centric smart environments can provide health monitoring services and support aging in place through adaptive interventions. The need for the development of such technologies is underscored by the aging of the population, the cost of formal health care, and the importance that individuals place on remaining independent in their own homes. The goal of this project is to design, implement, and evaluate in-home techniques for generating reports of activities and social interactions that are useful for monitoring well being and for automating intervention strategies for persons with dementia. The plan is to design machine learning techniques that make effective use of sensor data to perform automated activity monitoring and prompting-based interventions that are beneficial for the residents as well as for their caregivers and family. The environment is human-centric because it learns information about its human residents and uses this information to provide activity-aware monitoring and intervention services. By transforming everyday environments into smart environments, many older adults with cognitive and physical impairment can lead independent lives in their own homes. A key component of this project is an evaluation of the technologies in actual homes with volunteer older adults and thus will assess the technologies for acceptance with the target population. <br/><br/>This project addresses NSF?s Smart Health and Wellbeing goal of leveraging computational expertise leading to fundamental advances in the development of algorithms to create improvements in safe, effective, and patient-centered health and wellness services. Through design of a Gerontechnology class we are training students to design and use these technologies. This effort includes REU and IGERT students in the research project, which involves students from underrepresented groups in this multidisciplinary, collaborative effort. To facility community-wide use, comparison and collaboration, all of our datasets, tools, and course materials will be disseminated from our project web page."
"1010336","CRCNS: Data Sharing: A Joint Database of Experiments and Models of Reaching Movement","IIS","CRCNS, ROBUST INTELLIGENCE, PERCEPTION, ACTION & COGNITION","09/15/2010","06/13/2014","Konrad Kording","IL","Rehabilitation Institute of Chicago","Standard Grant","Kenneth C. Whang","08/31/2014","$425,000.00","Kurt Thoroughman, Lee Miller, Ostry David","kk@northwestern.edu","345 East Superior Street","Chicago","IL","606112654","3122384534","CSE","7327, 7495, 7252","7327","$0.00","Experiments in which subjects reach from one point to another are one of the workhorses of movement science. Many questions ranging from basic neuroscience (How do neurons represent movement?) to clinical (How do patients with Parkinson's Disease move differently from healthy controls?) to behavioral (How does loud noise lead to movement errors?) are studied using this paradigm. Moreover, many models have been constructed to describe reaching, and these models have strong links to robotics and computer science. This project will develop a database that contains both experimental results as well as models of reaching movement. The database will make it easier for experiments to falsify models and for models to be designed so that they overcome the limitations of previous models. <br/><br/>The objective of the joint database design is that multiple models should be able to make predictions for a given experimental dataset, and likewise, multiple experimental datasets can be used to constrain a given model. The project will start with a relatively narrow set of experiments and models, widening the scope gradually over the course of the project. Research on reaching spans a broad set of questions and a broad set of experimental methods; however, many experimental approaches share significant aspects. The objective of the project is to enable inclusion of the results of a broad set of communities while keeping the database sufficiently coherent to be useful. <br/><br/>To enable the inclusion of a broad set of participants who will share models and data the proposed project will include summer schools, workshops and competitions where participants can compare models. Access to the database will be free and open, and this possibility of access to high quality data promises to allow scientists from any movement related discipline to productively interact with movement data and models."
"1405634","CHS: Medium: Understanding and designing for online disclosure and its effects on well-being","IIS","Cyber-Human Systems","06/15/2014","06/13/2014","Natalya Bazarova","NY","Cornell University","Continuing grant","Kevin Crowston","05/31/2018","$285,053.00","Daniel Cosley, Janis Whitlock","nnb8@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7924","$0.00","From mundane details of daily life to tragic warnings of planned suicide, people exchange a massive amount of personal information in social media that defies traditional models of self-disclosure. This project will advance understanding of personal information disclosure in social media contexts and will use this information to develop well-being interventions designed to enhance self-reflection and capacity to productively seek and offer support. Such interventions benefit individuals and society overall by helping people know how and from where to seek support in informal and formal social networks. Knowledge about key drivers of self-disclosure will also be useful in improving the design of other systems that use personal data and will inform public discussions about the use and risks of personal information online. The PIs will work to raise awareness of disclosure benefits and risks through users' participation in experiments, use of systems, and publicizing research results beyond the research community, e.g., by working to move research results into practical applications through the Bronfenbrenner Center for Translational Research at Cornell.<br/><br/>More specifically, this research will yield a multi-theoretical and multi-level model of how individual attributes such as personality and mental health status, technological affordances such as reviewability and audience visibility, and social network properties such as size, density, diversity, and tie strength, individually and in combination, shape anticipated rewards and risks of disclosure and disclosure strategies. These models will incorporate responses by network members into the production cycle of disclosure, and examine how these combined characteristics determine both anticipated and actual outcomes. The researchers will collect examples of actual disclosure behaviors in both text and photos, annotated with information about people's disclosure goals and perceptions, individual characteristics, and social networks, and will use these to validate predictive models of the presence of and responses to disclosure in social media data. These models will help identify when people create meaningful content, which in turn can be used in systems and interventions that support the well-being of social media users, both in the general population and those at risk. These systems and interventions will operate by using disclosed information to facilitate reflection, enrich existing positive psychology interventions, and promote awareness of and effective responses to disclosure and mental health needs."
"1445930","Student Travel Grants for 2014 ACM Multimedia Conference","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","06/15/2014","06/13/2014","JungHwan Oh","TX","University of North Texas","Standard Grant","Jie Yang","05/31/2015","$10,000.00","","Junghwan.Oh@unt.edu","1155 Union Circle #305250","DENTON","TX","762035017","9405653940","CSE","1640, 7495","1640, 7495, 7556","$0.00","This student travel grant supports graduate/undergraduate students enrolled in US institutions to attend ACM Multimedia 2014 conference. ACM Multimedia is the worldwide premier conference in the multimedia field, covering latest technical papers, technical demos, grand challenge competition, open source software competition, doctoral symposium. It is extremely valuable for US students to take advantage of the unique research and education programs provided by this conference. Participation in such event allows students to learn/experience innovative research, develop professional networks, and interact with industry and academia leaders involved in practical applications and technology transfer. <br/><br/>ACM Multimedia conference offers various activities which particularly benefit students who are involved in research in this area. First, it hosts a Doctoral Symposium which will provide PhD students to present their ongoing work and receive feedback from established researchers. This also aims to establish a supportive worldwide community, and build professional networks for PhD students. Second, Multimedia Grand Challenges presents a set of problems and issues from industry leaders, geared to engage the Multimedia research community in solving relevant, interesting and challenging questions about the industry's 3-5 year vision for multimedia. Third, the ACM Multimedia Open-Source Software Competition is designed to promote the contribution of freely available resources, which advance the field by providing a common set of tools for building and improving multimedia research prototypes. Finally, the large Technical Demonstration session is intended as real, practical, and interactive proof of the presenters' research ideas and scientific or engineering contributions. This session allows students to demonstrate their own novel research prototypes, and also to view and interact first hand with live evidence of innovative solutions and ideas in the field of multimedia."
"1116051","HCC: Small: MobileAccessibility: Bridge to the World for Blind, Low-Vision, and Deaf-Blind People","IIS","Cyber-Human Systems","08/01/2011","06/27/2013","Richard Ladner","WA","University of Washington","Continuing grant","Ephraim P. Glinert","07/31/2015","$516,000.00","Jeffrey Bigham","ladner@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7923, 9251","$0.00","More than 160 million blind, low-vision, and deaf-blind people worldwide have not realized the full potential of the mobile revolution. People in these groups often use special-purpose portable devices to solve specific accessibility problems, such as obtaining product information from bar codes, finding location information via GPS, and accessing printed text using optical character recognition (OCR). Unfortunately, devices targeted at these groups are specialized for one or few functions, usually not networked, and expensive. Devices also target one disability, thereby preventing a deaf-blind person from, for instance, using a device designed for a low-vision person. Blind, low-vision, and deaf-blind people who can afford it must carry multiple devices with varying interfaces. This is despite the fact that many mainstream mobile devices already have the necessary sensors, such as a camera, microphone, GPS locator, accelerometer, and compass, to provide all of these functions on one device. MobileAccessibility is the PI's approach to providing useful mobile accessible functionality to blind, low-vision, and deaf-blind users. This approach leverages a smart phone's sensors, multi-modal output, and access to remote services to reduce the cost of existing accessibility solutions and enable completely new ones to be created. Some key user interaction problems for these groups of users that will be addressed in this project include: (i) how can a blind, low-vision, or deaf-blind person effectively use the camera on a smart phone to achieve an accessibility goal, (ii) how can enlarged presentations be effectively navigated by a low-vision person on the small screen of a smart phone, (iii) how can vibration be effectively used to convey information to a blind or deaf-blind person, (iv) how can valuable network services be best utilized by these communities, (v) how can the knowledge of one person about their environment be effectively captured, stored, and used among these communities. The user-centered design of these applications will involve blind, low-vision, and deaf-blind people throughout their development. Prototype applications to provide context to the research questions will be built for all three groups. Input will use speech recognition, the touch screen, and the keyboard. Output will be audio for blind users, enlargement for low-vision users, and vibration and tethering to Braille devices for deaf-blind and blind users. The resulting interfaces will be evaluated both in the lab and in the field. There will a focus on identifying common interaction techniques that can be employed by multiple applications.<br/><br/>Broader Impacts: This research represents a new paradigm in mobile assistive technologies where a single programmable device can serve a multitude of accessibility needs. Rather than using separate devices for different needs, accessibility solutions can be downloaded to a single device. The research challenge is to design, build, and evaluate novel accessibility solutions in this new paradigm. A mobile phone that can accomplish multiple accessibility tasks has the potential to provide the target communities with more independence than they have currently. Furthermore, the MobileAccessibility solution has the potential to be inexpensive and more sustainable than current accessibility solutions. Qualified students with disabilities will be recruited as researchers, giving them a chance to participate in work directly affecting them. New project-oriented curricula based on MobileAccessibility will be created."
"1445656","Support for the Academic and Research Leadership Symposium at the National Society of Black Engineers Convention","IIS","INFO INTEGRATION & INFORMATICS","07/01/2014","06/13/2014","William Robinson","TN","Vanderbilt University","Standard Grant","Sylvia J. Spengler","06/30/2015","$49,957.00","","william.h.robinson@vanderbilt.edu","Office of Sponsored Programs","NASHVILLE","TN","372407830","6158756070","CSE","7364","7364, 7484, 7556, 9102, 9150","$0.00","Computer science and engineering must diversity its workforce to meet the future demands for the technical professions. professional development for minority scholars to meet the anticipated needs in the technical workforce. Racial and ethnic minority groups, including African Americans, Hispanics, and Native Americans, remain substantially underrepresented in engineering and science, especially at the level of Ph.D. researchers and faculty. The Academic and Research Leadership Symposium (ARLS) is a symposium that is co-located with the Annual Convention of the National Society of Black Engineers (NSBE). The purpose of the ARLS is to develop minority engineers in academia, industry, and government laboratories, whose careers involve a strong focus on research, in order to prepare them for leadership and success in their chosen discipline. The ARLS has two threads: (1) a faculty development thread, and (2) a researcher development and networking thread. It provides an opportunity for seasoned researchers (university, corporate, government) to nurture connections with their peers, and be excited and inspired by the latest discoveries and technical advances across many disciplines of engineering and science. Opportunities for new collaborations and strategic career advancements are anticipated. The researcher development and networking thread consists of a networking reception with a keynote presentation by a high-profile researcher, a session on career development in an R&D centric environment (e.g., The Researcher Entrepreneur and Senior Leadership Strategies), and a poster session organized by members of the ARLS network for more in-depth technical discussions."
"1439292","III: Travel Fellowships for Students from U.S. Universities to Attend ISWC 2014","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/13/2014","Pascal Hitzler","OH","Wright State University","Standard Grant","Frank Olken","05/31/2015","$20,000.00","Krzysztof Janowicz, Michelle Cheatham","pascal.hitzler@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7364","7364, 7556","$0.00","Semantic technologies are beginning to play increasingly important roles across a broad range of applications. There is an urgent need for advanced training of graduate students to conduct research in this area and prepare for academic or industrial careers. Participation in premier research conferences in the area is an essential element of such training. This project will provide funds to subsidize the travel expenses of 10-15 students at U.S. universities to attend the 2014 International Semantic Web Conference (ISWC) which will be held October 19-23, 2014 in Riva del Garda, Italy. Broader impacts of the project include: Enhanced opportunities for training and mentoring of US-based graduate students in Semantic Web and related areas, broadening the particiation of students from groups (women and minorities) that are currently under-represented in Computer Science in general, and Semantic Web in particular.<br/><br/>ISWC is a premier international conference which offers a venue for the presentation of rigorously peer-reviewed research results in Semantic Web and related areas. The conference includes two events specially targeted to graduate students: The ISWC doctoral consortium offers an opportunity for doctoral students to present their work and receive feedback and mentoring. The ISWC Career Mentoring lunch provides an informal setting for students to discuss all issues pertaining to research careers with senior researchers in the community, and to establish long-term mentoring ties. This project will enhance the professional development of the participating students, by not only exposing them to the latest research ideas, but also by establishing connections with and receiving feedback from top international researchers.<br/><br/>For further information see the project webpage: http://pascal-hitzler.de/projects/iswc2014.html"
"1319874","RI: Small: Collaborative Research: Bio-inspired Collaborative Sensing with Novel Gliding Robotic Fish","IIS","ROBUST INTELLIGENCE","08/01/2013","06/12/2014","Fumin Zhang","GA","Georgia Tech Research Corporation","Continuing grant","Satyandra Gupta","07/31/2016","$171,026.00","","fumin@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7923, 7218","$0.00","Monitoring and understanding aquatic environments is critical to water sustainability. The goal of this award is to establish a theoretical framework and provide an enabling technology for robust underwater collaborative sensing with small, inexpensive robots. Inspired by the source-seeking behavior of live fish, computationally efficient algorithms are developed for cooperative tracing of the gradients of environmental fields, and their robustness is analyzed in the presence of localization error and changing communication topology. The algorithms are experimentally validated in thermal source seeking and tracing with a group of energy-efficient and highly maneuverable gliding robotic fish, which are enhanced in this project with optical communication and localization capabilities. Advanced controllers are developed for these robots to realize three-dimensional maneuvering and to track reference paths planned through collaborative sensing algorithms. This award offers fundamental understanding of limits and robustness properties of collaborative sensing by resource-limited robots, and contributes to the knowledge base in underwater communication and ranging for small robots. It enables technological advances for persistent sampling of versatile aquatic environments including coastal waters, lakes, and rivers, with a myriad of applications such as oil spill response, ecological monitoring, and port and drinking water security. The findings from this project are disseminated through publications, software sharing, and technology commercialization. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Outreach activities, including museum/aquarium exhibits and teacher training, are developed to pique the interest of K-12 students, teachers, and the public in science and engineering."
"1143921","EAGER: Automatic Document and Record Disposition and Retention","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/23/2011","C. Giles","PA","Pennsylvania State Univ University Park","Standard Grant","Maria Zemankova","07/31/2015","$200,000.00","","giles@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7364","7916, 7364","$0.00","Record and document retention (document disposition) has become a serious problem for both organizations and individuals since most documents now created are digital. Digital documents offer both problems and advantages. Digital documents are easily versioned, copied and disseminated. Thus, there can be several similar copies or versions of important or relevant documents in many locations. Document or record disposition can be applied to or is needed by individuals, organizations and domains (such as law, science, policy, etc.) for effective information management over long periods of time. This problem is of epic proportions and is becoming a major problem in organizations and for individuals throughout the world where effective record disposition is either required by law or by the organization or by practical limitations in systems.<br/><br/>This exploratory project investigates possible automatic document disposition methods based on algorithms for text inspection, mining, and search. The challenges lie in finding scalable, adaptable algorithms that can be used in several if not all application domains. In addition, variability in users presents many problems. A disposition method or procedure may vary depending on the user, organization and domain (e.g., law, health records, etc.). The approach explored in this project applies and extends machine learning methods to these problems since these methods adapt to variability in data, areas and domains. Using such approaches, automated disposition methods can be readily applied to these different areas such as science, email and legal records. This research lays the groundwork for adaptive methods for a variety of domains in terms of applicability, performance and scalability. this proof-of-concept project initially focuses on the Enron email data set that is publicly available and is be used to demonstrate the feasibility of the approach since email can be considered a special case of document disposition. If successful, other disposition domains such as science and government data will be explored. This work will show the viability of developing and applying machine learning methods to an important and diverse problem domain. <br/><br/>The results from this exploratory project together with insights gathered from methods used in large scale document search are expected to yield understanding as to how we can better manage our digital past and the rapidly expanding digital future. The results are expected to introduce this important problem to other researchers and document disposition professionals and lead to collaborations with industry. Data and research results will be made available through a publicly available website (http://clgiles.ist.psu.edu/disposeseer/) and research papers will be published and presented in appropriate venues. The project provides research experience for graduate and undergraduate students."
"1115153","III: Small: Real-World Traffic Data Management for Time-Dependent Spatial Queries","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","03/14/2012","Cyrus Shahabi","CA","University of Southern California","Standard Grant","Frank Olken","07/31/2015","$515,612.00","","shahabi@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7364","7923, 9251","$0.00","The two most important commodities of the 21st century are time and energy; traffic congestion wastes both. Several disciplines have studied the traffic congestion problem using mathematical models, simulation studies and field surveys. Recently, due to the sensor instrumentation of road networks and the availability of commodity sensors from which traffic information can be derived (e.g., CCTV cameras, GPS devices), a large volume of real-time traffic data at high spatiotemporal resolutions has become available. These data lay the ground for better understanding of the transportation network and for new applications.<br/><br/>The first objective of this project is to study the efficient acquisition and storage of traffic data. In particular, at the acquisition time, compact traffic patterns and outliers are constructed from raw data in real-time, supporting fast queries with approximate results and error bounds. The second objective is to utilize the traffic patterns to enable two critical query types that are building blocks of several important applications in time-dependent road networks: 1) shortest travel-time computation, and 2) k-nearest-neighbor search.<br/><br/>The broader impact of this project is to bring large amount of historical and real-time traffic data at the fidelities unseen before to the fingertip of transportation engineers, policy makers and end-users. This in turn enables them to alleviate one of the major problems of megacities, the main societal fabrics of the 21st century. Research results are incoporated into courses on Database Systems and Geospatial Information Management taught at University of Southern California and are also disseminated through papers published in conferences and journals. Details about the project including publications and open-source code are available at the project website: http://infolab.usc.edu/projects/TransDec/."
"1318971","RI: Small: Hierarchical Feature Learning by Heterogeneous Networks with Application to Face Verification","IIS","ROBUST INTELLIGENCE","09/01/2013","06/12/2014","Thomas Huang","IL","University of Illinois at Urbana-Champaign","Continuing grant","Jie Yang","08/31/2015","$408,612.00","","huang@ifp.uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","7495, 7923","$0.00","Learning good features is a key to computer vision problems such as recognizing human faces, and understanding scenes. Many computer vision researchers learn features by providing a semantic label for each image in a large database, limiting the amount of information per image to a few bits. Others learn features by identifying common patterns found in images such as lines, blobs, and more complicated shapes, but ignoring semantic information. This project develops algorithms to learn features that are common in images and also predict the semantics of images at various spatial scales using a new type of deep neural network called Heterogeneous Networks. The developed algorithms allow the incorporation of semantic information at intermediate layers. The algorithms developed can not only change how features are learned but also indicate how to scale feature learning to giant datasets of millions of images. The research team addresses challenging problems in human face verification using NCSA's petascale supercomputer, Blue Waters, and two large scale (millions of images) image data sets. <br/><br/>The research of this projected is integrated with both undergraduate and graduate education. The results obtained from this project are applicable to a wide range of applications in computer vision and pattern recognition. The research team plans to release algorithms and face data sets collected in this project to research communities once they are finished."
"1360566","RI: Small: Unsupervised Object Class Discovery via Bottom-up Multiple Class Learning","IIS","ROBUST INTELLIGENCE","07/01/2013","06/12/2014","Zhuowen Tu","CA","University of California-San Diego","Continuing grant","Jie Yang","08/31/2015","$420,029.00","","zhuowen.tu@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7495","7923, 7495","$0.00","This project develops an integrated framework to perform simultaneous object discovery and detector training in an unsupervised setting. It takes advantages of large amount (millions or even billions) of well-organized internet images to automatically learn rich image representations for a wide range of objects. The main activities in this project include the following. (1) The central component of this project is a formulation to turn unsupervised data into weakly-supervised ""noisy input"" through which commonalities are explored for rich object representation using a new learning method. (2) A large dictionary of mid-level image representations will be learned on a large scale number of images retrieved using thousands of object words through the internet search engine. (3) A new flexible object representation is developed to deal with articulated/non-rigid objects.<br/><br/>The project advances computer vision and machine learning fields by developing an unsupervised paradigm to explore a large scale of internet images. The learned mid-level and high-level representations from images retrieved using thousands of words can significantly enhance the object representation power and benefit researchers in the object recognition field. The formulations, algorithms, and methods resulted from this project are also helpful to researchers in other fields such as medical imaging and data mining. The project dissemination plan includes the source code and learned mid-level and high-level representations."
"1219253","RI: Small: Incremental Speech Processing for Rapid Dialogue","IIS","ROBUST INTELLIGENCE","09/01/2012","06/18/2013","David DeVault","CA","University of Southern California","Continuing grant","Tatiana D. Korelsky","08/31/2015","$457,984.00","David Traum, Kenji Sagae","devault@ict.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7923, 7495, 9251","$0.00","This project develops incremental language processing techniques to enable spoken dialogue systems to communicate in a way that is more highly interactive, more efficient, and more human-like. Most previous dialogue systems have employed a strict turn-taking regime in which one person speaks at a time, no attempt is made to understand or respond to speech until the speaker finishes speaking, and the overall latency in system responses is high in comparison to human-human conversation. This results in systems that are unable to provide a range of rapid and overlapping responses that human interlocutors frequently use to achieve an efficient and successful communication process, including back-channels, interruptions, collaborative completions, clarifications, and other rapid responses. This project is a computational and empirical investigation into how a system's assessment of its own incremental understanding of ongoing user speech can guide its strategic decisions to initiate such rapid and overlapping responses. The feature representations and response policies that can implement this decision-making are studied in the context of two fast-paced interactive dialogue games. These games are carefully chosen to support objective evaluation of incremental response strategies and fun gameplay that facilitates large-scale data collection.<br/><br/>The resulting computational models may improve the conversational skills of a range of dialogue systems, including not only game-oriented systems but also practical applications such as intelligent tutoring and training systems, information access systems, and entertainment applications. A second product of this project is an annotated corpus of human-human and human-system dialogue data for use by other researchers. A third product is the incorporation of relevant software into a publicly distributed toolkit for building dialogue systems, supporting further research and education."
"1116394","III: Small: RanKloud: Data Partitioning and Resource Allocation Strategies for Scalable Multimedia and Social Media Analysis","IIS","INFO INTEGRATION & INFORMATICS","08/15/2011","08/18/2011","K. Selcuk Candan","AZ","Arizona State University","Standard Grant","Maria Zemankova","07/31/2015","$499,410.00","Hari Sundaram, Maria Luisa Sapino","candan@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7923","$0.00","Today, multimedia data are produced and consumed in massive quantities in a broad range of applications with significant economic and societal benefit, including e-commerce, surveillance, education, web services, and social media. Hence, there is an urgent need for systems to provide highly scalable processing and efficient analysis of large media data collections. The RanKloud prototype system, developed in this research project, focuses on the needs and requirements of applications that deal with large quantities of multimedia data in a cloud-based scalable environment. <br/><br/>Most multimedia applications share a few core operations, including integration/fusion, classification, clustering, graph analysis, near-neighbor search, and similarity search. When performed naively, however, these core operations are often very costly, because the number of objects and object features that need to be considered can be prohibitive. Avoiding this cost requires that redundant work is avoided. This research focuses on the next generation cloud-based massive media processing and analysis systems where the fundamental principles that govern their design include an awareness of the utilities of data and features to a particular analysis task. Incorporating data and feature utilities for performing a particular utility task is expected to significantly reduce the overall cost of the analysis task. The RanKloud project research plan includes: (1) data model and query language to specify multimedia data processing workflows; (2) adaptable, rank-aware parallel multimedia data processing primitives; (3) run-time data sampling strategies to support adaptation to data and resource; and (4) waste- and unbalance-avoidance strategies for utility-aware data partitioning, resource allocation, and for incremental batched processing.<br/><br/>RanKloud bridges an important gap in our understanding of cloud-based computing in general, and efficient processing of multimedia data in particular. The results are expected to enable new tools and systems supporting scalability in a large class of problems in content-aware multimedia and social media analysis with impact in web intelligence, business intelligence, and scientific and sensor applications all of which need to handle imprecise multimedia data for more effective decision making. This project provides research experience opportunities for graduate and undergraduate students and includes research results and challenges in courses, including Capstone projects. Arizona State University (ASU) recruits top-quality undergraduates through a nationally recognized residential Honors College and the Minority Access to Research Careers program. The national and international dissemination of the project results includes premier conference and journal publications, as well as open source software licenses at the RanKloud Web site (http://aria.asu.edu/rankloud)."
"1320892","RI: Small: Speaker Independent Acoustic-Articulator Inversion for Pronunciation Assessment","IIS","LINGUISTICS, ROBUST INTELLIGENCE","08/01/2013","06/10/2014","Michael Johnson","WI","Marquette University","Continuing grant","Tatiana D. Korelsky","07/31/2016","$308,498.00","Jeffrey Berry","mike.johnson@marquette.edu","P.O. Box 1881","Milwaukee","WI","532011881","4142887200","CSE","1311, 7495","7495, 7923, 9251","$0.00","To support an integrated global economy, it is essential that people of all backgrounds be able to function together effectively despite language barriers, and development of Computer Aided Language Learning (CALL) and accent modification tools is a key part of making this possible. In order to support effective learning and provide specific, useful pronunciation feedback to users, systems for pronunciation correction must be able to capture and accurately describe errors in articulation. Accurate acoustic-to-articulator inversion, the estimation of articulatory trajectories from an acoustic signal, has the potential to significantly improve the accuracy and specificity of such feedback to language learners, and enhance methods for in-depth study of both native speaker and second language learner articulatory patterns.<br/><br/>This research addresses the problem of robust speaker-independent acoustic-to-articulator inversion, which is a challenging problem due to the complexity of articulation patterns and significant inter-speaker differences. To overcome this difficulty, a novel speaker-independent inversion approach called Parallel Reference Speaker Weighting is being developed, which uses parallel acoustic-articulator adaptation to create speaker-specific models for new speakers without kinematic training data, represented in a normalized articulatory working space. The new approach is being evaluated on the Marquette University EMA-MAE Corpus of parallel acoustic / 3-D electromagnetic articulography data including both American English and Mandarin Accented English speakers. <br/><br/>The primary impact of this work focuses on the improvement of pronunciation assessment and accent modification systems, with potential for contribution to numerous other speech technologies, including speech recognition, speech coding, and audio and video synthesis."
"1017296","III: Small: Usable Databases Through Organic Technology","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/01/2010","H. Jagadish","MI","University of Michigan Ann Arbor","Standard Grant","Sylvia J. Spengler","08/31/2015","$498,521.00","","jag@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364","7923","$0.00","Database systems are valued today on account of their ability to manage complex information and efficiently process queries on large data sets. However, they are difficult to use, requiring careful design of database structure, and precise specification of queries to match this structure. In consequence, there is a large barrier to adoption. This project seeks to remove these burdens from the user through the notion of organic, rather than engineered, creation of both database and queries.<br/><br/>This project is developing databases that can be used even before the complete structure is specified. In the beginning, before much information is added, there may even be no structure at all. Over time, the user will be able to grow and evolve the structure organically as data is added and needs change. This project is also developing querying techniques for databases that reduce the burden on the user to specify a query exactly, and to know both the structure of the database being queried and the desired structure of the query result. This project, in contrast, will allow users to state an information need incrementally. Rather than structuring the result at the time of query specification, the user will be able to manipulate and structure the result set. These benefits are accomplished through the use of a presentation data model, which is implemented in the database system as a full-fledged layer above the logical and physical data model layers. <br/><br/>Biomedical database applications are employed to test and refine the developed system. The research results are expected to greatly improve the way databases are used by both technical and non-technical users and to influence a generation of research in data management. Additional information about the project is available at http://www.eecs.umich.edu/db/usable/."
"1017225","III: Small: TROn - Tractable Reasoning with Ontologies","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","06/10/2014","Pascal Hitzler","OH","Wright State University","Continuing grant","Frank Olken","08/31/2015","$485,223.00","","pascal.hitzler@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7364","7364, 7923, 9251","$0.00","The Semantic Web is based on describing the meaning ? or<br/>semantics ? of data on the Web by means of metadata ? data describing<br/>other data ? in the form of ontologies. The World Wide Web Consortium<br/>(W3C) has made several recommended standards for ontology languages<br/>which differ in expressivity and ease of use. Central to these<br/>languages is that they come with a formal semantics, expressed in<br/>model-theoretic terms, which enables access to implicit knowledge by<br/>automated reasoning.<br/><br/>Progress in the adoption of reasoning for ontology languages in<br/>practice is currently being made, but several obstacles remain to be<br/>overcome for wide adoption on the Web. Two of the central technical<br/>issues are scalability of reasoning algorithms, and dealing with<br/>inconsistency of the ontological knowledge bases. These two issues<br/>are being addressed in this project.<br/><br/>The scalability issue has its origin in the fact that the expression<br/>of complex knowledge requires sophisticated ontology languages, like<br/>the Web Ontology Language OWL, which are inherently difficult to<br/>reason with ? as witnessed by high computational complexities, usually<br/>ExpTime or beyond. This project builds on recent new developments in <br/>polynomial time languages around OWL in order to remedy this. <br/>In particular, in this project efficient algorithmizations and tools are <br/>developed for the largest currently known polynomial-time ontology language, <br/>called ELP. Reasoning with knowledge bases with expressivity beyond ELP is<br/>enabled through approximating these knowledge bases within ELP.<br/><br/>The inconsistency issue has its origin in the fact that large knowledge<br/>bases, in particular on the web, are usually not centrally engineered,<br/>but arise out of the merging of different knowledge bases with<br/>different underlying perspectives and rationales. <br/>In this project tools are developed for efficient, i.e., <br/>polynomial-time reasoning with inconsistent ontologies.<br/><br/>The concrete outcome of the project is an open source reasoning<br/>system which is able to reason efficiently with (possibly)<br/>inconsistent knowledge bases around OWL, in at least an approximate<br/>manner. <br/><br/>For further information see the project web page at <br/>http://knoesis.wright.edu/faculty/pascal/projects/tron.html"
"1065154","HCC: Medium: Bringing Brain-Computer Interfaces into Mainstream HCI","IIS","Cyber-Human Systems","06/01/2011","04/14/2013","Robert Jacob","MA","Tufts University","Continuing grant","Ephraim P. Glinert","05/31/2015","$935,524.00","Matthias Scheutz, Sergio Fantini","jacob@cs.tufts.edu","20 Professors Row","Medford","MA","021555807","6176273417","CSE","7367","7367, 7924","$0.00","Brain-computer interfaces (BCI) have made dramatic progress in recent years. Their main application to date has been for the physically disabled population, where they typically serve as the sole input means. Recent results on the real-time measurement and machine learning classification of functional near infrared spectroscopy (fNIRS) brain data lead to this project, in which the PI and his team will develop and evaluate brain measurement technology as input to adaptable user interfaces for the larger population. In this case, brain input is used as a way to obtain more information about the user and their context in an effortless and direct way from their brain activity, which is then used to adapt the user interface in real time. To accomplish this a multi-modal dual task interface between humans and robots will be introduced, which will serve as a particularly sensitive testbed for evaluating the efficacy of these new interfaces.<br/><br/>The project will create and study these new user interfaces in domains where the effect on task performance of introducing the brain input to the interface can be measured objectively. They are most useful in demanding, high-performance, multitasking situations. Carefully calibrated multitasking applications scenarios from the team's research in Human-Robot Interaction will be employed. <br/><br/>The project will also advance the range of fNIRS brain measurements that can be applied to user interfaces. It will study a recently identified fNIRS signal obtained from the phase relationships among different regions of the scalp at low frequencies (0.1 Hz), as well as a wider range of sensor placement locations than previously examined. As these are developed into usable measurements for real-time signals with machine learning and other analysis approaches, they will be incorporated into new user interfaces.<br/><br/>Broader Impacts: The target of the research is adaptive interfaces for non-disabled users, where brain measurement is an additional source of user input. However, as the work proceeds toward making this into a more robust technology project outcomes will have promise for physically-challenged users, and ultimately they promise to improve the lives of people with severe motor disabilities."
"0953563","CAREER: Efficient and Accurate Computation for High Throughput Sequencing Related Problems in Population Genomics","IIS","INFO INTEGRATION & INFORMATICS","07/01/2010","06/10/2014","Yufeng Wu","CT","University of Connecticut","Continuing grant","Sylvia J. Spengler","06/30/2015","$512,406.00","","ywu@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","CSE","7364","1045, 9251, 1187, 9215, HPCC","$0.00","High-throughput sequencing is transforming the field of population genomics. The cost of obtaining an individual's genome via sequencing has dropped several orders of magnitude during the past decade, and may reach the so-called $1,000 genome target within the next few years. Now much attention has shifted to sequencing on a population scale. Large amount of population sequencing data has already been generated. Therefore, there is an urgent need for the development of new computational methods that work with noisy, high-throughput sequencing data to provide efficient and accurate analysis for important population genomics problems.<br/><br/>The intellectual merits of the work include the development of accurate computational methods that are capable of analyzing large-scale high-throughput sequencing data for several population genomics problems. Problems of interest include inferring genotypes, correcting sequencing errors and detecting meiotic recombination, as well as searching for disease-causing rare gene variants and other emerging applications of high-throughput sequencing. A key difference between the proposed research and many existing methods is that the proposed approaches are explicitly designed for processing large amount of high-throughput sequencing data. One particular focus is on applying combinatorial optimization techniques such as integer linear programming, which is not well-known to biologists. Probabilistic models will also be used and integrated with optimization approaches to provide efficient and accurate solutions. The expected project outcome includes efficient algorithms for the above population genomics problems, related open-source software tools, and rigorous methodologies for both theoretical and empirical evaluation of the algorithms.<br/><br/>Part of the contribution of this work to computer science is that the study of algorithms for handling short sequencing reads may contribute to the research of string matching algorithms, a problem of general interests in computer science. Noisy sequencing data motivates naturally approximate string matching and may lead to new string-based problem formulations. Due to the need of efficiency, algorithmic string processing techniques may play an important role in the proposed research. Other aspects of the proposed work are related to phylogenetic problems, which have been actively studied in computer science. Theoretical study on these algorithmic problems will be conducted to obtain rigorous results that may be of interest to computer science research community.<br/><br/>The broader impacts of the project include interdisciplinary collaboration and training, as well as educational impacts. The developed software tools will be made available freely to the multi-disciplinary research community, and are expected to enable novel biological applications of high-throughput sequencing. The PI will develop an interdisciplinary undergraduate and graduate educational curriculum at University of Connecticut. The proposed educational and outreach activities include reaching out to students with various backgrounds, and training of future researchers with unique interdisciplinary skills."
"1319700","III: Small: Integrating Crowd Sourcing, Volunteer Computing and Expert Observation to Robustly Classify Massive Quantities of Avian Nesting Video","IIS","INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","08/15/2013","06/10/2014","Travis Desell","ND","University of North Dakota Main Campus","Continuing grant","Sylvia J. Spengler","07/31/2016","$493,169.00","Susan Ellis-Felege","tdesell@cs.und.edu","University Station","Grand Forks","ND","582020000","7017774278","CSE","7364, 9150","7923, 9150, 7364","$0.00","New camera technology is allowing avian ecologists to perform detailed studies of avian behavior, nesting strategies and predation in areas where it was previously impossible to gather data. Unfortunately, studies have shown mechanical triggers and a variety of sensors to be inadequate in capturing footage of small predators (e.g., snakes, rodents) or events in dense vegetation. Because of this, continuous camera recording is currently the most robust solution for avian monitoring, especially in ground nesting species. However, continuous video footage results in a data deluge, as monitoring enough nests to make biologically significant inferences results in massive amounts of data which is unclassifiable by humans alone. This project will develop a citizen science project which combines volunteer computing, where people volunteer their computers to automatically analyze video with computer vision strategies, and crowd sourcing, where people volunteer their brain power by streaming the videos and reporting observations, to analyze over a hundred thousand of hours of avian nesting video.<br/><br/>This collaborative proposal will address the data deluge in avian research, where data acquisition rates are greatly outpacing the ability to process that data, by gathering, storing, and analyzing nest video at unprecedented scales for evaluating hypotheses about avian reproductive ecology and predator-prey interactions. The team will develop computer vision techniques based on the scale-invariant feature transform (SIFT) and speeded up robust features (SURF) algorithms and their variants capable of identifying events involving animals with cryptic coloration in uncontrolled outdoor settings for this analysis. In addition,they will use the nesting video to develop a large human annotated archival video resource for ecologists and computer vision researchers alike, generated using crowd sourced volunteer observations validated against each other and further refined by a scientific web portal for expert analysis of the volunteered responses. An enduring citizen science project combining crowd sourcing and volunteer computing to perform the analysis of the video and use it to foster public interest and involvement from K-12 classrooms, stimulating online education in STEM disciplines is also planned."
"1350133","CAREER: Scaling up Modeling and Statistical Inference for Massive Collections of Time Series","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/10/2014","Emily Fox","WA","University of Washington","Continuing grant","Frank Olken","05/31/2019","$99,342.00","","ebfox@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7364","1045, 7364","$0.00","Consider the task of predicting influenza rates at a very large set of spatial locations. Modeling each region independently does not leverage the information from related regions and can lead to poor predictions, especially in the presence of missing observations. Likewise, imagine estimating the value of every house in the United States. Capturing trends within a neighborhood is key; however, each neighborhood only has a few recent house sales. The challenges presented by these increasingly prevalent massive time series are endemic to a wide range of applications, from crime modeling for police resource allocation to forecasting consumer trends and social networks: the individual data streams often include only infrequent observations such that each alone does not provide sufficient data for accurate inferences. However, the structured relationships between them offer an opportunity to share information. A key question is how to discover these relationships. <br/><br/>This project takes a computationally-driven Bayesian nonparametric approach, trading off flexibility and scalability, to address the challenges of massive collections of infrequently observed time series. Our approaches exploit correlation among the data streams, e.g., among related regions, while enabling data-driven discovery of sparse dependencies. The multi-resolution and modular forms also allow incorporation of heterogeneous side information. Key to the success of the proposed methods is scalable Bayesian posterior inference. We focus on (i) parallel computations exploiting sparse graph dependencies, (ii) multi-resolution inference, and (iii) online algorithms for dependent data.<br/><br/>This project represents an ambitious cross-disciplinary effort, integrating ideas from machine learning, systems, engineering, and statistics. The work addresses a largely ignored question in the discussion on big data: How to cope with modeling and computational issues when the data has crucial structure across time, especially arising from individually sparse and disparate measurement sources. The tools developed will significantly broaden the scope of scientific questions that can be addressed. Results from this work will be publicly disseminated, including through open source software, and our industry partners aim to transition the technology into real-world systems. This project also involves developing (i) exciting and intensive programs harnessing existing infrastructure, UW DawgBytes, to increase the exposure of K-12 students, and especially girls, to machine learning; and (ii) curriculum training students in both statistical and computational thinking.<br/><br/>For further information, see the project website at http://www.stat.washington.edu/~ebfox/CAREER.html."
"1016921","III: Small: One Size Does Not Fit All: Empowering the User with User-Driven Integration","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","08/01/2010","K. Selcuk Candan","AZ","Arizona State University","Standard Grant","Sylvia J. Spengler","07/31/2015","$499,946.00","Keith Kintigh","candan@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7923","$0.00","Data and knowledge integration are costly processes. Consequently, most existing solutions rely on a one-size-fits-all approach, where the data are integrated upfront and then the integrated data or knowledge-bases are used as is. Such snapshot-based integration solutions, however, cannot be effectively applied when the data sources are autonomous and dynamic or when, as in most scientific and decision making applications, assumptions, beliefs, and knowledge of the domain experts are indispensable to the integration process.<br/><br/>The proposed work tackles the computational challenges underlying a user driven integration (UDI) system, keeping in mind the human constraints and challenges that underlie the technical considerations. The key technical and intellectual impacts are in algorithms and data structures that can help bridge the semantic gap between the expert user and the system through a user-driven integration process based on individual user feedback. The team will specifically investigate (a) continuously revisable data/metadata alignment through vector space embeddings and probabilistic and generative models and (b) algorithms for query processing and candidate enumeration to support feedback over graph-based models of data with alternative interpretations.<br/><br/>UDI has potential applications to many domains (such as science and business intelligence) that need user-driven integration to answer key questions over diverse data sets. In particular,UDI will be incorporated into the NSF-funded tDAR (the Digital Archaeological Record), which has the potential to transform archaeology?s scientific endeavors by enormously advancing the capacity for synthetic research. The investigation of fundamental information integration challenges will thus contribute substantially to a shared infrastructure of science and will enable crucial transdisciplinary research concerning complex systems.<br/><br/>Participation in this research by the computer science graduate students will prepare them to function effectively in multidisciplinary teams and enhance their appreciation of the associated challenges and opportunities. Use of UDI as a testbed will enable these students to experiment in scientific information management, thereby increasing their awareness of data integration and science-informatics issues. UDI We expect two graduate courses to leverage the data sets as well as the project software as an educational platform. Arizona State University also recruits top quality undergraduates through a nationally recognized residential Honors College and the Minority Access to Research Careers program and the project will involve undergraduate honors students to participate in the project. UDI will also serve as a testbed for undergraduate students through Capstone Projects."
"0916441","RI: Small: Acquisition and Modeling of Dense Nonrigid Shape and Motion","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","09/01/2009","06/10/2014","Li Zhang","WI","University of Wisconsin-Madison","Standard Grant","Jie Yang","08/31/2015","$308,250.00","","lizhang@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7453, 7495","7453, 7495, 7923, 9215, HPCC","$0.00","The objective of this project is to advance the state-of-the-art in acquiring and modeling dynamic non-rigid objects. The specific examples of non-rigid objects that the project is to focus on include: human faces, hands, soft tissues, cloths, and animals. The PI seeks to address the following two fundamental questions: (1) How can non-contact optical methods be used to measure dense 3D surface motion without physically modifying the appearance of the surface? (2) What physical and/or biological properties can be inferred from the acquired dense 3D motion data?<br/><br/>The research team addresses these two questions by two simple but general ideas, namely the space-time approach and data-driven models. The space-time approach builds upon space-time stereo, and enables accurate optical measurements of 3D surface motion, as well as automatic registration of shape sequences among different dynamic objects. The data-driven models are used for both material recognition and deformation-EMG correlation. The project has a wide range of scientific impacts, including generating data for 2D face alignment and 3D face recognition in biometrics, generating data for 3D face emotion recognition in human computer interaction, measuring human body deformation in biomechanics, modeling soft tissues for orthopedics and computer-aided surgery, and building virtual human models for entertainment and education. These scientific impacts translate into benefits to society, for example, by building more accurate biometric systems to secure our country, innovating surgery procedure to reduce health insurance cost, and creating 3D digital replicas of great teachers to make our education available anywhere, anytime, at a lower cost."
"1203450","CAREER: WE FEEL SCIENCE: We Engage with the Flexible, Experimental Environment for Learning in SCIENCE","DRL","Cyber-Human Systems, DISCOVERY RESEARCH K-12","08/15/2011","06/09/2014","Chang Nam","NC","North Carolina State University","Continuing grant","Julio E. Lopez-Ferrao","02/29/2016","$434,823.00","","csnam@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","EHR","7367, 7645","1045, 9177, SMET, 9251","$0.00","This five-year CAREER proposal aims at designing, evaluating, and implementing a learning-by-collaborating system that provides haptic, visual, and auditory feedback to students with and without visual impairments to work together in hands-on science learning opportunities. The setting and sample of the proposed study includes sighted and visually impaired students (N=120) from the Arkansas School for the Blind, the Virginia School for the Deaf and Blind, the Kansas State School for the Blind, and the Fayetteville (Arkansas) High School. The hypothesis that a haptically enhanced learning-by-collaborating system may increase the science learning of both sighted and visually impaired students guides the study and its four research questions: (1) To what extent does additional haptic feedback during collaborative hands-on practice influence students' learning performance?; (2) To what extent does additional haptic feedback during collaborative hands-on practice influence students' attitudes towards science learning?; (3) How does additional haptic feedback during collaborative hands-on practice influence students' motivation to learn?; and (4) What are the relationships among learner motivation, learning attitudes, and learning performance? <br/><br/>The study employs a research and development design consisting of three stages. The first, Synthesis and Application, allows the PI to identify the set of points of collaboration that need to be supported haptically, audibly, or both, through two group sessions with three pairs of totally blind and partially blind students per session. The second, Development and Formative Evaluation, facilitates the development of two modules on the Nature of Light (Electromagnetic Waves, and Vibrating Charges), as well as the modification of the Molecular Properties, and Heat and Temperature modules, already designed for visually impaired students only. A Design for Co-Touch software framework is used for this purpose, and quality of the interaction techniques will be assessed using internationally established standards for usability, effectiveness, efficiency, and satisfaction. All materials that visually impaired students use are provided in Braille. <br/><br/>The PI will investigate the cognitive and affective impacts of shared haptic experiences on students' science learning through the third stage, Summative Evaluation of Shared Haptic Experiences. A total of 30 pairs of visually impaired and 30 pairs of sighted students participate during this stage. The study employs a two-level-between-subjects condition to manipulate sensory feedback: visual + auditory (students will receive visual and verbal instructions on science concepts) vs. visual + auditory + haptic (students will receive haptic feedback in addition to visual and verbal). This research stage utilizes Campbell & Stanley's (1966) pretest-posttest control group design in which participants are randomly assigned to one of the two groups. <br/><br/>Instruments to be used in the study will be developed or modified and pilot-tested to determine their validity and reliability. To measure learning performance, two tests will be developed: (a) a recall and recognition test using Bloom's taxonomy, and (b) a transfer test to assess learners' ability to integrate and apply knowledge. To measure learning attitudes, the Test of Science-Related Attitudes (Fraser, 1981) will be used. To measure learning motivation, Keller's (2007) Instructional Materials Motivation Survey will be utilized. Statistical analysis (e.g., ANCOVA) will be used to control any initial differences in pretest scores between the groups. Multiple regression will be performed with the learning performance score (the sum of recall and transfer tests) as the dependent variable. Independent variables are learners' attitudes and learners' motivation."
"1419579","III: Student Travel Fellowships to ACM SIGMOD Conference 2014","IIS","INFO INTEGRATION & INFORMATICS","06/15/2014","06/09/2014","Curtis Dyreson","UT","Utah State University","Standard Grant","Frank Olken","05/31/2015","$19,850.00","Feifei Li","Curtis.Dyreson@usu.edu","Sponsored Programs Office","Logan","UT","843221415","4357971226","CSE","7364","7364, 7556, 9150","$0.00","The goal of this project is to provide a unique opportunity for database students to present their research results, learn cutting edge research, and interact with internationally recognized researchers from both academia and industry at the ACM SIGMOD 2014 Database Conference.<br/><br/>As one of the most prestigious conferences in data management research, ACM SIGMOD/PODS has contributed significantly to the advance of all aspects of data management technologies and applications since 1975. Today ACM SIGMOD is a dynamic and comprehensive program for publication, education, and interaction; and it is a leading international forum for database researchers, practitioners, developers, and users to explore cutting-edge ideas and results and to exchange techniques, tools, and experiences. <br/><br/>This project will provide partial support for students from U.S. institutions, especially female and minority students, to attend and present their research work at ACM SIGMO 2014 in Snowbird, Utah. Besides meeting with researchers from academia and industry during regular program sessions, in SIGMOD 2014 students will be able to participate in the following interactive activities as partially supported by this project: a new researcher symposium, an undergraduate research poster competition, face-to-face meetings with leading researchers, and a student mentoring workshop. These opportunities will have a long lasting impact on the future career of the participants. The broader impact is to train the future generation of leaders and workforce in the critical field of data management. <br/><br/>Further information concerning this award may be found at the SIGMOD Travel Fellowship web site: http://www.sigmod2014.org/grants3.shtml"
"1409837","RI: Medium: Collaborative Research: Models of Handshape Articulatory Phonology for Recognition and Analysis of American Sign Language","IIS","ROBUST INTELLIGENCE","06/01/2014","06/09/2014","Karen Livescu","IL","Toyota Technological Institute at Chicago","Standard Grant","Tatiana D. Korelsky","05/31/2017","$854,131.00","Gregory Shakhnarovich","klivescu@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372902","7738340409","CSE","7495","7495, 7924","$0.00","Sign languages are the primary means of communication for millions of Deaf people in the world, including about 350,000-500,000 American Sign Language (ASL) users in the US. While the hearing population has benefited from advances in speech technologies such as speech recognition and spoken web search, much less progress has been made for sign language interfaces. Advances depend on improved technology for analyzing sign language from video. In addition, the linguistics of sign language is less well-understood than that of spoken language. This project addresses both of these needs, with an interdisciplinary approach that will contribute to research in linguistics, language processing, computer vision, and machine learning. Applications of the work include better access to ASL social media video archives, interactive recognition and search applications for Deaf individuals, and ASL-English interpretation assistance.<br/><br/>This project focuses on handshape in ASL, in particular on one constrained but very practical component: fingerspelling, or the spelling out of a word as a sequence of handshapes and trajectories between them. Fingerspelling comprises up to 35% of ASL, depending on the context, and includes 72% of ASL handshapes, making it an excellent testing ground. The project addresses gaps in existing work by focusing on handshape in various conditions, including fast, highly coarticulated signing. The main project activities include development of (1) robust automatic detection and recognition of fingerspelled words using new handshape models, including segmental and ""multi-segmental"" graphical models of ASL phonological features; (2) techniques for generalizing across signers, styles, and recording conditions; (3) improved phonetics and phonology of handshape, in particular contributing to an articulatory phonology of sign; and (4) publicly released multi-speaker, multi-style fingerspelling data and associated semi-automatic annotation."
"1302134","III: Medium: Algorithms and Software Tools for Epigenetics Research","IIS","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, INFO INTEGRATION & INFORMATICS","09/15/2013","06/09/2014","Stefano Lonardi","CA","University of California-Riverside","Continuing grant","Sylvia J. Spengler","08/31/2016","$994,370.00","Karine Le Roch","stelo@cs.ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","1165, 1640, 7275, 7364","7924, 8750, 7364","$0.00","This project will develop a new computational framework to advance the understanding of epigenetic gene regulation in the human malaria parasite. Epigenetics is the study of heritable changes in gene expression or cellular phenotype caused by mechanisms other than changes in the underlying DNA sequence.At the core of the computational framework is the ability to solve a set of hard computational questions, which are the focus of the research plan. The computational challenges require the study of novel combinatorial optimization problems, the development of new time- and space-efficient algorithms, and ultimately the implementation and deployment of user-friendly web-based software tools. The ability to analyze the epigenome of the human malaria parasite will improve our comprehension of its biology and possibly enable molecular biologists to identify new antimalarial strategies. The proposed computational framework will also enable life scientists to make novel epigenetic discoveries and ultimately improve the understanding of the complex mechanisms that drive gene expression inother eukaryotic organisms. Software tools will be placed into the public domain, which will benefit researchers and the public worldwide, and potentially lead to new international and industrial collaborations. This project will support two graduate students and one post-doc in a highly interdisciplinary environment.<br/><br/>Most eukaryotic genomes have a second layer of information which is embedded on chemical marks added to DNA and to the protruding tail of special proteins that package DNA into a complex called the nucleosome. One of the most astonishing discoveries in molecular biology of the past decades is that this ""covert"" layer, called the epigenome, affects a variety of cellular and metabolic processes. Epigenetic marks not only controls what genes are accessible in each type of cell, but also determine when the accessible genes may be activated. Molecular biologists have also confirmed that the epigenome is affected by the interactions of the organism with the environment and that changes to the epigenetic marks induced by these interactions are inherited across cell division, despite not being encoded directly in DNA. <br/><br/>This project will study a set of computational challenges that will be brought about by the increasing number of epigenome projects. Specifically, the goal is to develop methods and software tools for (1) the analysis nucleosome and methylation maps(using a modified Gaussian mixture model and expectation maximization); (2) the study of dynamics of nucleosome positioning, histone tail modifications and DNA methylation patterns (using graph theoretical approaches, e.g., k-partite matching); (3) the analysis of DNA motifs for stable nucleosomes and specific histone modifications (using combinatorial optimization approaches); (4) the discovery of new genes using nucleosome or methylation landscapes (using machine learning classifiers); (5) the identification of statistically significant genome-wide correlations between nucleosome positioning, histone modifications, DNA methylation patterns and gene expression (using dynamic Bayesian networks). These five computational tasks will require the study of novel combinatorial optimization and machine learning problems, the development of new time- and space-efficient algorithms, and ultimately the implementation and deployment of user-friendly web-based software tools.<br/><br/>The ""platform"" on which the algorithms will be developed is P. falciparum, the parasite responsible each year for 350-500 million cases of malaria, and between one and three million of human deaths world-wide. There is no vaccine against malaria (one is currently on clinical trials) and the parasite is developing resistances to almost all drugs currently available. The methods and tools developed will not be malaria-specific, and will scale to a variety of other eukaryota with much larger/complex genomes.<br/>Updates and additional information about this project will be made available at http://www.cs.ucr.edu/~stelo/iis13.htm"
"1129855","U.S.-German Collaboration: Building common high-dimensional models of neural representational spaces","BCS","COGNEURO, COLLABORATIVE RESEARCH, CRCNS, ROBUST INTELLIGENCE","09/15/2011","09/26/2011","Peter Ramadge","NJ","Princeton University","Standard Grant","ping li","08/31/2014","$348,685.00","","ramadge@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085400036","6092583090","SBE","1699, 7298, 7327, 7495","1699, 5936, 5979, 7327, 7752","$0.00","Methods known as 'multivariate pattern' (MVP) analysis can be used to decode the information patterns in brain activity obtained using functional magnetic resonance imaging (fMRI). However, a new decoding model has to be built for each brain, because two brains (and the representational spaces they employ) are difficult to align at a fine spatial scale. As a consequence, we do not yet know if different brains use the same codes or idiosyncratic codes to represent the same things. With funding from the National Science Foundation, Drs. James V. Haxby of Dartmouth College, and Peter J. Ramadge of Princeton University, in collaboration with Michael Hanke of the University of Magdeburg (Germany), are developing new methods to discover a coding scheme that works accurately across different brains. The methods being developed align brain activity across brains by projecting individual brain data into a common, high-dimensional space. This approach allows the researchers to build models of brain representational spaces for different cortical areas that are valid both across brains and across a wide range of stimuli and cognitive states. The researchers are developing two algorithms. One is referred to as 'hyperalignment' and the other as 'functional connectivity hyperalignment.' Hyperalignment rotates the voxel spaces (i.e., the smallest units in a brain image) of individual brains into a single high-dimensional space, in which each dimension is a profile of differential responses to stimuli, that is common across brains. Functional connectivity hyperalignment aligns voxel spaces based on the functional connectivity profile (i.e., relationships among activated brain areas) for each cortical location. Functional connectivity profiles allow for models of areas that do not respond to external stimuli in a consistent manner, for example, those areas in the so-called 'default-intrinsic system' that plays a central role in social cognition. The investigators are an interdisciplinary partnership - cognitive neuroscientists and signal-processing engineers - who have been working together successfully for several years. <br/><br/>Developing the computational methods to build common models of representational spaces will augment the power of brain activity decoding techniques, making it possible to investigate how finer, more detailed information is embedded in brain activity patterns, and to read out that information from functional brain imaging data. The proposed methods also will allow extension of brain decoding to the neural codes that underlie social cognition, that is, the representation of knowledge about the personal traits and mental states of others. These models also will allow investigation of how neural coding is altered within brain regions that are affected by experience, by development, and by psychopathology.<br/><br/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF)."
"1445418","WORKSHOP: Doctoral Consortium at ACM Designing Interactive Systems 2014","IIS","Cyber-Human Systems","06/15/2014","06/09/2014","Jeffrey Bardzell","IN","Indiana University","Standard Grant","Ephraim P. Glinert","05/31/2015","$4,734.00","","jbardzel@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7367","7367, 7556","$0.00","This is funding to support participation by 3 PhD students based in US educational institutions in the Student Consortium (workshop) to be held in conjunction with the 2014 ACM Conference on Designing Interactive Systems (DIS 2014), which will take place in Vancouver, Canada, on June 21-25. The annual DIS conferences represent the growing interest in next-generation interactive user interfaces. Sponsored by the Association for Computing Machinery, they bring together 200-300 researchers and corporate leaders from North America, Europe, and Asia to present and discuss the latest multidisciplinary work on the design and evaluation of user interfaces, systems, and applications. At this year's conference approximately 100 papers will be presented, all of which will be published in the DIS Conference Proceedings and also in ACM's Digital Library. The program will also include invited keynote talks, system demonstrations, poster sessions, and a variety of workshops. <br/><br/>Topics of particular interest to the conference span a broad range, including: methods, tools, and techniques for engaging people; researching, designing, and co-designing interactive systems; the use of critical and cultural theory to understand, critique, and reflect on design products and contexts as well as design practices; user experience; usability; engagement; empowerment; well-being; designing things that matter; diversity; participation; materiality; making; sensors and actuators; mobile devices; novel artifact design; hybrid materials and surfaces; bio-electric systems; multi touch and touchless interaction; social media; personal; community, and public displays; health informatics; information and communication technologies for development (ICT4D); children-computer interaction; sustainability; and new media. More information about the conference may be found online at http://dis2014.iat.sfu.ca/. <br/><br/>This year DIS is for the first time organizing a Student Consortium with the goal of expanding student attendance and training in this area. The Student Consortium will be held as a full-day event on June 22, in parallel with the other conference workshops, and will provide participating students with exposure to their research community, with an opportunity to present their work and receive constructive feedback from peers and senior researchers in the field, and with ample time to start building a professional support network of peers and mentors. There were over 20 applications from students requesting to participate in the event, and the conference has accepted 12 of these, 3 of whom are from the United States. Each student will make a short presentation, followed by an open discussion and feedback from their peers. A senior researcher will be appointed as a mentor for each student, to lead the discussion, ask questions, and provide specific feedback. At lunch, sandwiches will be available in the session room so students can engage in general discussion with peers, with posters available for reference; in the evening, students will attend a group dinner for follow-on discussion and community building. All student participants receive free conference registration, a shared hotel room accommodation for the duration of the conference, and need-based travel support. The event organizers made special efforts to recruit women and members of under-represented groups; to further increase participant diversity, no more than one student per university or research institution will be supported."
"1444865","CAREER: Designing for Enlightened Trial and Error","IIS","Cyber-Human Systems","07/01/2013","05/22/2014","Scott Klemmer","CA","University of California-San Diego","Continuing grant","Ephraim P. Glinert","06/30/2015","$195,302.00","","srk@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367","1045, 1187, 7367, 9215, HPCC","$0.00","In design, prototyping is the pivotal activity that structures innovation, collaboration, and creativity. Designers prototype because ""enlightened trial and error outperforms the planning of flawless intellects"" (David Kelley). While a few leading-edge endeavors have shown the value of prototyping and learning from alternatives, these design successes have been resource-intensive or in niche contexts. Attempts to reach a broader audience have stumbled because they were heavyweight, bespoke, or against the grain of important design practices and values. Consequently, most interfaces today are launched with minimal understanding of alternative design choices and their relative efficacy. In this project the PI will explore, evaluate, and disseminate the techniques necessary to make enlightened trial and error a cornerstone of user interface design. To these ends, the project's technical and empirical research comprises three thrusts which will unearth fundamental principles and evaluate them through software tools that leverage web services<br/><br/>Creating Designs Analogically. Programming with traditional API documentation as the sole resource has the same difficulty as creating a meal with only a grocery list. The elements are all there, but none of the context necessary for composing a coherent and complete whole. The PI hypothesizes that tools specifically designed for creation by example modification would look quite different than current tools and yield significantly higher-quality results. The PI will carry out a systematic exploration of the design space for design-by-example tools to identify major design decisions and tradeoffs, and provide a performance and complexity comparison of important design points.<br/><br/>Exploring Alternatives Parametrically. Prototyping's concreteness benefit can also be its Achilles heel when it encourages premature commitment. To address this, the PI envisions parametric interfaces, a representation with lightweight semantic structure for fast and broad design space exploration. Design stakeholders and lead users lacking the time or expertise to design interfaces would be able to parameterize and rapidly iterate them, thereby shifting the designers' responsibility from creating a specific artifact to creating a context for participation. The PI's initial research suggests that parametric tools increase both broad exploration and fine-grained tuning. An additional benefit is that parametric interfaces would facilitate appropriate adaptation to user abilities and device characteristics.<br/><br/>Designing Pervasive Interactions. How can tools enable the rapid exploration and evaluation of new interactions that combine ubiquitous computing and web services? Such interactions would allow designers to leverage information repositories and data transformation (through web services), while engaging the user in the world instead of in front of the desktop (through ubicomp). While software has almost always been built with the assistance of toolkits and libraries, few software tools have deeply embraced this reality and leveraged it. The PI plans to create tools for designers to work opportunistically by foraging for and combining pre-existing, high-level blocks of functionality.<br/><br/>In each of the technical thrusts, the PI will conduct both quantitative and qualitative evaluation comparing the quality of designs produced with and without the technique, as measured by independent raters, and he will also conduct longer-term case studies for a more ecologically valid understanding of their use. <br/><br/>Broader Impacts: Design has emerged as a critical engine of innovation in today's multi-billion-dollar information technology industry. The software tools resulting from this project will contribute a conceptual understanding of how to most effectively create, manage, and learn from prototypes by leveraging web services, which are widespread yet still evolving. To enable ubiquitous access to enlightened prototyping, all of the software and course materials the PI has created and will create at Stanford are open source and available online. The PI will also serve as an advisor to the Stanford?s K-12 Learning Lab, which is bringing design thinking into public schools."
"1319382","HCC: Small: Experiments in Community Q&A","IIS","Cyber-Human Systems","09/01/2013","06/09/2014","Joseph Konstan","MN","University of Minnesota-Twin Cities","Continuing grant","Kevin Crowston","08/31/2016","$499,952.00","John Logie","konstan@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7367, 7923","$0.00","Online community question-and-answer systems such as Yahoo! Answers provide a venue where people can pose questions, provide answers and browse and comment on both. Such sites are now a central part of online interaction on a wide range of sites, including specialized sites for software development, tax preparation, and product support. In this projects, the PIs will experimentally answer a set of causal questions drawn from diverse research literatures about how to improve the performance of Q&A systems, specifically what leads people to provide good quality answers (and questions), how to route questions so they are answered by the best possible member, how referrals and profiles affect questions and answers, and to what extent different kinds of incentives affect behavior on the site.<br/><br/>The proposed research is important because online question and answer systems have become an important source of information and advice for individuals and businesses, an important and economical way for businesses to help their customers support each other, as well as an important source of content for web search engines. By understanding these systems, building models of usage and testing designs to support their improved operation, the project will help systems designers understand approaches that can promote beneficial social experiences for users and that can inform the construction of valuable community-contributed repositories of knowledge. Additional benefits include the release of data sets for other researchers and the training of student researchers."
"1017017","RI: Small: The Shape of Visual Motion","IIS","ROBUST INTELLIGENCE","08/15/2010","05/31/2011","Carlo Tomasi","NC","Duke University","Continuing grant","Jie Yang","07/31/2015","$457,499.00","","tomasi@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7923, 9251","$0.00","This project studies methods for describing motion in video. All visible points in the world are tagged by their identity, and trajectories of their projections on the image plane are tracked through space and time. This computation is performed globally, both in space and time, and motion discontinuities are explicitly delineated in the output. In contrast with previous techniques, which estimate motion primarily from the bottom up, starting with two frames at a time, the box of data from a video camera is carved up into tube-like regions whose shapes capture information about the motion and deformation of the objects visible in the scene. Novel methods include the projection of all visual motion onto a sparse basis of point trajectories through low-rank matrix data imputation; the use of L1 regularization in a function space that preserves boundaries; the generalization of robust estimation methods from variational calculus and quadratic programming for the efficient computation of tubes and occlusions in the multi-frame case; and several domain-specific techniques for initializing general but local optimization methods close to the global solution. The resulting descriptors enable video retrieval, medical diagnosis of heart rhythm anomalies, assessment of performance in sports, sign language recognition, traffic monitoring, surveillance, and more. The project also forms the basis for a new class on experimental methods for computer vision, the materials of which are made available online."
"1116541","RI: Small: Addressing Visual Analogy Problems on the Raven's Intelligence Test","IIS","ROBUST INTELLIGENCE","08/01/2011","07/30/2012","Ashok Goel","GA","Georgia Tech Research Corporation","Continuing grant","James Donlon","07/31/2015","$450,000.00","","ashok.goel@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7923","$0.00","This proposal aims to create purely image-based reasoning methods for solving visual analogy problems, particularly so-called Raven's Progressive Matrices (RPM) problems. The project draws on recent results from the study of human cognition as well computer science and mathematics. Raven's Progressive Matrices consist wholly of visual analogy problems in which a matrix of geometric figures is presented with one entry missing, and the correct missing entry must be selected from a set of answer choices. Recent analysis of RPM data suggests that although in general the performance of individuals with autism on most intelligence tests is significantly inferior to that of typically developing individuals, on the Raven's test the performance of the two groups is comparable. This data is consistent with the ""Thinking in Pictures"" hypothesis that has been proposed as a potential, partial cognitive explanation of autism. In both artificial intelligence and psychology, current theories of solving RPM problems first convert the visual inputs into verbal representations and then process the verbal representations. In contrast, this project explores the hypothesis that many RPM problems can be solved using only visual representations, without extracting any verbal representations from the input images. This project will develop and analyze computational techniques for addressing RPM problems with only visual representations. <br/><br/>In particular, this project will develop a novel algorithm based on affine transformations for addressing RPM problems as well as a second algorithm that makes use of fractal encodings. With both approaches -- affine and fractal -- the project seeks to achieve human-level performance on RPM in terms of percentages of problems solved correctly. The two algorithms will also be tested on the ""odd-man-out"" corpus that contains thousands of visual analogy problems. The project will formally characterize the set of visual analogy problems for which the affine and fractal algorithms are applicable, analyze the computational properties of the algorithms, construct proofs of their correctness for specific classes of problems, and compare the errors made by the two algorithms with those made by two groups of humans -- typically developing individuals and individuals with autism. The project will parameterize the visual algorithms to detect the settings under which the patterns of errors made by an algorithm on RPM problems most closely match the error patterns of the two human groupings. <br/><br/>Autism is an important problem of growing social concern. While the thinking-in-pictures hypothesis has long been a significant insight into cognition in autism, and empirical evidence -- both behavioral and neuroimaging -- in its favor is increasing, there have been no computational models for it. The proposed research would help provide a computational form to this hypothesis and may help establish a disposition towards visual thinking with autism. RPM is considered one of the core tests of intelligence, and although there have been several suggestions about the visuospatial nature of RPM problems, all current computational models addressing such visual analogy problems use sequential processing on propositional representations of the input images. The algorithms from this project that rely on visual representations for RPM could provide new insights into intelligence testing. Lastly, while fractal encodings have been used in computer graphics for generating images and in computer vision for texture analysis in image processing, this project's use of fractal encodings for visual analogies on intelligence tests will contribute to knowledge of fractal computing."
"1149697","CAREER: Predicting and Mining Phenome-genome Association across Species","IIS","INFO INTEGRATION & INFORMATICS, Systems and Synthetic Biology","08/01/2012","06/10/2014","Rui Kuang","MN","University of Minnesota-Twin Cities","Continuing grant","Sylvia J. Spengler","07/31/2017","$259,509.00","","kuan0009@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364, 8011","1045, 1228, 9109, 9177, 9179","$0.00","Understanding how genetic material determines the observable characteristics (phenotypes) of an organism relies on knowledge of phenotype-gene relations. From high-throughput genomic data, it is now possible to apply computational approaches to identify the associations between individual phenotypes and genes. Since the number of determined phenotype-gene associations is still very limited, no computational framework has been developed to perform large-scale cross-species analysis of the association between the whole collection of phenotypes (phenome) and genes (genome). The objective of this CAREER proposal is to develop new computational methods for predicting and understanding phenome-genome association across multiple species. With the prediction tools, a biologist or disease researcher could more reliably prioritize genes to test their association with phenotypes in the laboratory. The availability of the tools will greatly expedite the process of discovering new associations, especially for studying rare phenotypes. The developed methods will be applied to study phenome-genome associations for the analysis of several cancer tumor phenotypes and the growth phenotypes of Arabidopsis thaliana in collaboration with oncologists and biologists. The study of the plant growth phenotypes aims to identify genes that govern seedling de-etiolation and seed development. The collaboration should generate a potential increase in seed yield and concomitant increases in the contents of proteins and oil per seed for the crop plants. The study of the ovarian cancer and lung cancer tumor phenotypes will help reveal the driving pathways of chemoresistance, and result in useful prediction tools and drug targets for the treatment of ovarian cancer and lung cancer. The research in this proposal will deliver a web portal called Phenome-Genome Explorer with a collection of computational tools that utilize known phenotype-gene associations to predict new associations, find conserved associations and conserved modules of associations across species. The PI has a long-term commitment to teach a summer class in the BioSMART program for Minnesota high school students. He will also create a new course Computational Phenomics and Genomics to support two graduate programs for training students in biomedical/health informatics with knowledge in genomics and computer science. The education plan in the proposal aims to promote high school students' early interest in careers in computing science and biomedical/health informatics and integrate the research development on phenome-genome analysis into training graduate students to meet the need of workforce in the growing biomedical and health informatics industry, with a focus on recruiting students in minority and under-represented groups.<br/><br/>This proposal targets a systematic computational study of phenome-genome association in a network context. The comparative analysis across multiple species will expand the current scope of understanding evolutionary relation between phenome and genome. The proposed research work focuses on 1) How to discover patterns and predict new associations by learning with the sparse connections in a large heterogeneous network composed of phenotype network, gene network and their association network; and 2) How to compare multiple heterogeneous networks to find conserved patterns and modules, and to infer new associations. Both scenarios require development of scalable new algorithms to deal with multiple large heterogeneous networks."
"1445409","RI: Medium: Integrating Humans and Computers for Image and Video Understanding","IIS","ROBUST INTELLIGENCE","08/21/2013","06/10/2014","Tamara Berg","NC","University of North Carolina at Chapel Hill","Continuing grant","Jie Yang","04/30/2016","$529,382.00","","tlberg@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","7924, 7495","$0.00","In this project, the research team explores several research challenges to exploit the relationship between images, video, and the people viewing this visual imagery. Areas of exploration include: 1) behavioral experiments to better understand the relationship between human viewers and imagery, 2) development of human-computer collaborative systems for image and video understanding that utilize automatic computer vision algorithms in conjunction with active and passive cues from human viewers, and 3) implementing retrieval and collection organization applications using our collaborative models.<br/><br/>Billions of images and millions of videos are now available online via the infrastructure of amazingly successful companies from Google to Microsoft to Facebook. This wealth of visual data is creating considerable opportunities for communication and community, and tightening the social fabric of our world. In parallel to this explosion in online imagery, there is also an increasing proliferation of cameras viewing the user, from the ever present webcams peering out at us from our laptops, to cell phone cameras carried in our pockets wherever we go. This record of a user's viewing behavior, particularly of their eye, body movements, or descriptions, can provide enormous insight into how people interact with images or video, and can inform construction of more effective visual applications such as image or video retrieval. In addition, understanding what people recognize, attend to, or describe about an image or video is a necessary step toward high level goals of human centric image understanding that will have research benefits to many diverse fields, including computer vision and behavioral science."
"1321065","HCC: Small: How Do-It-Yourself Makers are Reinventing Production, Labor, and Innovation","IIS","Cyber-Human Systems","08/15/2013","06/10/2014","Silvia Lindtner","CA","University of California-Irvine","Continuing grant","Anthony Hornof","07/31/2016","$322,730.00","Garnet Hertz","lindtner@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7923","$0.00","The contemporary landscape of information technology production is one that has been profoundly influenced by the emergence of so-called ""maker culture"" in the 1960s and 1970s. From Mac OS X to Android, from TiVo DVRs to Linksys network appliances, from Amazon.com to Google Chrome, the technology landscape is full of products that depend upon open source and similar alternative models of production. Society currently finds itself in the middle of a new maker movement that both harkens back to the earlier model and also departs from it in significant ways. It is rooted in a growing network of ""makerspaces"" that expands ideas and practices of the Web generation into hardware and manufacturing. Makerspaces are cooperative studios where people develop new approaches to technology design based on the open sharing of software code and hardware designs through the use of technology such as computer controlled laser cutters, 3-D printers, and microcontroller kits. Makerspaces are places where new models of innovation are explored, where values of openness and participation are re-assessed, and where new relationships between people and technology are forged.<br/><br/>To understand these phenomena, this project will conduct ethnographic research at four makerspaces, studying them from a socio-technical perspective. The goal of the project is to understand the relationship between cultural and material practices in the maker movement. Accordingly, the focus is on the daily practices in makerspaces, with particular attention to how they experiment with models of social organization, distributed collaboration, and peer production. Specific research sites have been chosen to highlight key questions. Two are located in the United States, in centers of information technology (IT) innovation and production (New York and San Francisco); two are located in China, at key sites for the development of new models of commercial development (in Shenzhen, a major Chinese production hub, and in Shanghai, a center for the Chinese creative and IT industry). Through ethnographic investigation, the project will examine the questions of how DIY (Do-It-Yourself) making as a practice, and makerspaces as physical sites, contribute to the development of new models of technical, economic, and social innovation.<br/><br/>Within a broad cultural and sociopolitical context, this research will study peer production, DIY and open source making, models of innovation in action, and the material production of IT work. This exploration will help us to understand non-professional expertise and alternative forms of technical knowledge, distributed collaboration, and inter-cultural exchange of ideas and artifacts. This study complements previously published investigations of peer production by focusing on the effect of physical sites on social organization and open source production. The project provides a concrete, ethnographic foundation for emerging questions of materiality in human-computer interaction.<br/><br/>Broader Impacts: As sites of DIY production, makerspaces provide an important interface between technological production and the everyday world. At the same time, they may also represent important sites for rethinking contemporary processes of technological and commercial innovation. This research will help to assess and understand these possibilities, support educational developments in this area (such as makerspace infrastructures within schools), explore alternative forms of small-scale commercial production, incentivize participation, and develop intellectual property. To the extent that makerspaces embody a set of broader cultural values about relationships between people, technologies, and the innovation cycle, this project will provide empirical and conceptual material to support social processes around these questions. As a large-scale public practice, DIY production provides an important forum for connecting academic-based and citizen-based models of knowledge production, and the opportunity for outreach into communities in which scientific and technical work is part of their identity."
"1247809","EAGER: Collaborative Research: Towards Modeling Human Speech Confusions in Noise","IIS","ROBUST INTELLIGENCE","08/01/2012","08/08/2012","Abeer Alwan","CA","University of California-Los Angeles","Standard Grant","Tatiana D. Korelsky","07/31/2015","$100,000.00","Jody Kreiman","alwan@ee.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7495, 7916","$0.00","This EArly-concept Grant for Exploratory Research (EAGER) supports an exploratory study to evaluate model components for prediction of human speech recognition in the presence of noise. Such a model has the potential to predict confusions between fine phonetic distinctions in different levels of background noise and at different speaking rates. The study takes advantage of modern physiological results that indicate that the primary auditory cortex performs spectro-temporal filtering; that is, that there are cells that are sensitive to particular spectro-temporal modulations at each auditory frequency. In this project, perceptual experiments in the presence of both stationary and non-stationary additive noise and at different signal-to-noise ratios for a database of CVC syllables recorded at 2 different speaking rates yield confusion statistics. These statistics are then compared to those resulting from an auditory model enhanced by elements incorporating these spectro-temporal filters. <br/><br/>Successful results from this study will suggest enhancements to current hearing models and ultimately, after a broader study for which this EAGER is a pilot, advance the understanding of human speech perception. Background noise presents a challenging problem for a variety of speech and hearing devices including hearing aids and automatic speech recognition (ASR) systems. Since normal-hearing human listeners are extremely adept at perceiving speech in noise, this improved understanding of human models could lead to better artificial systems for speech processing. The databases and tools developed for this study will be disseminated to the research community."
"0748919","CAREER: Information Engineering and Synthesis for Resource-poor Languages","BCS","LINGUISTICS, ROBUST INTELLIGENCE","06/15/2008","06/22/2012","Fei Xia","WA","University of Washington","Continuing grant","Tatiana D. Korelsky","05/31/2015","$515,925.00","","fxia@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","SBE","1311, 7495","0000, 1045, 1187, 1311, 7495, 9102, OTHR, 9251","$0.00","For the majority of the world's languages, the amount of linguistic resources (e.g., annotated corpora and parallel data) is very limited. Consequently, supervised methods and many unsupervised methods cannot be applied directly, leaving these languages largely untouched and unnoticed. Another crucial issue, which has received little attention from the natural language processing (NLP) community, is that to date there have been very few studies that examine a large number of languages and incorporate cross-lingual information into NLP systems. As a result, languages are researched and processed in isolation rather than being looked at as part of a big language family.<br/><br/>This proposed research has two intertwined goals. The first goal is to create a framework that allows the rapid development of resources for resource-poor languages. This goal will be accomplished by bootstrapping NLP tools with initial seeds created by projecting syntactic information from resource-rich languages to resource-poor ones. The second goal is to use the automatically created resources to perform cross-lingual study on a large number of languages to discover linguistic knowledge. The knowledge will not only deepen our understanding on languages, but also provide additional information that can be incorporated into the bootstrapping module to produce better NLP tools. The research explores two key ideas: The first idea is to take advantage of resource-rich languages by using them to create seeds for bootstrapping NLP tools. The second idea is to identify the relation between languages and use this information to help machine learning. Both ideas point to the same direction; that is, languages are related to one another and should be treated as such."
"1018863","RI: Small: A New Voice Source Model: From Glottal Areas to Better Speech Synthesis","IIS","ROBUST INTELLIGENCE","09/01/2010","06/15/2011","Abeer Alwan","CA","University of California-Los Angeles","Continuing grant","Tatiana D. Korelsky","07/31/2015","$458,000.00","Jody Kreiman, Patricia Keating","alwan@ee.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7923, 9150, 9251","$0.00","The goal of the proposed research is to develop and evaluate a new voice<br/>source model based on physiological observations of the vocal folds of 30 adult speakers. Shortcomings of existing source models can be in part attributed to the way in which they were developed: based on limited data from a few speakers, without direct physiological observations, and without perceptual validation. A larger dataset would help in not only developing a source model that could account for a range of voice qualities within and across speakers, but also result in an understanding of how and which model parameter(s) are speaker and/or gender specific. Model development will consider the perceptual effects of the model's parameters from the earliest stages.<br/>A better source model might also improve the performance of speech processing algorithms such as text-to-speech synthesis (TTS). Typically in the development of such algorithms, the emphasis has been on acoustic features related to the speech spectral envelope. The acoustics of the voice source, on the other hand, have received less attention. <br/>The proposed work involves: 1) recording high-speed images of vocal fold<br/>vibrations with simultaneous audio recordings from 15 male and 15 female speakers, 2) extracting glottal area functions from the images to parameterize a new voice source model, 3) performing perception experiments to uncover which model parameters are perceptually salient, and 4) using the new voice source model in TTS. <br/>The project's interdisciplinary team (with expertise in modeling, synthesis, recognition, phonetics, and psycholinguistics) is uniquely qualified to conduct this transformative research."
"0808692","HCC-Large: Collaborative Research: Understanding Online Volunteer Communities: Toward Theory-Based Design","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","08/01/2008","02/12/2014","John Riedl","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","07/31/2015","$2,516,218.00","Mark Snyder, Yuqing Ren, Loren Terveen, Brent Hecht, Joseph Konstan","riedl@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","1640, 7364, 7367","1640, 7364, 7367, 7925, 9215, 9216, 9232, 9251, HPCC","$0.00","This project will develop a design-oriented science of online volunteer communities (OLVCs) such as Wikipedia, SourceForge, and TripAdvisor. These web sites attract hundreds of thousands of people - not to play games or socialize - but to produce content. The content produced by OLVCs is valuable. Wikipedia is among the ten most popular sites on the Web. SourceForge is the hub of the open source software movement, used by thousands of projects to organize their work. TripAdvisor brings together travelers whose reviews help each other find and vet hotels and services. Despite these successes, OLVCs face real challenges. Most fail quickly, and even the most successful have problems. Over two-thirds of SourceForge projects become inactive fairly quickly. Even Wikipedia struggles: vandalism is a constant problem, two thirds of the articles are stubs - the lowest quality article, which are too short to provide encyclopedic coverage - and recent data suggests that Wikipedia's constant growth may have halted and even reversed. <br/><br/>A design-oriented science of OLVCs could help solve these problems. Four specific research activities will be carried out to produce this science. First, the project will mine results from prior research to create models, formulate hypotheses, and define key success metrics. Second, it will develop algorithms and interfaces to help OLVCs function better. Third, it will evaluate the mechanisms in real OLVCs, for example, with experiments that measure the extent to which different social comparison interfaces motivate volunteers to step up their activity. Finally, the project will abstract the results to develop generalizable design principles for online volunteer communities. <br/><br/>This project will develop a broad set of software mechanisms to solve important and general problems of online volunteer communities. The algorithms and interfaces will be evaluated systematically in real OLVCs, thus providing an empirically grounded body of knowledge about their effectiveness. In addition, the results of this project can feed back to advance social science theories originally developed for offline volunteering."
"1445380","EAGER: Guide Drones for Blind Athletes","IIS","Cyber-Human Systems","09/01/2014","06/09/2014","Eelke Folmer","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Ephraim P. Glinert","08/31/2015","$72,080.00","","efolmer@unr.edu","1664 North Virginia Street","Reno","NV","895570325","7757844040","CSE","7367","7367, 7916, 9150","$0.00","There are approximately 25 million people with visual impairments in the United States, including 1.3 million who are legally blind. Lack of physical activity is a serious health concern for these individuals, who have fewer opportunities to engage in physical activities that provide the amounts and kinds of stimulation necessary to maintain adequate fitness and to support a healthy lifestyle, for a number of reasons: a lack of exercise partners or sighted guides with whom to exercise; safety concerns; and a general lack of accessible activities to choose from. Running is a popular form of exercise that offers various cardiovascular health benefits, but to run outdoors blind athletes must currently rely on a sighted person to safely guide them using a tether; in addition to the challenge of meeting someone who has a compatible schedule and is willing to exercise together, this dependency on others puts significant constraints on the frequency and duration with which blind individuals can exercise.<br/><br/>It has been suggested that robots may allow individuals with disabilities to lead more independent lives, but the approaches that have previously been explored primarily involve grounded robots moving at slow speeds. Because running is performed at a much faster pace than walking, this exploratory project will investigate the use of an unmanned aerial vehicle (commonly referred to as a drone) to safely guide a blind runner. The blind athlete follows the drone, which is flying ahead of him/her at a fixed distance, on the basis of sound alone, with no human exercise companion and no tether to impede his/her ability to run. The PI will employ a commercially available low-cost quadcopter platform that is controlled using an app on a smartphone, to explore audio feedback mechanisms that allow a blind runner to effectively follow the drone while avoiding obstacles and also correcting for unintentional veering off course.<br/><br/>The PI has secured the collaboration of a blind triathlon athlete as a consultant on this project, to provide feedback on design issues, to participate in early trials, and to help with subject recruitment. This research will make significant contributions in nonvisual Human-Robot Interaction while establishing design principles and laying the foundations for a new kind of assistive technology. Potential future extensions to the work could involve the use of guide drones for other physical activities such as swimming or cycling, where the use of a grounded robot and leash is impractical."
"1216045","RI: Small: Efficient Bayesian Learning from Stochastic Gradients","IIS","ROBUST INTELLIGENCE","09/01/2012","08/30/2012","Max Welling","CA","University of California-Irvine","Standard Grant","Jie Yang","08/31/2015","$500,000.00","Babak Shahbaba","welling@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","7923","$0.00","The total volume of data was estimated to be 0.8 Zettabytes in 2009 (1 Zettabyte = 1 trillion gigabytes) and predicted to grow to a staggering 35 Zettabytes in 2020, doubling every two years. Therefore, one of the primary challenges for machine learning is to develop statistically principled methods that will scale up to very large datasets. Moreover, we would like to (efficiently) learn highly complex models without the worry of overfitting and with confidence levels on our predictions. While Bayesian methods satisfy these latter desiderata, the current state-of-the-art inference procedures based on Markov Chain Monte Carlo (MCMC) posterior sampling do not meet the ""big-data"" challenge.<br/><br/>We propose a new family of MCMC procedures that typically requires only a few hundred data-cases per update. These ""stochastic gradient MCMC samplers"" inherit the efficiencies of stochastic approximation methods, but will asymptotically sample from the correct posterior distribution. This endows this family of methods with an ""anytime"" property, namely that one can sample cheaply from a rough approximation of the posterior but can obtain more accurate samples in exchange for more computation.<br/><br/>We believe this new class of methods will for the first time unlock the full strength of Bayesian methods for very large datasets. Due to their highly practical nature, the techniques developed under this grant are likely to gain widespread acceptance across a broad spectrum of academic disciplines as well as in industry. To expedite the transfer process we will publish open source software on our webpages and collaborate with a company (ID Analytics) to work on realistic, large scale inference problems. Two students at the University of California, Irvine (UCI) will be employed on this grant who will collaborate with a number of students and postdocs in the UK (University of Oxford and University of Bristol). UCI and UK students will also be exchanged for a few weeks a year to cross-fertilize research and to gain international experience. Research results from this grant will be integrated into artificial intelligence and machine learning courses at UCI through class projects."
"1018554","III: Small: Linking Relational Databases with OWL and SPARQL","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","06/13/2013","Daniel Miranker","TX","University of Texas at Austin","Continuing grant","Sylvia J. Spengler","05/31/2015","$511,299.00","","miranker@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7364","7364, 7923, 9251","$0.00","The Semantic Web is an emerging technology that stipulates that the content of<br/>each Internet web site provide self-describing metadata encoded using standard<br/>graph representations, (using the OWL and RDF computer languages). In the<br/>common Internet it is optional for web sites to provide topical descriptions of<br/>their content. Further, the optional methods that are provided simply allow <br/>developers to list keywords. The methods do not provide a way to detail the <br/>meaning of those keywords, i.e. their semantics.<br/><br/>The goal of this project is to develop and demonstrate algorithms that <br/>leverage the new, semantic aspects of the Internet and make it much easier <br/>to treat multiple web sites and their underlying databases as a single <br/>unified database. This is distinguished from the existing Internet where <br/>a browser enables people to view documents and data, in the form of <br/>documents, from different web sites in a single place. While the use <br/>of Internet browsers is now endemic and trivially intuitive, creating <br/>computer applications that process data from multiple web sites remains <br/>a highly skilled and labor-intensive process.<br/><br/>This project comprises two components. The first component helps create <br/>the Semantic Web by developing methods that automatically map existing <br/>databases to the Semantic Web graph languages. The methods comprise data <br/>mining techniques that discover the semantics already present, but not <br/>explicitly encoded in relational databases and recast those semantics <br/>in graph-based form. The second component comprises the development of <br/>a distributed query execution environment for processing graph structured <br/>queries, expressed in SPARQL.<br/><br/>The PI is an invited expert on the W3C working group on standards for <br/>relational database to RDF translation (RDB2RDF), the subject of this <br/>research. More information on this project can be found at <br/>http://www.cs.utexas.edu/~miranker/SemanticWeb.html."
"1409286","CHS: Medium: Collaborative Research: Computational Design and 3D Printing of Textiles","IIS","Cyber-Human Systems","08/01/2014","06/06/2014","Eitan Grinspun","NY","Columbia University","Standard Grant","Ephraim P. Glinert","07/31/2018","$499,899.00","","eitan@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7924","$0.00","In addition to being the essential fabric of the world's fashion industry, textiles are important components for automotive, aeronautical, architectural, and defense applications. Yet textile prototyping and design (whether for garments, upholstery or composite materials) is an arduous and expensive process. This research project seeks to understand and advance the role of new additive manufacturing technologies (commonly referred to as ""3D printing"") in the design and prototyping of textile products. The PIs' goal is to develop 3D printing hardware and computer software that enable engineers to prototype textile designs more quickly and economically, and with greater control over a broad gamut of mechanical, optical, and electrical characteristics such as aerodynamic drag, adhesion, heat regulation, friction, elasticity, porosity, density, electrical conductivity, and visual appearance. Beyond individual textiles, project outcomes will support the fabrication of complete products that do not require considerable stitching and assembly, and which may include curved shapes too difficult to cut from flat panels and/or complex composite assemblies too costly to fabricate via traditional methods. To achieve these objectives, the PIs will develop: a library of highly-optimized textile ""units"" that can be combined using a new language of textile functionality to form a vast array of possible textiles; computer optimization software that enables precise control of textile properties; a computer program that allows users to visually and interactively design complex textile products; and a specialized 3D Printer that is able to precisely fabricate textiles involving multiple materials.<br/><br/>Technically speaking, this project will create the first complete hardware/software pipeline for digital design and fabrication of textiles using multi-material 3D printing. The first fundamental step in this pipeline is constructing parameterized meta-material templates that provide users with high-level knobs for tuning the behavior and large-scale properties of a textile. Next, the ability to interactively simulate the behavior of a virtual textile will be achieved by combining continuum homogenization and data-driven methods; the PIs will develop an interactive design tool that employs first order sensitivity analysis tied to the physical simulation, to enable designers to navigate the huge space of possible designs at both the micro and macro levels. A new language for functionally specifying textile designs that employs a reducer-tuner model will allow engineers and designers to specify meta-materials in terms of desired behavior and performance, enabling designs with guarantees on their characteristics and compliance with standards. Printing volumes for current 3D printers are limited; however, by incorporating computational textile folding into the pipeline, the PIs' system will be able to print very large designs in much smaller folded configurations. Solution of the folding problem will involve nonlinear, non-convex, optimization with unilateral contact constraints. Finally, textiles and garments will be printed using both off-the-shelf 3D printers and a novel low-cost, high-resolution, modular 3D printing platform that is capable of printing with up to 12 different materials that vary in mechanical and appearance properties. In addition to photopolymer materials, the PIs plan to extend hardware capabilities to 3D print structures using co-polymers and solvent-based materials. More information about this project is available online at http://textiles.csail.mit.edu/"
"1111494","HCC: Large: Collaborative Research: Human-Robot Dialog for Collaborative Navigation Tasks","IIS","INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","08/15/2011","08/11/2011","Benjamin Kuipers","MI","University of Michigan Ann Arbor","Standard Grant","Ephraim P. Glinert","07/31/2015","$693,265.00","","kuipers@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364, 7367","7364, 7367, 7925","$0.00","This research involves collaboration among investigators at three institutions. The PIs anticipate a future in which humans and intelligent robots will collaborate on shared tasks. To achieve this vision, a robot must have sufficiently rich knowledge of the task domain and that knowledge must be usable in ways that support effective communication between a human and the robot. Navigational space is one of the few task domains where the structure of the knowledge is sufficiently well understood for a physically-embodied robot agent to be a useful collaborator, meeting genuine human needs. In this project, the PIs will develop and evaluate an intelligent robot capable of being genuinely useful to a human, and capable of natural dialog with a human about their shared task.<br/><br/>The Hybrid Spatial Semantic Hierarchy (HSSH) is a human-inspired multi-ontology representation for knowledge of navigational space. The spatial representations in the HSSH provide for efficient incremental learning, graceful degradation under resource limitations, and natural interfaces for different kinds of human-robot interactions. Speech is a natural though demanding way to use natural language to communicate with a robot. To maintain real-time performance, natural language understanding must be organized to minimize the amount of backtracking from early conclusions in light of later information. This project will answer three scientific questions.<br/><br/>(1) Can the HSSH framework, extended with real-time computer vision, express the kinds of knowledge of natural human environments that are relevant to navigation tasks? <br/>(2) Can the HSSH representation support effective natural language communication in the spatial navigation domain? <br/>3) Can we develop effective human-robot interaction that meets the needs of a person and improves the performance of the system?<br/><br/>To these ends, the PIs will perform this research with two different kinds of navigational robots, each learning from its travel experiences and building an increasingly sophisticated cognitive map: an intelligent robotic wheelchair which carries its human driver to desired destinations, and a telepresence robot that transmits its perceptions to a remote human driver as it navigates within an environment so the driver can achieve virtual presence and communicate with others remotely. To inform the design process, the PIs will conduct focus groups with potential users. They will also evaluate their implemented systems throughout the process, creating an iterative design-test cycle.<br/><br/>Broader Impacts: To be successful, an intelligent robot must not only be able to perceive the world, represent what it learns, make useful inferences and plans, and act effectively. It must also be able to communicate effectively with other agents, and particularly with people. This confluence among grounded knowledge representation, situated natural language understanding, and human-robot interaction is intellectually fundamental, and is the focus of this research. Since the domain of spatial knowledge is foundational for virtually all aspects of human knowledge, project outcomes will have broad applicability. This work will create technologies for mobility assistance for people with disabilities in perception (blindness or low vision), cognition (developmental delay or dementia), or general frailty (old age). It will also support telepresence applications such as telecommuting, telemedicine and search and rescue. The project includes outreach to K-12 and community college students, K-12 teachers, and the public in a number of venues."
"1409310","CHS: Medium: Collaborative Research: Computational Design and 3D Printing of Textiles","IIS","Cyber-Human Systems","08/01/2014","06/06/2014","Wojciech Matusik","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","07/31/2018","$600,000.00","","wojciech@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7367, 7924","$0.00","In addition to being the essential fabric of the world's fashion industry, textiles are important components for automotive, aeronautical, architectural, and defense applications. Yet textile prototyping and design (whether for garments, upholstery or composite materials) is an arduous and expensive process. This research project seeks to understand and advance the role of new additive manufacturing technologies (commonly referred to as ""3D printing"") in the design and prototyping of textile products. The PIs' goal is to develop 3D printing hardware and computer software that enable engineers to prototype textile designs more quickly and economically, and with greater control over a broad gamut of mechanical, optical, and electrical characteristics such as aerodynamic drag, adhesion, heat regulation, friction, elasticity, porosity, density, electrical conductivity, and visual appearance. Beyond individual textiles, project outcomes will support the fabrication of complete products that do not require considerable stitching and assembly, and which may include curved shapes too difficult to cut from flat panels and/or complex composite assemblies too costly to fabricate via traditional methods. To achieve these objectives, the PIs will develop: a library of highly-optimized textile ""units"" that can be combined using a new language of textile functionality to form a vast array of possible textiles; computer optimization software that enables precise control of textile properties; a computer program that allows users to visually and interactively design complex textile products; and a specialized 3D Printer that is able to precisely fabricate textiles involving multiple materials.<br/><br/>Technically speaking, this project will create the first complete hardware/software pipeline for digital design and fabrication of textiles using multi-material 3D printing. The first fundamental step in this pipeline is constructing parameterized meta-material templates that provide users with high-level knobs for tuning the behavior and large-scale properties of a textile. Next, the ability to interactively simulate the behavior of a virtual textile will be achieved by combining continuum homogenization and data-driven methods; the PIs will develop an interactive design tool that employs first order sensitivity analysis tied to the physical simulation, to enable designers to navigate the huge space of possible designs at both the micro and macro levels. A new language for functionally specifying textile designs that employs a reducer-tuner model will allow engineers and designers to specify meta-materials in terms of desired behavior and performance, enabling designs with guarantees on their characteristics and compliance with standards. Printing volumes for current 3D printers are limited; however, by incorporating computational textile folding into the pipeline, the PIs' system will be able to print very large designs in much smaller folded configurations. Solution of the folding problem will involve nonlinear, non-convex, optimization with unilateral contact constraints. Finally, textiles and garments will be printed using both off-the-shelf 3D printers and a novel low-cost, high-resolution, modular 3D printing platform that is capable of printing with up to 12 different materials that vary in mechanical and appearance properties. In addition to photopolymer materials, the PIs plan to extend hardware capabilities to 3D print structures using co-polymers and solvent-based materials. More information about this project is available online at http://textiles.csail.mit.edu/"
"1409111","CHS: Medium: Collaborative Research: Computational Design and 3D Printing of Textiles","IIS","Cyber-Human Systems","08/01/2014","06/06/2014","Victor Zordan","CA","University of California-Riverside","Standard Grant","Ephraim P. Glinert","07/31/2018","$100,000.00","","vbz@cs.ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","7367","7367, 7924","$0.00","In addition to being the essential fabric of the world's fashion industry, textiles are important components for automotive, aeronautical, architectural, and defense applications. Yet textile prototyping and design (whether for garments, upholstery or composite materials) is an arduous and expensive process. This research project seeks to understand and advance the role of new additive manufacturing technologies (commonly referred to as ""3D printing"") in the design and prototyping of textile products. The PIs' goal is to develop 3D printing hardware and computer software that enable engineers to prototype textile designs more quickly and economically, and with greater control over a broad gamut of mechanical, optical, and electrical characteristics such as aerodynamic drag, adhesion, heat regulation, friction, elasticity, porosity, density, electrical conductivity, and visual appearance. Beyond individual textiles, project outcomes will support the fabrication of complete products that do not require considerable stitching and assembly, and which may include curved shapes too difficult to cut from flat panels and/or complex composite assemblies too costly to fabricate via traditional methods. To achieve these objectives, the PIs will develop: a library of highly-optimized textile ""units"" that can be combined using a new language of textile functionality to form a vast array of possible textiles; computer optimization software that enables precise control of textile properties; a computer program that allows users to visually and interactively design complex textile products; and a specialized 3D Printer that is able to precisely fabricate textiles involving multiple materials.<br/><br/>Technically speaking, this project will create the first complete hardware/software pipeline for digital design and fabrication of textiles using multi-material 3D printing. The first fundamental step in this pipeline is constructing parameterized meta-material templates that provide users with high-level knobs for tuning the behavior and large-scale properties of a textile. Next, the ability to interactively simulate the behavior of a virtual textile will be achieved by combining continuum homogenization and data-driven methods; the PIs will develop an interactive design tool that employs first order sensitivity analysis tied to the physical simulation, to enable designers to navigate the huge space of possible designs at both the micro and macro levels. A new language for functionally specifying textile designs that employs a reducer-tuner model will allow engineers and designers to specify meta-materials in terms of desired behavior and performance, enabling designs with guarantees on their characteristics and compliance with standards. Printing volumes for current 3D printers are limited; however, by incorporating computational textile folding into the pipeline, the PIs' system will be able to print very large designs in much smaller folded configurations. Solution of the folding problem will involve nonlinear, non-convex, optimization with unilateral contact constraints. Finally, textiles and garments will be printed using both off-the-shelf 3D printers and a novel low-cost, high-resolution, modular 3D printing platform that is capable of printing with up to 12 different materials that vary in mechanical and appearance properties. In addition to photopolymer materials, the PIs plan to extend hardware capabilities to 3D print structures using co-polymers and solvent-based materials. More information about this project is available online at http://textiles.csail.mit.edu/"
"1029679","Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","09/01/2010","06/06/2014","James Rehg","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","08/31/2015","$3,347,016.00","Agata Rozga, Gregory Abowd, Mark Clements","rehg@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","1640, 7367","1640, 7367, 7723, 7969, 9218, 9251, ","$0.00","Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br/>Communicative Behavior<br/>Lead PI/Institution: James M. Rehg, Georgia Institute of Technology<br/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles."
"1116799","HCC: Small: Modeling Acoustic and Articulatory Features for Hybrid Synthesis","IIS","Cyber-Human Systems","10/01/2011","06/05/2014","Rupal Patel","MA","Northeastern University","Standard Grant","Ephraim P. Glinert","09/30/2014","$212,902.00","","r.patel@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7367, 7923, 9251","$0.00","In recent decades synthetic speech has become a ubiquitous and increasingly seamless aspect of human-machine interfaces. Although cars, microwaves, phones, and kiosks all ""talk"" in human-like ways, the naturalness and personality of these voices fall short of human expression. While this may not matter for many text-to-speech (TTS) applications, over two million Americans with severe speech-motor impairments require assistive communication aids with TTS output. Concatenative TTS synthesizers yield highly intelligible voices, yet many assistive devices rely on small footprint, formant synthesis that sounds robotic and has poor intelligibility. Moreover, the choice of voices on conventional devices is limited and does not reflect the user; it is not uncommon for a child to use the same voice her whole life and for her peers to share that same voice even when using different devices. This lack of attention to the individuality of synthetic voices has consequences on adoption of assistive technology as an extension of the user, and may adversely impact societal attitudes toward the user group.<br/><br/>In her prior work the PI began to address these issues by adapting a concatenative synthesizer constructed from acoustic recordings of a healthy talker using vocal source characteristics obtained from a target talker with speech impairment. The adapted voice was highly intelligible and conveyed the target user's identity, yet it also retained substantial elements of the healthy talker's identity due to the influence of vocal tract filter characteristics. This suggests that personalized speech synthesis may be more successful utilizing an alternative approach, in which acoustic and articulatory data from healthy talkers are combined with both source and filter characteristics from target talkers to generate an individualized voice. In this project, the PI will develop hybrid statistical parametric synthesis techniques to model vocal tract and source characteristics of impaired talkers, with the goal of generating highly intelligible and personalized synthetic speech. The PI envisages a future where source and filter parameters of a Hidden Markov Model (HMM) based synthesizer can be adapted to model a child user's vocal tract and modified over time to ""grow"" with his maturing vocal system, fostering a stronger personal connection between the user and the communication device.<br/><br/>Broader Impacts: This project strives to make communication accessible and socially fulfilling by designing an enabling technology that blurs the line between system and user. The human voice is not merely a signal; it has an individualized and personal quality that impacts how others perceive us and how we interact with those around us. The ultimate goal of this work is to afford users of TTS the same ownership and individuality as the natural voice. Project outcomes will have broad impact both on users of assistive aids and able-bodied users of TTS technologies. The research may also lead to a novel and innovative means of assessing the nature and articulatory locus of speech impairment, by comparing model parameters to impaired productions. The interdisciplinary nature of this research will promote teaching, training and learning in computer science and in speech and hearing sciences."
"1330205","Collaborative Research: Multiscale molecular simulations of protein-mediated bilayer fusion","MCB","COMPUTATIONAL MATHEMATICS, INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, INFO INTEGRATION & INFORMATICS, MSPA-INTERDISCIPLINARY","09/15/2013","09/10/2013","Cameron Abrams","PA","Drexel University","Standard Grant","Suzanne Barbour","08/31/2016","$350,852.00","","Cameron.F.Abrams@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","BIO","1271, 1640, 7275, 7364, 7454","1114, 7364, 7465, 8007, 8750, 9263","$0.00","INTELLECTUAL MERIT<br/>Perhaps the most important structure for cellular life as we know it is the lipid bilayer. Lipid molecules, consisting of a water-soluble ""head"" and water-insoluble ""tails"", spontaneously assemble into sandwich-like bilayer membranes, which surround all living cells and further compartmentalize the cellular interiors of all eukaryotic organisms the domain of life to which plants, fungi, animals, and humans belong. The network of membranes in a typical eukaryotic cell is very complex and highly dynamic: small compartments bud off from certain membranes like bubbles, carrying cargo from one part of the cell to another, where they can fuse with yet other membranes, including the outer membrane of the cell. Bilayer fusion is therefore a ubiquitous biological process, tightly linked to the transport of material and information, and therefore it is exquisitely controlled by several classes of membrane-associated proteins. These proteins clearly perform work on the fusing membranes, but the intricate sequence of geometric and topological shape transformations they induce on the molecular scale are impossible to observe directly in experiment. In contrast, molecular simulation offers a window onto these details, but until now the relevant length- and time-scales have proven too big to observe even a single fusion event for a realistic system size. This project establishes a collaboration between two investigators with the aim to meet this challenge by combining recent advances in multiscale coarse-grained modeling with enhanced-sampling molecular simulation. Since this strategy allows incorporating important chemical detail while simultaneously representing large-scale membrane deformations, the investigators will be able to elucidate how molecular-level mechanisms drive fusion events across the relevant physiological length- and time-scales. The project proceeds through three phases, namely: (i) modeling the fusion of pristine bilayers with enhanced sampling, (ii) development of coarse-grained models of model fusogenic proteins, the SNARE system, and (iii) combining these two steps into a single methodology. The project will pursue many topics of energetic, morphological, and mechanistic relevance, in particular questions revolving around the so-called hemifusion intermediate state, for which the two outer bilayer leaflets have already fused but a membrane formed by the two inner leaflets still separates the two compartments.<br/><br/>BROADER IMPACTS<br/>This project will impact many topics in the biological sciences due to the central importance of bilayer fusion in a variety of biological processes, including intracellular trafficking, viral entry, neurotransmitter release, fertilization, and more. Beyond the specific questions under study, the computational approach envisioned here takes early steps towards efficient simulation of more complicated multiple-protein/multiple-membrane phenomena and will therefore benefit future studies of a wider class of molecular biological topics. To broaden applicability of the research outcomes, the simulation framework developed in this project will be made freely available with tutorials that will support efficient learning and facilitate the transformation of existing techniques and modules towards novel applications. This project establishes cross-disciplinary exchange between engineering and (bio)physics, fostering a stimulating interdisciplinary environment for the academic growth of students mentored in this project. It will further the transfer of theoretical and computational methodologies from engineering and physics into the life sciences and their increasingly quantitative set of problems. The ubiquity of bilayer fusion and its connection to a wide class of fascinating themes in biological physics, which is in itself an intriguing cross-disciplinary subject, also present excellent opportunities for the expertise developed in this project to feed outreach specifically tailored towards groups underrepresented in STEM fields for instance through classroom material, lecture demonstrations, and public talks and both investigators will implement such activities, building on both their experience and existing successful programs at their respective institutions."
"1228082","CAREER: Similarity-based Representation of Large-scale Image Collections","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","03/01/2012","05/24/2013","Svetlana Lazebnik","IL","University of Illinois at Urbana-Champaign","Continuing grant","Maria Zemankova","07/31/2015","$372,050.00","","slazebni@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364, 7495","1045, 1187, 9102, 9216, HPCC, 7364","$0.00","This proposal is to develop a general representation framework that uses similarity to capture relationships in large scale image collections. The representation is not restricted to any specific distance function, feature, or learning model. It includes new methods to combine multiple kernels based on different cues, learn low-rank kernels, and improve indexing efficiency. In addition, new methods for nearest neighbor search and semi-supervised learning are proposed. It has relevance to machine learning and computer vision research agendas. Two major research problems addressed are: (1) defining and computing similarities between images' in vast, expanding, repositories, and representing those similarities in an efficient manner so the right pairs can be retrieved on demand; and (2) developing a system that can learn and predict similarities with 'sparse supervisory information and constantly evolving data.' The approach is notable in its embrace of the scale of web archives and its use of verbal and visual means of analysis."
"1132009","CRCNS Research Proposal: Coding and Propagation of Uncertainty Information During Perceptual Decisions","IIS","CRCNS, ROBUST INTELLIGENCE, ACTIVATION","09/01/2011","06/04/2014","Andreas Tolias","TX","Baylor College of Medicine","Continuing grant","Kenneth C. Whang","08/31/2015","$862,263.00","Whee Ky Ma, Andreas Tolias","astolias@bcm.edu","ONE BAYLOR PLAZA","HOUSTON","TX","770303411","7137981297","CSE","7327, 7495, 7713","7327, 7495, 7713","$0.00","Like Miss Marple in an Agathie Christie detective novel, the brain is often faced with the task of inferring a state of the world from noisy and ambiguous clues. An important question is whether, and if so how, the brain performs such inference in a near-optimal manner. This project combines visual decision-making experiments in humans and monkeys with computational modeling and state-of-the-art population recordings in monkey to investigate this question. The project will lead to new insights into the neural code and the relation between neurons and behavior.<br/><br/>A task is used in which an observer classifies a briefly flashed oriented stimulus into one of two classes. The classes are defined by fixed, overlapping probability distributions over orientation. Two common forms of uncertainty play a role in this task. Noise in the sensory observation causes sensory uncertainty, but even if this noise were taken away, a given observation would be consistent with either class; this is an example of ambiguity or class uncertainty. The optimal decision strategy requires the observer to keep track of sensory uncertainty on every trial and to appropriately combine this information with knowledge of the two classes.<br/><br/>The first part of this project will determine whether the computational strategy taken by humans and monkeys during this task is near-optimal. The second part is concerned with whether and how sensory uncertainty is encoded on a trial-by-trial basis in monkey primary visual cortex, and subsequently used in the monkey's decision. This study will put to the test well-known theoretical frameworks for the representation of sensory uncertainty. In the third part, the propagation of sensory uncertainty information from visual cortex to a higher-level decision area, prefrontal cortex, will be examined. Taken together, this project will constitute the first comprehensive test of optimal inference at the level of cortical populations."
"1302662","RI: AF: Medium: Learning and Matrix Reconstruction with the Max-Norm and Related Factorization Norms","IIS","ROBUST INTELLIGENCE, NUM, SYMBOL, & ALGEBRA COMPUT","06/01/2013","06/04/2014","Nathan Srebro","IL","Toyota Technological Institute at Chicago","Continuing grant","Todd Leen","05/31/2017","$596,549.00","Yury Makarychev","nati@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372902","7738340409","CSE","7495, 7933","7495, 7924, 7933, 9251","$0.00","Matrix learning is fundamental in many learning problems. These include problems that can be directly formulated as learning some unknown matrix, as well as a broader class of learning problems involving a matrix of parameters. The most direct matrix learning problem is matrix completion, completing unseen entries in a partially observed matrix. Matrix completion has recently received much attention both in practice in collaborative filtering (notably through the Netflix challenge), and theoretical analysis as an extension to compressed sensing. Matrix learning has also been used for clustering, transfer and multi-task learning, and similarity learning.<br/><br/>The dominant approach to matrix learning in recent years, especially in the context of matrix completion, has used the matrix trace norm (developed in part by the PI on this award). Indeed, trace norm-based methods enjoy much success in a variety of applications. This project develops and studies alternative matrix norms to the trace-norm, most importantly the promising max-norm.<br/><br/>Learning with the max-norm was initially presented in 2004 (along with the trace norm), but has not received the same attention, despite many theoretical and empirical advantages. This project identifies domains where the max-norm and related norms can be beneficial, develops computational methods for using these norms, and promotes the adoption of these norms. A central aim is to develop optimization methods for max-norm regularized problems that are as efficient as the corresponding methods for trace-norm regularized problems, such as singular value thresholding and LR-type methods. Beyond matrix completion, the project applies the max-norm both to problems where the trace-norm has been previously applied, and in novel settings. Novel applications include clustering, binary hashing, crowdsourcing, modeling rankings by a population, and similarity learning.<br/><br/>Research under this project links the machine learning and theory-of-computation research communities (where SDP relaxations essentially corresponding to the max-norm have played a significant role in recent years). The project forms bridges between the communities, enabled in part by cross-disciplinary tutorials. Through collaboration with sociologists the PIs reach out to the social sciences, and increase the broad impact of the work by presenting it in an approachable and useable way to this audience."
"1350763","EAGER: Towards Human Centered Visual Understanding: Exploring the Intended and Interpreted Meaning of Images in Social Multimedia","IIS","ROBUST INTELLIGENCE","09/15/2013","09/06/2013","Gang Hua","NJ","Stevens Institute of Technology","Standard Grant","Jie Yang","08/31/2015","$199,170.00","","gang.hua@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7495","7495, 7916","$0.00","This project explores a new direction in computer vision, which is to model the context dependent visual semantics associated with images in social multimedia. The context dependent visual semantics, e.g., the intended and perceived sentiment of an image in social multimedia, are dynamically formed based on the various contextual information associated with it. This is different from the static visual semantics that conventional computer vision research focused on studying, such as the object category presented in the image.<br/><br/>The project develops a set of new networked and context aware probabilistic latent semantic models, which integrate situated contextual information into visual content analysis for modeling context dependent visual semantics. The research team is verifying two hypotheses: 1) the context dependent semantics needs to be holistically modeled and jointly inferred from a collection of related images; and 2) related context dependent visual semantics, such as intended and perceived meaning of an image, also needs to be jointly modeled for more robust recognition.<br/><br/>The project is integrated with education through training graduate and undergraduate students. The outcome of the research can be applied to many domains, such as targeted online advertisements; open source information analysis and social event prediction; and social multimedia security."
"1009542","Text, Neuroimaging, and Memory: Unified Models of Corpora and Cognition","IIS","BIOMEDICAL ENGINEERING, ROBUST INTELLIGENCE","08/01/2010","06/04/2014","David Blei","NJ","Princeton University","Standard Grant","Kenneth C. Whang","07/31/2015","$732,296.00","Kenneth Norman","blei@cs.princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085400036","6092583090","CSE","5345, 7495","004E, 7327","$0.00","The PIs will develop new machine learning algorithms to explore how meaning is represented in the brain and how meaning representations shape human memory. Current neuroscientific theories of memory posit that forming a memory for a particular event involves associating the details of that event with the person's current mental context, i.e., everything else that she is thinking about at the time. When trying to remember the event, the person can access stored details by reinstating the mental context that was present when the memory was formed. This fits with the intuition that forgotten details (e.g., the location of misplaced house keys) can be retrieved by mentally ""re-tracing steps"", i.e., trying to reinstate the mindset that was present at the time of the original event. With these theories in mind, the goal of this work is to develop machine learning algorithms that make it possible to track, based on fMRI brain data and behavioral memory data, the process of ""mentally re-tracing steps""---the proposed algorithms will be able to decode the state of a person's mental context as she forms memories and (later) as she searches for these memories.<br/><br/>The proposed work uses two fundamental ideas about memory and meaning: The first idea is that mental context is shaped by the meanings of recently encountered stimuli. The second idea is that semantic relationships between concepts in the brain mirror statistical relationships between words in naturally occurring language. The developed algorithms will bring together data from three sources---behavioral data from subjects performing memory recall tasks, fMRI neuroimaging data collected while subjects performed these tasks, and large collections of documents---to discover a latent meaning space that can simultaneously describe all three types of information. Each point in this space describes a mental context. Thus the core of the proposed work is to develop latent variable models and algorithms that can infer from data how the mental context moves through meaning space as a person stores and searches for memories.<br/><br/>The proposed work will lead to fundamental advances in machine learning (new algorithms for inferring hidden variables based on multiple, heterogeneous data types) and neuroscience (more refined theories of how memory search is accomplished in the brain). Furthermore, this work will catalyze the development of new technologies for diagnosing and remediating memory problems, by making it possible to track how the contextual reinstatement process is going awry in people experiencing memory retrieval failure."
"1162131","HCC: Medium: Collaborative Research: Haptic Display of Terrain Characteristics and its Application in Virtual and Physical Worlds","IIS","Cyber-Human Systems","10/01/2012","06/05/2014","Peter Willemsen","MN","University of Minnesota Duluth","Continuing grant","Ephraim P. Glinert","09/30/2016","$168,429.00","","willemsn@d.umn.edu","1049 University Drive","Duluth","MN","558123011","2187267582","CSE","7367","7367, 7924, 9251","$0.00","The PIs' goal in this research is to realistically display terrain in an immersive Virtual Reality (VR) locomotion interface, based upon modification of the foot/terrain interaction coupled with graphical and auditory display of the terrain and user interaction. Project outcomes will include novel ""smart shoe"" technology capable of sensing and modifying the terrain perceived by the wearer at each step so that terrain slope, surface stiffness, height variations, slip and balance can be actively controlled. The approach is based upon an instrumented shoe sole with a directionally compliant structure using controllable bladders and embedded sensors to regulate terrain effects as the user walks. The design and control of the shoe will be based upon dynamic biomechanical and terrain interaction models. Subject data will provide a baseline for design, verification, and validation of the system. A robotic test-bed will validate shoe response characteristics prior to subject evaluations.<br/><br/>The platform for this work will be the existing TreadPort Active Wind Tunnel (TPAWT), which is capable of realistically displaying locomotion environments on varying slopes as well as providing controllable wind, heat, and odor display. The cave-like display of the TPAWT will be converted to a three dimensional stereo graphics system with seamless floor projection in order to present local terrain features such as shape, height variations, and surface texture. Combined representation, interpretation, and coordination of the graphical and physical artifacts will be considered with the aim of creating an immersive and realistic locomotion experience with the end goal of achieving practical application. This combined system is termed the TPAWT Terrain Display System (TPAWT-TDS).<br/><br/>The target test group for the new technology will be patients with Parkinson's Disease, (PD), for whom VR training has already shown some promising results for improving gait characteristics and reducing the likelihood of falls. Survey data from PD patients will motivate selection of the specific terrain. Regular and PD users will first be evaluated on physical mockups of the terrain, which will then be recreated and evaluated in follow-up trials in the VR environment. Once validated, the VR terrain display will be used for PD training. Users will again be evaluated on the physical mockups to evaluate gait and balance performance, which will also be compared to untrained subjects.<br/><br/>Broader Impacts: The ""smart shoe"" technology to be created in this project will allow exploration of new and sophisticated methods for combining 3D graphical terrain cues with an actively changing physical terrain in a novel VR interface. The resulting environment will have myriad potential applications as a rehabilitation and training tool, not the least of which is improved locomotion and fall prevention (since falls are the single most costly form of injury today). Development of the new technology will be combined with rigorous human participant studies. Research findings will be disseminated via websites and at major conferences, and also integrated into the robotics, virtual reality, ergonomics, and physical therapy curricula."
"1065027","HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics","IIS","Cyber-Human Systems","06/01/2011","06/05/2014","Richard Gillespie","MI","University of Michigan Ann Arbor","Continuing grant","Ephraim P. Glinert","05/31/2015","$429,967.00","","brentg@engin.umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7367, 7924, 9251","$0.00","This research involves collaboration among investigators at four institutions. Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning. While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms. For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control. The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions. These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof). The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags. The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date. In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics. To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR). An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis. Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder. To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined.<br/><br/>Broader Impacts: This research will revolutionize the control and interface of upper limb prosthetics. The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease. The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research. The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering."
"0845835","CAREER: Mothership/Daughtership Architectures for In Situ Science by Robotic Sensor Networks","IIS","ROBUST INTELLIGENCE, PHYSICAL & DYNAMIC METEOROLOGY","07/01/2009","06/12/2013","Eric Frew","CO","University of Colorado at Boulder","Continuing grant","Satyandra Gupta","06/30/2015","$511,497.00","","eric.frew@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7495, 1525","1045, 1187, 4444, 7495, 9215, 9251, HPCC","$0.00","The objective of this project is to develop fundamental understanding of control strategies that can exploit the complimentary computation, sensing, and communication capabilities of the members of a mothership/daughtership robotic sensor network performing in situ volumetric sensing. Concepts from networked unmanned systems, cooperative control, controlled mobility in ad hoc networks, motion planning, and optimal distributed sensing are combined to create a new heterogeneous robot team comprised of two classes of robots with significantly different, though complementary, attributes. Research activities are organized into three main thrusts: i.) daughtership control using ordered upwind methods for motion planning in the presence of strong currents and decentralized coverage control for cooperative sampling in the presence of intermittent communication; ii.) mothership control algorithms based on reinforcement learning to provide delay-tolerant networking and stochastic dynamic programming for optimal deployment and reassignment of the daughterships; and iii.) experimental demonstration performed on an indoor robotic sensor network, outdoors on a heterogeneous unmanned aircraft system, and part of field campaigns with atmospheric scientists.<br/><br/>The proposed research project will provide new capabilities for in situ volumetric sampling of complex atmospheric phenomena which will lead to a direct improvement in the ability to understand complex environments. This project will have its broadest impact through the applications that will benefit from robotic sensor networks performing in situ science. Collaborations focus on the study of tornadogenesis in severe storms, sea ice change, and spatio-temporal evolution of airmass boundaries. Additionally, research and education are integrated into activities aimed at improving the perception of the engineering field by K-12 students, retaining those students who are initially attracted to engineering, bringing hands-on active learning to several aerial robotic courses, and fostering interaction between scientists and engineering researchers."
"1116475","RI: SMALL: Modeling Voice Source Transformation in Monolingual and Crosslingual Non-parallel Voice Conversion Applications","IIS","ROBUST INTELLIGENCE","07/15/2011","05/07/2012","Elliot Moore","GA","Georgia Tech Research Corporation","Continuing grant","Tatiana D. Korelsky","06/30/2015","$252,637.00","","em80@mail.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7923, 9251","$0.00","Voice conversion (VC) systems transform segments of speech from a given source speaker so that it<br/>can be identified as spoken by a specified target speaker. Currently, standard VC systems require<br/>parallel training on extensively labeled sets of speech data where the source and target speaker share<br/>equivalent content for building direct mapping models. This project builds on the concepts of nonparallel<br/>VC systems reducing the need for labeled and shared speech content between source and target<br/>speakers as well as allowing for both intra-lingual and cross-lingual conversion scenarios. This project<br/>focuses on two main areas: (1) Building a framework for non-parallel VC without explicit phonetic,<br/>sound, word, or sentence level labels, and (2) Providing effective target speaker mapping to obtain<br/>converted speech with as good as or better quality compared to current VC systems. The VC<br/>framework consists of three main components: (1) A speaker independent language model; (2) An<br/>algorithm for model adaptation to target speaker; (3) A speech synthesis block to generate converted<br/>speech from a target-adapted language model.<br/><br/>This project will provide a broad framework for applications such as personalization of assistive textto-<br/>speech (TTS) systems, foreign language learning, and as a possible component in speech-to-speech<br/>translation systems. This project will support graduate student research and provide results for<br/>community distribution through conference and journal submission. Additionally, an open-source<br/>software toolset will be developed and freely distributed. The project will also be used in outreach for<br/>underrepresented groups in Science Technology Engineering and Mathematics (STEM) disciplines."
"1064606","III: Medium: Collaborative Research: Database-As-A-Service for Long Tail Science","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/17/2013","Michael Cafarella","MI","University of Michigan Ann Arbor","Continuing grant","Sylvia J. Spengler","07/31/2015","$231,977.00","","michjc@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364","7924","$0.00","With tremendous amounts of data existing in scientific applications, database management becomes a critical issue, but database technology is not keeping pace. This problem is especially acute in the long tail of science: the large number of relatively small labs and individual researchers who collectively produce the majority of scientific results. These researchers lack the IT staff and specialized skills to deploy technology at scale, but have begun to routinely access hundreds of files and potentially terabytes of data to answer a scientific question. This project develops the architecture for a database-as-a-service platform for science. It explores techniques to automate the remaining barriers to use: ingesting data from native sources and automatically bootstrapping an initial set of queries and visualizations, in part by aggressively mining a shared corpus of data, queries, and user activity. It investigates methods to extract global knowledge and patterns while offering scientists access control over their data, and some formal privacy guarantees. The Intellectual Merit of this proposal consists of automating non-trivial cognitive tasks associated with data work: information extraction from unstructured data sources, data cleaning, logical schema design, privacy control, visualization, and application-building. As Broader Impacts, the project helps scientists reduce the proportion of time spent ""handling data"" rather than ""doing science."" All software resulting from this project are open source, and all findings are disseminated broadly through publications and workshops. Sustainable support for science users of the software is coordinated through the University of Washington eScience Institute. The research is incorporated in both undergraduate and graduate computer science courses, and the software is also incorporated into domain science courses as well. The project's outreach activities include advising students through special programs geared toward under-represented groups such as the CRA-W DREU. More information about this project is found at http://escience.washington.edu/dbaas."
"1116636","HCC: Small: Collaborative Research: The Influence of Self-Avatars on Perception and Action in Virtual Worlds","IIS","Cyber-Human Systems","09/01/2011","05/20/2013","William Thompson","UT","University of Utah","Standard Grant","William Bainbridge","08/31/2015","$273,927.00","Sarah Creem-Regehr, Jeanine Stefanucci","thompson@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7367","7367, 7453, 7923, 9150, 9251","$0.00","The objective of this research is to enable more effective design and use of virtual worlds. The pervasiveness of visually-oriented online and interactive digital media allows people to represent themselves increasingly through surrogates in virtual worlds. These digital personae are called ""avatars,"" and when they closely represent the user, ""self-avatars."" Self-avatars enable forms of learning, interaction, and skill development that can increase a user's effectiveness in a virtual world. This project will explore how self-avatars play a significant role through three key components of perception and action: the relationship between action and the perception of space and objects, active acquisition of spatial memory, and the planning and execution of actions themselves. <br/><br/>This research will consider three properties of self-avatars themselves, each likely to have an effect across a broad range of situations: (1) the virtual perspective from which the avatar is seen, (2) the nature of the coupling between user size and motion and avatar size and motion, and (3) the naturalness of the interface system by which the user controls the avatar. The work builds on a growing body of knowledge about the role of body ownership in perceptual and cognitive tasks. This framework provides a theory in which to ground the research, a body of empirical knowledge about perception and action in the real world, and established methodologies that can be used for assessing the results of the research. The ability to utilize work from cognitive and perceptual science to solve a problem in computer graphics and user interaction is a major strength of the research. <br/><br/>Virtual environments are important in many domains, including architecture, education, medicine, simulation, training, and visualization. The core impact of this research is to enable self-avatars to enhance user experience in virtual environments, which are a major category of computer simulations. A broad impact of this project is that enhancing the user experience will lead to more capable applications of virtual environments in the aforementioned domains. This research will also have utility in entertainment systems, the dominant environments for avatars. It advances discovery and understanding while training students in cross-disciplinary research methods in an innovative intellectual environment. The interdisciplinary nature of the research and its consequent applications, together with the close integration of two research groups, will aid in bringing new students to computer science, beyond the students traditionally attracted to that field."
"1117663","III: Small: Collaborative Research: Shape Differences in the Biological Sciences","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/13/2012","Annamaria Amenta","CA","University of California-Davis","Standard Grant","Sylvia J. Spengler","08/31/2015","$437,223.00","Joel Hass, Owen Carmichael","amenta@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7364","7923, 9102, 9251","$0.00","Finding and quantifying differences between shapes is important in many areas of the biological sciences. This methodological research will contribute to ongoing research in two areas, neuroscience and paleontology. In neuroscience, the interest is mainly in tracking the progress of Alzheimer's disease and normal aging processes in the brain, and relating the 3D shape changes seen in MRI scans to cognitive measurements and other variables. NIH studies provide access to large amounts of such data. In paleontology, the only information on many extinct species comes from fossils, and estimates of the relationships between these fossil species and human ancestors is based largely on differences and similarities of shape. The goal is to put fossil shape data into the context of much larger sets of data collected from existing species, both morphological and genomic data from earlier research. <br/><br/>This collaboration is interested in defining and computing what it means for three-dimensional biological shapes to resemble each other; as specific examples, they consider the shapes of fossil primate bones and of regions in the brain such as the hippocampus. Current practical measures of shape difference are based on sets of corresponding point samples on the object surfaces. The team will add a surface mesh connecting these corresponding points, and represent a shape by the vector of the lengths of the edges in its copy of the mesh. The distance between two shapes is then the Euclidean distance between their corresponding edge vectors. This representation has some attractive mathematical properties. With a few simple additional requirements on the mesh, the edge-length vectors form a high-dimensional Euclidean space, within which standard statistical analyses can be performed. Second, the measure is invariant to rotations and translations not only of the entire object, but to a large extent to transformations of one part of the object with respect to the rest. <br/><br/>The research will include experimental work to compare the proposed metric and<br/>current methods in both neurobiology and in physical anthropology. They also intend to work on methods to simplify finding and optimizing corresponding points and meshes connecting them on input specimens, a perennial problem in three-dimensional data analysis. Not only is this important to facilitate experiments, but having a good practical shape metric will help improve techniques in this area. Finally, the team plans work on interesting related mathematical problems, specifically the convergence of the metric to property of smooth surfaces as the sampling density is increased <br/><br/>There are plans to release both software for the use of practitioners and ensembles of data annotated with corresponding meshes for the use of other researchers into the methodology of shape differences. In this way the research should benefit many others who analyze shape differences: our colleagues in paleontology and neuroscience, people who study the anatomy of humans, other animals and even plants, forensic scientists, and others."
"1018751","RI: Small: Learning and Inference with And-Or Graphs for Image Understanding","IIS","ROBUST INTELLIGENCE","08/01/2010","06/30/2011","Song-Chun Zhu","CA","University of California-Los Angeles","Continuing grant","Jie Yang","12/31/2014","$450,000.00","Yingnian Wu","sczhu@stat.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7923, 9150","$0.00","In this project, the PIs and students study a probabilistic and graphical representation, called the And-or graph (AoG) for visual knowledge representation. This AoG model embodies hierarchical and contextual models for visual objects and scenes and is the key to robust object and scene recognition. More specifically, the project addresses two major technical challenges: (i) Learning the AoG for representing objects and scenes in an unsupervised way; and (ii) Developing effective inference algorithm by scheduling top-down and bottom-up processes to extract semantic contents in a parse graph under the guidance of the AoG. The extracted semantics include the hierarchical decomposition of the image from scene to objects, and parts, as well as the contextual relations. These contents are crucial for filling in the semantic gap in large scale image search and retrieval. The technologies studied in this project are key to a number of applications, such as image content extraction for security surveillance, information gathering, Internet image search, and situation awareness. One specific application studied in this project is autonomous driving assistant for designing safer vehicles and reducing car accidence. The project also supports the training of 3 graduate students over the three year period. Research results are disseminated through public publications in major computer vision conferences and journals, institutional webpages, and shared data sets and code in the Internet."
"1116917","RI: Small: Planning Algorithms for Large Decentralized Multiagent Settings","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","09/01/2011","05/25/2012","Shlomo Zilberstein","MA","University of Massachusetts Amherst","Continuing grant","Jie Yang","08/31/2015","$474,906.00","","shlomo@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7298, 7495","5936, 5979, 7495, 7923","$0.00","This project is aimed at developing effective decision-theoretic planning algorithms for multi-agent systems that involve dozens or hundreds of agents. Current approaches to agent coordination that provide rigorous performance guarantees can only handle a few agents. The project addresses this barrier with the following objectives: (1) develop new problem representations that allow planning algorithms to leverage the interaction structure and independence relationships within a domain; (2) develop approximation methods that operate with limited memory and time, and exhibit anytime characteristics; (3) perform rigorous convergence analysis and establish tight error bounds on solution quality; (4) develop techniques that make it easy to exploit parallelization offered by multi-core processors; and (5) create a new set of challenging test problems and perform a rigorous evaluation. The project produces two fundamentally new approaches to planning in multi-agent settings. The first approach offers efficient message-passing planning algorithms based on computational paradigms such as expectation-maximization (EM) and the concave-convex procedure (CCCP). The second approach offers rollout sampling methods for domains that are too large to be explicitly represented. These new methods improve the scalability of existing techniques by several orders of magnitude. The results transform the ability of researchers and practitioners to apply rigorous decision-theoretic planning to multi-agent domains such as sensor networks and mobile robot coordination. The broader impact stems from the wide applicability of the resulting technology, undergraduate and graduate educational activities at UMass, dissemination efforts that make the experimental domain and algorithms publically available, and the development of international collaborations."
"1350799","CAREER: Measuring Search Engines' Ability to Help Users Complete Tasks","IIS","INFO INTEGRATION & INFORMATICS","06/01/2014","06/04/2014","Benjamin Carterette","DE","University of Delaware","Continuing grant","Maria Zemankova","05/31/2019","$102,766.00","","carteret@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7364","1045, 7364, 9150","$0.00","The purpose of this project is to improve search systems' ability to help users complete tasks. The usefulness of any search engine ultimately depends on how good it is at aiding its users. The systems and the tasks they are used for can be very complicated; small changes in a system's implementation or a task's execution can have major effects on the usefulness of the system, especially over a long lifespan of use by a large base of people. The traditional approach to understanding utility involves the use of test collections, which consist of a collection of documents to be searched, unchanging information needs, and human judgments of the relevance of documents to needs; these components are put into a simple batch process that measures search effectiveness and tests simple statistical hypotheses. While this approach is useful, it often fails to capture variability present in users and tasks: different users often interact with the same system in very different ways, meaning a system that is useful for one user or one task may not be useful for another user or task. Therefore, this project focuses on developing new methods for understanding, estimating, and improving the usefulness of information retrieval (IR) systems that take variability into consideration. <br/><br/>The methods investigated in this project are designed to model user interactions with a system to complete a task, including how users determine relevance in context, how they modify their interaction with a system over time, and how different approaches by different users affect the overall system usefulness. The project will produce new types of test collections, evaluation measures, and statistical methods for batch-style systems-based information retrieval evaluation for use by researchers and practitioners in academia and industry. The work will demonstrate how to use these both to improve system utility to a population of users as well as to pose deeper hypotheses about causality in IR system development, thus leading to improvements in IR technology in all domains. Research will be integrated with educational activities for students as well as researchers and practitioners to learn advanced experimental design and analysis. Educational efforts will include tutorials and teaching courses on empirical methods in IR and computer science, methods in use in the wider scientific community, and how the newly developed methods relate to those. Results produced from this project can be found on the project web site (http://ir.cis.udel.edu/IIS-1350799)."
"1117335","III: Small: Collaborative Research: A Large-Scale Data Mining Framework for Genome-Wide Mapping of Multi-Modal Phenotypic Biomarkers and Outcome Prediction","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","05/02/2012","Li Shen","IN","Indiana University","Standard Grant","Sylvia J. Spengler","07/31/2015","$216,000.00","Andrew Saykin","shenli@iu.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7364","7923, 9251","$0.00","Today's massive generation of digital data is greatly outpacing the development of computational methods and tools and presents critical challenges for achieving the full transformative potential of these data. For example, recent advances in acquiring multi-modal brain imaging and genome-wide array data provide exciting new opportunities to study the influence of genetic variation on brain structure and function. Major computational challenges are, however, bottlenecks for comprehensive joint analysis of these data due to their unprecedented scale and complexity. This project will employ the new capabilities of large-scale data mining techniques in multi-view learning, multi-task learning, and robust classification to address critical challenges in systematically analyzing massive multi-modal genetic, imaging, and other biomarker data. Specifically, this project will: (1) develop new multi-view learning methods to detect task-relevant phenotypic biomarkers from large scale heterogeneous imaging and other biomarker data, (2) implement new sparse multi-task regression models to reveal the genetic basis of phenotypic biomarkers at multiple levels (e.g., SNP, haplotype, gene and/or pathway), (3) design novel robust classification methods via structural sparsity for outcome prediction using integrated genotypic and phenotypic data, and (4) package these new methods into a data mining toolkit and release it to the public. <br/><br/>The intellectual merits of this project derive not only from the development of novel data mining methods, but also from their application to imaging genetic studies. These methods are designed to take into account interrelated structures among multiple data modalities and offer systematic strategies to reveal structural imaging genetic associations. The proposed methods and tools are expected to impact neurological and psychological research and enable investigators to effectively test imaging genetics hypothesis and advance biomedical science and technology. In addition, the proposed data mining framework addresses generic critical needs of large-scale data analysis and integration and, therefore, will impact a large number of research areas where high-value knowledge and complex patterns can potentially be discovered from massive high-dimensional and heterogeneous data sets. This project will facilitate the development of novel educational tools to enhance several current courses at UT Arlington and IUPUI. Both universities are minority-serving institutions, and the PIs will engage the minority students and under-served populations in research activities to give them a better exposure to cutting-edge scientific research."
"1444644","IEEE VIS Conference 2014: Doctoral Colloquium","IIS","INFO INTEGRATION & INFORMATICS","08/01/2014","06/03/2014","Jian Chen","MD","University of Maryland Baltimore County","Standard Grant","Maria Zemankova","07/31/2015","$20,880.00","","jichen@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7364","7364, 7453, 7556, 9102, 9179","$0.00","This is funding provides partial support to about 18 dissertation stage US-based doctoral students to participate in the Doctoral Colloquium that is a part of the IEEE Viz Conference to be held November 9-14, 2014 in Paris, France. The Doctoral Colloquium at IEEE VIS is a research-focused meeting which has taken place annually at the visualization conferences since 2006, and has helped launch the careers of a number of outstanding young researchers. The primary goal of the Doctoral Colloquium is to allow students to discuss their research directions in a supportive atmosphere with a panel of distinguished leaders and with their peers, who will provide helpful feedback and fresh perspectives. The workshop will support community building by connecting beginning and advanced researchers and foster a network of colleagues across the world. <br/><br/>Visualization, or the use of interactive graphics to support data analysis and understanding, has become an integral part and critical component of many application areas. IEEE VIS is the premier forum for visualization advances in science and engineering for academia, government, and industry, now bringing together about thousands researchers and practitioners from around the world with a shared interest in techniques, tools, and technology. VIS consists this year of the 25th Annual IEEE Scientific Visualization Conference (SciVis), the 20th Annual IEEE Information Visualization Conference (InfoVis), and the 9th Annual IEEE Visual Analytics Science and Technology Conference (VAST). It will also include the IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), the workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization (BELIV), and the International Symposium on Visualization for Cyber Security (VizSec). The papers will be published in the special conference issue of IEEE Transactions of Visualization and Computer Graphics -- a widely cited venue. More information is available online at http://www.ieeevis.org. &#8232;&#8232;"
"1064685","III: Medium: Collaborative Research: Database-As-A-Service for Long Tail Science","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/26/2013","David Maier","OR","Portland State University","Continuing grant","Sylvia J. Spengler","07/31/2015","$224,999.00","","maier@cs.pdx.edu","1600 SW 4th Ave","Portland","OR","972070751","5037259989","CSE","7364","7924","$0.00","With tremendous amounts of data existing in scientific applications, database management becomes a critical issue, but database technology is not keeping pace. This problem is especially acute in the long tail of science: the large number of relatively small labs and individual researchers who collectively produce the majority of scientific results. These researchers lack the IT staff and specialized skills to deploy technology at scale, but have begun to routinely access hundreds of files and potentially terabytes of data to answer a scientific question. This project develops the architecture for a database-as-a-service platform for science. It explores techniques to automate the remaining barriers to use: ingesting data from native sources and automatically bootstrapping an initial set of queries and visualizations, in part by aggressively mining a shared corpus of data, queries, and user activity. It investigates methods to extract global knowledge and patterns while offering scientists access control over their data, and some formal privacy guarantees. The Intellectual Merit of this proposal consists of automating non-trivial cognitive tasks associated with data work: information extraction from unstructured data sources, data cleaning, logical schema design, privacy control, visualization, and application-building. As Broader Impacts, the project helps scientists reduce the proportion of time spent ""handling data"" rather than ""doing science."" All software resulting from this project are open source, and all findings are disseminated broadly through publications and workshops. Sustainable support for science users of the software is coordinated through the University of Washington eScience Institute. The research is incorporated in both undergraduate and graduate computer science courses, and the software is also incorporated into domain science courses as well. The project's outreach activities include advising students through special programs geared toward under-represented groups such as the CRA-W DREU. More information about this project is found at http://escience.washington.edu/dbaas."
"1229628","MRI: Development of a Near-Real-Time High-Accuracy Musculoskeletal System Measurement and Analysis Instrument (SKELETALMI)","CNS","MAJOR RESEARCH INSTRUMENTATION, INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, ROBUST INTELLIGENCE, Smart and Connected Health","10/01/2012","09/20/2012","Dimitris Metaxas","NJ","Rutgers University New Brunswick","Standard Grant","Rita V. Rodriguez","09/30/2016","$1,111,040.00","Vladimir Pavlovic, Kang Li","dnm@cs.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","1189, 1640, 1714, 7495, 8018","1189, 8018","$0.00","This project, developing an instrument for near-real-time high-accuracy musculoskeletal system analysis named SKELETALMI, aims to enable timely and accurate measurement, analysis, and characterization of in vivo combined joint movement, whole body kinematics, skeletal muscle activity, and body reaction forces. The instrument consist of hardware components that include devices for fluoroscopic X-ray image acquisition, for measuring whole body movement, for skeletal muscle activity, for measuring lower and upper body reaction forces, and a high performance computer system; as well as software to analyze and characterize jointly in vivo joint kinematics, joint kinetics, and muscle activation.<br/>SKELETALMI is expected to <br/>- Allow real-time calibration through overlay between fluoroscopic images and optical images;<br/>- Automatically reconstruct 3D bone models from CT and MRI scans in real-time;<br/>- Automatically estimate 3D in vivo bone movement through 2D/3D registration; <br/>- Automatically establish 3D bone coordinated systems and convert the 3D in vivo movement into 3D joint kinematics;<br/>- Fuse the accurate joint kinematics, whole body kinematics, muscle activation, and body reaction forces and visualize all the information on digital human models.<br/>This development has a strong multidisciplinary component that involves algorithms, biomechanics, biomedical imaging, HCI, and computer graphics. The project constitutes a joint collaborative effort of Rutgers with the State University of NJ and Kessler Foundation Research Center.<br/><br/>Broader Impacts: <br/>The instrumentation impacts many application domains such as shoe design, athletic training, injury prevention, aging, design of movement-related medical device, and surgical/rehabilitation technique innovation. Underpinned by the capabilities of the instrument and the new related data collected, new courses will be developed in musculoskeletal biomechanics, graphics simulation, movement analysis, and biomedical image analysis. Consequently, the instrument also influences the educational programs at the institution that should generate graduates with a comprehensive knowledge of computational sciences, medical science, and product design."
"1218872","RI: Small: Collaborative Research: Detecting Abnormalities in Images","IIS","ROBUST INTELLIGENCE","05/15/2013","05/07/2013","Ahmed Elgammal","NJ","Rutgers University New Brunswick","Standard Grant","Kenneth C. Whang","04/30/2016","$339,962.00","Jacob Feldman","elgammal@cs.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7495","7495, 7923","$0.00","Computer interpretation of images has taken huge strides in recent years, but even the most modern algorithms can't come close to matching human capabilities on simple visual tasks. For example, in a brief glance at an image, people reflexively classify the objects in it in terms of the categories they belong to--people, animals, tools, and other significant classes. This allows us to understand the objects' meaning in the image, for example understanding that a scene with many pieces of food might be a dinner table. Because even modern computer vision systems can't make such a classification, they can't automatically detect when an object in a scene doesn't belong, that is, when it is abnormal relative to the categories present in the scene. Detecting such ""oddball"" or atypical objects is essential to understanding visual scenes, because objects that don't belong are often the ones that play the most important role and require immediate action (like a cat on the dinner table). Studies of human subjects have shown that humans are indeed especially adept at detecting atypical items, which often draw our visual attention even before we become consciously aware of them.<br/><br/>This project aims at developing algorithmic techniques to endow computer visions systems with the same ability. By adapting modern vision techniques to mimic the way human observers classify visual atypicality, researchers will develop computer systems that can examine an image and automatically detect abnormal objects, as well as identifying the nature of the abnormality and quantifying the degree of abnormality. The project involves a collaboration among researchers at multiple universities and multiple scientific specialties, including both computer vision and human vision. The result will be a new and useful class of computer vision techniques that can be applied to visual image understanding in many contexts."
"1320520","HCC: Small: Social Agents and Robots for Open-Ended Domains","IIS","Cyber-Human Systems","08/15/2013","05/09/2014","Brian Magerko","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","07/31/2016","$513,789.00","Andrea Thomaz, Mark Riedl","brian@magerko.org","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923, 9251","$0.00","Recreational activity is a fundamental aspect of human existence and an important part of the human condition within familial and social groups, where it serves to strengthen social ties by increasing affect between individuals and as a form of education in creative thinking. Despite a sizable accumulation of knowledge about such activity from sociology, anthropology, and psychology, ""play"" as a first-class concept has not been studied through the lens of computation. When today's agents engage with humans, they do so in the context of structured environments and are highly dependent on well-defined goals and/or behaviors. Contrast this to the domain of pretend play, which involves non-goal directed peer-to-peer activity in a shared imaginary second reality that is continually altered. Pretend play is a common form of engagement that is relevant to an array of social domains, such as elder care, peer learning, or social skills therapy for children with autism spectrum disorders. The PI's goal in this research is to imbue robot systems with procedural and declarative representations of play so that they are capable of engaging in such activity with humans as peers. The work aims to discover how to develop humanoid robots with the ability to engage, improvise, and create with humans in unstructured environments. Such robot capability would foster perceptions of lifelikeness, social acceptance, and companionship similar to the experience of playing with other people. These agents would encourage spirited behaviors and creativity in people. They would elicit high levels of interest, intrinsic motivation, and positive affect, which in turn would lead to better concentration, learning, and personal investment by the human participant. To achieve these goals, the PI will leverage his prior work on creativity and cognition to conduct a study of adults engaging in object-based pretend play to elicit a formal understanding of it in dyads. The findings will subsequently be applied to building social robots that engage, based on the team's expertise in human-centered AI and human-robot interaction. The resulting robot architecture will be evaluated to see how it can enhance robot affect and social acceptance. <br/><br/>Broader Impacts: This research will create a new academic research direction of Computational Play within the field of social robotics that has the potential to contribute a solid and unique advance to the field, and also to change how we interact with intelligent agents thereby increasing agents' social value and acceptance by the humans around them. The work will increase via empirical study our understanding of human engagement, and in particular of the knowledge and social dynamics involved in pretend scenarios. The playful robots to be designed, implemented and formally evaluated in this work will inform the human-robot interaction community as to how such activity can be used within HRI contexts to increase affect. This work also has the potential of improving the learning and creativity of those that interact with social agents, making computational play a valuable research direction for education. The project will provide a fertile ground for interdisciplinary training of graduate and undergraduate students, and a wealth of interaction data that will be shared with the scientific community."
"1029711","Collaborative Research: Understanding Climate Change: A Data Driven Approach","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2010","06/02/2014","Vipin Kumar","MN","University of Minnesota-Twin Cities","Continuing grant","Christopher Clifton","08/31/2015","$6,576,261.00","Shashi Shekhar, Jonathan Foley, Arindam Banerjee, Auroop Ganguly","kumar@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","1640, 7364","1640, 7364, 7723, 7969, 9218, 9251, HPCC","$0.00","Understanding Climate Change: A Data Driven Approach<br/><br/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br/><br/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br/><br/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br/><br/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br/><br/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br/><br/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to analyze physical processes. This project will also contribute to efforts in education, diversity, community engagement, and dissemination of tools and computer and atmospheric science findings."
"1409431","RI: Medium: Deep Neural Networks for Robust Speech Recognition through Integrated Acoustic Modeling and Separation","IIS","ROBUST INTELLIGENCE","06/01/2014","06/03/2014","Eric Fosler-Lussier","OH","Ohio State University","Continuing grant","Tatiana D. Korelsky","05/31/2017","$256,271.00","DeLiang Wang, Michael Mandel","fosler@cse.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7495","7495, 7924","$0.00","Over the last decade, speech recognition technology has become steadily more present in everyday life, as seen by the proliferation of applications including mobile personal agents and transcription of voicemail messages. Performance of these systems, however, degrades significantly in the presence of background noise; for example, using speech recognition technology in a noisy restaurant or on a windy street can be difficult because speech recognizers confuse the background noise with linguistic content. Compensation for noise typically involves preprocessing the acoustic signal to emphasize the speech signal (i.e. speech separation), and then feeding this processed input into the recognizer. The innovative approach in this project is to train the recognition and separation systems in an integrated manner so that the linguistic content of the signal can inform the separation, and vice versa. <br/><br/>Given the impact of the recent resurgence of Deep Neural Networks (DNNs) in speech processing, this project seeks to make DNNs more resistant to noise by integrating speech separation and speech recognition, exploring three related areas. The first research area seeks to stabilize input to DNNs by combining DNN-based suppression and acoustic modeling, integrating masking estimates across time and frequency, and using this information to improve reconstruction of speech from noisy input. The second area seeks to examine a richer DNN structure, using multi-task learning techniques to guide the construction of DNNs better at performing all tasks and where layers have meaningful structure. The final research area examines ways to adapt the spurious output of DNN acoustic models given acoustic noise. With the focus of integrating speech separation and recognition, the project will be evaluated both by measuring speech recognition performance, as well as metrics that are more closely related to human speech perception. This will ensure a broader impact of this research by providing insights not only to speech technology but also facilitating the design of next-generation hearing technology in the long run."
"1445149","Travel Awards for 2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM-2014)","IIS","INFO INTEGRATION & INFORMATICS","06/01/2014","06/03/2014","Xiaohua (Tony) Hu","PA","Drexel University","Standard Grant","Sylvia J. Spengler","05/31/2015","$20,000.00","","thu@cis.drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7364","7364, 7556","$0.00","Bioinformatics and Biomedicine research are fundamental to our understanding of complex biological systems, impacting the science and technology of fields ranging from agricultural and environmental sciences to pharmaceutical and medical sciences. The research requires close collaboration among multi-disciplinary teams of researchers in quantitative sciences, life sciences, and their interfaces. The 8th Annual IEEE International Conference on Bioinformatics and Biomedicine will provide an open and interactive forum to promote multi- and interdisciplinary research and education in Bioinformatics and Biomedicine, facilitating the cross fertilization of ideas and bridging knowledge gaps. The scientific program will cover synergistic themes on genomics, systems biology, translational bioinformatics, and cross-cutting bioinformatics infrastructure to promote new research collaboration. Two special panels, Big Data and Bioinformatics, and the Bioinformatics Educational Workshop will foster discussion on research and education opportunities and barriers. As an effort to engage young researchers, BIBM-2014 has involved them in the meeting organization and has included mentoring activities in the conference program. This support will provide the crucial funding needed to support the participation of early career researchers and graduate students, especially those from underrepresented groups, as a training opportunity for the next generation of scientists and engineers, thereby, broadening the scientific impact of this international conference."
"1350984","CAREER: Efficient Learning of Personalized Strategies","IIS","ROBUST INTELLIGENCE","06/01/2014","06/03/2014","Emma Brunskill","PA","Carnegie-Mellon University","Standard Grant","James Donlon","05/31/2019","$672,210.00","","ebrun@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","1045, 7495","$0.00","Online retailers frequently provide tailored product or movie recommendations. But the power of automated personalization, driven by data and statistics, could be far greater: imagine the impact on poverty reduction if all children had a personalized, self-improving tutoring system as part of their education. To realize this vision requires personalization systems that reason about both the immediate impact of a recommended item (e.g. will a learner immediately learn from a video lecture) as well as its longer term impact. For example, a recommended item or intervention may cause a user to change his/her preferences, state of knowledge, or reveal information about the user that was previously unknown. This requires methods for creating personalized strategies: adaptive rules about what decisions to make (whether or which ad to show, which pedagogical activity to provide) in which circumstances to maximize for long term outcomes. <br/><br/>This research involves developing new data-driven, machine learning approaches to construct such personalized strategies for related individuals, and using them towards improving the effectiveness of online mathematics educational systems. The project frames personalized strategy creation as sequential decision making under uncertainty research. Though there have been many advances in sequential decision making under uncertainty, existing approaches have focused primarily on other application areas, like robotics, and fail to account or leverage for some of the special features that arise when interacting with people. These include that accurate simulation of people is difficult but prior data is often available, and that individuals are often related. This project contributes algorithms for mining existing datasets to create and precisely bound the expected performance of new high-quality strategies and for online policy learning across a series of similar sequential decision making tasks."
"1419299","IEEE International Conference on Multimedia and Expo (ICME) 2014: Doctoral Consortium","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","06/01/2014","06/02/2014","YingLi Tian","NY","CUNY City College","Standard Grant","Maria Zemankova","05/31/2015","$16,000.00","","ytian@ccny.cuny.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","CSE","1640, 7364","7364, 7556, 9102, 9179","$0.00","This travel grant will provide partial support to about 10 U.S.-based graduate students to participate in the Doctoral Consortium at the IEEE International Conference on Multimedia and Expo (ICME) 2014, to be held be held July 14-18, 2014 in Chengdu, China. This is the first time the Doctoral Consortium is organized at ICME. The selected students will have the opportunity to present their work at the Doctoral Colloquium, receive feedback from senior researchers, attend the conference sessions, and interact with other graduate students as well as hundreds of other leading international researchers in the area of multimedia information systems. <br/><br/>The IEEE International Conference on Multimedia & Expo (ICME) has been the flagship multimedia conference sponsored by four IEEE societies since 2000. It serves as a forum to promote the exchange of the latest advances in multimedia technologies, systems, and applications from both the research and development perspectives of the circuits and systems, communications, computer, and signal processing communities. Multimedia data generally refer to audio, image, video, 3D, newer sensor data (e.g. depth) and related multi-modality data. In 2014, an Exposition of multimedia products, prototypes and animations will be held in conjunction with the conference. In addition, a number of workshops will be organized by the sponsoring societies. To further foster new emerging topics, ICME 2014 will also hold industrial exhibitions in parallel with the main conference. More information about ICME 2014 can be found at http://www.icme2014.org."
"1423438","MCBIOS Conference on Computational Biology and Bioinformatics","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","06/02/2014","Chaoyang (Joe) Zhang","MS","University of Southern Mississippi","Standard Grant","Sylvia J. Spengler","04/30/2015","$17,325.00","Cesar Compadre, Andy Perkins, Rakesh Kaundal, Debra Knisley","chaoyang.zhang@usm.edu","2609 WEST 4TH ST","HATTIESBURG","MS","394065157","6012664119","CSE","7364","7364, 7556, 9150","$0.00","The MidSouth Computational Biology and Bioinformatics Society (MCBIOS) is a nonprofit organization to promote research and education in bioinformatics and computational biology and address the need for the next generation of scientists who will work at the interface between computational and life sciences. This conference plays a special role in the region, providing a quality research-focused environment, serving as an arm for the international community of scientists in bioinformatics and computational biology. A major purpose of the MCBIOS annual conference is to foster collaborative research in bioinformatics and computational biology by providing a forum for scientists of various backgrounds and disciplines to interact to solve biological, health and/or biomedical problems by developing or using computational tools. The broader impacts of the project will be met through initiating future collaborations by the ensuing discussions of open problems, providing strong support to graduate and undergraduate students and a platform for new researchers to the field. The meeting also includes industry participants, which will provide students with knowledge of various types of employment opportunities and needed skill sets for those opportunities and provides for the publication of the proceedings in BMC Bioinformatics, a high impact factor journal."
"1054177","CAREER: Novel Approaches for Reasoning about Local Communities from Social Awareness Streams Data","IIS","Cyber-Human Systems","01/01/2011","02/10/2014","Mor Naaman","NJ","Rutgers University New Brunswick","Continuing grant","William Bainbridge","12/31/2015","$475,981.00","","mor.naaman@cornell.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7367","1045, 1187, 7367, 9251","$0.00","This project will examine temporal, social, and geographic patterns in large-scale social awareness streams (SAS) data for local communities. SASs, such as Twitter and Facebook, are radically altering our society's information fabric. These new communication platforms are used by millions of people to share brief status messages in socially connected public forums. These messages expose vast amounts of data from, and about, local geographic communities -- data that reflect people's activities, interests, and attention, in thousands of localities worldwide. Using this vast and still emerging sources of data, this research program will make SAS into a viable and significant source of information with capacity to transform our understanding of local communities.<br/><br/>As a first activity, the research will adapt algorithms from other fields to identify temporal patterns in SAS data that are stable across multiple communities. Importantly, the work will reason about how and when these patterns break. For example, SAS data may expose sleeping patterns in a community, and help identify mass anxiety when these patterns break. Further, the project will develop methods to identify differences in SAS patterns between local communities, and connect these findings to other sources of data. Next, the research will develop methods to compare how different groups (e.g., by age or ethnicity) use specific neighborhoods and cities. Finally, the work will examine the relations between local communities and network ties as reflected in SAS data. The findings will form the basis for developing novel models of computation for SAS systems, and inform the creation of tools and applications geared to re-imagine SAS as reliable information systems for local communities.<br/><br/>The project is rooted in social computing and in human-centered approaches to development of new technology. As such, the work entails interdisciplinary investigation using methods and research questions drawing on fields as diverse as information and computer science, sociology, and communication. The project will tackle significant information challenges that these SAS and other social computing platforms present, such as the scale, bias, and the increasing amount of noise and spam, as well as the brevity and lack of context of posted messages. The research will develop novel methods and approaches to using these new information sources to extract knowledge about, and for, local communities.<br/><br/>The research focus on social media and local communities lends itself well to outreach and education activities. The outreach efforts will enhance the connection of public libraries to the communities they serve, and relate the social media experiences of people?s everyday lives to scientific challenges. Participatory design workshops and visits to select educational institutions will engage individuals currently underrepresented in the sciences. An interdisciplinary education program will prepare a diverse set of students at all levels to lead the next generation of innovation, research, and education in socio-technical systems.<br/><br/>Finally, this project will have a significant impact on our society. By leveraging SAS as novel sources of information, the research will lay the foundation for new studies about local communities. The resulting technologies and insights will inform and transform the work of local governments, news organizations, planners, and researchers, as well as local residents and activists, allowing them to take full advantage of these new repositories of human expression and thought with relevance to such diverse social challenges as emergency response, resource planning, and public health."
"0945192","EAGER: Assessment of Barriers to Trusting Computer-Based Home Assistance","IIS","INFO INTEGRATION & INFORMATICS, TRUSTWORTHY COMPUTING","09/15/2009","09/11/2013","Paul Kantor","NJ","Rutgers University New Brunswick","Standard Grant","Sylvia J. Spengler","08/31/2014","$331,961.00","Cecilia Gal, Mark Aakhus","paul.kantor@rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7364, 7795","7484, 7795, 7916, 9216, 9251, HPCC","$0.00","Computer instrumentation of living environments promises to extend the independent life span of our aging populations. This technological potential will not be realized unless people are willing to trust their lives to such support systems, as a replacement for human support. Very little is known about how and why people make these important decisions. The proposed research will study this issue using a widely adopted, computer-dependent life-saving device, the Implantable Cardiac Device (ICD). This research will provide a foundation for understanding how and why people agree to place their life in the hands of computerized equipment that they cannot fully understand or control. The study will design and validate instruments for gathering data on this decision. The study will use in-depth interviews, and survey methods, and will gather data from persons who have accepted or refused implantable defibrillators. Phase I, will be an interview study, working through cardiologists, to reach their patients. Phase II will develop, an extensible Web-based survey that can be readily adapted to other patient populations and other technologies. Both graduate and undergraduate students will be involved in the research plan. In addition, there are a number of broader impacts. First, this research will enhance our understanding of the key factors in the decision to entrust one?s life to a complex computer whose workings are not understood. It will also add to the meager collection of instruments for collecting this kind of data. Second, the information gained about the decision to accept implant will be new, and can serve as a guide in the design of patient information material. Third, the information will guide the design of patient information for ?pervasive computing home environments? and will therefore be useful to scientists and engineers as they consider what will be the most useful features of any proposed design."
"0964597","III: Medium: Collaborative Research: Linguistically Based ASL Sign Recognition as a Structured Multivariate Learning Problem","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","09/10/2010","Dimitris Metaxas","NJ","Rutgers University New Brunswick","Standard Grant","Sylvia J. Spengler","08/31/2014","$739,000.00","","dnm@cs.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7364","7924","$0.00","The manifestation of language in space poses special challenges for computer-based recognition. Prior approaches to sign recognition have not leveraged knowledge of linguistic structures and constraints, in part because of limitations in the computational models employed. In addition, they have focused on the recognition of limited classes of signs. No system exists that can recognize signs of all morphophonological types or that can even discriminate among these in continuous signing. Through integration of several computational approaches, informed by knowledge of linguistic properties of manual signs, and supported by a large existing linguistically annotated corpus, the team will develop a robust, comprehensive framework for sign recognition from video streams of natural, continuous signing. Fundamental differences in the linguistic structure of signs, distinguishing signed languages in 4D, with spatio-temporal dependencies and multiple production channels from spoken languages, are critical to computer-based recognition. This is because finger-spelled items, lexical signs, and classifier constructions, e.g., require different recognition strategies. Linguistic properties will be leveraged here for (i) segmentation and categorization of significantly different types of signs, and then, although this subsequent enterprise will necessarily be limited in scope within the project period, (ii) recognition of the segmented sign sequences. Through the 3D hand pose estimation from a team-developed tracker, w significant tracking accuracy, robustness, and computational efficiency will be attained. This 3D information is expected to greatly improve the recognition results, as compared with recognition schemes using only 2D information. The 3D estimated information from the tracking will be used in the proposed hierarchical Conditional Random Field (CRF) based recognition, to allow for tracking and recognition of signs that are distinct in their linguistic composition. Since other signed languages also rely on a very similar sign typology, this technology will be readily extensible to computer-based recognition of other signed languages.<br/><br/>This linguistically-based hierarchical framework for ASL sign recognition?based on techniques with direct applicability to other signed languages, as well?provides, for the first time, a way to model and analyze the discrete and continuous aspects of signing, also enabling appropriate recognition strategies to be applied to signs with linguistically different composition. This approach will also allow the future integration of the discrete and continuous aspects of facial gestures with manual signing, to further improve computer-based modeling and analysis of ASL. The lack of such a framework has held back sign language recognition and generation. Advances in this area will, in turn, have far-ranging benefits for Universal Access and improved communication with the Deaf. Further applications of this technology include automated recognition and analysis by computer of non-verbal communication in general, security applications, human-computer interfaces, and virtual and augmented reality. In fact, these techniques have potential utility for any human-centered applications with continuous and discrete aspects. The proposed approach will offer ways to address similar problems in other domains characterized by multidimensional and complex spatio-temporal data that require the incorporation of domain knowledge. The products of this research, including software, videos, and annotations, will be made publicly available for use in research and education."
"1218377","CIF:Small: A Signal Processing Approach to the Analysis of Time-Varying Functional Networks of the Brain","CCF","ROBUST INTELLIGENCE, COMM & INFORMATION FOUNDATIONS, SIGNAL PROCESSING","09/01/2012","09/27/2013","Selin Aviyente","MI","Michigan State University","Standard Grant","John Cozzens","08/31/2015","$268,567.00","","aviyente@egr.msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7495, 7797, 7936","7923, 7936, 9251","$0.00","Complex network theory has proved to be a versatile framework to represent and analyze relational data in many disciplines including the social sciences, biology and information systems. One particular application that has benefited from these developments is cognitive neuroscience. Contemporary neuroimaging techniques provide neural recordings with increasing spatial and temporal resolution yielding rich multichannel datasets that can be exploited for detailed description of functional connectivity patterns in the brain. Recent research provides evidence that neural integration across various spatial and temporal scales plays an important role in a wide range of cognitive and executive processes as well as in the manifestation of neural diseases and psychopathologies. The current characterizations of functional brain networks are limited to global and static measures that quantify average activity across subjects, brain regions and time. This research addresses this problem by developing a signal processing framework to study the time-varying nature of the functional brain networks based on multichannel electroencephalogram (EEG) data for a better understanding of cognitive control. <br/><br/>This research develops three major approaches to study the dynamic nature of functional connectivity in the brain. First, time-varying measures of synchrony along with statistical hypothesis testing are implemented to construct sparse weighted graphs across time and frequency. Second, hierarchical multiple subject clustering algorithms are developed with information theoretic criteria to identify time-varying community structure. Third, a statistical signal processing framework is developed to summarize dynamic network activity with a few representative networks and to identify transient and stationary activity. Finally, this research is applied to the study of cognitive control for identifying the pathways that control cognition and perception, and in understanding the basic network causes of psychopathologies."
"1115532","HCC: Small: Design Methods: How They are Understood, Selected, and Used by Practitioners","IIS","Cyber-Human Systems","08/01/2011","05/25/2012","Erik Stolterman","IN","Indiana University","Continuing grant","Ephraim P. Glinert","07/31/2015","$467,066.00","","estolter@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7367","7367, 7923","$0.00","Huge efforts and funds are today deployed, in both academia and industry, with the purpose to develop new tools, techniques, and methods to support the design of innovative and creative interactive digital products and services. However, while a large proportion of these attempts lead to research insights, they are not always successfully transformed into design methods that fit the reality that practitioners experience. This lack of understanding of practice has in many cases led to a substantial lack of trust from practitioners towards the value of research contributions, while at the same time leading to frustrated researchers not understanding the lack of enthusiasm from practitioners when it comes to adapting new design methods emanating from research efforts. The proposed research will develop a solid understanding of this unfortunate situation by carefully investigating existing practice from the perspective of practitioners. <br/><br/>The research proposal is made up of five major studies and activities, conducted in parallel over three years. These activities are a combination of analytical studies of design methods and interview studies with practitioners (designers who employ design methods to create products and systems) and researchers (design method developers). The research will lead to insights and principles suitable for practitioners on how to strategize and handle their choice and use of design tools, techniques, and methods, and to insights and principles suitable for organizations for their strategic choices of design methods. Most importantly, the research will lead to educational guidelines suitable for design education on how to professionally think about and handle design methods. With increased knowledge about what constitutes appropriate design methods, these results will increase the probability for more creative and innovative designs of interactive products and systems."
"1161476","RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","IIS","ROBUST INTELLIGENCE","06/01/2012","09/26/2013","Endre Boros","NJ","Rutgers University New Brunswick","Continuing grant","Jie Yang","05/31/2015","$354,980.00","","Endre.Boros@rutcor.rutgers.edu","3 RUTGERS PLAZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7495","7495, 7924","$0.00","Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection. <br/><br/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers."
"1414452","CAREER: The Dynamics of Collective Intelligence","IIS","ROBUST INTELLIGENCE","08/10/2013","06/02/2014","Sanmay Das","MO","Washington University","Continuing grant","James Donlon","05/31/2015","$227,682.00","","sanmay@wustl.edu","ONE BROOKINGS DRIVE, CAMPUS BOX","SAINT LOUIS","MO","631304899","3148895100","CSE","7495","1045, 7495, 9251","$0.00","This project studies the design of information systems like wikis and information markets. Research in social science has established that often there is a ""wisdom of the crowd"" -- i.e., collectives can display more intelligence than the individuals they are composed of. When such collective information systems work, they serve as superb aggregators and disseminators of information. However, fundamental computational challenges remain in understanding how to design them optimally.<br/><br/>This research is advancing along several lines, including<br/><br/>(1) general theories of how information is aggregated in different social media, developed and validated using real data gathered from existing databases and generated from user experiments; <br/><br/>(2) algorithms for facilitation of user interactions so that the medium in question can deliver the promised results (for example, market-making algorithms for liquidity provision in information markets);<br/><br/>(3) theoretical and practical characterization of the possibilities for rogue users to manipulate collective wisdom systems;<br/><br/>(4) algorithms for detecting malicious users, and mechanisms that thwart miscreants. <br/><br/>The research is naturally interdisciplinary in nature, drawing from machine learning and probabilistic reasoning, data mining and social networks, as well as finance and economics. It contributes to our understanding of complex social phenomena like the growth of information in wikis and blogs, as well as to the development of intelligent reasoning algorithms for agents in complex, uncertain multi-agent environments like markets.<br/><br/>The design of agents that participate in markets and social systems improves the quality of online markets and improves information flow in virtual spaces. Further, insights gained from modeling market structures and social spaces can tell us how to design them better. For example, understanding the impact of different levels of central control on wiki articles or open source software projects yields guidelines for how much central control is optimal in different settings.<br/><br/>In a world where computation and social systems are increasingly intertwined, the PI's research and education program exposes students to multidisciplinary ideas through the introduction of a new class on collective intelligence, social networks and e-commerce, and the development and extensive use of the very objects of study -- information markets and wikis -- in classroom and lab settings. The PI is also developing an experimental project for putting freely accessible course wikis online, similar to online course materials at other universities, but open to editing by the community."
"1253980","CAREER: Enabling high-throughput data management in scientific domains","IIS","INFO INTEGRATION & INFORMATICS","06/01/2013","05/30/2014","Yicheng Tu","FL","University of South Florida","Continuing grant","Sylvia J. Spengler","05/31/2018","$209,948.00","","ytu@cse.usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139745465","CSE","7364","1045","$0.00","Many scientific domains have entered a data-driven era, in which scientific discovery depends heavily on effective and efficient analysis of large-scale data generated by wet-bench experiments or computer simulations. Current database management systems (DBMSs), while being very popular in the business world, fall short in high-throughput data processing required by scientific applications. The goal of this project is to design and implement a novel data management software architecture that enables high-throughput data management services for general scientific communities. The project achieves this goal via (1) a novel one-scan-fits-all data processing framework based on repetitive scans of large data sources; (2) a query engine that leverages the massive computing power of modern Graphics Processing Units (GPU) hardware; and (3) design and implementation of algorithms for popular analytics in three scientific domains on top of the query engine to demonstrate the effectiveness and efficiency of the proposed architecture. The project also aims at building a software prototype and evaluating this prototype with real-world scientific datasets and query workloads. <br/><br/>The project is expected to provide a highly efficient solution to satisfy the data management needs of a wide range of scientific fields. To deliver comparable performance, the proposed architecture requires only a fraction of the hardware and energy costs needed by existing systems. As a result, it has the potential to make scientific studies that are regarded as difficult or infeasible a reality. Integration of proposed research into educational endeavors that contribute to broadening the influence of computer science, nurturing the next generation of multidisciplinary scientists, and boosting the success of minority and women students in the computer science and engineering field are other broader impact activities planned."
"1016929","III:Small: Overlapping Clustering Analysis of Biological Networks","IIS","INFO INTEGRATION & INFORMATICS","08/15/2010","05/11/2011","Aidong Zhang","NY","SUNY at Buffalo","Continuing grant","Sylvia J. Spengler","07/31/2015","$500,000.00","Michael Buck","azhang@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7364","7923","$0.00","This project forms an interdisciplinary research team with integrated <br/>expertise of computer scientists and biomedical scientists to tackle<br/>the challenging issues in analyzing protein interaction data. Specifically,<br/>the project develops a novel approach to detecting overlapping clusters on<br/>emerging large volume of protein-protein interaction data and validates<br/>the computational approaches in yeast. The vast amount of protein-protein<br/>interaction data provides us with a good opportunity to systematically<br/>analyze the structure of a large living system and also allows us to<br/>understand essential principles like essentiality, genetic interactions,<br/>functions, functional modules, protein complexes, and cellular pathways.<br/><br/>The identification of functional modules in protein interaction networks is<br/>of great interest because they often reveal unknown functional ties between<br/>proteins and hence predict functions for unknown proteins. A protein may<br/>be included in one or more functional groups. Therefore, overlapping clusters<br/>need to be identified in protein interaction data. <br/><br/>This project develops a <br/>unique method to integrate domain knowledge with the protein interaction<br/>data so that the data will be more reliable. It also develops<br/>a unique method to support overlapping modularity analysis for<br/>protein interaction data that intelligently integrates biological<br/>information into the modularity analysis process. Another unique<br/>aspect of this project is the tight integration of computational methods <br/>with biological verification. By associating unknown proteins with the <br/>known proteins within each functional module, we can suggest that <br/>those proteins positively work for the corresponding functions that <br/>are assigned to the modules. <br/><br/>This project can also find broad applications in other areas which <br/>handle data with the modular network property, such as web network, <br/>social networks, and technological networks.<br/><br/>For further information see the project web page:<br/>http://www.cse.buffalo.edu/DBGROUP/PPI-networks/index.html"
"0808767","INT2-Large: Collaborative Research: Developing Social Robots","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","09/01/2008","07/22/2010","Javier Movellan","CA","University of California-San Diego","Standard Grant","Jeffrey Trinkle","08/31/2014","$2,650,000.00","Marian Bartlett, Virginia de Sa, Emanuel Todorov","movellan@mplab.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","1640, 7495","7717, 9215, HPCC","$0.00","The goal of this project is to make progress on computational problems that elude the most sophisticated computers and Artificial Intelligence approaches but that infants solve seamlessly during their first year of life. To this end we will develop a robot whose sensors and actuators approximate the levels of complexity of human infants. The goal is for this robot to learn and develop autonomously a key set of sensory-motor and communicative skills typical of 1-year-old infants. The project will be grounded in developmental research with human infants, using motion capture and computer vision technology to characterize the statistics of early physical and social interaction. An important goal of this project is to foster the conceptual shifts needed to rigorously think, explore, and formalize intelligent architectures that learn and develop autonomously by interaction with the physical and social worlds. The project may also open new avenues to the computational study of infant development and potentially offer new clues for the understanding of developmental disorders such as autism and Williams syndrome."
"1117957","RI: Small: Minimalistic Estimators for Navigation of Miniature Mobile Platforms","IIS","ROBUST INTELLIGENCE","07/01/2011","06/30/2011","Anastasios Mourikis","CA","University of California-Riverside","Standard Grant","Satyandra Gupta","06/30/2015","$447,283.00","","mourikis@ee.ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","7495","7495, 7923","$0.00","A new class of estimation methods are developed that can optimally utilize minima resources for high-precision pose tracking. This project develops the first formal methodologies for providing selections of parameters (e.g., camera frame rate, image resolution, number and type of detected features) for small portable devices to delay depletion of the battery. The approach is based on a rigorous study of the properties of the pose tracking problem with visual and inertial sensors and (1) identifies the fundamental limits of the attainable estimation accuracy, and (2) allows the analytical prediction of the accuracy as a function of the use of the sensing and processing resources. This makes possible the development of algorithms that optimally allocate system resources whose design relies on an optimization framework where the estimation errors constitute the cost function to be minimized, the resource limitations are explicitly modeled as constraints, and all the relevant design parameters (e.g., camera frame rate, number of features used) are the optimization variables. The immediate impact of this research effort is the increased cost efficiency and accuracy for navigation tasks in diverse applications.<br/><br/>The developed technology is available to the wider community through open-source position-tracking software for mobile phone devices and provides useful assistive technology. We engage K-12 students at local outreach events and introduce them to engineering as well collaborate with MESA, a long-standing program at the University of California at Riverside with a proven record of attracting underrepresented minority students to science and engineering."
"1161997","III: Medium: Hardware/Software Accelerated Data Mining for Real-Time Monitoring of Streaming Pediatric ICU Data","IIS","INFO INTEGRATION & INFORMATICS, IIS SPECIAL PROJECTS","07/01/2012","05/30/2014","Eamonn Keogh","CA","University of California-Riverside","Continuing grant","Sylvia J. Spengler","06/30/2016","$1,199,822.00","Walid Najjar, Vassilis Tsotras","eamonn@cs.ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","7364, 7484","7924, 7364","$0.00","On any given day in America, there are at least one thousand children fighting for their lives in Pediatric Intensive Care Units (PICUs). In the PICU the patient's condition is carefully monitored with automatic sensors. Most of this data is shown in a five-minute ""sliding window"" display, so a doctor summoned to a patient's bedside always has her most recent history to consider. However what happens to the data that ""falls off"" this sliding window? In most PICUs, a tiny fraction of it is coarsely aggregated and recorded, but surprisingly, most of this data is simply discarded. Even if most or all the data is recorded, its sheer volume simply overwhelms researchers and analysts; very few tools exist to help them make sense of and learn from this data. This currently discarded data is a potential goldmine of actionable knowledge that could improve outcomes (decreased mortality/morbidity, reduce pain, etc.), and reduce costs (implicit in reduced length of stay). However, the very nature of this data - multivariate, heterogeneous, high dimensional, temporal, noisy, biased, and high frequency - poses significant challenges for traditional analytical techniques from statistics and data mining.<br/><br/>In this project, an interdisciplinary team of investigators is developing: (a) xcalable machine learning algorithms for mining archives of annotated PICU data to find regularities and patterns that can be used to aid in diagnostics and prediction of outcomes; and (b) techniques for monitoring ICU telemetry in real time to detect whether the patterns and rules discovered in the offline step have occurred and can be used to guide interventions (actions by the doctor).<br/><br/>The project brings together experts in data mining (Keogh, Tsotras), high performance computing (Najjar), and medicine (Wetzel) to investigate holistic solutions to the above problems. The project contributes to research-based advanced training of graduate and undergraduate students at the University of California Riverside. The findings, datasets, software, and teaching materials created by this project will be archived in perpetuity at www.cs.ucr.edu/~eamonn/UCRPICU/"
"1110932","Collaborative Research: Improving Online Deliberation with Computational Supports for Frame Reflection","IIS","SOCIAL-COMPUTATIONAL SYSTEMS, Cyber-Human Systems","09/01/2011","04/15/2014","Geraldine Gay","NY","Cornell University","Standard Grant","William Bainbridge","08/31/2015","$491,019.00","","gkg1@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7953, 7367","7367, 7953, 9251","$0.00","This research will involve designing, implementing, and evaluating computational tools to support frame reflection in processes of online political engagement. The internet, social media, and online communication have great potential as a platform for political engagement, from seeking political information to participating in political discussion and deliberation. The wealth of content available via the web can make for more informed discussion, and the fact that discussion can take place on a much larger scale than face-to-face forums offers the potential for participation by many and diverse groups. However, thus far, online political participation has not proven radically democratic. Rather, it has tended to reproduce preexisting inequalities and balkanization in political talk. The constantly and rapidly increasing quantity of political content produced on a daily basis can also be difficult to understand and evaluate, particularly with respect to how issues are framed. The latter is especially important given the fact that, as numerous researchers have shown, how issues are framed?that is, how they are formulated in terms of familiar assumptions, metaphors, and images?profoundly affects how citizens understand, assess, and act upon those issues.<br/><br/>This project will both leverage existing computational techniques and develop novel analytic approaches to encourage citizens to identify and evaluate the frames that underpin competing positions on issues. Through evaluation in two real-world settings, public deliberative forums and readers of political blogs, this work will make two distinct sets of contributions. First, this project will develop human-computer interaction design principles for interactive tools and visualizations involving complex computational techniques. These principles will help ensure that such tools are designed to be useful for, comprehensible to, and interpretable by users. Second, by examining the impacts of various computational interventions, this work will enhance political and social scientific understanding of online political deliberation, both in terms of how technology mediates the deliberative process, and in terms of how deliberation can be improved through increased awareness of and reflection about framing.<br/><br/>The immediate impacts of this research will take the form of tools deployed in real-world settings with politically engaged users, namely through a partnership with a non-partisan convener of online forums, and through public deployment among readers of political blogs. Additionally, the tools developed in this project will be made readily available for use by others, either in support of political deliberative processes or in other contexts. In the long term, the work has significant potential to improve understanding of political deliberation, and it provides an opportunity to explore alternative roles that technology can play in supporting political participation."
"1361502","HCC: Small: Motivations, Expectations and Goal Pursuit in Social Media","IIS","Cyber-Human Systems","07/01/2013","10/29/2013","Donna Hoffman","DC","George Washington University","Continuing grant","William Bainbridge","08/31/2015","$216,896.00","","dlhoffman@gwu.edu","2121 Eye Street NW","Washington","DC","200522000","2029946255","CSE","7367","7923","$0.00","This research will test a conceptual model of the relationship between social media goal pursuit and well-being that is grounded in motivational theory and results from two pilot studies. In the theoretical framework, the broad range of goals people have for using social media is uniquely determined by two broad dimensions that specify the primary focus of the 1) content interaction and the 2) person interaction. The social media goals corresponding to these dimensions are hypothesized to be pursued according to the basic needs that social media satisfy for its users and the motivational orientations supported by those needs. The model states how goals lead to different well-being outcomes with the relationship between social media goal pursuit and well-being moderated by perceptions of overall well-being in specific life domains, along with constructs related to social identity. Three studies will test and validate the conceptual model: validation of the dimensions underlying social media goal pursuit (Study 1), development of new scales to measure the social media goals (Study 2), and testing and refinement of the model in a structural equation modeling framework (Study 3). The model will permit examination of a host of research questions including whether certain social media goals render individuals more vulnerable to negative well-being outcomes. For example, do individuals low in well-being pursue particular social media goals in the hope of improving their lives? Are these goals different from those that individuals more satisfied with their lives pursue? The model will allow researchers to build upon a common set of constructs and can increase understanding of why people use social media, along with its benefits and consequences. <br/><br/>A validated theoretical framework relating higher-order social media goals to subjective well-being in the context of basic needs and motivations has the potential to advance foundational research in multiple domains of inquiry. Consumer psychologists and marketing academics can use the framework to examine the relationship between social media goals and consumer response to marketing efforts in interactive media environments. Social psychologists and personality researchers can further refine and extend the framework to include other important constructs likely to impact social media goal pursuit and well-being. Computer information systems researchers can use the model to further understand how social media systems are impacted by individual differences. Although there has been a great deal of descriptive research examining the different usage behaviors people engage in when they use social media, most studies tend to focus narrowly on reasons or motivations for using a particular type of social media, rather than on organizing the results in the context of a broader conceptual framework that can explain what drives use and how usage goals are related to key well-being outcomes. Understanding the drivers of social media use and its consequences for well-being will have important national policy and consumer welfare implications."
"1216282","III: Small: Multi-field Hierarchical Discovery and Tracking (mf-HDT) of Emerging Topics","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","05/21/2014","Yiming Yang","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","09/30/2015","$515,182.00","","yiming@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7364, 7923, 9251","$0.00","The goal of this project addresses the open challenge of Multi-field Hierarchical Discovery and Tracking (mf-HDT) of emerging topics at different granularity levels based on combined evidence in heterogeneous data. The technical approaches consist of a new Bayesian framework with powerful inference algorithms, namely the multi-field Hierarchical Correlated Topic Modeling, for discovering multi-field hierarchies of latent topics, capturing inter-topic and cross-hierarchy correlations, and enabling query-driven threading of topics over a Markov chain of hierarchies. These technical innovations and capabilities go beyond existing Topic Detection and Tracking (TDT) methods and graphical models used to represent relationships between topics, citations, etc. Significant improvements are expected in both effectiveness and scalability over the existing methods, especially in terms of detecting newly emerging topics and tacking time-sensitive impact. The proposed approach will be evaluated on a four large datasets of scientific literature data in a broad range (Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance and Statistics) as well as news stories, with human-produced queries and relevance judgments and human-assigned topic labels to support task-oriented evaluations. <br/><br/>Productivity of researchers, educational practitioners and students, government agencies supporting research and industries highly depends on the availability of up-to-date big pictures about scientific emergence and co-emergence within and across many fields, along with evidence of the impact of new technologies, and research or development funding. The proposed techniques, if successful, will provide principled and effective solutions with a broad future impact in the applications above and beyond. Web site (http://nyc.lti.cs.cmu.edu/mfhdt/) will provide access to open-source software, of datasets, results and publication in order to enable comparative evaluations and further studies by related research communities. The students involved in the project benefit from direct experience with using and evaluating cutting-edge IT technologies in real-world applications. This is complementary to classroom teaching where the students can observe first-hand the direct implication of choosing various strategies for categorization, active learning and distributed computing."
"1218282","III: Small: Collaborative Research: Efficient, Nonparametric and Local-Minimum-Free Latent Variable Models: With Application to Large-Scale Computer Vision and Genomics","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","07/22/2013","Eric Xing","PA","Carnegie-Mellon University","Continuing grant","Sylvia J. Spengler","09/30/2015","$200,000.00","","epxing@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7923, 7364","$0.00","Many modern applications ranging from computer vision to biology require modeling and inferring high-dimensional continuous variables based on distributions with multimodality, skewness, and rich latent structures. Most existing models in this regime rely heavily on parametric assumptions where the components of the model are typically assumed to be discrete or multivariate Gaussian, or the relations between variables are linear, which may be very different from the actual data generating processes. Furthermore, existing algorithms for discovering the latent dependency structures and learning the latent parameters largely are restricted to local search heuristics such as expectation maximization. Conclusions inferred under these restricted assumptions and suboptimal solutions can be misleading, if the underlying assumptions are violated or if the suboptimal solutions differ greatly from the globally optimal ones. This project aims to develop a novel framework which can (i) discover and take advantage of latent structures in the data, while (ii) allowing parts to handle near-arbitrary distributions, and (iii) allowing the models to scale to modern massive datasets in a local-minimum-free fashion. <br/><br/>The key innovation in the project is a novel nonparametric latent variable modeling framework based on kernel embedding of distributions. The basic idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances, projections, linear transformations and spectral analysis. Conceptually, the framework represents components from latent variable models, such as marginal distributions over a single variable, joint distributions over variable pairs, triplets and more variables, as infinite dimensional vectors, matrices, tensors and high-order tensors respectively. Probabilistic relations between these components, i.e., conditional distributions, Sum Rule, Product Rule etc. become linear transformations and relations between these feature space components.<br/><br/>The framework supports modeling data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. It supports the application of a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning and latent feature extraction. The framework applies not only to general continuous variables, but also to variables that take values on strings, graphs, groups, compact manifolds, and other domains on which kernels may be defined.<br/><br/>Besides advancing the state of the art in machine learning,the new non-parametric methods resulting from the project find applications in image data and understanding and gene expression data analysis. It also contributes to research-based training of graduate and undergraduate students at Georgia Tech and CMU."
"1218932","RI: Small: Natural Language-Based Human Instruction for Task Embedded Robots","IIS","ROBUST INTELLIGENCE","09/01/2012","08/31/2012","Manuela Veloso","PA","Carnegie-Mellon University","Standard Grant","Satyandra Gupta","08/31/2015","$300,000.00","","veloso@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7923","$0.00","This project will advance the scientific state of the art in social service robots by introducing a novel approach for performing, composing, and correcting tasks using spatial language, and for handling the challenges of long-term interaction with people. The team of investigators will leverage prior work on CoBot service robots as a scientific platform. CoBots can transport objects, deliver messages, escort people and go to places, continuously executing these tasks over multiple weeks in a multi-floor building. The team will collaborate to research, develop, and evaluate algorithms for learning, composing, and correcting the execution of tasks via natural language. The proposed research will enable any person to train the robot; we will use the CoBot robots to perform evaluation and testing of our proposed algorithms.<br/><br/>The vision of a continuously operating robot in a real-world environment that can update its behavior in response to human instruction will have a broad impact on the way students, faculty and visitors interact with and view the usefulness of robots. Some examples include: (1) Customizable intelligent robots will give people the creative power to simply and intuitively update robot behavior, making the system broadly accessible to non-experts. (2) Outreach to the community will transform the view that robots are static unchangeable systems by creating an awareness towards robots co-inhabiting our environment. We will invite children of different age groups and people from different cultures to interact with our co-robot through language-based instruction. (3) Synergistic activities across multiple research groups have and will continue to be explored and encouraged (e.g., continuous environmental measurement and monitoring)."
"1160862","III: Medium: Collaborative Research: Connecting the Ephemeral and Archival Information Networks","IIS","INFO INTEGRATION & INFORMATICS","08/01/2012","07/20/2012","Jamie Callan","PA","Carnegie-Mellon University","Continuing grant","Maria Zemankova","07/31/2016","$431,086.00","","callan@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7924","$0.00","This collaborative research project (IIS-1160894, W. Bruce Croft, University of Massachusetts Amherst and IIS-1160862, Jamie Callan, Carnegie-Mellon University) addresses the complex issues of ephemeral information that is generated as part of social interactions is different in terms of time scale, quantity, and quality to archival information found on the web. This project investigates the hypothesis that, because of the context provided, searching either ephemeral or archival information is enhanced using the connections between them. It develops new retrieval models and features for ranking functions in a range of search tasks that can exploit an integrated ephemeral/archival network. Some search tasks are based on previous TREC blog, microblog, and web activities. It also investigates two new tasks, conversation retrieval and aggregated social search. Conversation retrieval targets information units in the form of ""conversations"" or ""events"" instead of simply retrieving social postings or web pages. Aggregated social search ranks information in different granularities, such as sentence, posting, conversation, or thread, based on the underlying query intent. <br/><br/>Research that explores the connections between ephemeral and archival information requires a dataset that contains both types of information. A crucial part of this project extends the archival ClueWeb12 dataset with ephemeral microblog, blog, and discussion forum data that links to the web data. This extension is distributed to the research community as the ClueWeb12++ dataset. This project (http://ciir.cs.umass.edu/research/ephemeral/) is the first to address the full possibilities of search that exploits all the connections and contexts created by bringing together the two ""worlds"" of information. It also develops and distributes a unique new dataset that supports the development of a new generation of tools to access a broad range of information. Students at collaborating institutions, University of Massachusetts Amherst and Carnegie-Mellon University will be involved in educational activities and benefit from research experience."
"1111166","Collaborative Research: Supporting Newcomer Socialization in Online Production Communities","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","08/15/2011","05/02/2014","Robert Kraut","PA","Carnegie-Mellon University","Standard Grant","William Bainbridge","07/31/2015","$480,786.00","Rosta Farzan","robert.kraut@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7953","7367, 7953, 9251","$0.00","The goals of this research are (1) to understand ways of recruiting and socializing volunteers to online production communities like Wikipedia, (2) to design processes and tools that assist the newcomers' information-seeking as part of their socialization, and (3) to build processes and tools to support the interpersonal processes of socialization, including peer mentorship and mentorship with more senior community members. Online production communities are becoming increasingly important, because they are creating the software that drives the Internet, generating valuable scientific data and building history's largest encyclopedia. In the face of inevitable turnover, every online community must incorporate successive generations of newcomers to survive. Newcomers are a source of content, labor, new ideas, and audience. However, attracting and incorporating newcomers into existing communities can be difficult. Socialization is the process of teaching newcomers the behaviors and attitudes essential to playing their roles in the group. Communities have available a variety of socialization tactics. Research from offline organizations shows that organizations' use of institutionalized socialization tactics and newcomers' active information seeking are effective in increasing newcomers' commitment to the organization, their satisfaction and their productivity. However, those tactics are not commonly used in online communities and seem to have different effects when they are used.<br/><br/>This project pursues theory-guided design. The findings from the research will extend existing theories on socialization in groups and organizations by supplementing findings primarily based on self-report measures with ones based on behavioral measures, and by providing evidence on socialization in online communities, where constraints on newcomers are radically different than they are offline. The research will develop processes and tools for solving important problems of newcomers' socialization, which will be evaluated in the context of socializing newcomers in Wikipedia and especially in the Wikipedia initiative of the Association for Psychological Science, which seeks to improve the scientific quality of articles in psychology. These tools will be made freely available to other scientific associations and other online production communities more generally.<br/><br/>This project supports NSF's mission to inform the public about science by improving Wikipedia as a vehicle for disseminating scientific knowledge about psychology in particular, and by developing a model for how other scientific societies could partner with Wikipedia or similar efforts to better generate and assess scientifically up-to-date and accurate information meant for the public. It will directly involve many college students, who will be assigned to write or improve psychology articles; they will get feedback from the broader community on their performance. As such it directly supports teaching and learning psychological science and will help increase students' involvement with their scientific societies."
"1444285","31st Annual Conference on Machine Learning (ICML 2014)","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","05/15/2014","05/14/2014","Artur Dubrawski","PA","Carnegie-Mellon University","Standard Grant","Todd Leen","04/30/2015","$35,000.00","","awd@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 7364, 7495","7556","$0.00","This grant enables student participation at the International Conference on Machine Learning (ICML). ICML is one of the premier conferences in Machine Learning. In addition to rigorously refereed conference papers, it features poster sessions, tutorials, workshops and invited talks. This award provides funds for travel scholarships for students from US institutions to help cover their travel and costs of attending the conference. The selection of students to be funded is based on a review by the selection committee of their authorship and financial needs. The student scholarships are very important for encouraging student participation in this premier conference and for shaping the future of the field as a whole. Special attention will be paid to broadening the participation of students from groups that are traditionally underrepresented in Computer Science in general and Machine Learning research in particular, and students from institutions with limited Machine Learning expertise who would benefit from the opportunity to interact with researchers from around the world. <br/><br/>Attendance at the ICML represents a unique opportunity for students interested in Machine Learning research. The poster sessions at the conference are designed enable students to recieve feedback from leading Machine Learning researchers from around the world and to help them become part of the larger Machine Learning research community. The award contributes to the education and training of the next generation of researchers and educators in an increasingly important area. It also helps broaden the participation of underrepresented groups and women in Machine Learning research."
"1218542","RI: Small: Multi-Agent (Multi-Robot) Task Allocation with Formal Guarantees in Dynamic Environments under Realistic Constraints","IIS","ROBUST INTELLIGENCE","08/01/2012","07/24/2012","Katia Sycara","PA","Carnegie-Mellon University","Standard Grant","James Donlon","07/31/2015","$450,000.00","","sycara@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7923","$0.00","This proposal aims to develop algorithms for decentralized task allocation among multiple intelligent agents in uncertain environments with a focus on provable performance bounds. Four task settings and their combinations are to be considered: (1) constraints among tasks (e.g., disjoint task groups, precedence relations among tasks); (2) constraints among agents (e.g., maintenance of a communication network); (3) constraints among groups of agents (e.g., requiring a group to include agents with specialized skills); (4) on-line arrival of additional tasks. Existing algorithms for task allocation that have provable performance bounds usually do not consider the realistic constraints stated above. On the other hand, approaches that consider some of the constraints above do not have performance bounds. Furthermore, current algorithms often assume the existence of a centralized coordinator (e.g., an auctioneer in market-based approaches) and may not be scalable. Thus, there is a gap between the existing literature and the practical requirements in multi-robot applications. Hence, there is a need to design distributed task allocation methods that take into consideration practical constraints and have formal performance guarantees. The evaluation plan will use simulated and real robots in search and rescue contexts. The project will use the USARSim environment with approximately 50 simulated robots.<br/><br/>The mathematical techniques upon which this project will rely to develop algorithms for task allocation will depend on the problem characteristics. When there are constraints among tasks, the project will use techniques from combinatorial optimization and linear programming. For tasks where each task can be performed by multiple agents, the project will use concepts from cooperative game theory and coalition formation in conjunction with integer optimization techniques. For dynamically arising tasks, the project will explore the use of stochastic programming techniques with the key idea being use of the dual of the integer program model of the task allocation problem to design ""bidding rules"" for agents that ensure a performance guarantee for the overall system.<br/><br/>A wide range of application domains -- including emergency response, homeland security, environmental monitoring, hazardous waste cleanup and manufacturing -- stand to benefit from the task allocation techniques proposed in this project. Results from this project will enable application domains to more fully reap the benefits of emerging robotic technology by providing techniques that allow robots to autonomously and efficiently coordinate and allocate tasks among themselves. Graduate students will play a major role in conducting the proposed research. Additionally, this project will provide research opportunities to undergraduate students both within Carnegie Mellon University and from other institutions through the Robotics Institute Summer Scholar program."
"1252440","Learning by Teaching a Synthetic Peer: Investigating the effect of tutor scaffolding for tutor learning","DRL","INFO INTEGRATION & INFORMATICS, REAL","10/01/2013","05/14/2014","Noboru Matsuda","PA","Carnegie-Mellon University","Standard Grant","John Cherniavsky","09/30/2016","$1,503,349.00","Gabriel Stylianides, William Cohen, Ken Koedinger","noboru.matsuda@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","EHR","7364, 7625","9177, 9251, SMET","$0.00","This project focusses on equation solving in Algebra I for seventh and eighth grade students. This research extends research on an on-going project on developing an on-line, game-like learning environment called APLUS (Artificial Peer Learning environment Using SimStudent) in which students learn by teaching a synthetic peer called SimStudent. Learning by teaching is an exciting and innovative approach to learning and instruction that is often reported to be effective in classroom trials. However, little is known about the underlying cognitive and social theory on how and when students learn by teaching. Although some studies have shown a potential for scale learning by teaching through implementation in technology, very little is known about the transformative theory to successfully implement learning by teaching. To address this issue, the researchers build on their current work to further develop the theory of learning by teaching and to understand how best to achieve the theory development through advanced technology support. The researchers also investigate the similarities and differences between learning by teaching and learning by being tutored to better engineer effective advanced learning technology. In particular, the researchers propose to improve the effectiveness of APLUS by providing adaptive scaffolding for students to teach SimStudent correctly and appropriately. The researchers also propose to collect detailed process data that show fine-grained interactions between the student and SimStudent in addition to outcome data, which are test scores. By combining the process and outcome data, the researchers will explore the cognitive and social theory of learning by teaching. The researchers hypothesize that providing help on how to solve problems (cognitive help) and how to tutor (metacognitive help) will facilitate tutor learning. They also conjecture that the interaction between cognitive and metacognitive help will yield a rich learning environment that, in combination with the unique characteristics of learning by teaching, will be more effective than learning by being tutored. The following research questions will be addressed:<br/><br/>Q1: Does cognitive help facilitate tutor learning? If so, how and why?<br/><br/>Q2: Does metacognitive help facilitate tutor learning? If so, how and why?<br/><br/>Q3: Is learning by teaching with the meta-tutor assistance better than learning by being tutored?<br/><br/><br/>Learning by teaching has been widely recognized to be effective for academically challenging populations, including African American students and underprivileged students. Therefore, the proposed intervention, if proven to be effective, would contribute to the development of effective STEM learning support system for all students regardless of their race/ethnicity, gender, socioeconomic status, or geographical locale in contemporary US classrooms. Since the entire proposed technology would run as a web-based application, the software products will be distributed widely and rapidly. The study data will be shared through the opendata repository, DataShop, under the direct supervision of the Pittsburgh Science of Learning Center. Thus, the research effort will contribute to the general learning research community by providing that community opportunities to conduct secondary data analyses."
"1250350","EAGER: Nonparametric Machine Learning on Sets, Functions, and Distributions","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/18/2012","Barnabas Poczos","PA","Carnegie-Mellon University","Standard Grant","Sylvia J. Spengler","08/31/2014","$200,000.00","Artur Dubrawski","bapoczos@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7364, 7916","$0.00","Most machine learning algorithms operate on fixed dimensional feature vector representations. In many applications, however, the natural representation of the data consists of more complex objects, for example functions, distributions, and sets, rather than finite-dimensional vectors. This project aims to develop a new family of machine learning algorithms that can operate directly on these complex objects. The key innovation is efficient estimation of certain information theoretic quantities for learning predictive models from complex data. The research is organized around three specific aims: (a) Development and analysis of nonparametric estimators for certain important functionals of densities, such as entropy, mutual information, conditional mutual information, and divergence; and study of the theoretical properties of these estimators including consistency, convergence rates of the bias and variance, and asymptotic normality. (b) Use of the preceding estimators to design new learning algorithms for clustering, classification, regression, and anomaly detection that work directly on sets, functions, and distributions without any additional, hand-made feature extraction, histogram creation, or density estimation steps that could lead to loss of information. (c) Study of the theoretical properties of these new machine learning algorithms (computation time, sample complexity, generalization error) and empirical evaluation of the algirithms them to a variety of important real-world problems, including nuclear detection astronomical data analysis, and computer vision in collaboration with researchers at Lawrence Livermore, University of Washington and Johns Hopkins University, and Carnegie Mellon University respectively.<br/><br/>Broader Impact. The project, if successful, could substantially advance the current state-of-the-art in building predictive models from complex data. The results of research, including publications and open source software, will be freely disseminated to the larger scientific community. The project provides enhanced research-based training opportunities for graduate and undergraduate students at Carnegie Mellon University as well as the collaborating institutions."
"1208382","SoCS: Collaborative Research: Strategies for Crowdsourcing Complex Design Work","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2012","04/02/2014","Steven Dow","PA","Carnegie-Mellon University","Standard Grant","Kevin Crowston","08/31/2015","$403,800.00","","spdow@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7953","7367, 7953, 9251","$0.00","This project investigates how education and training methods from traditional work settings can be applied to paid online crowdsourcing. The focus is on how methods such as scaffolding, examples, critique, and apprenticeship affect worker performance, learning, task perseverance, and satisfaction. The project will produce guidelines for a more sustainable crowdsourcing infrastructure where employers can embed relevant domain knowledge into online tasks, and workers can learn key principles and then train less experienced members. The research focuses on worker-centered training strategies in the domain of visual design, which will yield knowledge about effective design principles and instructional methods for visual design. <br/><br/>Broader impacts: The project will contribute to increase the availability of online work. It will expand the capabilities and skills of crowd workers, thereby allowing online work to become a more viable part of the American economy. The project will also lead to novel methods for organizations to achieve complex visual design work. More generally, the project will lead to new knowledge about how to train crowds to perform a complex activity and produce practical guidelines to help requesters write tasks and manage the crowd. Finally, the project will provide interdisciplinary training for graduate and undergraduate students in socio-computational system design, HCI concepts, educational theory, and evaluation methodologies. All course materials will be available online for reuse and adaptation. Undergraduate researcher training will focus on supporting underrepresented student groups."
"1344017","Machine Learning Summer School Pittsburgh 2014","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","09/01/2013","08/28/2013","Alexander Smola","PA","Carnegie-Mellon University","Standard Grant","Sylvia J. Spengler","08/31/2014","$40,000.00","Zico Kolter","smola@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, 7495","7364, 7495, 7556","$0.00","Machine learning has many important applications in science and industry. Modern machine learning uses a mix of insights from different disciplines, most notably artificial intelligence, statistics and optimization - areas that traditionally have not had much overlap. The participants will take part in tutorials given by experts from several different areas of machine learning - an opportunity that many students do not have at their home institutions. <br/><br/>The project supports student participation in a Machine Learning Summer School to be held at Carnegie Mellon University in Pittsburgh during June 16-27, 2014. The summer school emphasizes big data and scalable machine learning algorithms. It features speakers from academia and industry with established experience in large scale data analysis. Approximately 50 graduate students from around the U.S. are expected to participate in person. The content will be streamed live as well as archived online making it possible for a much larger number of students from academia and industry to benefit from the summer school. In addition to in-depth tutorial lectures given by leading researchers, the summer school will include exercise sessions that provide the participants hands-on experience with large scale data (using the Kaggle platform and Amazon cloud services). <br/><br/>Broader Impact: The Summer School provides state-of-the art knowledge of machine learning and big data analytics to graduate students - an opportunity that many students do not have at their home institutions. Thus, it would not only help train an new generation of machine learning and big data analytics researchers, but also reduce the barrier to entry of researchers who want to apply state-of-the-art machine learning techniques to applications in areas such as social network analytics, bioinformatics etc."
"1320651","RI: Small: Statistical Perceptual Inference in Visual Cortical Neural Circuits","IIS","ROBUST INTELLIGENCE","09/15/2013","09/06/2013","Tai Sing Lee","PA","Carnegie-Mellon University","Standard Grant","Kenneth C. Whang","08/31/2016","$499,961.00","","tai@cnbc.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","This interdisciplinary research project seeks to elucidate the computational machinery and algorithms in our brain that enables us to perceive 3-dimensional surfaces of objects in visual scenes based on the 2D images projected on our retinae. The first conjecture of the project is that the neural circuitry underlying perceptual inference in our brain can be predicted by the statistical structures in our natural environment. To prove this conjecture, statistical studies on 3D natural scenes will be carried out and their predictions on neural connectivity will be compared with the functional connectivity and tuning properties of depth-sensitive neurons in the primate visual cortex obtained using large-scale multi-electrode recording techniques. This will provide deeper insights into how the brain represents and builds models of the structures of the external world to enable perceptual inference. To understand what such circuits can compute, the investigator conjectures that neural circuits realize a class of generative models in computer vision and computational neuroscience called Markov random fields and Boltzmann machine. This second conjecture will be evaluated by exploring the theoretical link between the neural circuits and these computational models, by comparing experimental neural observations with behaviors of these computational models, and by evaluating the computational performance of the inferred neural circuits in solving stereo computation and surface interpolation problems in real world data. The research combines techniques in machine and statistical learning, computer vision, neural networks and neurophysiology to dissect neural circuits from a functional perspective. By linking real circuits to a powerful class of computational models in statistical inference, the project will have broader impacts by providing novel evidence and fundamental insight to the neural mechanisms and computational algorithms underlying statistical perceptual inference in the brain. This interdisciplinary project will be a catalyst for the development of educational initiatives to bring bringing computer science and neuroscience together for undergraduates and graduate students, and to promote the awareness and involvement of students from multiple disciplines, including under-represented groups, in the field of computational neuroscience."
"1314356","HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","IIS","Cyber-Human Systems, Software Engineering","08/01/2013","04/01/2014","Brad Myers","PA","Carnegie-Mellon University","Standard Grant","Ephraim P. Glinert","07/31/2017","$945,478.00","","bam@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7944","7367, 7925, 7944, 9251","$0.00","In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br/><br/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask ""why"" questions to understand the differences among variations of a system. For novices, an ""Idea Garden"" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br/><br/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students."
"1147266","BCSP: Collaborative Research: ABI Development: Exploring Taxon Concepts (ETC) through analyzing fine-grained semantic markup of descriptive literature","DBI","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","07/01/2012","06/12/2012","Hong Cui","AZ","University of Arizona","Standard Grant","Anne Maglia","06/30/2016","$1,095,682.00","James Macklin","hongcui@email.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","BIO","1165, 1640, 7364","8750, 9179","$0.00","A collaborative award has been made to the University of Arizona and the University of California at Davis to develop novel ways of tying scientific names directly to published biological characteristics of organisms, and to implement a new user-friendly program, the Explorer of Taxon Concepts (ETC), to assist with the disambiguation of the scientific names of species at all taxonomic ranks. Prototypes from several successful NSF-funded projects are integrated through ETC to enable: (i) text-mining extraction of taxonomic knowledge from scientific literature, (ii) analysis and integration of this knowledge using logic-based reasoning and information theoretic methods, and (iii) result visualization. The results shed light on similarities and differences among various scientists' understanding of a particular species, as well as relations between the terminology used by different scientists, allowing for more accurate integration of data gathered by different investigators. A component of the ETC project is computer science research aimed at a novel integration of state-of-the-art logic inference and information theoretic approaches to taxonomic science.<br/><br/>Scientific names are the primary identifiers for organisms and the anchor for the communication and comparison of biological knowledge. However, there is constant revision of the definition of taxa by experts, making interpretation of the names through time challenging. This project will produce and demonstrate the use of ETC software on descriptive scientific literature from the Rosaceae (the Rose family) and Apoidea (the Bee super-family) to facilitate research into critical pollination systems. These pollination systems are currently of great concern due to reductions in bee populations globally with the potential to reduce yield of many staple food crops. ETC's components support scientific knowledge value added to its inputs, making them useful in many other biodiversity information applications. Character and anatomy ontologies built and enhanced by the ETC project will benefit all knowledge-based applications in biology. The project adopts the following strategies to broaden its accessibility: The integration of ETC components with existing biological computing infrastructure such as DataONE and iPlant will make the tools broadly available. The partnership with iPlant's successful Education, Outreach, and Training (EOT) group will document the software for instructional use and encourage its adoption in the classroom. Components of the research and the final products will also be packaged into learning modules for college and graduate level courses at University of Arizona, the University of California at Davis, and other universities. Project outcomes will be accessible via the link provided at: http://sirls.arizona.edu/node/684."
"1149885","CAREER: Dissecting the Mechanisms of Genetic Control of Biological Systems via High-Dimensional Sparse Graphical Models","MCB","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, Systems and Synthetic Biology","06/01/2012","04/09/2014","Seyoung Kim","PA","Carnegie-Mellon University","Continuing grant","Susanne von Bodman","05/31/2017","$565,101.00","","sssykim@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","BIO","1640, 7364, 8011","1045, 7465, 8750, 9102, 9179, 9251","$0.00","Since the completion of genome sequencing projects for various organisms including human and other model organisms, the fundamental goal of research in computational genomics, systems biology, and genetics has been to gain a complete understanding of how the instruction sets encoded in genomes get executed within a cell system and organism. The recent advances in the high-throughput technology and next-generation sequencing technology have allowed the researchers to collect a large amount of data for the genomes and various other aspects of a cell system. Such datasets hold the key to understanding the detailed mechanisms of the genetic control of a biological system and further deepening our knowledge of cell biology with the potential for broad application. This project will develop statistical machine learning methods based on high-dimensional sparse graphical models for integrative analysis of genomic datasets. As graphical models provide a powerful tool for representing the complex structure of the unknown biological processes that underlie the observed genomic data, the computational methods to be developed in this project will be able to extract rich information on the genetic control of gene regulation systems from genome-scale datasets.<br/><br/>This project will also include training the next-generation computational biologists by supervising graduate students and incorporating the research results into the curriculum. The project will involve collaboration between computational scientists and biologists to participate in outreach programs for high-school students to present them an alternative career path that combines biological and computer sciences. In addition, the project will contribute to increasing womens participation in science and engineering."
"1012763","TC:Large:Nudging Users Towards Privacy","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, INFO INTEGRATION & INFORMATICS, TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace","07/01/2010","08/12/2013","Alessandro Acquisti","PA","Carnegie-Mellon University","Continuing grant","Christopher Clifton","06/30/2015","$2,749,662.00","Lorrie Cranor, Norman Sadeh","acquisti@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 1714, 7364, 7795, 8060","7434, 7795, 7925, 9178, 9251, 7923","$0.00","Making the ``right'' privacy decision --- that is, balancing revelation and protection of personal information in ways that maximize a user's welfare --- is difficult. The complexity is such that our judgments in this area are prone to errors, leading to decisions that we may later stand to regret. These errors stem from lack of information or computational ability; but also from problems of self-control and limited self-insight. Our research focuses on designing and testing systems that anticipate and counter cognitive and behavioral biases that hamper users' privacy (as well as security) decision making. Our approach is informed by the growing body of behavioral economics research on ?soft,? or asymmetric, paternalism, as well as by research in behavioral decision research and usability. Inspired by these streams of research, we design and study systems that ``nudge'' users towards certain privacy or security behaviors ? which the users themselves have stated to prefer, or which empirical evidence has demonstrated to be beneficial. Helping users avoid mistakes, decrease regret, and achieve more rapidly the desired balance between sharing and protecting personal information has clear, and significant, societal importance. However, our research will also inform the work of privacy (and security) technologists and policy makers by advancing our understanding of what makes privacy decision making difficult, and how to counter biases that adversely affect privacy- and security-sensitive behavior."
"1017256","III: Small: Privacy Preserving Techniques for Speech Processing","CNS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE, TRUSTWORTHY COMPUTING","09/01/2010","01/24/2012","Bhiksha Raj","PA","Carnegie-Mellon University","Standard Grant","Christopher Clifton","08/31/2014","$524,931.00","","bhiksha@gmail.com","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7298, 7495, 7795","5936, 5979, 7495, 7923","$0.00","Voice-processing systems that perform speaker verification, keyword spotting, speech recognition, etc. need complete access to the speech signal, albeit in parameterized form. These data could potentially be logged for future playback, analysis or even malicious activities and represent a threat to the privacy and security of users. This project aims to develop techniques that enable some key voice processing tasks, namely speaker identification or verification and keyword spotting, while preserving the privacy of the speaker?s voice. The techniques will perform their operations without observing any intelligible form of the speech signal from which one could glean any information about the speaker or what they said; yet at the end of the computation the results, which will only be delivered to an authorized party, will be indistinguishable from those that would be obtained if the system were not secured in this manner.<br/><br/>The proposed work draws upon approaches from cryptography and secure multiparty computation. It is explained how these techniques can be used to devise privacy-preserving algorithms for voice processing, and the development of such algorithms for the three problems mentioned, speaker identification and verification and keyword spotting, has been proposed.<br/><br/>For further information see http://mlsp.cs.cmu.edu/projects/secureaudio"
"1018317","III: Small: Modeling and Predicting Term Mismatch for Full-Text Retrieval","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","09/02/2010","Jamie Callan","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","08/31/2014","$495,547.00","","callan@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7923","$0.00","Many text search engines use probabilistic reasoning to determine how well a word represents a person?s information need. The probability that a term appears in relevant documents ? documents that satisfy the information need ? is a fundamental quantity in the theory of probabilistic information retrieval, however prior research provided few clues about how to estimate it reliably. This project uses exploratory data analysis to identify common reasons that user-specified query terms fail to match relevant documents, develops features correlated with each reason, and integrates them into a model that can be trained from data. The resulting term necessity predictions can be used in state-of-the-art retrieval models to improve retrieval accuracy substantially.<br/><br/>Term necessity predictions are based on a two-stage approach to text retrieval. A feature-based analysis of an initial retrieval develops evidence that can be linked to a variety of common reasons that a term might not match relevant documents, for example, centrality, synonymy, and abstractness. This model-based approach can be trained from available data, making it easy to incorporate new features that test new hypotheses, or to train a corpus-specific predictive model. It also has the advantage that probability predictions are query-specific, and linked to features that can guide automatic term weighting as well as interactive or automatic query refinement. The project develops several focused interventions for interactive, automatic query expansion, and relevance feedback refinement of queries.<br/><br/>This project makes an impact on the scientific community by providing new approaches to a central problem that affects probabilistic retrieval models, and the diagnosis and correction of problems in query formation. Improvements in search engine accuracy also affect a broad population of everyday users. The proposed research improves search accuracy for ?ordinary people? using unstructured keyword queries, as well as professional searchers who often use sophisticated structured queries to search structured documents.<br/><br/>Research results will be disseminated in research papers and via project web site (http://www.cs.cmu.edu/~callan/Projects/IIS-1018317/). New techniques will be implemented and disseminated in periodic releases of the Lemur Project?s Indri search engine (http://www.lemurproject.org/indri/). Indri is used by a broad international research community, thus this form of dissemination makes it more likely that other researchers will study and extend the proposed research."
"1054319","CAREER: Flexible Learning for Natural Language Processing","IIS","ROBUST INTELLIGENCE","02/01/2011","02/19/2014","Noah Smith","PA","Carnegie-Mellon University","Continuing grant","Tatiana D. Korelsky","01/31/2016","$468,627.00","","nasmith@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","1045, 1187, 7495, 7945, 9251","$0.00","Statistical learning is now central to natural language processing<br/>(NLP). Bridging the gap between learning and linguistic<br/>representation requires going beyond learning parameters. This CAREER<br/>project addresses three challenging, unresolved questions:<br/><br/>1. Given recent advances in learning the parameters of linguistic<br/>models and in approximate inference, how can the process of feature<br/>design be automated?<br/><br/>2. Given that NLP tasks are often defined without recourse to real<br/>applications and that a specific annotated dataset is unlikely to<br/>fulfill the needs of multiple NLP projects, can learning frameworks be<br/>extended to perform automatic task refinement, simplifying a<br/>linguistic analysis task to obtain more consistent, more precise, or<br/>faster performance?<br/><br/>3. Can computational models of language take into account the non-text<br/>context in which our linguistic data are embedded? Building on recent<br/>success in social text analysis and text-driven forecasting, this<br/>CAREER project seeks to exploit context to refine models of linguistic<br/>structure while enabling advances in this application area.<br/><br/>This basic research supports advances in a wide range of language<br/>engineering applications and discrete data analysis. In addition to<br/>core research advances, this CAREER project contributes a new<br/>publicly-available parser that models the most consistently learnable<br/>elements of syntactic struture. Educational activities include a new<br/>project-based on text-driven forecasting within the PI's undergraduate<br/>NLP course and a new undergraduate course in machine learning. It<br/>supports involvement by the PI in outreach activities to high school<br/>students and to a wider range of students at CMU by exposing aspects<br/>of his research in non-CS classrooms."
"1065251","RI: Medium: Interactive Transfer Learning in Dynamic Environments","IIS","ROBUST INTELLIGENCE","09/01/2011","06/18/2013","Jaime Carbonell","PA","Carnegie-Mellon University","Continuing grant","James Donlon","08/31/2014","$1,048,227.00","Avrim Blum","jgc@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7924","$0.00","Machine learning (ML) has witnessed tremendous success both in establishing firm theoretical foundations and reaching out to major applications ranging from the scientific (e.g. computational biology) to the practical (e.g. financial fraud detection, spam detection). However the reach of machine learning has been hampered by an underlying inductive framework that largely has not evolved from using only labeled instances of concepts (e.g. emails and yes/no labels on whether they are spam) and its overly simple view of the role of the user or subject matter expert (SME) as a mere provider of the labels for the training instances. However, when instructing humans, teachers provide richer information: Why is an instance of a concept a good positive example? What are key differences between instances belonging to different classes? Which properties are transient and which are invariant? Where should the learner focus attention? What does the current learning task have in common with previously acquired concepts or processes? Answers to such questions not only enrich the learning process, but they also can effectively reduce the hypothesis space and provide significant speed ups in learning than can be achieved with use of class membership feedback only.<br/><br/>The aim of this project is to bring this kind of richer interaction into the realm of machine learning by developing frameworks as well as machine learning methods that can take advantage of fuller mixed-initiative communication. In particular, this project aims to develop ML algorithms that can exploit information from SME's such as (1) identification of landmark instances; (2) proposing rules of thumb; (3) providing feedback on similarity of instances; and (4) transfer of similarity measures themselves. This project brings to bear four streams of research: (1) algorithms based on similarity functions and landmark instances; (2) active and ""pro-active"" learning; (3) Bayesian active transfer learning; and (4) learning to cope with temporal evolution in the underlying data distribution. In order to reach practical results, this project focuses on challenges where these new methods are both most needed and likely to prove most effective, such as learning in dynamic environments with concept drift, and where potential for long-term transfer learning is present. Broader impacts include more effective learning by incorporating scientific domain knowledge in eScience, for instance in computational proteomics. Educational and research-community outreach includes participation of graduates and undergraduates from Howard University, for instance in yearly research gatherings involving all students on the project, and reusable open-source methods and data sets."
"1054630","CAREER: Online Education as a Vehicle for Human Computation","IIS","Cyber-Human Systems","03/15/2011","03/16/2011","Luis von Ahn","PA","Carnegie-Mellon University","Standard Grant","William Bainbridge","02/29/2016","$482,052.00","","biglou@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","1045, 1187, 7367","$0.00","Human computation is a growing research area that studies how to harness the combined power of humans and computers to solve problems that would be impossible for either to solve alone. The goal of this project is to introduce online education as a new vehicle and incentive mechanism for human computation. The central hypothesis is that problems that are difficult for computers can be transformed into tasks that are also educational, so that students solve the problems at the same time as they learn. With millions of people learning online, education could provide a powerful motivator for participation in distributed human computation. This project will demonstrate that education allows significantly more complex problems to be attacked with human computation than has been possible with previous paradigms for human computation. The project will also explore whether human computation can be a motivator for education. <br/><br/>The hypothesis will be tested on a new large-scale system called Duolingo, a free language-learning site in which students will solve problems that computers cannot yet solve. The site will present students with many types of activities, each exercising a different aspect of the foreign language while simultaneously channeling the students to perform a different task that artificial intelligence cannot yet accomplish. Some of the tasks that students will perform include: language translation, audio transcription, and image tagging. <br/><br/>Broader impacts. The project will provide a free language-learning site expected to help millions of users learn a foreign language. It will also provide large quantities of useful data in many languages to train more accurate machine learning algorithms for language translation, voice recognition, and computer vision. Duolingo will also serve as a platform for performing large-scale experiments on how people learn languages online. In addition, undergraduate and graduate classes will be improved and developed using this research."
"0914927","RI: SMALL: LexE: Using Two-part Lexical Entrainment for More Efficient and Reliable Spoken Dialogue Systems","IIS","ROBUST INTELLIGENCE","09/01/2009","08/15/2010","Maxine Eskenazi","PA","Carnegie-Mellon University","Continuing grant","Tatiana D. Korelsky","08/31/2014","$430,000.00","","max@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923, 9102, 9215, HPCC","$0.00","When humans speak to each other and want the dialogue to go well, they adapt to each other?s manner of speaking, using the same words, grammatical constructions and expressions. In order to make fundamental improvements in the performance of spoken dialogue systems, LexE is using subtle techniques to model this adaptation, which is called lexical entrainment. LexE is getting users to adapt their speech to the system, as well as getting the system?s speech to adapt to what the user says. To do this, LexE studies human-human dialogues to find the words and constructions (the ?primes?) that are often adopted by dialogue participants. The spoken dialogue system then uses these primes in its output. The system also detects the expressions that its user employs to refer to objects uses them in its synthetic speech. <br/>Two real-user spoken dialogue systems are being used as test platforms for LexE. The first is a bus information system for the Port Authority of Allegheny County; the second is the City of Pittsburgh 311 non-emergency service. By making these publicly-available spoken dialogue systems easier to use, LexE makes them (and other spoken dialogue systems) more accessible to a large part of our population, many of whom, the elderly, for example, get much of their information over the telephone. The techniques developed in this project also provide insights for the education of non-native speakers and for speech therapy, where tutoring systems can imitate the way humans implicitly correct errors in what their interlocutors say."
"0953950","CAREER: Novel Data Mining Technologies for Complex Network Analysis","IIS","INFO INTEGRATION & INFORMATICS","04/01/2010","05/29/2014","Ruoming Jin","OH","Kent State University","Continuing grant","Sylvia J. Spengler","03/31/2015","$536,359.00","","jin@cs.kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","CSE","7364","1045, 9251, 1187, 7364, 9215, HPCC","$0.00","The long-term research goal is to develop novel data mining<br/>technologies to elucidate the structures and dynamics of complex<br/>but ubiquitous networks. A complex network is a large system<br/>of elements (vertices) that are joined by non-trivial relationships<br/>(edges). Examples of such complex networks include the WWW,<br/>metabolic and protein networks, social networks, and economic<br/>and financial markets. The underlying principles and laws of these<br/>network systems can help us construct more effective<br/>communication mechanisms, find cures for fatal diseases, and<br/>deal with economic crises.<br/><br/>In spite of the significant advances that have been made towards<br/>understanding the fundamental laws that govern the structure and<br/>behavior of complex networks, there is still a disconnect between<br/> current analytical techniques and their applicability to real-world<br/>complex networks. A principled approach is lacking to systematically<br/>analyze a single large complex network and link system behaviors to<br/> network structure. There is also immediate and crucial need for a<br/>theoretical framework to understand the relationships between<br/>multiple networks, which is the key for comparative network analysis. <br/>How to integrate and leverage the rich system data, such as<br/>measurement time series, associated with network topology to study<br/>complex systems is still an open question. This project addresses<br/>these issues by: 1) developing novel graph and information<br/>theoretical approaches to extracting network backbones which both<br/>simplify and highlight network structures; 2) developing information<br/>theoretical network distance measures and clustering algorithms for<br/>comparative network analysis; 3) applying causality inference and<br/>network modularity to integrate time series with network topology.<br/>The proposed mining methodologies build upon an innovative blend<br/>of graph theoretical, information theoretical, and statistical learning<br/>concepts and techniques, and can greatly expand the reach of<br/>data mining. This project will also help us better analyze the<br/>emerging complexity, heterogeneity, and large scale of real-world<br/>complex network data.<br/><br/>In a close collaboration with domain experts from social and political<br/>sciences, software engineering, and bioinformatics, the proposed<br/>techniques have the potential to help understand how human society is<br/>organized at the individual level (social networks) and organizational<br/>level (political science); illuminate how large scale software systems<br/>form and evolve; reveal the organizational principles of biocellular<br/>systems in a dynamic environment; and identify therapeutic or drug<br/>targets. Using the popular online social networks, such as MySpace<br/>and Facebook, as ``hooks'', this project will attract, recruit, and<br/>prepare students from underrepresented groups including women<br/>and minorities to computer science and involve underrepresented<br/>students in the cutting-edge research.<br/><br/>For further information see the project web page at:<br/>http://www.cs.kent.edu/~jin/NSFCAREER/"
"0905148","HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction","IIS","Cyber-Human Systems, TRUSTWORTHY COMPUTING","09/01/2009","04/06/2011","Aaron Steinfeld","PA","Carnegie-Mellon University","Standard Grant","Ephraim P. Glinert","08/31/2014","$339,000.00","","steinfeld@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7795","7367, 7924, 9218, 9251, HPCC","$0.00","It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified. As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems. A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger. This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time. Using this information, the robot will be able to adjust its interaction accordingly. <br/><br/>Promoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities. The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots. Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance."
"1318815","RI: Small: Collaborative Research: Learning Causal Structure from Complex Time Series Data","IIS","ROBUST INTELLIGENCE","09/01/2013","08/26/2013","David Danks","PA","Carnegie-Mellon University","Standard Grant","Kenneth C. Whang","08/31/2016","$217,497.00","","ddanks@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","In many important domains, one must learn the causal structure of a dynamical system in order to design appropriate interventions, policies, and experiments. This project develops a well founded theory and practical algorithms for such learning when scientists cannot measure the system quickly enough and/or omit causally important variables. Moreover, the theory and algorithms will focus on the most challenging case, when scientists do not know how much information is missing because of lack of either speed or breadth. For example, fMRI measurements in cognitive neuroscience experiments occur roughly every two seconds, but communication between neural regions happens much more quickly (though exactly how much more quickly is unknown). In addition, neuroscientists are almost certainly unable to record all causally significant variables, such as other bodily states. Similarly, many climatological studies omit important variables (e.g., land use) and yield only monthly (or slower) measurements, even though the underlying phenomena presumably proceed on a faster timescale.<br/><br/>This project will first focus on the challenge of learning from an undersampled time series (with unknown undersample rate), which will require (a) extending the formal framework of causal graphical models to represent such possibilities; (b) providing a set of theorems characterizing how causal structures change under undersampling; (c) developing algorithms that infer constraints on the ""true"" timescale causal structure from the causal structure learned from the undersampled data; (d) implementing these algorithms in a pre-existing, open-source causal learning environment; (e) testing these algorithms in silico through extensive simulations; and (f) applying them to real world datasets, including large-scale neuroimaging data. This last step is particularly important as it will enable real-world validation of the theory and algorithms developed earlier. In parallel, the project will address the same six challenges for situations in which data are correctly sampled, but causally significant variables are missing. Finally, these two pieces will be merged into an integrated framework and algorithms for situations in which both challenges arise simultaneously. The resulting set of theorems, algorithms, and applications will both extend the current theory of causal modeling and causal structure learning, and also address the practical needs of researchers engaged in causal learning from complex, real-world time series data."
"1352440","EAGER: PARTIAL: An Exploratory Study on Practical Approaches for Robust NLP Tools with Integrated Annotation Languages","IIS","ROBUST INTELLIGENCE","09/01/2013","08/19/2013","Noah Smith","PA","Carnegie-Mellon University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$100,000.00","Chris Dyer","nasmith@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7916","$0.00","In order to develop natural language processing (NLP) technologies for text in a wider range of languages, dialects, genres, and styles, this Early Grant for Exploratory Research investigates a novel methodological approach. Conventionally, linguistic experts are employed to create gold-standard linguistically annotated datasets to which supervised machine learning algorithms are applied. This project frees annotators from the requirement that annotations be complete by moving more of the burden to learning algorithms. Algorithms are developed that are robust to partial evidence, annotator variation, and noise due to errors. As a result, any language enthusiast (not just trained experts) can provide annotations so that NLP can be developed for more kinds of text in more languages for less money. In this exploration, the focus is on dependency parsing, a fundamental NLP component that predicts the grammatical relationships between words in sentences, with experimentation on data in English (two genres), Chinese, and Farsi. The formal basis for the approach is a framework called Graph Fragment Language (GFL). The project assesses the quality of parsers learned from GFL and the productivity of annotators accorded this new flexibility.<br/><br/>Beyond documentation and assessment of the new methodology, this project produces open-source software tools for gathering annotated data and constructing NLP tools using the data. It emphasizes the usability of these tools in classrooms, contributing exercises that can be used in NLP and linguistics courses to allow students to engage directly with data, with the models that make use of the data, and with the technological goals that data annotation supports."
"1217929","HCC: Small: New Infrastructure Concepts for Robust Handling of Inputs with Uncertainty","IIS","Cyber-Human Systems","08/15/2012","07/26/2013","Scott Hudson","PA","Carnegie-Mellon University","Continuing grant","Ephraim P. Glinert","07/31/2015","$519,119.00","Jennifer Mankoff","hudson@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","7367, 7923, 9251","$0.00","The conventional software currently used to handle input in nearly all modern graphical user interfaces (GUIs) is effective and highly evolved. This has the advantages of promoting reuse rather than reinvention of interaction techniques, and making it easy to create GUis, even for those with limited programming ability. However, these successful software abstractions assume the inputs reported to the system accurately reflect the actions of the user - that input is certain rather than uncertain. Unfortunately, this does not hold for some of the most interesting new input technologies including naturalistic inputs such as free space gestures (e.g., as sensed by the Kinect depth camera), pen input (including handwriting, gestures, and free hand drawing), touch input, sensors for context, and voice input. Some of these new technologies contain inherent uncertainty, such as when a finger touch area (that the user cannot see) is much larger than the pixels of a display. Others make use of recognizers for input and typically produce estimates of what might have occurred. Since conventional methods of input handling have no way to manage uncertainty in input, many of them force uncertainty to be resolved before input processing even starts. For example, the location of input from a touch screen may be represented as certain using a single point (its centroid). But when uncertainty information is thrown away, interfaces can quickly become brittle; small recognition errors can derail the interaction and destroy the user experience. As a result, these new and very promising forms of input have often proven difficult to use to their full potential. The PI's goal in this project is to overcome this problem by creating a redesigned input-handling infrastructure, which will robustly model, and make use of, inputs with uncertainty. It will do this by treating all input, and all UI actions stemming from that input, on a probabilistic basis, entertaining multiple possible interpretations of input (and all its consequences over time), along with estimates of the likelihood of each interpretation. As a result, when decisions need to be made and irreversible actions undertaken, systems will have a sound basis for choosing among interpretations. Rather than starting with completely new input concepts, the PI's approach is to extend conventional input abstractions with support for uncertainty. Normally, a single certain input event is dispatched to a single interactor, which interprets its meaning to track its own interactive state and eventually request actions. Now, each of these parts of the input process will be done probabilistically. An estimated probability distribution will be tracked over input alternatives that might have occurred, interactors which might have received that input, states that interactors might be in, and actions that interactors might request as a result. These probability distributions can then be used to make informed decisions about when, whether, and which actions to actually undertake. To hide the complexity of maintaining each of these distributions over time from the UI programmer, the PI will employ a Monte Carlo representation of a probability distribution (i.e., a weighted set of samples each indicating the probability of one definite value). Crucially, this representation will allow the code to simply execute traditional (certain) input processing steps multiple times - once for each sample in the relevant probability distribution(s). This hides nearly all the complexity associated with uncertainty, and allows programmers to use their current conceptual models, and even code nearly identical to their current practices, for most aspects of input handling.<br/><br/>Broader Impacts: Project outcomes will radically change the ease with which readily available new input technologies can be incorporated into interactive systems, and thus will have wide impact in expanding our ability to build and deploy interfaces with new forms of input. As part of this research, the PI will develop working solutions for both graphical user interfaces and context-aware applications. He will also create and widely distribute a full teaching toolkit which embodies these concepts (where the term ""teaching"" is used in the same spirit that Pascal was a teaching programming language - it used good concepts and the best practices of the time; it was conceptually clean, yet suitable for real work). This teaching toolkit will be integrated into educational activities at the PI's institution, and curricular modules will be developed which should allow this to be carried to other universities."
"1302206","III: Medium: Selective Search of Large-Scale Text Collections","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/07/2013","Jamie Callan","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","08/31/2017","$1,083,395.00","","callan@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7924, 7364","$0.00","This project develops an alternative architecture for large-scale text search in which the document corpus is decomposed into index shards that are expected to have skewed utility distributions, thus enabling most index partitions to be ignored for most queries. This selective search architecture is as effective as conventional search engine architectures, but has far lower computational costs and reveals new challenges and opportunities in large-scale search. The decomposition process creates text collections, thus inviting research on what characteristics are desired or to be avoided in a text collection to enable accurate search. New resource selection algorithms are developed to address efficiency problems in existing algorithms and dynamically adjust search costs based on query difficulty. The project includes collaboration with three research groups at other universities, to help their research, leverage their expertise in designing new approaches to problems, and investigate the effectiveness of our research in more varied situations. The result is an ""off-the-shelf"" method that provides an order of magnitude reduction in search costs over the current state-of-the-art, especially on corpora of more than a billion documents, and that can be easily customized or extended to support varied needs.<br/><br/>Selective search is significant in part because it provides a new perspective on how to organize a very large collection of documents so that it can be searched accurately and efficiently. This new understanding reveals new research problems and undiscovered weaknesses in existing algorithms that will have impact within the scientific community. Text search is one of the most widely used computer science technologies; hence selective search is of practical significance. The state-of-the-art in many areas of industry and science is increasingly associated with large-scale datasets, which makes it difficult for organizations with modest computational resources to compete. This project reduces the computational costs of searching large-scale text collections by an order of magnitude or more. It has the potential to reduce the energy and other costs associated with the data centers of large search providers, which has important economic and societal benefits. Research results from this project are disseminated via project web site (http://www.cs.cmu.edu/~callan/Projects/IIS-1302206/); in research publications; in the Lemur Project's open-source search engines, which are used by a broad international scientific community; and in the Lemur Project's ClueWeb public search services, which integrate research and education by enabling scientists and classroom students to do experiments on large, state-of-the-art text corpora."
"1304939","III: EAGER: Automatically Building Test Collections Using Implicit Relevance Signals from the Web","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","01/16/2013","Eduard Hovy","PA","Carnegie-Mellon University","Standard Grant","Sylvia J. Spengler","08/31/2014","$103,233.00","","hovy@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","7916","$0.00","Helping users find relevant information is undeniably an important problem vital to the functioning of today's information-based societies. It is therefore no surprise that millions of people worldwide make use of search engine technologies each and every day. Although existing search technologies work well, there is still considerable room for improvement. Search engine innovation is driven by the ability to rapidly, and repeatedly, measure the quality of the results produced by a given system. This type of measurement typically requires some form of human input. For example, a human expert may be hired to assess the relevance of search results, or the search engine may log user interactions, such as the queries entered and the results clicked. After a sufficiently large amount of data has been collected, it can then be used to accurately measure search engine quality. It can also be used to improve the quality of existing search engines via a process known as ""tuning"" or ""training"". However, gathering large amounts of this information typically requires a significant amount of human effort or computational resources. Therefore, sustained innovation is only possible at a very steep cost.<br/><br/>Techniques for constructing large information retrieval test collections that require no human effort are the primary focus of this research study. Rather than relying on human-curated information, implicit relevance signals from the Web are mined to automatically construct large, reusable test collections for a variety of search tasks, including Web search, news search, and enterprise search. The observation that the Web contains a large number of implicit relevance signals is the starting point of the research. The simplest example of an implicit relevance signal is the hyperlink, which can be interpreted as a signal acknowledging the relevance of the target page by the source author. The hypothesis that such implicit relevance signals can be effectively mined and aggregated in a completely unsupervised manner to create test collections without any human effort is investigated in this research. Automatically generated test collections are evaluated in two different ways. First, the test collections are evaluated according to their ability to accurately measure the quality of search systems compared to human-generated test collections. Second, the quality of search engines tuned using the automated test collections are compared against engines tuned using manual test collections.<br/><br/>The broader impact of this project is derived from automatically constructed test collections that are freely distributed to the broader research community. Advances in search engine technologies are expected as the result of increased availability of training data to systematically evaluate and tune search engines, both in industrial and academic settings. Additional broader impact is expected from the integration of research and education at both the graduate and undergraduate levels and from engaging women and underrepresented students through various outreach programs."
"1252412","CAREER: Distilling information structure from big and dirty data: Efficient learning of clusters and graphs in modern datasets","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","02/21/2014","Aarti Singh","PA","Carnegie-Mellon University","Continuing grant","Sylvia J. Spengler","02/28/2018","$390,439.00","","aartisingh@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364","1045, 7364","$0.00","This CAREER project aims to advance the state-of-the-art in theory and methods for extracting clusters and graphs from big and dirty datasets arising in modern application domains. Clusters and graphs provide a meaningful representation of the structure of information contained in data, e.g. in neuroscience and health care domains, clustering patients with similar phenotypes and genotypes helps identify target groups for drug design, clustering fiber tracks generated by high-resolution Digital Surface Imaging (DSI) scans of brains help identify significant neural pathways, and graph structures can reflect connectivity between brain regions. The results of this work will significantly enhance the ability to exploit such modern datasets through new methods for learning clusters and graphs from data that is large-scale, high-dimensional, under-sampled, corrupted, and often only available in a compressed or streaming representation. <br/><br/>Specifically, this project will develop computationally efficient and principled methods for learning clusters and graphs that can (i) perform unsupervised feature selection to discard irrelevant features in high dimensions, (ii) leverage feedback based on intelligent adaptive queries that focus resources on most informative variables and features, (iii) use compressive measurement design that adapts to the information structure for measurement and computation efficiency, and (iv) be able to handle noisy streaming data. The algorithms will be accompanied with performance guarantees in the form of a precise characterization of the mis-clustering rate and graph recovery error. Additionally, the project will investigate the tradeoffs between number of measurements, computational complexity and robustness in these problems. The methods and theory developed will be evaluated through simulations as well as their applicability to real datasets in neuroscience and healthcare domain, in collaboration with practitioners from these fields. <br/><br/>The results of this research could potentially transform many application domains that involve grouping similar variables and learning complex interactions between them, based on big and dirty datasets. In particular, the neuroscience and healthcare applications are likely have very direct and significant implications for society. Accurately mapping neural pathways will help diagnose and treat brain pathologies at an early stage, and help understand brain functioning. Clustering patients and discovering disease spreading pathways based on few measurements of relevant genetic features or indicators could help prevent and cure diseases, and also minimize healthcare costs. The research activities will be tightly integrated with education efforts that aim to develop a diverse workforce that is better equipped with cross-disciplinary tools to address the challenges of modern datasets. The education plan includes development of two inter-disciplinary courses, and enhancement of the joint Statistics & Machine Learning PhD program at Carnegie Mellon University (CMU). Outreach activities include promoting undergraduate research, broadening participation of women and underrepresented groups in STEM fields through OurCS (Opportunities for Undergraduate Research in Computer Science), Andrew?s Leap (a summer enrichment program for area high school and middle school students) and CS4HS program aimed at High School and K-8 teachers at Carnegie Mellon University. The results of this project (including publications, data sets, and software) will be disseminated online at http://www.cs.cmu.edu/~aarti/research_projects/."
"1265301","EAGER: Constructing, Indexing, and Searching Super-Enriched Document Representations in the Cloud","IIS","INFO INTEGRATION & INFORMATICS, ","09/01/2012","11/29/2012","Eduard Hovy","PA","Carnegie-Mellon University","Standard Grant","Sylvia J. Spengler","08/31/2014","$236,111.00","","hovy@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, K155","170E, 7364, 7916","$0.00","There are billions of new digital documents created around the world every day. Examples include emails, blog posts, legal documents, and news articles. To enable effective information management, many of these documents are processed by information retrieval systems, such as desktop search tools or Web search engines. Most existing technologies represent documents digitally. To a computer, these representations are nothing more than a sequence of bits, completely devoid of any explicit meaning. Since most modern search engines utilize such basic representations, they often fail to properly account for the meaning of the words found in the documents, thereby diminishing the quality of their results. Despite the importance of this fundamental problem, there have been surprisingly few attempts to build, and subsequently search, document representations that encode the deeply rich meaning of text, especially for data sets that contain millions or billions of text documents.<br/><br/>This research investigates how to automatically construct, index, and search next-generation super-enriched document representations. The approach relies on the careful integration of traditional text representations with natural language processing-based sources (e.g., named entities, synonyms, and paraphrases), rich knowledge sources (e.g., Wikipedia and Freebase), contextual sources, and other value-added sources of content. Constructing such representations for large document collections requires computationally intensive batch processing to mine, aggregate, and join data across disparate sources. To overcome these challenges, a scalable, massively distributed cloud computing solution is adopted. The resulting enriched document representations can be effectively applied to a wide variety of information retrieval, natural language processing, and data mining tasks."
"1116583","RI: Small: Clustering, Classification and Alignment of Time Series for Human Sensing","IIS","ROBUST INTELLIGENCE","09/01/2011","05/15/2014","Fernando De la Torre","PA","Carnegie-Mellon University","Standard Grant","Todd Leen","08/31/2015","$458,000.00","","ftorre@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923, 9251","$0.00","Time series analysis is central to the study of computer vision, signal processing, computer graphics, machine learning, and social sciences, among other fields. This project entails original contributions towards algorithms for unsupervised pattern discovery and temporal alignment of time series, and its applications to model human motion. In particular, the PI proposes three new methods: (1) a discriminative temporal clustering that factorizes a set of time series into segments belonging to one of k temporal clusters, (2) a method for discovering the set of most discriminative segments between two sets of time series, and (3) an unsupervised algorithm for temporally aligning multi-modal time series. The PI proposes an energy minimization framework to encompass these three problems. This framework should provide researchers with a thorough understanding of a large number of existing time series techniques, and it may serve as a tool for dealing with other problems in time series as they arise.<br/><br/>Enabling computers to understand human behavior has the potential to revolutionize many areas that benefit society such as clinical diagnosis, human computer interaction, and social robotics. Advances in time series to model human actions and events from sensory data have been critical to the success of systems that can recognize and characterize human behavior. However, most existing algorithms have been supervised in nature. Supervised learning typically requires large amounts of human annotation, that is typically labor intensive and is difficult to standardize across coders. In this proposal the PI explores the use of unsupervised learning techniques for aligning and discovering patterns in time series of human motion that have been captured with accelerometers, video or motion capture technologies. The PI will show how the proposed algorithms outperform state-of-the-art techniques in several human sensing tasks such as temporal alignment of human motion, temporal clustering of human activities from video, learning motion primitives, and joint segmentation and classification of human behavior. In the educational aspect, the PI will continue to provide support to the Carnegie Science Center to demonstrate human sensing technologies, as well as incorporate a large number of undergraduates in his research. The research source code will be made available to the scientific community."
"1115489","HCC: Small: Development of an Eyeglass-Style Compact Eye-Tracked Near-Eye Display Using Freeform Optical Technology","IIS","Cyber-Human Systems","08/15/2011","08/12/2011","Hong Hua","AZ","University of Arizona","Standard Grant","Ephraim P. Glinert","07/31/2015","$499,954.00","","hhua@optics.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7367","7367, 7923","$0.00","An integrated eye-tracking head-mounted display (ET-HMD) able to display stereoscopic virtual images while also tracking the direction of the user's gaze would benefit both fundamental scientific research and a host of emerging applications. Yet despite significant advances in and commercial availability of stand-alone HMD and eye-tracking technologies, a portable, lightweight, accurate and robust system that conforms to the form factor of a pair of sunglasses remains elusive. The PI's goal in this project is to develop a fundamentally new optical technology that will make it possible to realize this dream by overcoming the limitations of the conventional methods that have been applied to ET-HMD designs to date. In most previous work on designing ET-HMD systems, the optical systems for the HMD and eye-tracking paths were treated separately, and rotationally symmetric optical surfaces were used. In contrast, the PI's approach is to utilize freeform optical technology in combination with an innovative optical scheme that uniquely combines the display optics with the eye imaging optics. To these ends, she will investigate the challenges of designing the freeform ET-HMD system and develop appropriate design methods along with an optimization strategy for the required high performance optical system. She will implement a fully integrated, portable prototype system, and develop calibration and assessment methods for evaluating both the display and eye-tracking performance. As a testbed application for the new technology, the PI will evaluate the feasibility of adopting ET-HMD displays to augment communication by patients suffering from ALS (amyotrophic lateral sclerosis) or similar neurological disease that causes loss of speech. Project outcomes will include the first lightweight and portable ET-HMD display prototype that has a form factor close to that of sunglasses.<br/><br/>Broader Impacts: The new technology resulting from this project will have critical impacts in many fields. It will create a revolutionary and intriguing platform for mobile communication, wearable computing, and portable entertainment. It will provide a new tool for research related to vision and human factors, where eye movements provide a sensible metric for understanding human perception in 3D space and effectiveness at specific tasks. It will afford augmentative and alternative human-computer interfaces for people with proprioceptive disabilities or with situational impairments due to having their hands and feet occupied. And it will undoubtedly spur development of a host of new and thrilling applications. The research will also provide a vehicle for training the next generation of interdisciplinary scientists and engineers, at both the undergraduate and graduate levels."
"1111750","HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","IIS","Cyber-Human Systems","09/01/2011","03/28/2012","James Herbsleb","PA","Carnegie-Mellon University","Standard Grant","Kevin Crowston","08/31/2014","$741,831.00","Laura Dabbish, Linda Argote","jdh@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","7367, 7925, 9251","$0.00","In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br/><br/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br/><br/>Broader Impacts: As society enters the era of ""ultra large scale"" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities."
"1117965","III: Small: Collaborative Research: A Large-Scale Data Mining Framework for Genome-Wide Mapping of Multi-Modal Phenotypic Biomarkers and Outcome Prediction","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","04/05/2012","Heng Huang","TX","University of Texas at Arlington","Standard Grant","Sylvia J. Spengler","07/31/2015","$315,904.00","Fillia Makedon","heng@uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7364","7923, 9251","$0.00","Today's massive generation of digital data is greatly outpacing the development of computational methods and tools and presents critical challenges for achieving the full transformative potential of these data. For example, recent advances in acquiring multi-modal brain imaging and genome-wide array data provide exciting new opportunities to study the influence of genetic variation on brain structure and function. Major computational challenges are, however, bottlenecks for comprehensive joint analysis of these data due to their unprecedented scale and complexity. This project will employ the new capabilities of large-scale data mining techniques in multi-view learning, multi-task learning, and robust classification to address critical challenges in systematically analyzing massive multi-modal genetic, imaging, and other biomarker data. Specifically, this project will: (1) develop new multi-view learning methods to detect task-relevant phenotypic biomarkers from large scale heterogeneous imaging and other biomarker data, (2) implement new sparse multi-task regression models to reveal the genetic basis of phenotypic biomarkers at multiple levels (e.g., SNP, haplotype, gene and/or pathway), (3) design novel robust classification methods via structural sparsity for outcome prediction using integrated genotypic and phenotypic data, and (4) package these new methods into a data mining toolkit and release it to the public. <br/><br/>The intellectual merits of this project derive not only from the development of novel data mining methods, but also from their application to imaging genetic studies. These methods are designed to take into account interrelated structures among multiple data modalities and offer systematic strategies to reveal structural imaging genetic associations. The proposed methods and tools are expected to impact neurological and psychological research and enable investigators to effectively test imaging genetics hypothesis and advance biomedical science and technology. In addition, the proposed data mining framework addresses generic critical needs of large-scale data analysis and integration and, therefore, will impact a large number of research areas where high-value knowledge and complex patterns can potentially be discovered from massive high-dimensional and heterogeneous data sets. This project will facilitate the development of novel educational tools to enhance several current courses at UT Arlington and IUPUI. Both universities are minority-serving institutions, and the PIs will engage the minority students and under-served populations in research activities to give them a better exposure to cutting-edge scientific research."
"1117519","RI: Small: Distributed Network of BacteriaBots","IIS","ROBUST INTELLIGENCE","08/01/2011","07/18/2012","Bahareh Behkam","VA","Virginia Polytechnic Institute and State University","Continuing grant","Jeffrey Trinkle","07/31/2015","$425,348.00","Birgit Scharf","behkam@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7495","7923","$0.00","The project exploits the sophisticated and robust machinery of bacteria for actuation, sensing, communication, and control of a new class of micron scale robotic systems called BacteriaBots. This is achieved through (1) computational modeling of bio-actuation and sensing, (2) use of quorum sensing-based behaviors, and (3) use of mobile networks of BacteriaBots.<br/><br/>This effort contributes to the critical understanding required to advance the science of bio-hybrid micro-robotics and distributed control at reduced length scales. This holds enormous promise for socio-economic benefit by significantly impacting the fields of bio-sensing, medicine, micro-manufacturing and assembly, microelectronics, and bio-materials. A multi-tier education and outreach plan integrates research elements and discoveries into multi-disciplinary educational research experiences for K-12, undergraduate and graduate students."
"1116533","RI: Small: Physical Interaction with Dynamically Stable Mobile Robots","IIS","ROBUST INTELLIGENCE","08/01/2011","04/11/2012","Ralph Hollis","PA","Carnegie-Mellon University","Standard Grant","Satyandra Gupta","07/31/2015","$510,562.00","Paul Rybski","rhollis@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7923, 9251","$0.00","The project studies three important domains which highlight physical Human-Robot Interaction involved in assisting humans in the home and workplace: (1) human guidance through cluttered environments using physical contact, (2) cooperative carrying of large objects through complex and dynamic environments, and (3) robot assisted sitting and getting up. This is accomplished through the evolution of an experimental single-wheel mobility platform into an autonomous robot that is instructed and guided by people in a natural way.<br/><br/>Such systems are needed in many public health domains, including care for the elderly, rehabilitation and assistive programs. Project results are incorporated into coursework offered by two different departments at CMU, and exposes students to unique robot planning, control and Human-Robot Interaction issues. High school students are introduced to this area as part of the Andrew Leap program. Students from underrepresented groups participate through the ARTSI program. Results may be presented in cooperation with museums or entertainment companies."
"1149797","CAREER: Distributed Sensemaking: Making Sense of the Web Together","IIS","Cyber-Human Systems","03/01/2012","05/08/2014","Aniket Kittur","PA","Carnegie-Mellon University","Continuing grant","William Bainbridge","02/28/2017","$314,800.00","","nkittur@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","1045, 7367, 9251","$0.00","This project will develop web-based knowledge-building environments for the collaborative creation of information landscapes: interactive visualizations that support the sensemaking individuals engage in online, and capture their efforts for the benefit of others who come after them. To guide and motivate the design of these environments, the research builds on theories of sensemaking, which describe the nested and parallel loops through which individuals seek out, analyze, and understand information, grounded in a rich history from organizational behavior, social and cognitive psychology, and human-computer interaction. It will extend theories of individual sensemaking to the situation in which an individual's processing of information for themselves is consumed by others, whose processing in turns improves the sensemaking of those coming after them - what can be called the ""distributed sensemaking cycle."" <br/><br/>Examining distributed sensemaking in a way that is both rigorous and environmentally valid is a challenging prospect, so this project will take a multi-stage approach involving laboratory studies to characterize the distributed sensemaking process and iteratively develop interfaces; ""virtual lab"" experiments harnessing crowdsourcing to evaluate these processes and interfaces at a larger scale while bootstrapping the system's value; and controlled field trials to test theories and interfaces in environmentally valid settings. <br/><br/>In order to capture the benefits and costs to both the producer and the consumer, the research will employ an experimental framework that elicits both of their perspectives. The general approach involves the producer using an interface for a sensemaking task and the consumer doing the same task but starting with the results of the producer's work. This approach will iteratively develop interfaces that help individuals forage for information, integrate the results of their foraging into information landscapes, and convey the judgments, decisions, and work they engaged in during the process to others. <br/><br/>The results of this research will advance scientific understanding across a variety of domains, including sensemaking, collaboration, schema induction, and interface design. The research has the potential to improve the efficiency of knowledge work, the training and practice of scientists, and the effectiveness of education. The tools developed in this research will be incorporated and evaluated in educational practice, and will become the center of a community linked to several existing knowledge bases."
"0968484","SoCS: Collaborative Research: Information Farming: Intelligent Interfaces for an Online Production Community","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/15/2010","05/05/2014","Aniket Kittur","PA","Carnegie-Mellon University","Standard Grant","William Bainbridge","08/31/2014","$419,800.00","","nkittur@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7953","7367, 7953, 9251","$0.00","Social production communities can be powerful engines for harnessing the efforts of many individuals to produce valuable artifacts and knowledge. However, their success critically depends on members' ability to effectively contribute. As the size and complexity of the community grows, so do challenges to members' understanding of the content and collaboration. These challenges decrease the ability of the team to work together, and the quality of the work product.<br/><br/>The researchers propose partnering humans with intelligent interfaces that improve contribution effectiveness. They will create intelligent algorithms and interfaces that go beyond supporting people simply foraging for information to information farming, in which members of the community work together to plant the seeds of the information the community needs, nurture the growth of those seeds into valuable information, and weed out the information that detracts from the value of the farm.<br/><br/>The research is based on theories of human information processing, and will extend those theories to environments in which people are producing information. The researchers will explore new algorithms and interfaces based on the extended theories, and will carry out studies to understand how the theories work in practice.<br/><br/>Social production communities are economically and socially important. Open source software runs large parts of our economy; Wikipedia is revolutionizing knowledge production and consumption, providing free access to one of the largest bodies of knowledge gathered in human history. The proposed research will directly improve Wikipedia, and will contribute to understanding how social production communities work."
"0709077","CRI: IAD Laboratory for Research in Human-Robot Interaction","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE, Cyber-Human Systems, ROBUST INTELLIGENCE","09/01/2007","07/30/2012","Sara Kiesler","PA","Carnegie-Mellon University","Continuing grant","Jeffrey Trinkle","09/30/2014","$601,481.00","","kiesler@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 1714, 7359, 7367, 7495","7359, 9102, 9178, 9215, 9218, 9251, HPCC","$0.00","Proposal #: CNS07-09077<br/>PI(s): Kiesler, Sara B. <br/>Institution: Carnegie Mellon University <br/> Pittsburgh, PA 15213-3890<br/>Title: IAD: Laboratory for Research in Human-Robot Interaction<br/><br/>Project Proposed:<br/>This project, developing a new generation of social robots for studies in human-robot interaction, aims at creating robots and modular robotics kits to be used to study robot social behavior, mutual understanding in human-robot communication, and the impact of assistants in group dynamics. The research involves understanding and testing theories of how these three aspects of human-robot interaction independently and interactively affect collaborative work and investigating how assistive robots can be designed best to aid people in domains such as health and aging. Designed to motivate and test theories, the work studies <br/>. Fundamental laboratory research on behavioral characteristics of robots performing social tasks, especially as these characteristics reflect likeness;<br/>. Controlled experiments and field studies of interpersonal communication and development of mutual understanding between robot and human, and<br/>. Robots in work groups.<br/>Aiming to better understand the societal impact of robots, a multidisciplinary team (robotics, computer science, social psychology, engineering, organization science, design) draws from and builds on basic research in cognitive and social psychology, and on recent research in robotics, computer graphics, and design. The team seeks a foundation for understanding and designing collaborative work with robots in critical environments like mines, hospitals, households with elderly or disabled residents, in challenging scientific settings and in situations in which the robot is remote.<br/><br/>Broader Impacts: This development contributes to public and student awareness of the human side of robotics. A life-size robot will be taken to school for educational purposes."
"1433108","Workshop: Support for a workshop on scientific research applications of natural language technologies","IIS","LINGUISTICS, Cyber-Human Systems, ROBUST INTELLIGENCE","05/01/2014","04/29/2014","Noah Smith","PA","Carnegie-Mellon University","Standard Grant","Kevin Crowston","04/30/2015","$25,000.00","","nasmith@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1311, 7367, 7495","1311, 7367, 7495, 7556","$0.00","This is funding for a one-day workshop on scientific research applications of natural language technologies to be held at the annual meeting of the Association for Computational Linguistics (ACL), in Baltimore on June 26, 2014. A major growth area in applied computer science has been the application of automated techniques to massive datasets to answer scientific questions about people and society. Although much work in this area focuses on structured data or network data, linguistic data is also a key source of evidence for these phenomena. While some existing natural language processing (NLP) techniques have found use in this growing community, new techniques for discovering and analyzing social meanings and structures in text are in high demand.<br/><br/>Intellectual merit. Engagement between NLP researchers and domain scientists will introduce new problem formulations and new theoretical frameworks that will broaden and deepen applications of language technology to social science. Potential topics for presentations and discussion include (but are by no means limited to): inferring social relations from conversation and other linguistic behavior; automatic extraction of event data from text; inference of author and speaker properties from text and speech; relating text datasets to author social networks; tracking language change over space, time, and communities; measuring linguistic influence; computational analysis of literary and historical corpora; and tracking the flow of information, ideas, and sentiment through social networks. Much of the data to be studied comes from online communities, which are a focus of the Cyber-Human Systems program.<br/><br/>Broader Impact. This workshop will increase the visibility of the computational social science application area for ACL researchers and will help build connections between language technologists and social scientists. The workshops format aims at fostering interactions among participants and invited speakers, contributing towards building a community interested in language technologies and domain scientists. This format is especially beneficial to student participants, who will leave with new ideas about guiding applications. As is typical for ACL workshops, an archival proceedings will be published openly through the ACL Anthology. The workshop organizers will report on the workshop, synthesizing the discussion at the workshop with an emphasis on research topics with greatest potential in the near future. The report will be published openly (e.g., posted to arXiv and possibly submitted for publication in a relevant journal) within a few months after the workshop."
"1320620","RI: Small: Expressiveness and Automated Bundling in Mechanism Design: Principles and Computational Methodologies","IIS","ROBUST INTELLIGENCE","09/01/2013","08/27/2013","Tuomas Sandholm","PA","Carnegie-Mellon University","Standard Grant","James Donlon","08/31/2016","$425,000.00","","sandholm@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","Mechanism design is the science of designing the rules of a game (e.g., auction or election) so that good outcomes ensue despite each participant (human or computational) acting based on self-interest. Intuitively, allowing individuals or organizations to express richer preferences should yield better outcomes. Billions of dollars of annual savings from outcome efficiency improvements due to increased expressiveness have indeed been observed, for example, in combinatorial sourcing auctions by the PI and others. What is missing is a rigorous methodology for designing appropriately expressive mechanisms. This project combines new theoretical results in mechanism design - including computational measures of expressiveness - with custom search algorithms and machine learning techniques. The goal is to create knowledge about mechanism design with varying levels of expressiveness. The work also involves developing an operational methodology to guide the design of appropriately expressive mechanisms across a broad class of combinatorial and multi-attribute domains. Furthermore, the work will yield new theory and computational methodologies for bundling. The objects of study are rational agents and agents with forms of bounded rationality.<br/><br/>While many of the results will be general, the work will be validated in qualitatively different applications such as combinatorial auctions, advertising markets, and catalog-offer-based (web) commerce. In the US alone, combinatorial multi-attribute sourcing auctions give rise to tens of billions of dollars in annual trade. Annual volumes associated with advertising markets, spectrum auctions, consumer-to-consumer auctions, and catalog-based commerce are all in hundreds of billions or trillions of dollars. Improvements would thus offer substantial economic and societal benefits."
"1322241","VOSS: Collaborative Research: Is Larger Smarter? Investigating the Effect of Group Size on Collective Intelligence","ACI","Cyber-Human Systems, Science of Organizations","10/01/2013","08/30/2013","Anita Woolley","PA","Carnegie-Mellon University","Standard Grant","Almadena Y. Chtchelkanova","09/30/2016","$167,624.00","","awoolley@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 8031","7642, 9102, 9179, 7367, 8031","$0.00","From Wikipedia to Linux to scientific and business work-groups all over the world, both online and off-line groups are becoming a pervasive part of modern life. It is becoming increasingly important, therefore, to understand how to improve the performance of these groups. The work proposed here will use a new measure of generalized group effectiveness -- called ""collective intelligence"" -- to help do this. <br/><br/>Building on previous work by the investigators, the project will first develop an online test for collective intelligence. Then it will compare the results of online and face-to-face groups taking this new test with previous results for groups taking an offline version of the test. This will help clarify the degree to which online and off-line groups differ in their general effectiveness on a wide range of different tasks. Next the project will use this test to systematically measure the collective intelligence of online groups that range in size from 2 to 20 people. This will lay the foundation for exploring whether larger online groups can take advantage of the increased resources that more people bring, without suffering as much from the process losses that usually accompany increased group size in face-to-face groups. Finally, the project will systematically measure the collective intelligence of online groups with varying proportions of women. In doing so, the project will also test one particularly promising explanation for a gender effect on group performance: that groups with more women are less interpersonally competitive, and that this lower intra-group competitiveness leads to higher collective intelligence. <br/><br/>While there have been decades of research on factors that affect the performance of groups, almost all these studies have each focused on a single task. Thus, strictly speaking, the lessons to be learned from this previous work are limited to the specific tasks studied. The work proposed here uses the perspective of collective intelligence to investigate, not just the ability of a group to perform a single task, but the group?s general ability to perform a wide range of tasks. Since many real-world groups must cope with a wide range of problems, just such a perspective may be needed to systematically predict their performance. In addition, the approach developed here can provide a significant economy of effort in evaluating potential ways of improving online group effectiveness. Instead of testing interventions on many different specific tasks, researchers will be able to test the interventions once with this general measure, and then have some basis for predicting the effects of the intervention on many other tasks. By making an online test of collective intelligence available to other researchers, the project will help advance scientific practice in this area. More generally, by providing a firmer scientific foundation for measuring and improving the performance of groups, the project may help our society address many of its most important problems more effectively. For instance, with the right kinds of collaboration tools, online groups may be able to be much more effective than face-to-face groups, taking advantage of the simultaneous efforts of far more people without the coordination losses that usually occur in larger groups. And understanding the dynamics of gender diversity may help us to improve the collaboration of the groups in which both men and women work, by giving everyone?s best ideas a better chance to be heard. And perhaps, someday, this will help create groups that are more collectively intelligent than any groups have ever been before."
"1302522","HCC: Medium: Personalized information access for online deliberation systems","IIS","Cyber-Human Systems","08/01/2013","07/23/2013","James Herbsleb","PA","Carnegie-Mellon University","Continuing grant","Kevin Crowston","07/31/2017","$1,122,000.00","Carolyn Rose","jdh@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","7367, 7924","$0.00","Online deliberation seeks to improve group decision making by accessing diverse expertise and experience, informing and marshaling evidence in a fruitful exchange of ideas. Successful deliberation environments can bring great benefits, such as broadening participation, tapping a greater range of knowledge, testing ideas against each other, and fostering appreciation of other views. However, for large and complex problem spaces that generate extensive discussion, it is difficult for would-be participants to find where they could best make a contribution, to understand how various contributions fit together, or to grasp the contingencies between needs and contributions. <br/><br/>To address this problem, this project will develop and test a system that provides a personalized view of a large information space that reveals the shape and foci of contributions in a way that reflects the goals, expertise, and interests of each user. The system will allow participants to see how their goals and interests match current themes and to find groups of people and related sets of contributions that would be of interest. To do this, the research will integrate insights from sociolinguistics with state-of-the-art latent variable modeling techniques from the field of language technologies to extend prior work in the areas of perspective and stance modeling in order to identify the necessary structure in textual data to enable personalized information extraction, summarization, and presentation. <br/><br/>The project includes archival data analysis to develop algorithms and data representations, experiments to test the value to users of various ways of representing topics and social networks, a staged series of deployments for formative and summative evaluation, and the development of tool architecture and user interfaces to support experimentation and deployment. Through these activities, the investigators will systematically explore the effects of design decisions on participation, navigability and the nature of the deliberation."
"1320083","RI: Small: Functional Scene Representation for Image Understanding","IIS","ROBUST INTELLIGENCE","08/15/2013","08/19/2013","Abhinav Gupta","PA","Carnegie-Mellon University","Standard Grant","Jie Yang","07/31/2016","$450,000.00","","abhinavg@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","What does it mean to ""understand"" an image? One popular answer is simply naming the objects seen in the image. During the last decade most computer vision researchers have focused on this ""object naming"" problem. While there has been great progress in detecting things like ""cars"" and ""people"", such a level of understanding still cannot answer even basic questions about an image such as ""What is the geometric structure of the scene?"" ""Where in the image can I walk""?<br/><br/>The goal of this project is to develop a geometric and functional representation of our visual world for scene understanding. This project aims to develop this functional representation by learning relationships between the physical/visual representation of the scene and the space of the interactions an agent can perform in that scene. The key advantage of functional scene representation is that it is subjective, explicitly task-based and takes into account the agent?s capabilities.<br/><br/>This project is anticipated to result in major advances within the image understanding community, bringing it closer to researchers in robotics. It is anticipated to result in improvements in: (a) 3D Scene Understanding; (b) Recognition; (c) Human Activity Understanding, and hence could be a critical enabling technology for applications such as autonomous systems, surveillance, and personal robotics. This project is also expected to contribute to education through course development, student projects, workshops, and tutorials involving a broader audience as well as using popular online media (e.g., YouTube) and interactive web demos to involve young children."
"1318343","III: Small: Extending and Automating Dynamic Specialization of Database Management Systems","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/29/2013","Richard Snodgrass","AZ","University of Arizona","Standard Grant","Frank Olken","08/31/2016","$496,830.00","Saumya Debray","rts@cs.arizona.edu","888 N Euclid Ave","TUCSON","AZ","857210001","5206266000","CSE","7364","7923, 7364","$0.00","Database management systems (DBMSs) are ubiquitous in industry and their performance and functionality are crucially important in commercial IT infrastructure. There has been a lot of work on improving the performance of these critical systems. This project adopts a complementary and orthogonal approach to substantially increasing the performance of DBMSs. This is done by exploiting runtime information about the DBMS to specialize the DBMS code on the fly in order to eliminate as much unnecessary work as possible. This dynamic code optimization, which we term ""micro-specialization"", is highly aggressive and goes well beyond what can be achieved using existing compiler optimization technology. This focus on runtime code optimization is also very different from most of the current research on DBMS performance improvement. The project investigates algorithms for automatic identification of code sequences where micro-specialization may profitably be applied; algorithms that can micro-specialize such identified target code sequences; and techniques for ensuring the correctness of the resulting code. Preliminary studies on disparate DBMSes suggest that micro-specialization offers significant performance improvements when applied to mature, high-performance DBMSs and to industry-standard benchmarks, and that there are rich opportunities for other substantial performance gains, with minimal impact on the DBMS architecture.<br/><br/>Broader impacts of this project include increased efficiency of the IT infrastructure used by a wide variety of companies, leading to improved overall productivity. Graduate and undergraduate students are involved in all aspects of the research activities as an integral part of the project. The PIs have an established track record of integrating research activities into the undergraduate curriculum and involving undergraduates, including women and members of underrepresented minorities, in research; this project continues this tradition.<br/><br/>For further information see the web site at http://www.cs.arizona.edu/projects/microspecialization/ ."
"0953330","CAREER: Machine Learning and Event Detection for the Public Good","IIS","INFO INTEGRATION & INFORMATICS, SCIENCE OF SCIENCE POLICY","07/01/2010","03/31/2010","Daniel Neill","PA","Carnegie-Mellon University","Standard Grant","Maria Zemankova","06/30/2015","$529,962.00","","neill@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7364, 7626","0000, 1045, 1187, 7364, 7626, 9215, HPCC, OTHR","$0.00","The goal of this research is to create and explore novel methods for detection of emerging events in massive, complex real-world datasets. The approach consists of new algorithms to efficiently and exactly find the most anomalous subsets of a large, high-dimensional dataset, as well as methodological advances to incorporate incremental model learning from user feedback into event detection, incorporate society-scale data from emerging, transformative technologies such as cellular phones and user-generated web content, and augment event detection by creating methods and tools for event characterization, explanation, visualization, investigation and response. <br/><br/>The experimental research is integrated with a multi-pronged educational initiative to incorporate machine learning into the public policy curriculum through development of courses and seminars, workshops in machine learning and policy research and education, and establishment of a new Joint Ph.D. Program in Machine Learning and Policy. The results of this project will be incorporated into deployed event surveillance systems and applied to the public health, law enforcement, and health care domains, enabling more timely and accurate detection of emerging outbreaks of disease, prediction of emerging hot-spots of violent crime, and identification of anomalous patterns of patient care. Project results, including publications, software, and datasets, will be disseminated via project web site (http://www.cs.cmu.edu/~neill/CAREER)."
"0964562","RI: Medium: Collaborative Research: Recognition of Materials","IIS","ROBUST INTELLIGENCE","07/01/2010","07/15/2013","Srinivasa Narasimhan","PA","Carnegie-Mellon University","Continuing grant","Kenneth C. Whang","06/30/2015","$406,581.00","","srinivas@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7924, 9251","$0.00","We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.<br/><br/>The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums."
"0964100","HCC: Medium: Collaborative Research: Surface Haptics via Tractive Forces","IIS","Cyber-Human Systems","07/01/2010","05/07/2013","Roberta Klatzky","PA","Carnegie-Mellon University","Continuing grant","Ephraim P. Glinert","06/30/2015","$234,838.00","","klatzky@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","7924, 9215, HPCC","$0.00","Surface Haptics, or the creation of virtual haptic effects on physical surfaces, is a topic of rapidly growing importance in human?]computer interaction because of the increasingly widespread use of touch screens. Touch is at once an elegant and maddening interface modality. It is elegant in its simplicity: one can make a selection or tap a button or key with no intervening mouse or joystick. Moreover, touch (especially multi?]finger touch) supports gestures, such as swiping and expanding, which are satisfyingly natural. It is maddening, however, due to the lack of tactile and kinesthetic feedback that are so critical to natural touch. Typing on a virtual keyboard, for instance, is typically an experience of visually guided hunt?]and?]peck with liberal use of the back?]space key.<br/><br/>In this research the PIs will further develop a new class of surface haptic devices, called xPaDs, that promise to enrich the use of touch screen and touchpad interfaces for sighted as well as blind users. xPaDs are notable because they provide controllable shear forces between the fingertips and an ordinary sheet of glass. By controlling shear force in response to a measure of fingertip position (which may be obtained using a variety of existing technologies), it is possible to simulate a huge array of virtual effects; examples include toggle switches that flip from one state to another (each state is a ""potential well"" on the glass surface that pulls the finger to a given location), and contours that can be easily traced.<br/><br/>The heart of the current project lies in the systems engineering that will lead to practical and effective devices capable of controlling a force at one or more fingertips, and in the psychophysical and application?]based studies that will teach us how these capabilities may best be used. xPaDs are sophisticated dynamic systems that employ ultrasonic vibrations to modulate friction synchronized with in?]plane vibrations to produce controllable force vectors. The PIs will address the challenges of controlling force individually at each fingertip, of producing xPaDs with large surface area, and of minimizing energy consumption and audible noise generation. They will use the idea and methodology of ""pop?]out"" experiments to find haptic primitives, that is to say features the human perceptual system can extract with minimal or no perceptual load. The PIs will measure the information transmission capacity of surface haptic devices treated as symbolic channels. And they will explore the ability of the perceptual system to ""bind"" surface haptic features presented to different fingertips into a meaningful, coherent whole. These studies will position the PIs for investigating a set of applications for the blind.<br/><br/>Broader Impacts: Computer interfaces for the blind often rely heavily on speech, which necessarily presents information serially. The PIs argue that a haptic surface can augment a speech?]based interface with critical spatial information. They will study the editing and reading of mathematical expressions, of locating key content on a web page, of navigating intersections, and of planning routes with tools such as Google Maps. In addition, the PIs will develop a low?]cost xPaD development kit, make the plans and code available on the Internet, and develop a high school enrichment unit based upon these materials."
"0911032","III: Large: Discovering Complex Anomalous Patterns","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2009","09/06/2011","Artur Dubrawski","PA","Carnegie-Mellon University","Continuing grant","Frank Olken","08/31/2014","$2,598,153.00","Gregory Cooper, Gilles Clermont, Jeff Schneider, Daniel Neill","awd@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1640, 7364","7364, 7925, 9216, HPCC","$0.00","Many of the most interesting and valuable discoveries that can be made from data arise not from the evaluation of single records, but from identifying a set of records that are anomalous in some interesting way. Together they may indicate for example the emergence of a disease outbreak or new patterns of criminal activity. One can view pattern discovery as an interactive process between data analysis algorithms and human users who have expertise in the domain. This research will develop an integrated framework of probabilistic methods to interact with the user in detecting, characterizing, explaining, and learning anomalous patterns over groups of records. The focus is on the many situations where the data (and the probabilistic patterns to be discovered) are not appropriate for using other existing techniques, such as graph mining or frequent sets. The proposed methods will search over arbitrary subsets of records and evaluate their correspondence to known, potentially very complex, probabilistic patterns, or their failure to match baseline data under various learned statistical models. These methods will assist the user in understanding and modeling the discovered, previously unknown anomalies to be identi&#64257;able as a known pattern when encountered in the future. <br/><br/>Intellectual Merit<br/>This collaborative team of researchers will develop, implement, and evaluate a general, comprehensive, and widely applicable probabilistic framework for pattern discovery. The proposed work will address these challenging and important research questions: <br/> - How can machine learning concepts such as classi&#64257;cation and anomaly detection be generalized to consider groups of records rather than single records?<br/> - How can a detection algorithm simultaneously detect and differentiate between known and currently unknown pattern types?<br/> - How can an algorithm explain clearly to a user what pattern was found and why?<br/> - How can an algorithm learn new pattern types through feedback from a user?<br/><br/>The ability to detect, characterize, explain, and learn patterns from groups of records in massive datasets will provide a qualitatively new approach for advancing discovery of knowledge from data. <br/><br/>Broader Impact<br/>Although the applications for these algorithms are innumerable, development and testing will be prioritized in the areas of patient care in the intensive care unit (ICU) and aircraft &#64258;eet maintenance. Through the team's existing collaborations, the algorithms will also be used during the project in other areas including food safety, scientific discovery in astronomy sky surveys, and detection of geographic hot-spots of criminal activity. Together, these applications will demonstrate the methods' value across a wide spectrum of domains and tasks. <br/><br/>Key Words: anomalous patterns; pattern discovery; probabilistic models; incremental learning."
"1116843","RI: Small: Collaborative Research: Learning to perform consistently in human/multi-robot teams","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","08/01/2011","05/02/2013","Elizabeth Sklar","NY","CUNY Brooklyn College","Standard Grant","James Donlon","07/31/2015","$322,374.00","Simon Parsons","sklar@sci.brooklyn.cuny.edu","Office of Research & Sponsored P","Brooklyn","NY","112102889","7189515622","CSE","7298, 7495","5946, 5979, 7298, 7495, 7923, 9251","$0.00","This project focuses on practical deployment of human/multi-robot teams in situations where robots can explore regions that are unsuitable for humans. For example, a team of ""rescue"" robots can sweep through a collapsed building searching for victims and transmit their positions to human first-responders outside. Managing a human/multi-robot team in a dynamic environment is a challenging problem. Not only is the world mutable, but also the team can experience altered membership because a robot gets lost or a human operator needs rest---the world is changing, and so is the team that is exploring that world.<br/><br/>The goal of this research is to develop strategies for human/multi-robot teams to learn to perform consistently and effectively. Three primary aims will be pursued: first, to mitigate changes in team composition via a practical framework for institutional memory that remembers and uses past experiences; second, to model and record expertise for later use by learning behaviors performed by a human operator; and third, to distribute tasks among team members efficiently by providing a balanced mechanism for social choice. The novel approach of this project is applicable to a broad spectrum of human/multi-robot, and human/multi-agent teams, by integrating institutional memory, learning from human teammates, and resolving conflict among differing perspectives. The strategies will be evaluated using a human/multi-robot testbed comprised of one human operator plus a heterogeneous set of inexpensive, limited-function robots. Although each individual robot has restricted mobility and sensing capabilities, together the team members constitute a multi-function, human/multi-robot facility.<br/><br/>This project addresses important challenges in robust intelligence, including behavior modeling, learning from experience, making coordinated decisions, and reasoning under uncertainty. Expected outcomes include strategies for human/multi-robot teams that learn to collaborate effectively under a variety of conditions and can maintain their performance despite run-time changes in team membership, as well as knowledge about how people interact with robot teams. Broader impacts include providing access to a networked experimental testbed for remote collaborators; publishing proven curricular materials on multi-robot teams addressed to graduate, undergraduate and high school students; involving undergraduates in research activities; and working with existing contacts at local museums to demonstrate results to the general public."
"1116631","RI: Small: Collaborative Research: Visual Attributes for Identification and Search in Images","IIS","ROBUST INTELLIGENCE","07/01/2011","06/30/2011","David Jacobs","MD","University of Maryland College Park","Standard Grant","Jie Yang","06/30/2015","$250,000.00","","djacobs@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7923","$0.00","The automatic identification in images of people, places, objects, and especially object categories is a central and ongoing challenge within computer vision. This project addresses this problem using low-level image features to learn intermediate representations, ones in which objects in images are labeled with an extensive list of highly descriptive visual attributes. This work demonstrates this approach in three domains: faces, plant species, and architecture. In each domain, it develops techniques for deriving visual attribute vocabularies, training attribute detectors, and building compositional models to automatically label attributes in images.<br/><br/>The project is making four fundamental contributions to the use of visual attributes. 1) It is developing new methods by which automatic systems and humans can interact to select domain-appropriate attribute vocabularies and label large image collections. 2) It is developing compositional models that capture dependencies between attributes. This provides more accurate attribute detection and enables inference of global properties of objects. 3) Using compositional models, the project is developing new, localizable attributes that capture the geometric relations between object parts and landmarks. 4) The project is designing algorithms that combine attributes to identify objects, search through image vast collections, and automatically annotate image databases.<br/><br/>Not only is this research generating large datasets of labeled images that should help catalyze new research, it is also demonstrating the feasibility of new systems for analyzing images in specialized domains such as faces, plants, and architecture. For example, the project develops new software applications for analyzing and searching images of faces as well as free mobile apps for plant species identification."
"1147097","Recognition of Occluded Objects as Statistical Inference: A Neurophysiological Study in Awake, Behaving Monkeys","IOS","ROBUST INTELLIGENCE, ACTIVATION","03/15/2012","01/17/2014","Jay Hegde","GA","Georgia Regents Research Institute, Inc.","Continuing grant","David Coppola","02/29/2016","$592,209.00","","jhegde@gru.edu","1120 Fifteenth Street","Augusta","GA","309120004","7067212592","BIO","7495, 7713","1096","$0.00","In the real world, visual objects commonly block, or occlude, each other from view. Very little is known about how the brain makes up for the missing information about an occluded object and recognizes it nonetheless. This project will help elucidate the mechanisms by which the brain recognizes occluded objects using neurophysiological methods and will determine what individual cells in the relevant brain regions do when the brain recognizes an occluded object. The study will also help characterize which tell-tale features in the visible portions of an occluded object the brain uses for this purpose, and how it uses them. For example, someone's eyes may serve as a dead give-away for them, thus the brain may use this information about the eyes to recognize that person, even when the rest of the face is occluded. Given the ubiquity of occluded objects in the real world, understanding how one perceives occluded objects is critical to understanding, in a larger sense, how the brain works. This research will also facilitate the development of better machine-vision tools, so as to help computers better recognize objects of interest in the real world.<br/><br/>This project also has a significant educational component. For example, classroom courses and hands-on research experience opportunities will not only impart scientific knowledge, but also help students develop an active interest in pursuing careers in science and technology. Undergraduates and graduate students from the Investigator's institution as well as from many other local colleges and universities will participate in this project, providing additional opportunities for students. The results, resources, and tools generated by this project will be made publically available on the Investigator's website at http://www.georgiahealth.edu/medicine/discovery/bbdi/hegde."
"1350522","CAREER: Machine Learning for Complex Health Data Analytics","IIS","INFO INTEGRATION & INFORMATICS","09/01/2014","05/28/2014","Benjamin Marlin","MA","University of Massachusetts Amherst","Continuing grant","Sylvia J. Spengler","08/31/2019","$102,685.00","","marlin@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","1045, 7364","$0.00","The fields of health and behavioral science are currently undergoing a data revolution. The Health Information Technology for Economic and Clinical Health act of 2009 has resulted in the wide adoption of electronic health records and the emergence of increasingly vast stores of heterogeneous clinical data. Simultaneously, emerging mobile health (mHealth) technologies are enabling the collection of ever-larger volumes of continuous physiological measurements and behavioral self-report data in non-clinical settings. Such data sources have the potential to yield transformative advances in the fundamental understanding of human behavior and health. They also have the potential to significantly enhance numerous applications including data-driven clinical decision support and continuous health monitoring, which will lead to increased efficiency within the healthcare system and facilitate a transition to patient-centered, personalized care. The proposed work will address several fundamental sources of complexity in the analysis of both clinical and mHealth data, enabling researchers in health and behavioral science to extract more useful knowledge from these data sources. The software toolboxes that will be developed will have immediate applications in research conducted by a network of research partners, and will also be broadly disseminated. The integrated education plan includes the development of an innovative applied machine learning course that will provide training in topics like cloud-scale computing that are of direct relevance to massive health data analytics. The outreach plan involves developing and running a health data-themed outreach workshop for underrepresented groups to foster computational thinking and broaden participation in computing. <br/><br/>The ability to learn models from complex data and apply those models to extract useful knowledge is at the core of machine learning research. This proposal seeks to significantly expand the frontiers of machine learning by developing new models and algorithms designed to meet the challenges posed by complex health data analysis. Key sources of complexity in clinical and mHealth data include sparse and irregular sampling, incompleteness, noise, non-stationary temporal dynamics, between-subjects variability, high volume, high velocity and heterogeneity. The presence of one or more of these factors in a given data source is often sufficient to render current machine learning methods ineffective or completely inapplicable. The long-term goal of this research is the development and validation of customized machine learning models and algorithms that can respond to all of these challenges. The objective of this proposal is to develop models and algorithms that address the following specific problems: (1) How can we extract useful knowledge from sparse and irregularly sampled clinical time series data? (2) How can we automate feature discovery from wearable physiological sensor data in the presence of high levels of noise, significant between subjects variability, and heterogeneous sensing modalities? (3) How can we make the learning of physiological time series event detection algorithms robust to event labels that are obtained through self-report mechanisms with limited reliability and temporal fidelity?"
"1150068","CAREER: Time-Aware Heuristic Search","IIS","ROBUST INTELLIGENCE","06/01/2012","05/27/2014","Wheeler Ruml","NH","University of New Hampshire","Continuing grant","James Donlon","05/31/2017","$332,610.00","","ruml@cs.unh.edu","51 COLLEGE RD SERVICE BLDG 107","Durham","NH","038243585","6038622001","CSE","7495","1045, 9150","$0.00","Planning is a useful capability -- for instance, it enables robots to be autonomous and it helps people save money and conserve natural resources. Traditional planning methods search for perfect plans; this often requires exponential time and therefore takes too long for many problems. It is often better to promptly take a reasonable but possibly suboptimal action than it is to deliberate long enough to guarantee an 'optimal' plan. This project develops new methods for time-aware search and planning, along with an on-line handbook to help those who use search techniques choose an appropriate method.<br/><br/>This project focuses on developing algorithms for time-aware search in four different settings. (1) In utility-based search, the algorithm optimizes a user-specified combination of planning time and plan execution time. This captures the situation in which one wishes to achieve a goal as soon as possible (e.g., minimize the sum of planning time and plan execution time). (2) In incremental search, actions can be selected and begin to be executed while planning continues. This allows the algorithm to benefit from early execution if a good first action is apparent, but deliberate carefully if the selection of the first action appears crucial. (3) In on-line continual search, new goals can arrive asynchronously during execution. This requires the algorithm to determine if it is worthwhile to re-plan from scratch or whether simple additions to the existing plan will suffice. (4) In search under a deadline, a complete plan must be found within a given bound on search time. This is the objective in many applications.<br/><br/>This project also involves the creation and curation of an online Handbook of Search Algorithms. It will provide a comprehensive taxonomy of planning and optimization problem settings, together with the most appropriate algorithms that have been proposed for each setting. The handbook will integrate on-going research and educational activities of the PI. It will accelerate the uptake of academic research on heuristic search and draw attention to compelling settings that have traditionally received less attention, such as time-aware planning. The creation and curation of the handbook will be a long-term collaboration between the PI, students in a yearly seminar course taught by the PI, and students in the PI's research group. For graduate and advanced undergraduate students, authoring the handbook immerses them in research, while promoting fundamental skills in literature review, scientific writing, and empirical methodology."
"1442079","Workshop:The International Linguistics Olympiad","BCS","LINGUISTICS, ROBUST INTELLIGENCE","06/01/2014","05/27/2014","James Pustejovsky","MA","Brandeis University","Standard Grant","William J. Badecker","02/28/2015","$15,000.00","","jamesp@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","SBE","1311, 7495","1311, 7495, 7556, SMET","$0.00","Attracting and training new students in linguistics is essential to meeting the nation's needs for research in language and communication. This award will provide travel support for two teams of American high school students to participate in the 12th International Linguistics Olympiad, which will take place in Beijing, China, in July, 2014. More than 100 of the world's brightest and most motivated high school students will gather for the Linguistics Olympiad. The American teams, each comprised of four students, were top finishers in the 8th North American Computational Linguistics Olympiad (NACLO), held in January and March, 2014.<br/><br/>The International Linguistics Olympiad provides students with a hands-on experience of the scientific approach to linguistics and the documentation and analysis of language. Unlike math and science Olympiads, which focus on material that students have already mastered, linguistics Olympiads introduce new material through logic puzzles in languages unfamiliar to the students. In the course of solving a puzzle, the students can discover something about the grammar or sounds of a language, its conceptual system, its associated culture, or its historical relationship to other languages. In addition to fostering insight into human linguistic and cultural diversity, this competition fosters meta-linguistic reasoning that is essential for computer science, language technologies, and indeed any career involving analytical problem-solving skills and the ability to present a logical argument supported by data. Because it has been the tradition of linguistics Olympiads to base half of the score on the written explanation of the answer, the contests also encourage the ability to clearly present a hypothesis and explain how it is supported by the data."
"1218544","HCC: Small: Socio-technical Issues in Mobile Time Banking","IIS","Cyber-Human Systems","08/15/2012","04/15/2014","John Carroll","PA","Pennsylvania State Univ University Park","Continuing grant","William Bainbridge","07/31/2015","$529,553.00","","jcarroll@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7923, 9251","$0.00","Time banking refers to community-based volunteering in which participants provide and receive services; for example, one neighbor might be a competent handyman, another has a heavy-duty pickup truck. Each can provide community service doing what he/she can do for other members. For this, they receive time credits that can be exchanged for other services, say, gardening. A community brokering entity, a time bank, keeps track of time credits earned and redeemed. Time banks have pervasive implications for conceptions of work, citizenship, volunteering, community engagement, and social inclusion. Time banking has spread rapidly in recent years throughout the world.<br/><br/>Current time banking focuses on asynchronous transactions. This project will incorporate mobile computing and Web 2.0 services to carry out a design research investigation of mobile time banking. The work will support finer grain, near-real time scheduling of neighborhood service exchanges. This approach allows many new time banking possibilities. For example, a child comes home from school with a headache. His mother posts a request, and a neighbor who is stopping at the local drug store anyway gets the aspirin.<br/><br/>Broader impacts: This project will fundamentally extend the concept of time banking, and support for time banking throughout the world, by directly extending current time banking infrastructures. It can provide domestic and community infrastructure to ease the busyness stresses of too many to-dos, while enhancing quality of life through improved health and sense of community. It can increase the visibility and valuing of informal quasi-work activities that are often devalued in money-based economies, and facilitate the transition from volunteer activity to paid work, a key policy strategy for reducing chronic unemployment. This project integrates education, research, and community service for student participants. The PIs will work with campus programs to ensure that a diversity of students is aware of our work."
"1248047","EAGER: Collaborative Research: Towards Modeling Human Speech Confusions in Noise","IIS","ROBUST INTELLIGENCE","08/01/2012","08/08/2012","Nelson Morgan","CA","International Computer Science Institute","Standard Grant","Tatiana D. Korelsky","07/31/2015","$100,000.00","","morgan@icsi.berkeley.edu","1947 CENTER ST STE 600","BERKELEY","CA","947044115","5106662900","CSE","7495","7495, 7916","$0.00","This EArly-concept Grant for Exploratory Research (EAGER) supports an exploratory study to evaluate model components for prediction of human speech recognition in the presence of noise. Such a model has the potential to predict confusions between fine phonetic distinctions in different levels of background noise and at different speaking rates. The study takes advantage of modern physiological results that indicate that the primary auditory cortex performs spectro-temporal filtering; that is, that there are cells that are sensitive to particular spectro-temporal modulations at each auditory frequency. In this project, perceptual experiments in the presence of both stationary and non-stationary additive noise and at different signal-to-noise ratios for a database of CVC syllables recorded at 2 different speaking rates yield confusion statistics. These statistics are then compared to those resulting from an auditory model enhanced by elements incorporating these spectro-temporal filters. <br/><br/>Successful results from this study will suggest enhancements to current hearing models and ultimately, after a broader study for which this EAGER is a pilot, advance the understanding of human speech perception. Background noise presents a challenging problem for a variety of speech and hearing devices including hearing aids and automatic speech recognition (ASR) systems. Since normal-hearing human listeners are extremely adept at perceiving speech in noise, this improved understanding of human models could lead to better artificial systems for speech processing. The databases and tools developed for this study will be disseminated to the research community."
"1361549","HCC: Medium: Collaborative Research: Neural Control of Powered Artificial Legs","IIS","Cyber-Human Systems","06/30/2013","05/27/2014","He Huang","NC","North Carolina State University","Continuing grant","Ephraim P. Glinert","05/31/2017","$288,632.00","","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","7367, 7924","$0.00","Recent breakthroughs in the mechatronics of powered lower limb (LL) prostheses hold the promise of enabling restoration for the large and growing population of lower limb amputees of a broad spectrum of functionality (e.g., standing up when seated in a chair, climbing stairs, and even running). The PIs argue that to realize this potential it is essential to provide neural control of artificial legs. The application of existing upper limb (UL) neural control approaches is inappropriate to this end, because the UL and LL neural control mechanisms are significantly different. In particular, most activities involving the lower limbs recruit both involuntary (spinal cord) and voluntary (supra-spinal) neural control, present high dynamics, and require multi-joint coordination and control of unstable locomotion, characteristics which combine to make the design specifications for neural control of LL prostheses much more demanding than those for UL devices. In this project the PIs will address this challenge by developing an innovative neural control system for powered artificial legs that can recognize and exploit multi-scale user intent (e.g., general motor commands such as intended task vs. detailed motor commands such as intended joint motion) to modulate intrinsic (autonomous) control of multiple LL prosthetic joints for locomotor and nonlocomotor task performance. The goals are to support reverse-engineering of the neural control of human locomotion while creating innovative neural-machine interfacing (NMI) technology that enables users to control the dynamics of LL prostheses in a natural, adaptive and flexible way. Inspired by what is currently known about the neurological organization and function of the human motor control system, the PIs' approach is to design a novel NMI based on a combination of noninvasive scalp electroencephalography (EEG) and surface electromyography (EMG). The hypothesis is that fusion of low-level peripheral and high-level central neural control sources can achieve multi-scale user intent recognition with higher accuracy and more rapid response time than can be realized with either EEG or EMG alone. A hierarchical control scheme for powered LL prostheses, in which multi-scale user intent identified by the NMI modulates intrinsic (autonomous) control, will support intuitive and efficient prosthesis use in dynamic, multi-joint coordinated movements while significantly reducing the mental burden of the prosthesis user in locomotion because the cyclic motion is achieved autonomously (this is desired because we rarely think about knee and ankle control when walking). The PIs will also explore correlation across EEG and EMG signals, which may provide insight into neural adaption and the time course of cortical control during the initiation and generation of gait, including how the brain initiates walking and regulates motor output in anticipation of key events such as foot placement at landing or during stepping up and down, weight acceptance, and push-off into swing phase. Finally, the PIs will use translational research to validate their novel approach in patients with trans-femoral amputations (a high and challenging amputation level).<br/><br/>Broader Impacts: The PIs' long-term objective is to develop true bionic prostheses that feel and work just like real legs. Their approach in this project represents a paradigm shift in the control of lower limb wearable prosthetics. As such, project outcomes will directly impact both the Human-Robot Interaction and Brain-Machine Interface research communities. The findings will also be relevant to the neuroscience and rehabilitation communities, in that they will help elucidate the adaptive spinal cord and cortical contributions to human locomotion, while providing innovative and functional neuro-prosthetics solutions to improve the lives of lower limb amputees."
"1320260","RI: Small: Collaborative Research: Towards Modeling Source Separation from Measured Cortical Responses","IIS","ROBUST INTELLIGENCE","09/15/2013","09/08/2013","Nelson Morgan","CA","International Computer Science Institute","Standard Grant","Kenneth C. Whang","08/31/2015","$269,993.00","Daniel Ellis","morgan@icsi.berkeley.edu","1947 CENTER ST STE 600","BERKELEY","CA","947044115","5106662900","CSE","7495","7495, 7923","$0.00","This project will use new technologies for measuring brain activity to understand in detail how human listeners are able to separate competing, overlapping voices, and thereby to help design automatic systems capable of the same feat. Natural environments are full of overlapping sounds, and successful audio processing by both humans and machines relies on a fundamental ability to separate out sound sources of interest. This is commonly referred to as the ""cocktail party effect,"" based on the ability of people to hear what a single person is saying despite the noisy background audio from other speakers. Despite the long history of research in hearing, this exceptional human capability for sound source separation is still poorly understood, and efforts to automatically separate overlapping voices by machine are correspondingly crude: although great advances have been made in robust processing of noisy speech by machine, separation of complex natural sounds (such as overlapping voices) remains a challenge. Advances in sensor technology now enable the modeling of this function in humans, giving an unprecedented, detailed view of sound representation processing in the brain. This project works specifically with measurements of neuroelectric response made directly on the surface of the human cortex (currently with a 256-electrode sensor array) for patients awaiting neurosurgery. Using such measurements made for controlled mixtures of voices, the project will endeavor to both develop models of voice separation in the human cortex by reconstructing an approximation to the acoustic stimulus from the neural population response, and in the process learning the linear mapping between the neural response back to a spectrogram measure of the stimulus. To attempt to significantly improve the ability of machine algorithms to mimic human source separation capability, the project will also focus on a signal processing framework that supports experiments with different combinations of cues and strategies to optimize agreement with the recordings of neural activity. The engineering model is based on the Computational Auditory Scene Analysis (CASA) framework, a family of approaches that have shown competitive results for handling sound mixtures."
"1149530","CAREER: Advancing Innovation in Bio-Design through Reality-Based Interaction","IIS","Cyber-Human Systems","02/01/2012","02/11/2014","Orit Shaer","MA","Wellesley College","Continuing grant","Ephraim P. Glinert","01/31/2017","$312,984.00","","oshaer@wellesley.edu","106 Central Street","Wellesley","MA","024818204","7812832079","CSE","7367","1045, 7367","$0.00","In recent years, research in human-computer interaction (HCI) has generated a broad range of interaction styles that move beyond the desktop into new physical and social contexts. Key areas of innovation in this respect are tabletop, tangible, and multi-touch user interfaces. These interaction styles leverage users' existing knowledge and skills of interaction with the real, non-digital world; thus, they are often referred to as reality-based interfaces. Such interfaces offer a natural, intuitive, and often collaborative form of interaction that reduces the mental effort required to learn and operate a computational system. While these advances in HCI have been successfully applied to a broad range of application domains, little research has been devoted to investigating reality-based interaction in the context of scientific discovery. The PI argues that it is particularly important to study reality-based interaction in this context, where reducing users' mental workloads and supporting collaborative work could potentially lead to exciting scientific advances. For example, in a preliminary study of the workflow and computational tools employed by synthetic biologists, the PI found that members of this research community often experience difficulties in specifying, comparing, documenting, and sharing information - interactions that have previously been shown as critical for scientific discovery. She further observed that the limitations of current computational tools pose barriers for collaboration, information flow, and exploration. This lack of appropriate computational tools coupled with the inherent complexity of biological systems has limited progress to date, despite the enormous potential of synthetic biology to solve problems such as low-cost drug development and alternative energy production. In this project, the PI will investigate how reality based interfaces may be able to advance innovation in biological design. To address this question, she will develop and evaluate a suite of reality-based interfaces that support the design and assembly of novel biological systems, and which she expects will promote collaborative, effective, and safe workflow, facilitate exploration of alternative solutions, and reduce the mental workload associated with accessing and relating large amounts of information.<br/><br/>Broader Impacts: Project outcomes will include: design, implementation, and evaluation of a suite of reality-based interfaces for synthetic biologists; a set of design requirements for developing future such systems; a methodology for evaluating the efficacy of computer-supported cooperative work of scientists; novel techniques for fluid interaction with heterogeneous computational devices of different scale; and a set of design considerations and a participatory design process for supporting scientific discovery. The PI will train three female undergraduate researchers per year, who will be an integral part of her research team and will participate in an international science competition. The project will impact computing and science courses at the PI's institution (a women's college) and at collaborating institutions. In addition, this research will serve as a highly visible ""magnet"" project that attracts undergraduate and high-school students' attention to computer science research through outreach activities."
"1064852","HCC: Medium: Social Search and Deliberation in Digital Political Information and Collaboration Domains","IIS","Cyber-Human Systems","08/15/2011","05/23/2014","Scott Robertson","HI","University of Hawaii","Continuing grant","William Bainbridge","07/31/2015","$977,537.00","","scott.robertson@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","CSE","7367","7367, 7924, 9150, 9251","$0.00","Participation in political debate and deliberation is critical to democracy. Browsing political material is a direct way of acquiring knowledge about civic activities, the operations of government, and the issues of the day. This project examines a fast growing, but little understood new type of political participation: online information seeking, deliberation and decision making in the context of Web 2.0 technologies. The research includes three intertwined threads of study: (a) user-centered design of enhancements to a search/browse tool and a cross-application, user-generated interlinkage browser; (b) laboratory studies of how potential voters browse and make decisions in social computing environments; and (c) longitudinal observation of users of novel, socially-enabled political search/browse tools through at least three U.S. election cycles.<br/><br/>Intellectual Merit: The central research question is how exposure to and participation in social networking activities influences information seeking and decision making in politics. An important practical outcome will be search/browse tools for civic participation and political discourse that are integrated with the social networking environments that many people now use every day. The research will contribute to theories of deliberation in the domain of digital politics and to the design of tools for exposing and navigating the structure of online political dialog.<br/><br/>Broader Impacts: Tools and theory developed from this project will provide contexts that broaden opportunities for participation in civic life in the 21st century, thereby helping to bridge the digital divide. The work will also benefit education through the training of graduate students and post-doctoral researchers."
"1444258","RSS 2014 Workshop on Women in Robotics","IIS","ROBUST INTELLIGENCE","06/01/2014","05/23/2014","Andrea Thomaz","GA","Georgia Tech Research Corporation","Standard Grant","Satyandra Gupta","05/31/2015","$10,000.00","","athomaz@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7556, 8086","$0.00","Robotics is undergoing growth in recent years, over a wide range of important areas, from transportation, to manufacturing, entertainment, space exploration, health-care and education. While the field is progressing forward, both in research findings and industrial markets, the percentage of female roboticists continues to lag far behind their male counterparts. This award supports travel for ten women robotics researchers to the workshop ""Women in Robotics"" being held at the Robot Science and Systems (RSS) 2014 conference. This opportunity is expected to have a significant effect towards helping them start their career and establish themselves as young robotics researchers. The workshop plan includes: (1) a full-day of invited talks by women leaders in the field from both academia and industry, demonstrating that women can and do play an important role in the field, (2) a poster session featuring works by junior researchers, giving them exposure in the community, (3) a panel discussion on the topic of ""steps towards building a successful career in robotics,"" featuring women at various stages of their careers, and (4) a networking dinner to provide time for junior and senior participants have a chance to make real one-on-one connections. Bringing together women from various disciplines in robotics is expected to strengthen the community and provides an important opportunity for networking."
"0905417","HCC: Medium: Collaborative Research: Generating Effective Dynamic Explanations in Augmented Reality","IIS","Cyber-Human Systems","09/01/2009","08/01/2012","Barbara Tversky","NY","Teachers College, Columbia University","Continuing grant","William Bainbridge","08/31/2015","$396,404.00","","btversky@stanford.edu","525 West 120th Street","New York","NY","100276625","2126783000","CSE","7367","7367, 7924, 9215, HPCC","$0.00","To survive and flourish, people must interact with their environment in an organized fashion. To do so, they need to learn, imagine, and perform an assortment of transformations on and in the world. Primary among these are manipulation of objects and navigation in space. This project integrates research in computer science and cognitive science to develop and evaluate augmented reality tools to create effective dynamic explanations that enhance manipulation and navigation, in conjunction with identification and visualization. Augmented reality refers to user interfaces in which virtual material is integrated with and overlaid on the user?s experience of the real world; for example, by using tracked head-worn and hand-held displays. Dynamic explanations are task-appropriate sequences of actions, presented interactively, with appropriate added information. The tools will be created in collaboration with subject matter experts for exploratory use in indoor and outdoor real world domains: navigating and identifying landmarks in a wooded park area, assembling a piece of furniture, and navigating and visualizing for planning the site of a new urban campus. Cognitive science research will determine the best ways to convey explanations and information to people. Computer science research will address the design and implementation of systems that embody the best candidate approaches for identifying objects and locations, specifying actions, and adding non-visible information. In situ experiments will be used to assess and refine the systems. <br/><br/>Manipulation, navigation, identification, and visualization are representative of important things that people do every day, ranging from fixing broken equipment to reaching a desired destination in an unfamiliar environment. The ways in which we perform these tasks could potentially be improved significantly through augmented reality systems designed using the principles to be developed by this project. Both the cognitive principles and the augmented reality tools will have broad applicability. The systems developed will inform the design of future systems that can aid the general public, for educational and recreational ends, as well as systems that can assist people with auditory, visual, or physical impairments."
"1320959","CGV: Small: Digital Forensic Facial Reconstruction from Incomplete Datasets","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","08/15/2013","05/23/2014","Xin Li","LA","Louisiana State University & Agricultural and Mechanical College","Standard Grant","Jie Yang","07/31/2016","$463,611.00","Warren Waggenspack, Mary Manhein","xinli@lsu.edu","202 Himes Hall","Baton Rouge","LA","708032701","2255782760","CSE","7453, 7495","7453, 7923, 9251, 9150","$0.00","In forensic investigations, the skeletal evidence analysis and facial reconstruction play important roles in identification of the decedent. In current practice, effective skull processing and facial reconstruction are accomplished manually. This project studies 3D geometric analysis and modeling algorithms to automate and augment fragmented/incomplete skull restoration and craniofacial reconstruction and advocates a potential evolution of manual processing to a digital platform for better efficiency, robustness, and objectivity. Two key challenging problems to solve in these forensic tasks are geometric restoration (from small fragmented pieces) and geometric shape synthesis (with complex geometric and semantic constraints). This project studies effective 3D shape matching and transformation techniques to tackle these problems. Geometric restoration is solved through reliable partial matching and symmetry guidance; geometric synthesis is explored via heterogeneous volumetric deformation that enforces given geometric constraints on non-uniform interior layers. <br/><br/>The new geometric algorithms can benefit incomplete data modeling and analysis in many computer graphics and vision tasks. In this project, computer scientists are collaborating with forensic specialists to build a digital computational platform and evaluate the application of these new geometric algorithms in forensic skull processing and craniofacial reconstruction. This project facilitates incomplete data analysis and reconstruction in forensic law enforcement, archaeology, biological anthropology, and craniofacial orthopedics. The research and education are integrated by taking research advances into existing and future courses, involving RET/REU/K-12 students in geometric modeling research and graphics/visualization system development; and attracting K-12 and under-representative students into STEM education."
"1346655","WORKSHOP: Doctoral Consortium for the International Conference on Multimodal Interaction (ICMI 2013)","IIS","Cyber-Human Systems","07/01/2013","07/25/2013","Carlos Busso","TX","University of Texas at Dallas","Standard Grant","Ephraim P. Glinert","06/30/2015","$17,840.00","","busso@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7367","7367, 7556","$0.00","This is funding to support participation by about 6 graduate students from U.S. institutions, along with 5-6 senior members of the ICMI community (faculty and industry researchers, who will receive partial support only), in a Doctoral Consortium (workshop) to be held in conjunction with and immediately preceding the 15th International Conference on Multimodal Interaction (ICMI 2013), which will take place December 9-13, 2013, in Sydney, Australia, and which is organized by the Association for Computing Machinery (ACM). The ICMI conference series is the premier international forum for multidisciplinary research on multimodal human-human and human-computer interaction, interfaces, and system development. The conference focuses on theoretical and empirical foundations, component technologies, and combined multimodal processing techniques that define the field of multimodal interaction analysis, interface design, and system development. Topics of special interest to the conference this year include multimodal interaction processing, interactive systems and applications, modeling human communication patterns, and data, evaluation and standards for multimodal interactive systems. ICMI 2013 will feature a single-track main conference which includes: keynote speakers, technical full and short papers (including oral and poster presentations), special sessions, demonstrations, exhibits and doctoral spotlight papers. The ICMI 2013 proceedings will be published by ACM The ICMI proceedings will be published by ACM Press and included in the ACM Digital Library. As a further incentive for high-quality student participation ICMI will be awarding outstanding paper awards, with a special category for student papers. More information about the conference may be found online at http://www.acm.org/icmi/2013. <br/><br/>The goal of the ICMI Doctoral Consortium is to provide PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers interested in designing multimodal interfaces. Student participants will present their ongoing thesis research as a short talk at the Consortium and also as a poster at the conference Doctoral Spotlight Session. This year, the organizers seek to expand the scope of the Doctoral Consortium to provide more opportunities for interaction between the students and senior members of the field; to this end, the program will also include a lunch on the day of the workshop for students and mentors, a career panel that will provide the students and mentors the opportunity to ask and answer questions and discuss challenges and opportunities in the field, and a dinner that will provide the students with the opportunity to hold informal conversations among themselves as well as with the organizers and mentors. <br/><br/>Broader Impacts: The Doctoral Consortium will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. The organizers will take steps proactively to achieve a diversity of research topics, disciplinary backgrounds, methodological approaches, and home institutions among the students. Priority will be given first to minority students, female students, students from geographically underrepresented states, and finally to students whose advisors or departments have insufficient funds to support their participation in the conference. To further increase diversity no more than two students will be invited from any given U.S. institution of higher learning."
"1217765","CGV: Small: Measurement-based Editing of Reflectance Properties in Photographs","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","08/15/2012","05/22/2014","Pieter Peers","VA","College of William and Mary","Continuing grant","Jie Yang","07/31/2015","$490,498.00","","ppeers@cs.wm.edu","Office of Sponsored Programs","Williamsburg","VA","231878795","7572213966","CSE","7453, 7495","7453, 7923, 9251","$0.00","This project endeavors to answer the fundamental research question whether it is possible to alter the appearance of specific reflectance properties in a photograph of a scene by only partially characterizing the appearance of the scene via measurements. Specifically, the research team investigates novel appearance editing techniques that minimize the modeling effort, while maintaining maximum editing flexibility and at the same time impose minimal restrictions on the scene, while guaranteeing a physically plausible editing result. A common application of appearance modeling is to digitally clone a real-world scene, then change some scene properties, and finally revisualize the scene. Despite the enormous advances in appearance modeling, it still requires significant effort and expertise to create a digital clone of a physical scene. The effort needed to make the desired alterations to the scene often pales in comparison to the required appearance modeling effort. This project focuses on three reflectance phenomena suited for measurement-based editing: translucency, surface albedo, and surface reflectance.<br/><br/>This research program has a far-reaching impact beyond computer graphics. It has the potential to impact product development and pre-visualization, virtual reconstruction of archaeological artifacts, forensics, virtual cosmetics, fine-arts and entertainment, and other applications that require the visualization of an object/subject with altered reflectance conditions. Besides supporting the traditional research roles of graduate students, undergraduate education is enhanced by hands-on research experience and the incorporation of research results into existing courses."
"1353312","EAGER: Understanding Barriers to Workplace Collaboration for People with Visual Impairments","IIS","Cyber-Human Systems","09/15/2013","09/05/2013","Shaun Kane","MD","University of Maryland Baltimore County","Standard Grant","Anthony Hornof","08/31/2015","$164,982.00","","skane@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7367","7367, 7916","$0.00","People with visual impairments face significant barriers to participation in public life and productive contributions in the workplace. Barriers due to inaccessible information and communication technology can make it difficult for a person with visual impairments to excel in school or find employment commensurate with his or her abilities and potential. Fortunately, accessible computing technology enables people with visual impairments to access information that was previously inaccessible. For example, people with visual impairments can use screen reader software to translate electronic documents into speech or Braille. However, barriers still exist in the context of using computers to participate in the contemporary classroom or workplace because these are now places where active, real-time, face-to-face collaboration with other people has become the norm, and because there is a gulf between the look and feel of assistive technology such as screen readers and the look and feel of contemporary graphical user interfaces such as those used routinely by people without disabilities. Screen readers are difficult to learn and use, and operate quite differently than contemporary graphical user interfaces, and most sighted people do not know how to use screen readers, and so the opportunity for shared artifacts in communication and collaboration is reduced.<br/><br/>The focus of this proposal is to explore and identify barriers to collaboration between people with and without visual impairments. This research will support the development of tools that will bridge the gap between the non-graphical user interfaces used by people with visual impairments and the graphical interfaces used by sighted people, enabling individuals with any level of visual ability to collaborate at school or work. Building on prior research on developing accessible user interfaces for people with visual impairments, this project will explore the challenges of collocated synchronous collaboration between people with and without visual impairments. The researchers will conduct formative interviews and observational studies of professional adults with and without visual impairments to understand the barriers to collaboration within and across these populations. Very little prior research has explored these issues. This project will conduct a deep exploration to reveal accessibility barriers that were previously hidden and unknown.<br/><br/>Broader Impacts: This research will identify existing barriers to employment that can be addressed through changes in policy or practice, or through the development of new technology. Enabling people with visual impairments to work alongside their sighted peers will significantly improve educational and employment outcomes for millions of people. The research project itself will be developed in the context of a collaboration between people with and without visual impairments, and will include blind and visually impaired people from the local community."
"1318215","HCC: Small: Thermal Displays in Human Computer Interactions","IIS","Cyber-Human Systems","08/15/2013","05/22/2014","Lynette Jones","MA","Massachusetts Institute of Technology","Continuing grant","Ephraim P. Glinert","07/31/2016","$491,915.00","","LJones@MIT.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7367, 7923","$0.00","To date most of the research concerned with exploring the use of the skin for human-computer communication has focused on tactile displays, which represent a promising arena for enhancing the display of information in situations in which the visual and auditory systems are overloaded. But in addition to its tactile sensors, the skin also houses thermal receptors that respond to changes in skin temperature and convey information about the magnitude and rate of change in temperature. Thermal feedback may potentially be of use as a channel of communication or in enhancing tactile and visual feedback in multisensory displays. The PI's objective in this research is to explore the domains in which thermal feedback can be used as a medium of communication and to identify the types of inputs that are most effective for users, with the long term goal of discovering conditions under which thermal feedback enhances human performance as reflected in more efficient information processing or the ability to respond more effectively to an external event. The focus is on using thermal interfaces within the context of a multisensory environment to display abstract information rather than to facilitate object recognition in a virtual environment or when controlling a tele-operated robot. The human thermal sensory system presents unique challenges when considered as a medium of communication due to its spatial and temporal properties which differ from those of other sensory systems. Although this constrains the types of cues that can be presented to users, it also opens up the possibility of creating new forms of feedback which by virtue of their novelty may be quite compelling to users. The work will be divided into three thrusts: determine the optimal configuration and operating characteristics of thermal displays interfaced with input devices used to interact with computers; evaluate the feasibility of using thermal stimuli to represent abstract information and appraise the viability of using thermal cues to present novel sensory experiences such as illusions of moisture or wetness; and examine whether the representation of information in multisensory displays is enhanced when thermal feedback is presented concurrently with tactile and visual cues.<br/><br/>Broader Impacts: There is very little research on the feasibility of using thermal displays to present abstract information, so this work has the potential to open a fundamentally new application domain for thermal interfaces. The availability of thermal cues in displays should increase the designer's ability to choose among modalities and assign functions and types of information to the channel that is best suited for their presentation. Project outcomes will also contribute to the development of sensory substitution systems for those with visual, auditory or vestibular impairments; there has been a considerable amount of research on using the sense of touch to compensate for deficiencies in other senses and the addition of thermal feedback to such displays provides an added dimension for communication, potentially increasing the reliability of communication."
"0964526","III: Medium: Collaborative Research: Data Mining and Cleaning for Medical Data Warehouses","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","06/28/2013","Christopher Jermaine","TX","William Marsh Rice University","Continuing grant","Maria Zemankova","08/31/2015","$600,000.00","","Christopher.m.jermaine@rice.edu","6100 MAIN ST","HOUSTON","TX","770051827","7133484820","CSE","7364","7364, 7924","$0.00","A clinical data warehouse (CDW) is a repository that aggregates medical patient data from many different sources: billing records, electronic medical records including structured data (e.g., codes for diagnoses, procedures, vital signs, etc.), semi-structured reports and free-text dictations. A key benefit of maintaining a CDW lies in its ability to provide the raw data that are needed for large-scale study of real-world health care -- for example, finding a previously unknown association between a pain killer (e.g., Vioxx) and heart disease. Unfortunately, CDWs are riddled with systematic errors that make it difficult to answer even the simplest questions (such as ""What fraction of female outpatients have breast cancer?"") with any accuracy.<br/><br/>This project focuses on statistical models and learning algorithms for quantifying and correcting errors in CDW records. For example, the project is developing semi-supervised learning methods that use the structured data present in electronic medical records (patient age, weight, medications, billing codes, etc.) in order to quantify the likelihood of error that is associated with the diagnosis codes present in the record (for example, being able to state ""There is a 0.2 probability that the correct code was migraine instead of the listed headache""). The project will also develop methods that attempt to control for confounding variables present in the records, in order to remove systematic biases from the data.<br/><br/>These models and learning algorithms will allow CDW users to manage and monitor the uncertainty and error in the data. This in turn will allow fundamentally new types of analysis to be undertaken, which will result in the discovery of actionable medical knowledge that saves both lives and money. To make the models and algorithms accessible to medical professionals who may lack computational or statistical background, they will be added to an open-source release of the widely-used I2B2 CDW software.<br/><br/>The project is a collaboration between the Computer Science Department at Rice University and the School of Biomedical informatics at the University of Texas Health Science Center at Houston. All project results will be made available online (http://www.cs.rice.edu/~cmj4/CDW.htm)."
"0753069","INTEROP: Sustainable Interoperability for Language Technology","BCS","LINGUISTICS, COLLABORATIVE RESEARCH, DATA INTEROPERABILITY NETWORKS, ROBUST INTELLIGENCE, INFO INTEGRATION & INFORMATICS","09/01/2008","05/22/2014","Nancy Ide","NY","Vassar College","Continuing grant","Tatiana D. Korelsky","02/28/2015","$755,496.00","James Pustejovsky","ide@cs.vassar.edu","124 Raymond Avenue","Poughkeepsie","NY","126040657","8454377092","SBE","1311, 7298, 7701, 7495, 7364","0000, 5914, 5979, 7752, 9139, OTHR, 9178, 9251, SMET, 7495","$0.00","This project supports U.S. participation in an international Network to work toward achieving interoperability among language resources, for which parallel European support has been provided by the European Commission eContentplus Programme. The Network involves members of the language processing community and related areas who are working to build consensus regarding the sharing of data and technologies for language resources and applications, interoperability of existing data and tools, and the promotion of standards for resource building and annotation. The participation of colleagues in Asia is also being sought. <br/><br/>The resources and technologies to be addressed include annotated corpora (texts, audio), lexicons, ontologies, automatic speech recognizers, lemmatizers, taggers for all levels of linguistic phenomena, named entity recognizers, information extractors, as well as systems for search, access, and annotation. The creation and use of these resources span the field of linguistics and several related but relatively isolated disciplines within computer science and engineering, including natural language text and speech processing, information retrieval, machine translation, and the semantic web. The goal is to turn existing, fragmented technologies and resources developed within these groups in relative isolation into accessible, stable, and interoperable resources that can be readily reused across several areas. This project is being funded through the INTEROP solicitation in the Office of Cyberinfrastructure, with funding also from the Directorates of Social, Behavioral & Economic Sciences and Computer & Information Science & Engineering, and the Office of International Science & Engineering."
"1319152","RI: Small: BCSP: Robustness and Adaptation in Morphogenetic Collective Systems","IIS","INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, ROBUST INTELLIGENCE, ANIMAL BEHAVIOR","09/15/2013","05/02/2014","Hiroki Sayama","NY","SUNY at Binghamton","Standard Grant","Satyandra Gupta","08/31/2016","$376,567.00","","sayama@binghamton.edu","4400 VESTAL PKWY E","BINGHAMTON","NY","139026000","6077776136","CSE","1640, 7275, 7495, 7659","7495, 7923, 8750, 7556, 7659","$0.00","The objective of this project is to understand the roles of general morphogenetic principles such as heterogeneity of components, differentiation/re-differentiation of components, and local information exchange among components in the self-organization of biological collectives, and to utilize them to improve the performance of collective artificial systems. The research is conducted in the following four steps: (1) Study the effects of morphogenetic principles on self-organizing patterns of heterogeneous collectives using mathematical/computational models. (2) Apply the results of theoretical investigation to construct models of actual self-organizing patterns found in real-world heterogeneous biological collectives. (3) Introduce the morphogenetic principles to existing collective artificial systems and develop mechanisms for programming their structures and behaviors. (4) Measure the overall performance of the proposed morphogenetic collective systems in decentralized optimization and exploration tasks. This research contributes to biology and ecology by providing new theoretical insight into how heterogeneous collectives may self-organize without centralized control, and also to computational science and engineering by bringing an unexplored combination of morphogenetic principles into bio-inspired computational systems. It is expected to produce societal impacts by providing a novel framework for the design of growing, self-organizing, self-repairing, and evolving artifacts. This project involves the following educational activities: (1) Interdisciplinary graduate certificate program in complex systems science. (2) New course on computational approaches to the origin and evolution of life. (3) Regional high school research program. (4) Public exhibition of morphogenetic collective systems at New York Hall of Science. Efforts will be made to attract female and ethnic minority students who are currently underrepresented in STEM."
"0964102","RI: Medium: Collaborative Research: Semi-Supervised Discriminative Training of Language Models","IIS","ROBUST INTELLIGENCE, COLLABORATIVE RESEARCH","06/01/2010","03/18/2014","Alexander Kain","OR","Oregon Health and Science University","Continuing grant","Tatiana D. Korelsky","05/31/2015","$519,050.00","Izhak Shafran, Richard Sproat","kaina@ohsu.edu","3181 S W Sam Jackson Park Rd","Portland","OR","972393098","5034947784","CSE","7495, 7298","7924, 5940, 7495","$0.00","This project is conducting fundamental research in statistical language modeling to improve human language technologies, including automatic speech recognition (ASR) and machine translation (MT).<br/><br/>A language model (LM) is conventionally optimized, using text in the target language, to assign high probability to well-formed sentences. This method has a fundamental shortcoming: the optimization does not explicitly target the kinds of distinctions necessary to accomplish the task at hand, such as discriminating (for ASR) between different words that are acoustically confusable or (for MT) between different target-language words that express the multiple meanings of a polysemous source-language word.<br/><br/>Discriminative optimization of the LM, which would overcome this shortcoming, requires large quantities of paired input-output sequences: speech and its reference transcription for ASR or source-language (e.g. Chinese) sentences and their translations into the target language (say, English) for MT. Such resources are expensive, and limit the efficacy of discriminative training methods.<br/><br/>In a radical departure from convention, this project is investigating discriminative training using easily available, *unpaired* input and output sequences: un-transcribed speech or monolingual source-language text and unpaired target-language text. Two key ideas are being pursued: (i) unlabeled input sequences (e.g. speech or Chinese text) are processed to learn likely confusions encountered by the ASR or MT system; (ii) unpaired output sequences (English text) are leveraged to discriminate between these well-formed sentences from the (supposed) ill-formed sentences the system could potentially confuse them with.<br/><br/>This self-supervised discriminative training, if successful, will advance machine intelligence in fundamental ways that impact many other applications."
"1117257","CGV: Small: Discrete Variational Contact, Impact, and Dissipative Dynamics","IIS","GRAPHICS & VISUALIZATION, ROBUST INTELLIGENCE","08/15/2011","05/22/2014","Eitan Grinspun","NY","Columbia University","Continuing grant","Jie Yang","07/31/2015","$515,879.00","Daniel Kaufman","eitan@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7453, 7495","7923, 7453, 9251","$0.00","This project investigates computational techniques for modeling dissipative physical systems experiencing contact, impact, friction and plasticity. The attendant optimization problems are strongly nonlinear, nonsmooth, and nonconvex in nature, necessitating the development of novel numerical methods. The research grounds the development of these methods by building on discrete geometric mechanics and variational integrators, which restate the fundamental principles of physics in a discrete, hence immediately computable form. The research examines five core behaviors arising from the Principle (momentum/energy/symmetry preservation, breaking contact, and non-interpenetration) and thereby derives computer algorithms whose outputs capture these physical behaviors. The project success is measured by (a) the production of novel computer algorithms that are able to simulate dissipative physical phenomena more accurately and efficiently than ever before, (b) new theoretical results on what can be expected of computer algorithms that simulate these phenomena, and (c) the successful adoption of the novel techniques by industry partners. The project results are publicly disseminated via articles in journals, release of source code on the world wide web, and transfer of technological expertise and data to industrial partners. <br/>Improving computational techniques for the simulation of contact, impact, and dissipative phenomena helps make engineering safety analyses, biomechanical models, computer visualizations, surgical training tools, and industrial manufacturing simulations that better predict reality. Algorithms that accurately capture the physics help to gain important new insights into many open questions that influence our understanding of large-scale geophysics of earthquakes and calving of icebergs, small-scale dissipation in high-frequency micro- and nano-electronic mechanical devices, prosaic domestic phenomena such as the chattering of chalk on a board and even the excitation of violin strings."
"1350078","CAREER: Supervised Learning for Incomplete and Uncertain Data","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","05/22/2014","Alina Zare","MO","University of Missouri-Columbia","Continuing grant","Todd Leen","04/30/2019","$102,673.00","","zarea@missouri.edu","310 JESSE HALL","COLUMBIA","MO","652111230","5738827560","CSE","7364","1045, 7364, 9251, 9150","$0.00","This CAREER project will advance the state of the art in supervised machine learning to allow for incomplete, uncertain and unspecific label information. Supervised machine learning algorithms produce desired outputs for given input data by learning from example training data. The methods generally rely on completely and accurately labeled training data to drive the learning algorithm. However, many applications are plagued with labels that are incomplete, uncertain, and unspecific (lack precision). Current techniques do not adequately handle such data.<br/><br/>For example, analysis of satellite imagery to identify the content of each pixel is often conducted by coupling unsupervised learning methods (that do not rely on labeled training data) with manual exploration. This is time-consuming, error-prone, and expensive. Imagine, instead, easy-to-use tools that could understand the content of each pixel in satellite imagery. Extremely large amounts of road map data (for example from Google Maps or OpenStreetMap) and social media information (for example geo-tagged photographs, video clips, and social networking posts) are continually collected and stored. These data could be used as sparsely-labeled training data (with varying degrees of specificity and uncertainty) to guide understanding of satellite imagery.<br/><br/>Although the data is available, algorithms have yet to be developed to combine these data sources and identify the content of pixels in satellite images. This work will advance this and other potential applications of machine learning where incomplete, uncertain and unspecific labels in training data challenge the development of effective machine learning algorithms. <br/><br/>This CAREER project will achieve these advances through the following research objectives:<br/>(1) Investigate and develop a mathematical framework and associated algorithms for Multiple Instance Function Learning that addresses linear and non-linear classification and regression problems with varying levels and types of sparsity, uncertainty, and specificity in training labels.<br/><br/>(2) Study and apply the proposed framework and algorithms towards the fusion of satellite imagery, road map data and social media for global scene understanding. <br/><br/>This research will be conducted in conjunction with integrated education and outreach activities. In particular, an interactive web application will be developed to provide an avenue for introducing concepts from machine learning and remote sensing to the public for dissemination and outreach. This interactive web application will also be used, along with additional hands-on activities, to introduce high school students to machine learning and remote sensing concepts during an annual summer engineering camp held at the University of Missouri in Columbia, MO. Paired with the web application will be a research website in which data, code, publications and presentations will be shared with the research community. Furthermore, undergraduate and graduate research assistants will be trained in the areas of machine learning and remote sensing. Finally, relevant research topics will be introduced in the PI's undergraduate and graduate courses."
"1217485","III: Small: Collaborative Research: RUI: Learning to Model Sequences","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","05/21/2014","Douglas Turnbull","NY","Ithaca College","Continuing grant","Maria Zemankova","09/30/2015","$202,000.00","","dturnbull@ithaca.edu","Danby Road","Ithaca","NY","148507000","6072743111","CSE","7364","7923, 9229, 7364, 9251","$0.00","This collaborative research project involves faculty and students from Cornell University (IIS-1217686) and Ithaca College (IIS-1217485) in an interdisciplinary project. The ability to learn predictive models of sequences is a component in several application problems, ranging from language models for machine translation to the recommendation of material to read in order to master a subject. The goal of this project is to develop new machine learning algorithms that can learn sequence models for items that are difficult to describe by attributes. In particular, the project develops models that automatically embed items in a latent feature space based on training sequences, that can integrate partial and noisy side information, and that have the ability to model long-range dependencies.<br/><br/>The resulting predictive models have a potential to be employed in science and education and can support the economic shift towards online business applications. The project focuses on the recommendation of music playlists as the main testbed. A deployed online music recommendation system not only provides the framework for testing and evaluation, this application domain helps to attract a broad spectrum of students from collaborating institutions, Cornell University and Ithaca College (an undergraduate institution), enabling the integration of undergraduates in the research. Project results, including open source software and annotated data set, are disseminated via the project Web site (http://www.cs.cornell.edu/People/tj/playlists/)."
"1115742","HCC: Small: Collaborative Research: Gestural and Linguistic Expressivity and Entrainment in Dialogue","IIS","Cyber-Human Systems","09/01/2011","04/15/2014","Jean Fox Tree","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","08/31/2015","$297,999.00","Marilyn Walker","foxtree@ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","7367, 7923, 9251, 7453","$0.00","This research will advance the state of the art in conversational character systems (Intelligent Virtual Agents) in two ways. First, it seeks to better understand the interplay of gesture and language in both generating the perception of personality and allowing participants to adapt to the ongoing conversational context. Second, it will use this understanding to build novel computational models for gesture and language generation that provide fine grained control over the perception of personality and support agent adaptation in response to the conversational context. The theoretical basis for the personality-based modeling in this project is the well-established ""Big Five"" model of personality, which consists of five orthogonal dimensions of individual variation.<br/><br/>The work on adaptation will be couched in the collaborative theory of language use and communication accommodation theory, which predict that communicative behavior varies based on partner specificity. Initial work will form a motion capture, video and audio corpus of three kinds of exchanges. This will be used to both study gestural entrainment during human interactions, determining if audio-based findings extend to the gestural domain, and to enhance scientific understanding of the relationship between gesture and personality. This will inform the modeling work which will build a joint model for personality-based language and gesture production. The model will extend a pilot study on gesture generation for extraversion to three Big Five traits and integrate it with personality-based language generation. An experimental stage will validate these models and study the interactions of movement and language. The research will also study the role of adaptation. Questions to be answered include: (1) whether people gesturally entrain with computers, or indeed produce any gestures while communicating with a computer, (2) whether computers? gestural entrainment promotes similar levels of affiliation as observed with vocal entrainment, and (3) whether changing gestural entrainment over the course of an interaction is more powerful than aligning gestures from the outset of an interaction. <br/><br/>Character systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior like entrainment, has a direct impact on the effectiveness of the applications in which they are used. For example, it will have a direct impact on student learning. As these applications become more ubiquitous in society, particularly among children, it is important to be able to harness their full benefit, and indeed, avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent interactions."
"0746816","CAREER: Developing Dynamic Relational Models to Anticipate Tornado Formation","IIS","INFO INTEGRATION & INFORMATICS, PHYSICAL & DYNAMIC METEOROLOGY, EXP PROG TO STIM COMP RES","07/01/2008","05/21/2014","Amy McGovern","OK","University of Oklahoma Norman Campus","Continuing grant","Maria Zemankova","06/30/2015","$608,000.00","","amcgovern@ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7364, 1525, 9150","1045, 1187, 7364, 9150, 9215, HPCC, 9102, 4444, 9216, 9251, 9178","$0.00","The goal of this research is to revolutionize the ability to anticipate tornadoes by developing advanced techniques for statistical pattern discovery in spatially and temporally varying relational data. These models are applied to complete fields of meteorological quantities obtained through data assimilation and simulation. Doppler radar data is limited and, while modern data assimilation techniques allow the unobserved quantities to be estimated, the resulting four- dimensional fields are too complicated for the extraction of meaningful, repeatable patterns by either humans or current data mining techniques. By studying a full field of variables, the models can identify critical interactions among high level features. The models are developed and verified in close collaboration with domain experts.<br/><br/>The interdisciplinary research is used to improve retention and recruitment in computer science (CS). This draws on recent evidence that underrepresented groups are not drawn to computing careers because they do not appreciate how computing can be used to solve real world problems. Introducing authentic projects into both early CS and meteorology classes will improve the number of technically trained students in both majors.<br/><br/>The primary broader impact of this research is to society, through the <br/>potential for reduction in loss of human life, property, and money. <br/>Models will be made available to operational meteorologists as they are verified. Another broader impact will come from increasing the number of computing oriented minors and majors through authentic projects. All data and results will be disseminated through peer reviewed publications and via open source online repositories accessible on the project Web site (http://www.cs.ou.edu/~amy/career/)."
"1320791","III: Small: Managing Spatial Data in a Distributed Environment","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","05/21/2014","Hanan Samet","MD","University of Maryland College Park","Continuing grant","Maria Zemankova","08/31/2016","$339,011.00","","hjs@umiacs.UMD.EDU","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923, 7364, 9251","$0.00","Advances in distributed computing enable the pooling of resources located across the Internet to provide a scalable, and robust solution for many computational needs. Distributed key-value store systems like Google's BigTable and Amazon's Dynamo allow the indexing and retrieval of a large amount of data in parallel, while distributed computing frameworks like MapReduce and Pregel provide a fault-tolerant way to process a large amount of data using distributed computing resources. These distributed computing techniques are applied to the spatial database domain. Specifically, issues involved in storing and retrieving spatial data in a distributed environment, as well as, processing spatial queries in parallel using a distributed computing framework are investigated. All of these methods rely on variants of hashing in order to obtain near constant time behavior in distributing the data and it is preferable that they are as close as possible to being distance-preserving. Specifically, spatial objects in proximity should have similar hash values. In particular, it is desirable to be able to estimate how far apart two objects are (within a given error bound) by just considering their hash values. Such hash functions enable performing an approximate range query using simple hash table lookup operations. Other issues involve the parallel processing of spatial queries. Some easy examples are the distance join query which finds pairs (p,q) of objects (from two different sets) where the distance between p and q is less than a given threshold, or computing the shortest paths from each node to every other node in a road network. More difficult are the spatial problems which can not be easily decomposed into multiple tasks running in parallel, e.g., the distance semi-join query, and network Voronoi diagram construction. This requires developing a generic method to traverse a graph or a tree in parallel to solve these query problems. Ideally, the method should require little or no communication between parallel tasks which will be accomplished by allowing the parallel tasks to produce redundant results which can then be pruned.<br/><br/>The developed tools will help improve the robustness and scalability for spatial data management. The parallel query processing results can be useful for query problems which requires traversing a tree or a graph which are often spatially embedded. Having a method to traverse a graph or a tree in parallel that requires little or no communication enables processing of many types of spatial queries using distributed computing resources where currently communication can be very costly. Specifically, it can be expected that the tools will enable spatial applications such as online mapping, computer aided design, online gaming and scientific simulations to handle terabytes of spatial data while it is impossible or inefficient to do with the current technologies. This is of utility to all organizations that process spatial data and attempts will be made to use it in some government agencies. In addition, the project provides educational and research opportunities for graduate and undergraduates. The project web site (http://www.cs.umd.edu/~hjs/distributed-spatial.html) will be used to disseminate results."
"1253549","CAREER: Observing the world through the lenses of social media","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","05/21/2014","David Crandall","IN","Indiana University","Continuing grant","Maria Zemankova","02/28/2018","$226,429.00","","djcran@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7364","1045, 7364, 9251","$0.00","Every day, millions of people across the world take photos and upload them to social media websites. Their goal is to share photos with friends and others, but collectively they are creating vast repositories of visual information about the world. Each photo is an observation of how the world looked at a particular point in time and space. Aggregated together, these photos could provide new sources of observational data for use in disciplines like biology, earth science, social science or history. This project is investigating the algorithms and technologies needed for mining these large collections of photographs and noisy metadata to draw inferences about the physical world. The project has four research thrusts: (1) investigating techniques for identifying and correcting noise in metadata like geo-tags and timestamps, (2) developing algorithms for extracting semantic information from images and metadata, (3) creating methods for robust aggregation of noisy evidence from multiple photos, (4) validating these techniques on interdisciplinary applications in biology, sociology, and earth science.<br/><br/>The project is laying the foundation for using visual social media as a new source of observational data for a variety of scientific disciplines. The educational component is preparing students for the next generation of ""big data"" jobs through new undergraduate and graduate courses and online instructional materials. Undergraduate students (particularly from under-represented groups) are recruited to participate in the research program and encouraged to pursue scientific careers. An annual workshop is planned to educate general audiences, particularly senior citizens, about data mining and social media. Source code, datasets, course materials, and other results of the project will be disseminated to the public via the project web site (http://vision.soic.indiana.edu/career/)."
"1213026","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS, ICER","10/01/2012","05/21/2014","Naphtali Rishe","FL","Florida International University","Standard Grant","Maria Zemankova","09/30/2017","$1,299,000.00","Tao Li","rishen@cs.fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","CSE","7364, 7699","7925, 7433, 7364, 9251","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1002921","Pilot: Expressing Dramatic Character in Dialogue: A Toolkit for Creative Exploration of Linguistic Style","IIS","CreativeIT, Cyber-Human Systems","07/01/2010","05/07/2013","Marilyn Walker","CA","University of California-Santa Cruz","Standard Grant","Ephraim P. Glinert","06/30/2015","$394,365.00","Noah Wardrip-Fruin","mawalker@ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7788, 7367","7367, 7788, 9251","$0.00","Computer games and other forms of interactive media have many potential benefits -- ranging from the educational to the economic. Games are used to educate in areas such as computer science, health care, and language learning, while game industry revenue is now larger than feature film box office receipts. But many subjects we would wish to teach, and many genres in which we would like to entertain, are fundamentally limited by current authoring approaches: in particular, the amount of character dialogue that must be hand-authored. This project will use what is known about the creative work of human authors together with advanced techniques from the field of ""natural language generation"" to explore a new approach to addressing this problem. In particular, it will integrate a new model of dialogue generation into an advanced tool for interactive story authoring, then evaluate the results when both expert and beginning authors work with the tool, giving us our first understanding of the promise of such techniques for enhancing the creativity of authors.<br/><br/>The need for a new approach to dialogue is pressing. For example, the forthcoming commercial game LA Noir has a script of 2,200 pages (roughly equivalent to 12 feature films). Producing this amount of dialogue is simply impossible for educational game producers, and is nearing the limit of what commercial producers can manage, yet games can only continue to grow in sophistication by having more dialogue. This research works toward a solution for this dilemma, opening the door to further educational development and economic growth, by enhancing author creativity through cutting edge computer science. In addition, this project will help develop broader understanding of the field of Creative IT, providing a case study of how the knowledge of creative professionals and scientists can combine to produce social benefits that would be impossible for either working alone."
"0916219","III:Small: Information Integration and Human Interaction for Indoor and Outdoor Spaces","IIS","INFO INTEGRATION & INFORMATICS","09/15/2009","05/21/2014","Michael Worboys","ME","University of Maine","Continuing grant","Maria Zemankova","08/31/2014","$484,715.00","Nicholas Giudice","worboys@spatial.maine.edu","5717 Corbett Hall","ORONO","ME","044695717","2075811484","CSE","7364","7364, 7923, 9150, 9216, HPCC, 9251","$0.00","The goal of this research project is to provide a framework model that integrates existing models of indoor and outdoor space, and to use this model to develop an interactive platform for navigation in mixed indoor and outdoor spaces. The user should feel the transition between inside and outside to be seamless, in terms of the navigational support provided. The approach consists of integration of indoors and outdoors on several levels: conceptual models (ontologies), formal system designs, data models, and human interaction. At the conceptual level, the project draws on existing ontologies as well as examining the ""affordances"" that the space provides. For example, an outside pedestrian walkway affords the same function as an inside corridor. <br/><br/>Formal models of place and connection are also used to precisely specify the design of the navigational support system. Behavioral experiments with human participants assess the validity of our framework for supporting human spatial learning and navigation in integrated indoor and outdoor environments. These experiments also enable the identification and extraction of the salient features of indoor and outdoor spaces for incorporation into the framework. Findings from the human studies will help validate the efficacy of our formal framework for supporting human spatial learning and navigation in such integrated environments. <br/><br/>Results will be distributed using the project Web site (www.spatial.maine.edu/IOspace) and will be incorporated into graduate level courses on human interaction with mobile devices, shared with public school teachers participating in the University of Maine?s NSF-funded RET (Research Experiences for Teachers). The research teams are working with two companies and one research center on technology transfer for building indoor-outdoor navigation tools with a wide range of applications, including those for the persons with disabilities."
"1242304","EAGER: Efficient Methods for Characterizing Large-Scale Network Dynamics","IIS","INFO INTEGRATION & INFORMATICS","08/01/2012","08/06/2012","Chandan Reddy","MI","Wayne State University","Standard Grant","Sylvia J. Spengler","07/31/2015","$100,000.00","","reddy@cs.wayne.edu","5057 Woodward","Detroit","MI","482023622","3135772424","CSE","7364","7364, 7916","$0.00","Many real-world phenomena can be modeled by dynamic networks whose connectivity as well as activity changes over time. Hence, there is a growing interest in elucidating the structure and dynamics of such networks. Existing approaches to this problem focus mainly on utilizing either coarse network properties or global structural features to comprehend network dynamics. Such methods often rely on extensions of network features of static networks to understand dynamic networks and fail to capture the rich dynamics of real-world networks. <br/><br/>This exploratory project explores a hierarchical approach to decomposition of network structure and dynamics that can explain changing dynamics at multiple scales ranging from node-level to community-level. The approach is novel, and because of its untested nature, somewhat risky. The research is organized around three aims:(i) Develop information-theoretic flow based approaches that can extract multiple layers of dynamics by simultaneously optimizing for explicit community structures and partial flow dynamics in complex networks. (ii) Develop a computational framework for dynamics-aware network summarization that preserves the flow dynamics of graphs and provides a summary of the large-scale graph dynamics.<br/><br/>The project advances the current state-of-the-art in network data analytics. The resulting tools for elucidating the structure and dynamics of complex networks at multiple scales could potentially transform the way we understand, design, engineer, and control complex networks. The project enriches research-based training and outreach activities at Wayne State University."
"1217104","RI: Small: Collaborative Research: Exploring Audiovisual Emotion Perception using Data-Driven Computational Modeling","IIS","ROBUST INTELLIGENCE","09/01/2012","06/20/2013","Carlos Busso","TX","University of Texas at Dallas","Continuing grant","Kenneth C. Whang","08/31/2015","$201,573.00","","busso@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7923, 7495","$0.00","This project explores perception-driven models of human audio-visual emotion using statistical analyses, data-driven computational modeling, and implicit sensing. Emotion underlies and modulates human communication. It is used in the diagnosis of many mental health conditions and is tracked in therapeutic interventions. Research in emotion perception seeks to identify models that describe the felt sense of 'typical' emotion expression -- i.e., an observer/evaluator's attribution of the emotional state of the speaker. This felt sense is a function of the methods through which individuals integrate the presented multi-modal emotional information. However, the nature of the interaction of the multi-modal cues is still an open question. This project will investigate multi-modal cue integration by studying how emotional inconsistency affects human perceptual judgment. In pursuit of this goal, the research objectives of this proposal are (1) to identify and validate primary and secondary audio-visual cues responsible for emotion perception, (2) to create a data-driven model to automatically predict the emotion perception of an evaluator, and (3) to predict evaluator state using implicit physiological and body gesture cues. <br/><br/>The first research objective addresses the open question of how distal cues, the encoding of a speaker's communicative goals, interact and result in the felt sense of specific emotion states. Novel techniques will be used to identify emotionally salient distal cues using emotionally consistent and inconsistent audio-visual information. This identification has implications in the design of emotion classification algorithms and the emotional behavior of affective agents. The second research thrust addresses the open question of how human-centered models (rather than data-driven models) can be designed for use in emotion classification tasks. The project will investigate the efficacy of novel dynamic structures to model emotionally inconsistent information. These new structures will provide insights into the development of human-centered emotion classification inspired by the emotion perception process, rather than solely on data fluctuations. The third research objective addresses the open question regarding the effect of audio-visual emotion evaluation tasks on the evaluator's internal state. We will assess evaluator inattention in the context of emotional evaluation tasks. Models that can accurately predict evaluator inattention have applications in long-term human-computer and human-robot interaction platforms. The insights gained from this project will facilitate the design of emotion-focused algorithms that replicate the process by which humans interpret and integrate emotional audiovisual signals. It will also aid in the creation of emotional interfaces for health informatics applications, which will lead to more specifically targeted interventions and treatments for many mental health conditions including schizophrenia, depression, and autism."
"1253314","CAREER: Resource-adaptive distributed estimation for teams of micro aerial vehicles","IIS","ROBUST INTELLIGENCE","03/01/2013","03/11/2013","Anastasios Mourikis","CA","University of California-Riverside","Continuing grant","Jeffrey Trinkle","02/28/2018","$295,091.00","","mourikis@ee.ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","CSE","7495","1045","$0.00","The proposed work focuses on developing resource-adaptive distributed estimation algorithms for teams of micro aerial vehicles (MAVs). Among the several challenges one faces when designing estimators for MAV teams, the most important one is the stringent resource limitations of MAVs. While in any engineered system the resources are inevitably finite, cost, power, and weight considerations make the limitations particularly strict for teams of small MAVs. In this work, we will develop a rigorous, optimization-based framework for the design of estimation and inference algorithms, as well as for the design of the MAV platforms themselves. Our approach will yield distributed estimators capable of optimally allocating the sensing, processing, communication, and energy resources of an MAV team. The methods to be developed will lead to efficient design tools, and will permit a systematic study of the tradeoff curves between MAV resource availability and estimation performance.<br/><br/>The algorithms and theoretical results that will result from this effort will dramatically increase the capabilities of MAV teams, in domains ranging from scientific exploration to search-and-rescue operations. In turn, these systems will yield benefits that will directly impact our lives, from advancing our state of scientific understanding to saving humans in disaster sites. Additionally, the proposed research plan will create opportunities for both graduate and undergraduate students from UC Riverside's diverse student body to conduct meaningful research. Undergraduate students will be recruited to work on new MAV designs, and it is anticipated that such an involvement will increase the likelihood of them pursuing a graduate education. Moreover, as part of an integrated outreach program, we will leverage the nature of the proposed research (flying robots capture the imagination of young minds) to inspire and recruit underrepresented minority students to science and engineering. These efforts will aid in closing the educational attainment gap for underrepresented groups."
"1149235","CAREER: Reliable Contact Under Uncertainty: Integrating 3D Perception and Compliance","IIS","ROBUST INTELLIGENCE","03/01/2012","02/24/2014","Marsette Vona","MA","Northeastern University","Continuing grant","Jeffrey Trinkle","02/28/2017","$291,844.00","","vona@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7495","1045","$0.00","This project, developing a coarse/fine approach to walking on unstructured terrain based on integrating 3D perception and compliant contact, addresses central challenges in robotic locomotion. Despite recent advances, unstructured tasks such as walking on rocks with sparse footfalls - a task that is easy for humans - remains very challenging for robots. This effort seeks to solve this type of problem with a coarse approach using 3-D perception that uses range sensing to find general curved surface patches in the environment that might be suitable for foot placement. Along with patches on the robot itself, these patches are placed into a novel dynamic spatial patch map with estimated uncertainty that mates robot patches with environmental patches. The fine alignment is handled by a compliant ankle that allows the patches to mesh naturally. This approach is applicable to dexterous manipulation, as well.<br/><br/>Broader Impacts: We are now at a transformative frontier where we must introduce robots to unstructured tasks -- in factories, hospitals, and labs; in outer space; and in the home -- where now only humans can manage the uncertainty. Through building robot analogues to the human process of uncertainty tolerance combining vision and compliance, this work will help enable a new science of high-uncertainty robotics. The proposed education plan is built around modules and open hardware that will be portable to mobile manipulation courses at other institutions, which will be actively promoted. It also aims for broader audiences with specific plans to engage younger students and adult self-learners."
"0732155","Annual Telluride Workshop on Neuromorphic Cognition 2007-2012","SBE","INFO INTEGRATION & INFORMATICS, Engy, Pwr, Ctrl, Ntwks (EPCN), Science of Learning Activities","09/01/2007","08/13/2013","Timothy Horiuchi","MD","University of Maryland College Park","Standard Grant","Soo-Siang Lim","08/31/2014","$619,950.00","Shihab Shamma, Ralph Etienne-Cummings","timmer@isr.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","SBE","7364, 7607, 7704","0000, 7364, 7556, 7704, OTHR","$0.00","The Telluride Workshop on Neuromorphic Cognition Engineering<br/>Neuromorphic engineers design and fabricate artificial neural systems whose detailed architecture, design, and computational principles are based on those of biological nervous systems. Over the past 12 years, this research community has focused on the understanding of low-level sensory processing and systems infrastructure; efforts are now expanding to apply this knowledge and infrastructure to addressing higher-level problems in perception, cognition, and learning.<br/>The annual three-week intensive Workshop (held in Telluride, Colorado) consists of background lectures (from leading researchers in biological, cognitive, computational, engineering and learning sciences), practical tutorials (from state-of-the-art practitioners), hands-on projects (involving established researchers and newcomers/students), and special interest discussion groups (proposed by the workshop participants). For researchers in this community, this is the premier workshop for training students, initiating collaborations, and in-depth discussions on scientific issues.<br/>In this workshop and through the Institute for Neuromorphic Engineering (INE), the mission is to promote interaction between senior and junior researchers; to educate new members of the community; to introduce new enabling fields and applications to the community; to promote on-going collaborative activities emerging from the Workshop, and to promote a self-sustaining research field.<br/>Specific Goals for the period of 2007-2012: While there is no question that the Workshop has been very successful in its mission, three new challenges have been identified for the Workshop: 1) with a rapidly expanding community in both the U.S. and Europe, the Workshop experience needs to reach more people without increasing the size of the Workshop, 2) as larger and more challenging projects are tackled, more opportunities for group interactions are needed throughout the year, and 3) as more complex questions are asked at the system-level, more voices from cognitive neuroscience are needed.<br/>To meet these new challenges, a new version of the Workshop is envisioned with: 1) an expanded theme to focus on Perception, Cognition, and Learning, 2) an expanded constituency, educational mandate and research focus to incorporate members of the NSF Science of Learning Centers (SLC), 3) to create a two-part Workshop series (to allow yearlong collaborations and deeper investigation into large scale projects), one held in the U.S. and funded by U.S. resources and the other held in Europe and supported by European resources and 4) a modified Workshop schedule to emphasize training at the beginning of the workshop to provide a needed focus on education for both beginners and experts alike. The infusion of new researchers (from the SLCs) that focus on learning at multiple scales (from synapses to classroom) will provide the needed knowledge, new collaborations, and new perspectives to move the community towards cognitive-level neuromorphic systems. <br/>Broader impact of the Workshop to the public: The Telluride Neuromorphic Cognition Engineering Workshop will continue its tradition of public interaction. In particular, there will be a continuation of the educational program for K-12 students (based on neuromorphic/robotics design kits), undergraduate and graduate students (Workshop courses, new classes/lectures at participants? universities and REU), and to established researchers (exposure to new areas in the field). The workshop will also continue to educate the Telluride community with public lectures on the latest developments/issues in the field.<br/>Recruitment of minorities and women to the field will be continue by organizing lectures at various Universities, particularly HBCUs (Morgan State U., MD, Lincoln U., PA, Morehouse College, Atlanta, GA, and others). By sending presenters to institutions local to their home universities, minimal funding will be required and provide the most likely connections for future collaborations. The Institute for Neuromorphic Engineering, currently housed at the University of Maryland (College Park, MD), will arrange the logistics. The lectures and other teaching materials developed at the workshop will also be made available to all interested parties and posted on the INE website. <br/>Lastly, the workshop will continue to develop the researchers and leaders for the emerging field of biologically-inspired systems, cognitive/learning systems, robotics and implantable electronics. Various agencies and governments have recognized that smart devices (such as interactive humanoid robots) that mimic living organisms will have great academic and commercial value in future."
"1444518","WORKSHOP: AMIA Doctoral Consortium 2014","IIS","Cyber-Human Systems","06/01/2014","05/20/2014","Madhu Reddy","PA","Pennsylvania State Univ University Park","Standard Grant","Ephraim P. Glinert","05/31/2015","$19,965.00","","mreddy@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7556","$0.00","This is funding to support a workshop of approximately 12 promising doctoral students along with 5 distinguished research faculty. The event, the 7th doctoral consortium on Sociotechnical Issues in Medical Informatics, will take place in conjunction with the 2014 Annual Symposium of the American Medical Informatics Association (AMIA) in Washington DC on November 15-19. Held every fall, this is the premier AMIA conference and the largest biomedical informatics conference in the United State, attracting researchers, professionals and students from an array of occupational settings who are interested in all aspects of health information technologies. More information about the conference may be found at (http://www.amia.org/amia2014. <br/><br/>One issue that is of particular importance within medical informatics is the need to design/deploy systems with an understanding of how these systems fit into organizational and social contexts. The term sociotechnical denotes the importance of considering technical and organizational/social issues together rather than in isolation. For instance, the medical informatics community has long been interested in the technical features of the Electronic Medical Record (EMR), but less attention has been paid to how the design of the EMR will be affected by who the primary users of the system are, what context it is used in, and what interactions it should support. Yet, to design effective EMR systems, we need to understand how these different issues impact each other. The growing need for integrating research across disciplines (e.g., HCI and Medical Informatics) is the primary motivation for this doctoral consortium. Therefore, student participants will span a broad range of disciplines and approaches that inform medical informatics, including computer science, information science, engineering, clinical sciences, law, management and related fields. The doctoral consortium will take place on the weekend prior to the AMIA Symposium so the students can also participate in the conference, which will introduce them to the exciting breadth of research topics within the medical informatics community. Conversely, bringing a new generation of scholars from different disciplines into the medical informatics community will broaden that community's understanding of what other research disciplines can offer medical informatics.<br/><br/>The consortium will provide a forum for doctoral students to share their work and also network with other doctoral students and researchers. Student participants will give short presentations during the consortium and will receive constructive remarks and feedback on their research from prominent researchers as well as through interaction with other students. The feedback is designed to help students understand and articulate how their work is positioned relative to related research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Thus, the consortium will help shape both these ongoing and future inter- and multi-disciplinary research projects focusing on organizational and social issues surrounding health-related technologies. The names and abstracts of the accepted participants will be printed in the AMIA program guide, and will also be made available to the public on a special website to be developed by the organizers.<br/><br/>The doctoral consortium will bring together people from different disciplines who might not otherwise engage with one another and will expose them to different scientific research approaches and questions. It will foster a sense of community among the young researchers by allowing them to create a supportive mentoring and social network both among themselves and with senior researchers at a critical stage in their professional development. The organizers will make a concerted and proactive effort to ensure a diverse pool of student participants including members of under-represented groups in the STEM disciplines; this, in turn, will broaden the students' horizons to the future benefit of the field."
"1319084","RI: Small: Dynamic Payload Transport and Manipulation by Teams of Cooperating Mobile Robotic-Cranes","IIS","ROBUST INTELLIGENCE","09/01/2013","05/15/2014","Venkat Krovi","NY","SUNY at Buffalo","Standard Grant","Jeffrey Trinkle","08/31/2016","$458,000.00","","vkrovi@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7495","7495, 7923, 9251","$0.00","We seek to investigate the systematic design and dynamic-control of cooperative payload transport and manipulation by teams of semi-autonomous mobile robotic-crane modules. The Intellectual Merit of the proposed research lies in its contribution to the development of design and control theory for general mechanical systems under various restrictions. First, the cooperative systems under consideration require unidirectional control inputs. Second, the proposed research will also contribute to the fundamental design and control theory for multiple nonholonomic systems under physical constraints. Ultimately, the proposed research also provides fundamental understanding of networked robotic systems that must operate in complex, dynamic, and unstructured environments. There is still relatively little work that treats the physical-interactions and physical power-flows within the broad multi-agent-systems literature, which we seek to remedy.<br/><br/>The Broader Impacts of this research are in application areas such as cooperative payload transport, technologies to assist first responders at accident scenes, search and rescue applications, and remote scientific studies of many kinds, such as experiments conducted in undersea environments, rain forest environments, or arctic environments. Remote construction, remote cleanup of hazardous environments, land mine search and remote deactivation, are just a few of the numerous applications that may be impacted by semi-autonomous human/robot interaction. In adition, this project will develop courses, tools and the human resource base to conceive, investigate, implement and validate such systems-of-systems. In addition to graduate and undergraduate student training, planned educational initiatives include: (i) developing and integrating a new graduate course in robotics into the curriculum; (ii) creating educational technology curricular modules for encapsulating knowledge and for dissemination, and (iii) outreach within the university, with local high schools and industry and the educational community at large."
"0964665","RI: Medium: Planning and Control for Dynamic Robotic Manipulation","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","04/15/2010","08/23/2013","Kevin Lynch","IL","Northwestern University","Continuing grant","Jeffrey Trinkle","03/31/2015","$854,050.00","","kmlynch@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495, 8013","7924, 8086, 9251, 7495","$0.00","Manipulation allows a robot to alter its environment by performing mechanical work on it. Combined with locomotion, autonomous manipulation will be a key enabling capability in future robot systems for exploration, home care, military, industrial, and space applications. While most current robotic manipulation consists of simple grasp-and-carry operations, the spectrum of manipulation methods is much broader, including throwing, pushing, rolling, sliding, tapping, etc. Humans and animals make use of these methods on a daily basis, but robots do not. What is missing is a theoretical framework for combining and sequencing such manipulation methods for automatic planning and control of robotic manipulation.<br/><br/>This project is working toward autonomous manipulation by bridging the gap from individual robotic manipulation primitives to full manipulation sequence planning. The project is developing theoretical tools, a mechanics-based manipulation planning framework, feedback control algorithms, and an experimental manipulation testbed incorporating high-speed vision. The tools developed for autonomous planning and execution of manipulation sequences will allow future robot users to program robots at a much higher level of abstraction than currently possible. For example, instead of programming low-level control of motors, the user can simply say ""place object A on object B."" This will help grow the field of personal robotics, by allowing non-experts to interact with robots.<br/><br/>International partners in this work include leading laboratories in Italy and Japan. These collaborations provide unique access for graduate and undergraduate researchers to the world's leading experts in robotic manipulation."
"0916807","RI Small: On Robot Motor Capability for Skill Learning","IIS","ROBUST INTELLIGENCE","08/01/2009","08/21/2012","C.S. George Lee","IN","Purdue University","Continuing grant","Jeffrey Trinkle","01/31/2015","$486,000.00","","csglee@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495","7495, 7923, 9215, 9251, HPCC","$0.00","Endowing humanoid robots with the ability of skill learning will enable them to be versatile and skillful in performing various tasks. The problem of transferring human skills to humanoid robots raises tremendous research interest in studying human and robot motor skills. Our research aims at developing a quantitative measure of robot motor capability of a humanoid root motor system for the application of transferring human skills to a humanoid robot. An in-depth study of basic intrinsic properties of robot motor capability based on information theory will be performed to derive a pseudo index of motor performance. This pseudo index of motor performance is derived from robot kinematics, dynamics, and control with the speed-accuracy constraint taken into consideration. With the speed-accuracy constraint, the motor performance of a robot is optimized to accomplish a task. The research results demonstrate an increased understanding of robot motor capability that shows the capability and limitation of a robot for learning skills from human demonstration. The project plans to verify the result on an existing humanoid robot. The project results will provide new insights in humanoid robot motor learning and control, and launch a new research direction on human-robot interaction when both humans and robots better know their respective motor capabilities. The broader impacts include incorporation of research results into existing graduate and undergraduate robotics courses, and outreach activities of a weeklong robotics summer camp and a lab open house for high-school students. The research results will be disseminated in professional conferences, workshops and archival journal publications."
"1218310","HCC: Small: Automatic Simplification Methods for Tactile Graphics","IIS","Cyber-Human Systems","09/01/2012","05/20/2014","Dianne Pawluk","VA","Virginia Commonwealth University","Continuing grant","Ephraim P. Glinert","08/31/2016","$404,161.00","Carolyn Graham","dtpawluk@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","7367","7367, 7923, 9251","$0.00","Unfortunately for individuals who are blind and visually impaired, although access to text has greatly improved with computers, the computer has also greatly facilitated the ease of producing, storing, transmitting and using graphical representations to convey information. This has created a serious obstacle for the millions of people in the United States who are visually impaired or blind, because graphics are now ubiquitous and used in many instances as the sole information presentation method. Although presenting graphical information in terms of tactile diagrams is one alternative that has been proven useful, creating these diagrams remains a complex art that usually requires participation of a trained human. This is because to be effective tactile diagrams must be simplified; otherwise, they may be impossible to understand. Automating this process would have advantages in terms of cost, in terms of providing diagrams in a timely fashion (or even providing them at all), and in terms of independence for the intended users. In this project, which takes a first step toward this goal, the PI and her team will focus on the automatic conversion to tactile diagrams of two kinds of graphics: photographs and line drawings. To this end, a multi-step process is envisaged. First, techniques to segment images without a lot of fragmentation will be examined, modified and/or developed based on the current computer vision literature. Next, techniques will be developed for automating the simplification process, based on the manual steps as outlined by the Braille Authority of North America. Two main aspects will be considered: simplifying lines/curves in the diagram, and reducing clutter (defined as a situation where components of the graphic are too close together or so similar that they are hard to distinguish tactually). Then, automatic, metric rectification techniques will be explored, modified and/or developed to remove perspective from an image and replace it with a standard canonical view (because removing perspective seems to improve the user's ability to understand a tactile diagram). Finally, user studies will be conducted to evaluate the effectiveness of the tactile graphics created by the new automatic methods in comparison to those created manually by expert tactile diagram makers.<br/><br/>Broader Impacts: The ultimate goal of this line of research is to provide people who are blind or visually impaired with immediate and automatic access to any desired information, and thereby to remove the current barriers due to the graphical nature of computers and visual digital media. Project outcomes will be useful not only to adult members of the target communities; they will also make it possible to provide access to children's picture books to promote development in blind and visually impaired youngsters. The project will train at least one graduate and several undergraduate students in understanding the needs of the target communities and developing assistive technology for them. Results will be disseminated through the usual scientific channels and also in presentations to relevant stakeholders including individuals who are visually impaired, their teachers and other rehabilitation professionals. Results from this work will also be presented in workshops to K-12 students at the Math, Science, Innovation Center of Richmond to foster interest in STEM fields."
"1217991","RI: Small: Sampling Based Feedback Motion Planners","IIS","ROBUST INTELLIGENCE","09/01/2012","07/22/2013","Suman Chakravorty","TX","Texas Engineering Experiment Station","Continuing grant","Jeffrey Trinkle","08/31/2015","$369,206.00","Nancy Amato","schakrav@aero.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495","7923","$0.00","This project, developing robust and computationally intelligent randomized sampling based feedback motion planning techniques for constrained systems operating under ""process"" and ""sensing"" uncertainty, addresses an important research area for real-world systems. Such motion planning techniques are valuable because the high computational burden of these problems makes the solution of such problems intractable for anything but the simplest low dimensional systems. In particular, one of the most fundamental requirement of robots is that they operate in a safe, efficient and autonomous fashion in the presence of such uncertainty. Thus, a principled set of computationally intelligent techniques, with guaranteed performance, is required. This proposed work will generalize the Probabilistic RoadMap technique (PRM) of robotic path planning shall such that the roadmap construction incorporates both process and sensing uncertainty. This will result in a computationally tractable solution technique for a large class of constrained Markov Decision Problems (MDP) and Partially Observed MDPs (POMDP), known as constrained stochastic shortest path problems, along with guaranteed performance of the planners in terms of a probability of success. <br/><br/>Broader Impacts: The ability to solve high dimensional constrained MDP and POMDP problems in a computationally tractable fashion will have significant impact on multiple different robotic applications including robotic operations in hazardous environments such as disaster areas and battlefields, surgical robotics, prosthetics and unmanned planetary exploration. The impact of such computationally intelligent solution techniques cannot be overstated due to the ubiquitous nature of MDPs and POMDPs, which are fundamental decision making problems inherent in myriad different fields ranging from Engineering through Economics to Biology. The assimilation of K-12/undergraduate/graduate students, with a focus on underrepresented minorities, with high school teachers in projects related to the research, through experiments and demonstrations related to the research at the annual ""TAMU Physics and Engineering fair"", and the annual department ""summer camp"" for high school students and their parents, will disseminate the results of the project to a broad audience."
"0643680","CAREER: Distributed Estimation and Active Sensing with Mobile Robot Networks","IIS","ROBUST INTELLIGENCE","01/15/2007","09/25/2013","Stergios Roumeliotis","MN","University of Minnesota-Twin Cities","Continuing grant","Jeffrey Trinkle","12/31/2014","$581,998.00","","stergios@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","1045, 1187, 7495, 9178, 9215, 9218, 9251, HPCC, SMET","$0.00","CAREER: Distributed Estimation and Active Sensing with Mobile Robot Networks<br/><br/>Abstract<br/><br/>The objective of this research effort is to address current limitations on the autonomous operation of large, geographically distributed groups of robots and sensors collaborating for detecting events and objects of interest, and estimating their key parameters. The unifying theme throughout this endeavor is that communication, coordination, and performance evaluation are intertwined aspects of a new category of problems, specific to distributed systems, whose solution requires a holistic approach. <br/><br/>This research effort will focus on developing detailed models that quantify the effect on the accuracy of distributed estimation tasks of important factors such as the size of the robot team, type and precision of sensors, frequency of observations, and availability of communication and processing resources. Examples of cases that will be considered are cooperative localization, mapping, tracking, and detection with robots navigating in 3D under realistic sensing, communication, and processing limitations. This analysis will culminate in a concrete set of rules and methods that will be used to direct the design of robotic groups capable of achieving their mission objectives as described by user-imposed requirements on the expected precision and time to complete their task. The direct impact of this work will be significant cost savings during the design phase of a robotic team and throughout the robots' operation. Furthermore, this performance evaluation effort will empower robotics engineers with the ability to extrapolate from current design paradigms and reason for their selections based on formal analysis. The analytical results from this work will also be used as the basis for determining the optimal motion and communication strategies that maximize the efficiency of distributed sensing and estimation tasks. These algorithms will advance the state of the art in robot coordination for information acquisition, communication, and management by providing adaptability to changing conditions and increasing the reliability of mobile robot networks."
"0845925","CAREER: Word Meaning: Beyond Dictionary Senses","IIS","LINGUISTICS, ROBUST INTELLIGENCE","08/15/2009","05/22/2013","Katrin Erk","TX","University of Texas at Austin","Continuing grant","Tatiana D. Korelsky","07/31/2015","$441,451.00","","katrin.erk@mail.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","1311, 7495","1045, 9102, 9215, HPCC, 9251","$0.00","Most words have more than one meaning. The standard computational model for word meaning is through lists of dictionary senses. However, choosing the right dictionary sense is a highly difficult task for humans as well as machines. This CAREER project follows the hypothesis, based on current models of human concept representation, that word meaning is better described through a graded notion of similarity than through dictionary senses. The hypothesis is tested through a novel meaning annotation framework and computationally through a vector space model of word meaning. The model uses vector characterizations of typical arguments to compute the meaning of an individual occurrence compositionally from the words in its syntactic context. For evaluation, the project focuses on the ability to draw appropriate inferences, in both shallow and deep frameworks, from similarity-based meaning representations. The research effort goes together with educational work that focuses on supporting undergraduate research, stressing hands-on data exploration and interdisciplinary work.<br/><br/>The characterization of word meaning is a central issue in lexical semantics and in computational linguistics as a whole. This CAREER project will yield a broadly applicable paradigm that describes word meaning without recourse to dictionary senses. It aims both to provide a more cognitively adequate model and to benefit language technology applications, in particular information retrieval, which already relies heavily on vector space models."
"1320348","RI: Small: A Compositional Approach to Video Segmentation","IIS","ROBUST INTELLIGENCE","10/01/2013","05/09/2014","James Rehg","GA","Georgia Tech Research Corporation","Standard Grant","Jie Yang","09/30/2016","$499,443.00","Fuxin Li","rehg@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7923, 9251","$0.00","This project is pursuing a novel strategy for video segmentation based on the decomposition of a video into multiple overlapping segments of pixels, and the subsequent composition of these segments into hypotheses about the existence of objects within the video. Given an input video, this approach produces a set of spatio-temporal pixel regions as its output, where the set of output regions has a high degree of overlap with the objects that are present in the video. The project further develops methods for semantic segmentation, occlusion analysis, and activity recognition which can exploit a segment-based video representation. The basis for the approach is a statistical framework known as composite likelihood, which implicitly models the joint distribution of a random vector through distributions of low-dimensional statistics on overlapping subsets of variables. This statistical model is ideally-suited to describing video objects as a collection of multiple overlapping segments. Using this framework, methods are being developed to track overlapping segments within a video and generate object hypotheses. Additional efforts are aimed at improving the computational efficiency of the approach in order to address applications in on-line video analysis.<br/><br/>The resulting algorithms yield improved performance in video object segmentation and tracking, and provide new approaches to content-based video categorization and retrieval, for unstructured video collections such as those found on YouTube. The project is producing a novel publicly-available dataset containing fine-grained ground truth video object segmentations, in order to facilitate research activities in video analysis. The project is integrated with education and outreaches high school students to research in STEM."
"1065497","HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics","IIS","Cyber-Human Systems","06/01/2011","05/20/2014","Marcia O'Malley","TX","William Marsh Rice University","Continuing grant","Ephraim P. Glinert","05/31/2015","$242,158.00","","omalleym@rice.edu","6100 MAIN ST","HOUSTON","TX","770051827","7133484820","CSE","7367","7367, 7924, 9251","$0.00","This research involves collaboration among investigators at four institutions. Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning. While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms. For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control. The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions. These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof). The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags. The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date. In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics. To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR). An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis. Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder. To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined. <br/><br/>Broader Impacts: This research will revolutionize the control and interface of upper limb prosthetics. The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease. The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research. The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering."
"1253719","CAREER: Robotic Perception through Human Context","IIS","ROBUST INTELLIGENCE","03/15/2013","03/21/2013","Ashutosh Saxena","NY","Cornell University","Continuing grant","Jeffrey Trinkle","02/28/2018","$284,151.00","","asaxena@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495","1045","$0.00","To successfully operate in human environments, a robot needs to be able to properly interpret its surroundings and manipulate human objects. In human environments such as a household, we can bring to bear significant information about the expected spatial layout and the function of common household objects. However, for most reasoning methods for robotic perception and manipulation, humans play a secondary role. In this proposal, we propose to make humans central to our reasoning algorithms. We argue that such explicit modeling and consideration of humans, even when they are not present, will enable robots to better perceive, manipulate, and plan. Through such reasoning, we will make advances in the following areas: (a) Modeling 3D Scenes with Objects and Humans, (b) Human Activity Detection and affordances, and (c) Robot Manipulation for assistive tasks.<br/><br/>This research has the potential to significantly impact the quality of life of a large number of elderly people. In fact, one of the most promising applications of this research is in assistive care for the elderly and those with difficulty in performing daily tasks. Assistive care for the elderly is an increasingly important problem: a growing fraction of the US population is elderly; by 2030 about 1 in 5 Americans will be over 65. Many elderly people (including about 50% of those 85 years or older) require some personal assistance. Just to mention one basic example: a key concern in elderly care is that the subject does not drink enough water throughout the day and becomes dehydrated. Our robot (or a monitoring system) can observe the water consumption, remind the subject to drink water when needed, and even bring some if desired. Other outreach activities include incorporating young students and minorities into robotics research, curriculum development, and open-source robotics software."
"0911133","RI: Small: A Microgripper with Concurrent Actuation and Force Sensing","IIS","COLLABORATIVE RESEARCH, Catalyzing New Intl Collab, ROBUST INTELLIGENCE","09/01/2009","05/20/2014","Ron Lumia","NM","University of New Mexico","Standard Grant","Jeffrey Trinkle","08/31/2015","$492,498.00","","lumia@unm.edu","1700 Lomas Blvd. NE, Suite 2200","ALBUQUERQUE","NM","871310001","5052774186","CSE","7298, 7299, 7495","5927, 5978, 7299, 7923, 9150, 9215, 9251, HPCC","$0.00","The goal of this work is to develop a better fundamental understanding of the actuation and force sensing required for micromanipulation (objects from 5-500 microns) by exploring the following hypothesis: it is possible to manipulate micro-sized rigid and flexible objects while measuring physical properties, such as stiffness, by using the same microfinger to act simultaneously as an actuator and sensor. This hypothesis is explored both theoretically and experimentally by creating a set of smaller and smaller microgrippers. Two models, one analytical, the other numeric, of this new microfinger will be developed to predict performance as a function of size. Experiments using actual microgrippers verify the quality of the model.<br/><br/>The work impacts science, education, and outreach to minority populations. A compliant microgripper is an enabling technology to manipulate flexible and fragile bio-objects for applications in bioengineering, microbiology and genomics. A microgripper squeezes an oocyte to determine its viability by measuring the stiffness of the cell before subsequent injection of DNA or RNA, turning tedious manual procedures into programmed, automatic sequences, thereby reducing cost. New ways of detecting diseases, such as malaria, by measuring physical properties of cells with the microgripper become possible. Broader impacts include education and outreach. Great emphasis is spent on having supported students give talks about this technology at local middle schools and high schools to entice the next generation to become engineers. These talks improve the professional capabilities of the graduate students while simultaneously demonstrating to young students the purpose of studying math and science."
"0910586","HCC: Large: Collaborative Research: Widescale Computer-Mediated Communication in Crisis Response: Roles, Trust & Accuracy in the Social Distribution of Information","IIS","Cyber-Human Systems","09/01/2009","08/20/2009","Leysia Palen","CO","University of Colorado at Boulder","Standard Grant","Ephraim P. Glinert","08/31/2015","$2,396,515.00","James Martin, Douglas Sicker, Kenneth Anderson","palen@cs.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7367","7367, 7925, 9215, HPCC","$0.00","Information and communication technology (ICT) promises to help reduce impacts of large-scale disruptions from natural hazards, pandemics, and terrorist threat. This research focuses on a critical aspect of large-scale emergency response -- the needs and roles of members of the public. By viewing the citizenry as a powerful, self-organizing, and collectively intelligent force, ICT can play a transformational role in crisis situations. This view of a civil society augmented by ICT is based on socio-behavioral knowledge about how people behave in crisis, rather than on simplified and mythical portrayals. With a critical reframing of emergency response as a socially-distributed information system, the project aims to leverage the knowledge of members of the public through reuse of publicly available computer mediated communications (CMCs) (e.g., community, mapping, and social networking sites; blogs; Twitter). The project will study and integrate that heterogeneous information and -- with techniques of information extraction through natural language processing as well as trust and reputation modeling -- add meta-information to help users assess context, validity, source, credibility, and timeliness to make the best decisions for their highly localized, changing conditions.<br/><br/><br/>The results of this research addresses matters of policy, practice and technological innovation, responding directly to needs identified in national policy statements, including Grand Challenge #1 of the National Science and Technology Council's Subcommittee on Disaster Reduction, which calls for the provision of ""hazard and disaster information where and when it is needed"" (SDR, 2005). At-risk populations are disproportionately affected by crises; the results of this research could mitigate the impacts on these communities. The research is also inclusive of people across different cultures/ethnic groups within the U.S. and from different countries. The project broadens the future STEM workforce, since socio-technical and practical orientations to computational research attract women to study STEM disciplines. The research contributions include cyberinfrastructure-aware applications, techniques, and services built from empirical knowledge of the social structures that produce crisis data."
"1157954","CAREER: Development of a Robotic Prosthetic Hand with Programmable Passive Dynamics","IIS","Cyber-Human Systems, ROBUST INTELLIGENCE, National Robotics Initiative","07/20/2011","05/14/2014","Ashish Deshpande","TX","University of Texas at Austin","Continuing grant","Jeffrey Trinkle","04/30/2016","$446,191.00","","ashish@austin.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7367, 7495, 8013","1045, 1187, 7367, 7495, 8086, 9251, 9150","$0.00","A prosthetic robot hand is designed and developed with programmable passive dynamics modeled after human hands. The goals include the development of mathematical models of variable passive dynamics in human hands, the study of the role of passive dynamics in hand operations, the design of novel joint mechanisms, development of a hand prototype and an EMG control interface, and the development of pedagogical laboratory modules for education.<br/><br/>The project develops technology to substantially improve rehabilitation and quality of life for persons with hand disabilities, including amputees returning from ongoing wars. This work addresses the acute need for substantial improvement in the functionality and control mechanisms for prosthetic hands. Most current prosthetic hands do not address the underlying design constraints of a useful prosthetic hand, namely, weight and size limitations, limited control, ease of control and suitable aesthetics. In addition, students learn this new subject and contribute to the advance of science and technology in this domain. Finally, programs are in place to recruit women, individuals with disabilities, and Native American students in engineering research and education."
"1016772","RI: Small: Temporal Causality For Video Event Analysis","IIS","ROBUST INTELLIGENCE","09/01/2010","09/05/2010","James Rehg","GA","Georgia Tech Research Corporation","Standard Grant","Jie Yang","08/31/2014","$455,768.00","","rehg@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7923","$0.00","This project is pursuing a novel strategy for the analysis of temporal structure in video through the exploitation of statistical tests of temporal causality. The motivation is the need for unsupervised video analysis methods which do not require a pre-defined set of video categories or a large corpus of labeled examples. The starting point is the classical formulation of Granger causality, which provides a principled statistical test for directed influence between two time series. Modifying the classical pair-wise Granger test leads to a method which is suitable for video events, which are represented as multiple point processes. Using this representation, methods are being developed for grouping visual words into sets based on their interaction over time. This results in a novel bottom-up segmentation approach which can identify interactions between visual words without supervision. A further goal is the development of an integrated approach to modeling visual events and identifying causal relations. Additional efforts are aimed at developing novel features constructed from causal relations with the goal of improved performance on categorization and retrieval tasks. <br/><br/>In summary, the project is developing new unsupervised methods for representing and segmenting video based on temporal causal analysis. The resulting algorithms yield improved performance in video retrieval and categorization tasks, and provide new approaches to organizing and searching unstructured content such as YouTube videos. Novel datasets for video segmentation and categorization are being developed along with a library of analysis software to facilitate adoption by the research community."
"1116012","RI: Small: A Region-Based Approach to Reconstructing Urban Scenes","IIS","ROBUST INTELLIGENCE","08/01/2011","03/19/2013","Yi Ma","IL","University of Illinois at Urbana-Champaign","Standard Grant","Jie Yang","07/31/2015","$450,000.00","","yima@uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","7923","$0.00","Recently, reconstructing full and detailed 3D models for large-scale urban environments has become the crucial technology for many applications and offers a natural platform for different services. Although conventional structure from motion (SFM) techniques have been engineered to their maturity, they normally do not utilize rich global structures of urban scenes, including regularity, symmetry, and self-symmetry; and the very repetitive shapes and textures ubiquitous in urban scenes make detecting and matching features extremely challenging for the conventional techniques. <br/><br/>This project develops a novel approach for inferring highly accurate 3D geometry from an individual or multiple 2D images of an urban scene. It takes full advantage of the rich global symmetry and regularity in urban scenes by leveraging powerful computational tools from modern high-dimensional convex optimization. The developed method can accurately recover the regular 3D geometry and 2D texture of the scene directly from the raw image pixels/regions without relying on extracting any intermediate local features. The research includes developing a set of useful tools and a full system that can significantly improve the efficiency and scalability of 3D modeling of large urban scenes and give significantly more compact representation of the 3D geometry and 2D appearance, enabling online real-time rendering and visualization.<br/><br/>Research results from this project can be easily integrated into and significantly improve the current computer vision course on 3D reconstruction. The associated technologies can be useful for a very wide range of commercial applications such as online or mobile visual search, visual guidance, navigation, or surveillance, virtual tourism, and augmented reality etc."
"1344205","INSPIRE Track 1: The Informatics of Making","CMMI","INSPIRE, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, SPECIAL STUDIES AND ANALYSES, ENGINEERING SYSTEMS DESIGN, ENG INTERDISC RES (IDR)","10/01/2013","05/19/2014","Vadim Shapiro","WI","University of Wisconsin-Madison","Continuing grant","Christiaan Paredis","09/30/2016","$799,672.00","William Regli","vshapiro@engr.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","ENG","8078, 1640, 7364, 1385, 1464, 7951","1385, 1464, 1640, 7364, 7951, 8653, 068E, MANU","$0.00","This INSPIRE award is partially funded by the Engineering and Systems Design and the Manufacturing programs in the Civil, Mechanical and Manufacturing Innovation Division of the NSF Engineering Directorate and by the Information Integration and Informatics Program in the Division of Information and Intelligent Systems in the NSF Computer and Information Science and Engineering Directorate.<br/><br/>The objective of this research project is to establish a universal formal computational model for the information that flows from design into additive manufacturing. This model plays a role similar to that of the Church-Turing model that underlies general computation. It describes part geometry and materials while connecting to the physics that underlies a part. The computational model is necessary to embody complex information and enable new behaviors in ways that existing tools and technologies cannot accommodate.<br/><br/>In the new world of additive manufacturing, the central embodiment of an artifact, the thing that we buy and sell and improve, will be the information used to additively manufacture an object, not the object itself. This project is developing a language in which to express that information, a language sufficiently rich and rigorous to unleash design capabilities and control manufacturing processes. Development of such a language / model is a critical step to bringing the Maker culture into the economic mainstream."
"1064912","HCC: Medium: Control of a Robotic Manipulator via a Brain-Computer Interface","IIS","Cyber-Human Systems","08/06/2010","05/19/2014","Dean Krusienski","VA","Old Dominion University Research Foundation","Standard Grant","Ephraim P. Glinert","06/30/2015","$655,425.00","","dkrusien@odu.edu","4111 Monarch Way","NORFOLK","VA","235082561","7576834293","CSE","7367","7367, 7924, 9215, HPCC","$0.00","A brain-computer interface (BCI) is a system that allows users, especially individuals with severe neuromuscular disorders, to communicate and control devices using their brain waves. There are over two million people in the United States afflicted by such disorders, many of whom could greatly benefit from assistive devices controlled by a BCI. Over the past two years, it has been demonstrated that a non-invasive, scalp-recorded electroencephalography (EEG) based BCI paradigm can be used by a disabled individual for long-term, reliable control of a personal computer. This BCI paradigm allows users to select from a set of symbols presented in a flashing visual matrix by classifying the resulting evoked brain responses. One of the goals of this project is to establish that the same BCI paradigm and techniques used for the aforementioned demonstration can be straightforwardly implemented to generate high-level commands for controlling a robotic manipulator in three dimensions according to user intent, and that such a BCI can provide superior dimensional control over alternative BCI techniques currently available, as well as a wider variety of practical functions for performing everyday tasks.<br/><br/>Electrocorticography (ECoG), electrical activity recorded directly from the surface of the brain, has been demonstrated in recent preliminary work to be another potentially viable control for a BCI. ECoG has been shown to have superior signal-to-noise ratio, and spatial and spectral characteristics, compared to EEG. But the EEG signals used at present to operate BCIs have not been characterized in ECoG. The PI believes ECoG signals can be used to improve the speed and accuracy of BCI applications, including for example control of a robotic manipulator. Thus, additional goals of this project are to characterize evoked responses obtained from ECoG, to use them as control signals to operate a simulated robotic manipulator, and to assess the level of control (speed and accuracy) between the two recording modalities and compare the results to competitive BCI techniques. Because this is a collaborative effort with the Departments of Neurology and Neurosurgery at the Mayo Clinic in Jacksonville, the PI team will have access to a pool of ECoG grid patients from which to recruit participants for this study.<br/><br/>Broader Impacts: This research will make a number of contributions in the emerging field of BCI and thus will serve as a step toward providing severely disabled individuals with a new level of autonomy for communicating with others and for performing everyday tasks, which will ultimately dramatically improve their quality of life."
"0954083","CAREER: Discriminative Spatiotemporal Models for Recognizing Humans, Objects, and their Interactions","IIS","ROBUST INTELLIGENCE","06/01/2010","05/19/2014","Deva Ramanan","CA","University of California-Irvine","Continuing grant","Jie Yang","05/31/2015","$444,511.00","","dramanan@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","1045, 1187","$0.00","One of the goals of computer vision is to build a system that can see people and recognize their activities. Human actions are rarely performed in isolation -- the surrounding environment, nearby objects, and nearby humans affect the nature of the performed activity.<br/>Examples include actions such as ""eating"" and ""shaking hands."" The research goal of this project is to approach human performance in understanding videos of activities defined by human-object and human-human interactions.<br/><br/>This project makes use of structured, contextual representations to make predictions given spatiotemporal data. It does so by extending recent successful work on object recognition to the space-time domain, introducing extensions for spatiotemporal grouping and contextual modeling. Video enables the extraction of additional dynamic cues absent in static images, but this poses additional computational burdens that are addressed through algorithmic innovations for approximate parsing and large-scale discriminative learning.<br/><br/>To place activity recognition on firm quantitative ground, the proposed models are evaluated using concrete metrics based on activities of daily living (ADL) and human proxemic models from the medical and anthropological communities. Examples include systems for automated monitoring of stroke patients interacting with everyday objects and automated analysis of crisis response team interactions during emergency drills. This project produces non-scripted, real-world, labeled action recognition datasets, of benefit to the research community as a whole."
"1444234","CAREER: Toward a General Framework for Words and Pictures","IIS","ROBUST INTELLIGENCE","08/28/2013","05/07/2014","Tamara Berg","NC","University of North Carolina at Chapel Hill","Continuing grant","Jie Yang","05/31/2016","$174,244.00","","tlberg@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","1045, 1187","$0.00","Pictures convey a visual description of the world directly to their viewers. Computer vision strives to design algorithms to extract the underlying world state captured in the camera's eye, with an overarching goal of general computational image understanding. To date much vision research has approached image understanding by focusing on object detection, only one perspective on the image understanding problem. This project looks at an additional, complimentary way to collect information about the visual world -- by directly analyzing the enormous amount of visually descriptive text on the web to reveal what information is useful to attach to, and extract from pictures. This project presents a comprehensive research program geared toward modeling and exploiting the complimentary nature of words and pictures. One main goal is studying the connection between text and images to learn about depiction -- communication of meaning through pictures. This goal is addressed through 3 broad challenges: 1) Developing a richer vocabulary to describe the information provided by depiction. 2) Developing image representations that can visually capture this more nuanced vocabulary. 3) Constructing a comprehensive joint words and pictures framework. <br/><br/>This project has direct significance to many concrete tasks that access images on the internet including: image search, browsing, and organization, as well as commercial applications such as product search, and societally important applications such as web assistance for the blind. Additionally, outputs of this project, including progress toward a natural vocabulary and structure for visual description, have great potential for cross-cutting impact in both the computer vision and natural language communities."
"0905581","DC: Medium: Collaborative Research: ELLF: Extensible Language and Library Frameworks for Scalable and Efficient Data-Intensive Applications","IIS","DATA-INTENSIVE COMPUTING, INFO INTEGRATION & INFORMATICS","09/01/2009","05/16/2014","Eric Van Wyk","MN","University of Minnesota-Twin Cities","Standard Grant","Sylvia J. Spengler","08/31/2014","$810,000.00","Vipin Kumar, Michael Steinbach","evw@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7793, 7364","7793, 7924, 9216, HPCC, 9251, 7364, 7752","$0.00","The growth of scientific data sets to petabyte sizes offers significant opportunities for important discoveries in fields such as combustion chemistry, nanoscience, astrophysics, climate prediction and biology as well as from data on the internet. However, the realization of new scientific insights from this data is limited by the difficulty of creating scalable applications due to the lack of easy-to-use programming models and tools. To address challenges in creating data intensive applications, the project will build an extensible language framework, backed by an expressive collection of high-performance libraries (I/O and analytic), to provide a development environment in which multiple domain-specific language extensions allow programmers and scientists to more easily and directly specify solutions to data-intensive problems as programs written in domain-adapted languages. The project will build on recent attribute grammar research to build an extensible specification of C to host domain-specific language extensions which will also address the inadequate performance in storage, I/O and analysis capabilities in low-level language such as C. <br/><br/><br/><br/>The proposed extensible language and library framework has the potential to be a transformative problem solving environment for programmers and scientists since it allows scalable and efficient solutions to data-intensive problems to be specified at a high-level of abstraction. The resulting language framework and libraries will be freely available to researchers writing applications for climate and other applications involving spatio-temporal data. This includes many applications in the physical sciences and engineering and thus it is expected that the framework will find use in other scientific domains as well."
"1160894","III: Medium: Collaborative Research: Connecting the Ephemeral and Archival Information Networks","IIS","INFO INTEGRATION & INFORMATICS","08/01/2012","05/15/2014","W. Bruce Croft","MA","University of Massachusetts Amherst","Continuing grant","Maria Zemankova","07/31/2016","$607,407.00","","croft@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","7924","$0.00","This collaborative research project (IIS-1160894, W. Bruce Croft, University of Massachusetts Amherst and IIS-1160862, Jamie Callan, Carnegie-Mellon University) addresses the complex issues of ephemeral information that is generated as part of social interactions is different in terms of time scale, quantity, and quality to archival information found on the web. This project investigates the hypothesis that, because of the context provided, searching either ephemeral or archival information is enhanced using the connections between them. It develops new retrieval models and features for ranking functions in a range of search tasks that can exploit an integrated ephemeral/archival network. Some search tasks are based on previous TREC blog, microblog, and web activities. It also investigates two new tasks, conversation retrieval and aggregated social search. Conversation retrieval targets information units in the form of ""conversations"" or ""events"" instead of simply retrieving social postings or web pages. Aggregated social search ranks information in different granularities, such as sentence, posting, conversation, or thread, based on the underlying query intent. <br/><br/>Research that explores the connections between ephemeral and archival information requires a dataset that contains both types of information. A crucial part of this project extends the archival ClueWeb12 dataset with ephemeral microblog, blog, and discussion forum data that links to the web data. This extension is distributed to the research community as the ClueWeb12++ dataset. This project (http://ciir.cs.umass.edu/research/ephemeral/) is the first to address the full possibilities of search that exploits all the connections and contexts created by bringing together the two ""worlds"" of information. It also develops and distributes a unique new dataset that supports the development of a new generation of tools to access a broad range of information. Students at collaborating institutions, University of Massachusetts Amherst and Carnegie-Mellon University will be involved in educational activities and benefit from research experience."
"1444648","WORKSHOP: Joint Doctoral Colloquium at the UbiComp 2014 and ISWC 2014 Conferences","IIS","Cyber-Human Systems","07/01/2014","05/15/2014","Shwetak Patel","WA","University of Washington","Standard Grant","Ephraim P. Glinert","06/30/2015","$30,755.00","","shwetak@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7556","$0.00","This is funding to support a joint doctoral research colloquium (workshop) of approximately 20 promising doctoral students from the United States and abroad (up to 2 international participants to be supported by NSF), to be selected through a peer review process, along with two panels of 4 invited outstanding researchers from both academic and industrial labs (of these, 18 will be supported by NSF funds and the remaining 10 from sponsorship and other sources). The event will take place in conjunction with the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp) and the 18th ACM International Symposium on Wearable Computing (ISWC), to be collocated in Seattle on September 13-17, and which are sponsored by the Association for Computing Machinery.<br/><br/>The ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp) is the result of a merger of the two most renowned conferences in the field: Pervasive and (the former) UbiComp. While it retains the name of the latter in recognition of the visionary work of Mark Weiser, its long name reflects the dual history of the new event. UbiComp is a premier interdisciplinary venue in which leading international researchers, designers, developers, and practitioners in the field present and discuss novel results in all aspects of ubiquitous and pervasive computing. This includes the design, development, and deployment of ubiquitous and pervasive computing technologies and the understanding of human experiences and social impacts that these technologies facilitate. Relevant research topics include, but are not limited to, systems and infrastructures, devices and techniques, applications and experiences, methodologies and tools, and theories and models. More information about the conference may be found at http://www.ubicomp.org/ubicomp2014. <br/><br/>ISWC is a conference dedicated to cutting-edge research in wearable technologies, and is the premier forum for wearable computing and issues related to on-body and worn mobile technologies. Every year, ISWC brings together researchers, product vendors, fashion designers, textile manufacturers, users, and related professionals to share information and advances in wearable computing. The 18th edition of ISWC is scheduled to include dedicated workshops, a juried design competition, a lively gadget show, and high-quality paper presentation sessions revealing the latest in wearable computing progress. More information about this conference may be found at http://iswc.net/iswc14/. <br/><br/>The goals of the ISWC/UbiComp Doctoral Colloquium are: to provide a forum that will allow senior-level doctoral students to attend the ISWC/UbiComp conferences and take part as contributors to the program, as well as encourage further participation in the future; to give emerging ISWC and UbiComp researchers the opportunity to present their work and receive feedback, guidance, and encouragement from respected researchers to whom they may not have ready access at their home institutions; to provide opportunities for discussion among senior-level doctoral students to expose them to new perspectives on their field and in closely related fields; to foster the building of research relationships that will continue to benefit the students as they progress in their careers; and to expose the diversity and depth of research in the field as being undertaken by junior researchers to the greater UbiComp/ISWC community. To these ends, the format of the doctoral colloquium will facilitate the open exchange of ideas and in-depth discussion among members of the next generation of wearable and ubiquitous computing researchers and established top researchers in the area. The colloquium will begin with a joint ""madness"" session in which all participants will present a 1-minute version of their research. Subsequently, participants will present in-depth in two parallel tracks, attended by the respective conference panels. Students will be encouraged to move freely between the sessions, attending presentations according to their interests. The colloquium will close with a joint career development panel. Meals and breaks will be shared. Presentations will be scheduled with ample time allotted for questions and constructive feedback from the panel and from the other student participants. Particular emphasis will be given to such topics as focusing research questions and ensuring that research activities appropriately address the research questions, the selection and application of fitting and correct methods given the intended contributions of the work, and the appropriate analysis, framing, and communication of findings, results, and contributions. Additional opportunities for more informal discussion and networking will be during the DC lunch and dinner events. Extended abstracts from the DC will be distributed in the conference's adjunct proceedings to all conference attendees, and indexed in the ACM and IEEE digital libraries, offering further exposure. Finally, colloquium participants will also be asked to prepare a poster for a joint ISWC/UbiComp DC poster session as part of the main conference.<br/><br/>The doctoral colloquium will help expand the participation of young researchers pursuing graduate studies in the various fields associated with ubiquitous computing, by affording them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Several participants in past UbiComp doctoral consortia have since gone on to high profile research careers. To support diversity among the student participants, the event organizers have committed that no more than 2 students will be accepted from any one institution."
"1256172","EAGER: A Nugget-Based Information Retrieval Evaluation Paradigm","IIS","INFO INTEGRATION & INFORMATICS","09/15/2012","09/25/2012","Javed Aslam","MA","Northeastern University","Standard Grant","Maria Zemankova","02/28/2015","$150,000.00","","jaa@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7364","7364, 7916","$0.00","Evaluating information retrieval systems, such as search engines, is critical to their effective development. Current performance evaluation methodologies are generally variants of the Cranfield paradigm, which relies on effectively complete, and thus prohibitively expensive, relevance judgment sets: tens to hundreds of thousands of documents must be judged by human assessors for relevance with respect to dozens to hundreds of user queries, at great cost both in time and expense. This exploratory project investigates a new alternative to information retrieval evaluation paradigm -- based on ""nuggets"". ""Nuggets"" are atomic units of relevant information, and one instantiation of these nuggets is simply the sentence or short passage that causes a judge to deem a document relevant at the time of document assessment. The hypothesis is that while it is likely impossible to find all relevant documents for a query with respect to web-scale and/or dynamic collections, it is much more tractable to find all or nearly all nuggets (i.e., relevant information), with which one can then perform effective and reusable evaluation, at scale and with ease. At evaluation time, relevance assessments are dynamically created for documents based on the quantity and quality of relevant information found in the documents retrieved. This new evaluation paradigm is inherently scalable and permits the use of all standard measures of retrieval performance, including those involving graded relevance judgments, novelty, diversity, and so on; it further permits new kinds of evaluations not heretofore possible.<br/><br/>The project plan includes the development and release of nugget-based evaluation data sets for use by academia and industry. In fostering this effort, the project team has close ties with the US National Institute of Standards and Technology (NIST) and the Japanese National Institute of Informatics (through NTCIR), two of the premier organizations that develop and release information retrieval data sets. All research results and data sets developed as part of this project are available at the project website (http://www.ccs.neu.edu/home/jaa/IIS-1256172/). The project also provides educational and training experience for students and the development of curricular materials based on the project results."
"1317560","Collaborative Research: Visual Cortex on Silicon","CCF","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","10/01/2013","05/15/2014","Vijaykrishnan Narayanan","PA","Pennsylvania State Univ University Park","Continuing grant","Ephraim P. Glinert","09/30/2018","$1,948,787.00","John Carroll, Chitaranjan Das, Mary Beth Rosson, C. Giles","vijay@cse.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","1640, 7367","7723, 7367, 9251","$0.00","The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br/><br/>While several machine vision systems today can each successfully perform one or a few human tasks - such as detecting human faces in point-and-shoot cameras - they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br/><br/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned."
"1116530","RI: Small: Robust Auditory Object Recognition with Spike Sequence Coding and the State-Dependent Dynamics of Cortical Networks","IIS","ROBUST INTELLIGENCE","09/01/2011","08/22/2011","Dezhe Jin","PA","Pennsylvania State Univ University Park","Standard Grant","Kenneth C. Whang","08/31/2014","$296,470.00","","djin@phys.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7495","7923","$0.00","Recognizing speech or other auditory objects in adverse environments -- e.g. with noise, reverberation, and multiple speakers -- is essential for human and animal communication. Current speech recognition technologies work well in high signal-to-noise conditions, but perform orders of magnitude below human performance in adverse conditions. Converging evidence from neuroscience suggests that auditory information is encoded in sparse and precisely timed spikes of sub-cortical neurons. However, the extent to which codes based on spike timing might underlie the robustness of human auditory object recognition has not yet been fully investigated. This project bridges this gap by devising a biologically inspired computational model of auditory processing at the cortical level and extracting computational principles that are essential for the model to achieve robust auditory object recognition.<br/><br/>The approach is to transform sounds into the spike sequences generated by feature-detecting thalamic auditory neurons, and to integrate these spikes spatially and temporally using the state-dependent dynamics of cortical neurons with active dendrites. In the proposed model, an auditory object first evokes sequential spiking of thalamic neurons that have been trained to detect useful features. Then, through feed-forward excitation and inhibition from the thalamus, and lateral excitation and inhibition from the cortical neurons, the state of the cortical network evolves, leading to temporal integration. Recognition of the auditory object is signaled when the cortical neurons reach a specific network state. The computational model is constrained by experimental results on the properties of cortical neurons, the organization principles of cortical networks, and the activity-dependent plasticity rules of the network structures. The project aims both to design feature detectors that can robustly represent auditory objects with spatiotemporal spike sequences, and to build a cortical network model that can recognize specific auditory objects using state transitions driven by the thalamic inputs, with neuron dynamics that can be compared with those observed in the auditory cortex. The recognition performance of the computational model will be evaluated and improved with auditory tasks designed to compare different approaches to speech recognition."
"1444630","Student Support for User Modeling, Adaptation and Personalization Conference","IIS","Cyber-Human Systems","06/01/2014","05/14/2014","Bamshad Mobasher","IL","DePaul University","Standard Grant","Ephraim P. Glinert","05/31/2015","$15,330.00","","mobasher@cs.depaul.edu","1 East Jackson Boulevard","Chicago","IL","606042287","3123418000","CSE","7367","7367, 7556","$0.00","User interfaces that adapt themselves to available user information (such as special needs or individual preferences) are becoming increasingly important, so much so that adaptability has become a selling point for software products. A system with the ability to construct and consult a user model (an explicit representation of properties of a particular user or group of users) can adapt diverse aspects of its performance and enhance its effectiveness, usability and/or acceptance in a variety of situations (e.g., to reduce information overload, to improve the quality of information retrieval, filtering and annotation, and to generate useful information visualizations). Applications for user modeling range from electronic commerce and intelligent learning environments to health care and assistive technologies. Relevant platforms for user modeling include mobile and wearable systems and smart environments, as well as individual desktop systems, groupware, adaptive hypermedia, and other web-based systems. <br/><br/>The annual International Conferences on User Modeling, Adaptation and Personalization (UMAP) are the premier forum at which academic and industrial researchers from all these fields gather to exchange their complementary insights on user modeling issues. UMAP is a merger of the long-running and successful International Conferences on User Modeling (UM, 1986-2007), and the more recent important series of Adaptive Hypermedia and Adaptive Web-Based Systems Conferences (AH, 2000-2008). This is funding to support travel for up to 5 students currently enrolled in PhD programs in U.S. institutions, to present their accepted papers and posters and/or to attend the Doctoral Consortium associated with the 22nd UMAP Conference (UMAP 2014), to be held in Aalborg, Denmark, on July 7-11. More information about the conference is available at http://www.um.org/umap2014/. <br/><br/>This year's UMAP will once again include a Doctoral Consortium session, thereby continuing the tradition established at UMAP 2009 and before that at both the UM and AH conferences. Lively and useful discussions have enabled students to receive suggestions about their ongoing research and allowed more experienced participants to hear some fresh ideas and view some of the new trends in the field. Students whose work has been selected for presentation at the Doctoral Consortium will be invited to write a paper that will be published in the UMAP 2014 conference proceedings. They will have 15 minutes to present their work (which may include a short demonstration if appropriate), to be followed by an additional 15 minutes for questions and discussion. During both the question/discussion period and in subsequent informal interactions, organizing committee members and other participants will provide constructive comments on each student's work and attempt to address aspects on which the student has requested advice. <br/><br/>Attending and presenting their work at UMAP, the top conference in its field, will have a significant impact on the careers of the future generation of user modeling, adaptation, and personalization researchers. Students who participate in the Doctoral Consortium will also benefit from that experience in several ways. First, they will have the opportunity to present their work to a knowledgeable audience and get useful comments at an early stage of their research when it will be most useful. Just as importantly, they will have an opportunity to meet established researchers and other graduate students doing similar work, to exchange ideas, and to make contacts that will be invaluable to them as they progress in their scientific careers. Interacting with the young researchers is also useful to more experienced investigators, by providing new perspectives. Thus, the Doctoral Consortium is a great confidence builder for the students involved, and highly stimulating to the established researchers who participate. Many past participants in the UMAP Doctoral Consortium have gone on to become well-regarded researchers and practitioners in the field. The organizers have reaffirmed the long-standing and demonstrated UMAP commitment to diversity; to this end, they will make special efforts to recruit participants who are women and members of under-represented groups, and they will ensure institutional diversity by supporting no more than one student from any given university."
"1444493","III: Small: Collaborative Research: Detection and Presentation of Community and Global Event Content from Social Media Sources","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","05/14/2014","Mor Naaman","NY","Cornell University","Continuing grant","Sylvia J. Spengler","08/31/2014","$113,512.00","","mor.naaman@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7364","7923, 7364","$0.00","Social media sites such as Twitter, Facebook, YouTube, and Flickr host an ever-increasing amount of user content captured or produced in association with real-world events, from presidential inaugurations to community-specific events. Unfortunately, the existing tools to find, organize, and present the social media content associated with events are extremely limited. This project will address critical end-to-end information processing and presentation methods that will transform public access to real-world event information from social media sources. In particular, this work will increase the digital presence of currently underrepresented communities and address their information needs: for these communities, events are often not covered by mainstream media, but are increasingly available on social media services. As a distinctive characteristic, the project will draw on several research areas, namely, information retrieval and databases, human-computer interaction, and social media, thus contributing to educating multidisciplinary students. The PIs will continue to include undergraduate students and students from underrepresented populations in the research.<br/><br/>The project will result in new data analysis and visualization techniques for event-based information tasks, addressing human and computational factors in social media systems to handle vast collections of noisy, user-contributed content of widely varying structure and quality. To enable effective browsing, search, and presentation of event content, this work will use the wealth of social media documents to address several fundamental problems. The first<br/>problem is the detection of events in repositories of social media content. Such content, increasingly posted by users in real time, is noisy and highly heterogeneous, but can help in the early detection of a wide range of events of all sizes. The second problem is the comprehensive identification of content related to detected or known events, currently fragmented across social media sites and often hard to find and collect. The third problem is content presentation, which requires the development of novel presentation and visualization techniques for social media event content. The amount of content<br/>available even for a single event can be overwhelming and hinder data exploration and sense-making. <br/><br/>The project will create new tools that will transform the viewing experience of the event information. These tools will allow users to create and share personalized views of the event data as a story-telling practice. Finally, as a main outcome, the data used in the research will be made available to other researchers whenever possible. Moreover, another main outcome will be a publicly available prototype system based on this research, designed to help connect computing and information science challenges to the activities and natural interests of a diverse set of users."
"1319909","III: Small: Collaborative Research: Supporting Efficient Discrete Box Queries for Sequence Analysis on Large Scale Genome Databases","IIS","INFO INTEGRATION & INFORMATICS, Big Data Science &Engineering","09/01/2013","05/14/2014","Sakti Pramanik","MI","Michigan State University","Standard Grant","Sylvia J. Spengler","08/31/2016","$281,419.00","Charles Brown","pramanik@cse.msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7364, 8083","7364, 7433, 7923, 8083, 9251","$0.00","This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets (i.e., overlapping k-length subsequences obtained from genome sequences) for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, including error correction, variant detection, and assembly, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. The approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are explored. The results from this research will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial. <br/><br/>This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. In particular, a new index tree, named the BoND-tree, specially designed for a non-ordered discrete data space characterized by k-mer data sets is developed. The unique properties of the space are exploited to develop new node splitting heuristics for the index tree, and theoretical analysis is performed to show the optimality of the proposed heuristics. Besides the BoND-tree, which is based on data partitioning, space-partitioning based index schemes for box quieres in such a space are also developed. To support a more flexible type of query (i.e., hybrid box and range queries), hybrid index schemes integrating strengths of both box query indexes and range query indexes are studied. To facilitate an efficient index construction for large scale k-mer data sets, bulk loading techniques are also developed for the proposed index trees. In addition, the approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are also explored. The research in the project will result in the discovery of fundamental properties of the data space for sequence data in bioinformatics, the development of a number of novel storage, indexing and retrieval techniques exploiting the properties of such a data space, and the applications of the proposed techniques for solving important problems in sequence analysis. These results will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial."
"1065024","RI: Medium: Collaborative Research: Towards Perpetual Flight of a Gliding Unmanned Aerial Vehicle in the Jet Stream","IIS","ROBUST INTELLIGENCE","03/01/2011","04/08/2013","Jacob Langelaan","PA","Pennsylvania State Univ University Park","Continuing grant","Satyandra Gupta","02/28/2015","$242,365.00","","jlangelaan@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7495","7924","$0.00","The necessary science and technology are developed to demonstrate sustained dynamic soaring of an unmanned aerial vehicle. This has four primary components. First, the team develops novel, real-time solutions specific to the dynamic soaring motion planning problem to enable perpetual flight. Second, they develop compact representations for estimating wind field in real time. These measurements serve as input to the motion planner to optimize energy that is recovered from a given soaring cycle. Third, they develop a novel airframe whose design is tightly coupled with motion planning algorithm development. Finally, a significant technical evaluation is performed which culminates in a demonstration of sustained low-altitude dynamic soaring.<br/><br/>The realization of unmanned aerial vehicles capable of staying aloft is transformative for many fields, e.g., as a low altitude and cost alternative to conventional satellite systems. Such pseudo-satellites serve as a sensor network and provide surveillance data, weather monitoring, and act as relay nodes in telecommunications networks. They are put into place, recovered, and maintained without the significant expense and failure risk associated with a space launch. A dynamically soaring unmanned aerial vehicle is ideal for hurricane observation since the craft is designed with the required strength and the associated wind gradients provide sufficient aircraft endurance for the life of the storm. One major outreach effort is the Robotics and Aerospace Camp for a group of 20-30 eighth and ninth grade students; this is part of a year round academy to promote academic achievement and college placement for economically and academically challenged middle level and high school students."
"1218346","HCC: Small: Semantic Interaction for Visual Text Analytics","IIS","Cyber-Human Systems","09/01/2012","05/14/2014","Christopher North","VA","Virginia Polytechnic Institute and State University","Continuing grant","Kevin Crowston","08/31/2015","$516,000.00","","north@cs.vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7367","7367, 7923, 9251","$0.00","The goal of this project is to enable the creation of new human-centered computing tools that will help people effectively analyze large collections of textual documents by providing powerful statistical analysis functionality in a usable and intuitive form. To accomplish that, this project investigates ""semantic interaction"" in visual analytics as a method to combine the large-data computationally-intensive foraging abilities of formal statistical mining algorithms with the intuitive cognitively-intensive sensemaking abilities of human analysts. Semantic interaction enables users to inject their domain expertise into the algorithms by interacting directly with the data. For example, analysts synthesize hypotheses about a set of documents by simply re-organizing them within a spatial visualization, highlighting important sentences, or annotating in the margins. Meanwhile, the underlying statistical models learn from these actions and interactively respond to help spatially organize additional relevant information according to the user's feedback. <br/><br/>Intellectual merit: Semantic interaction offers a new approach to interactive visual analytics that emphasizes usability. This research will (1) contribute new user interaction and visual feedback techniques for naturally controlling algorithms via the interactive sensemaking process; (2) contribute a flexible visual analytics framework that seamlessly integrates mathematical models with interactive visualization; and (3) evaluate the effectiveness of semantic interaction, which provides a quantitative mechanism to investigate the complex interplay between human intuition and formal statistical methods.<br/><br/>Broader impacts: This research will support a broad range of applications in visual text analytics, including intelligence analysis, funding portfolio management, and literature research. Participating agencies will test the software in ecologically valid settings. The software framework will be distributed to enable others to integrate additional models and to provide a usable platform for analysts. The project also proposes an educational and outreach agenda called ""CS for CSI"" that exploits the popularity of crime investigation stories to attract young students to technology research."
"1218729","RI: Small: Distributed Combinatorial Optimization for Crowd-Scene Analysis","IIS","ROBUST INTELLIGENCE, COMM & INFORMATION FOUNDATIONS","09/01/2012","08/30/2012","Robert Collins","PA","Pennsylvania State Univ University Park","Standard Grant","Jie Yang","08/31/2015","$450,000.00","","rcollins@cse.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7495, 7797","7323, 7923, 7936","$0.00","This project develops efficient computer vision algorithms based on distributed message passing for solving crowd-scene analysis tasks such as detection and tracking of closely spaced individuals. These and other vision tasks can be formulated as discrete combinatorial optimization problems, e.g., binary linear or quadratic programs, and studying their underlying mathematical structure can yield insights that allow larger and more challenging problem instances to be addressed. Recent theoretical work proving the correctness of message passing for some classes of binary linear programming problems is being leveraged to develop practical vision algorithms for crowd scene analysis and extended to develop algorithms for finding good approximate solutions to harder problems. The project team is also exploring approximate inference methods based on randomization and on decomposition of large-scale problems into collections of interrelated subtasks that can be solved more efficiently and in parallel. <br/><br/>Automated vision systems can continuously monitor crowded public spaces to provide real-time situational awareness of crowd density and to detect early signs of dangerous behavior or deviations from normal traffic flow. The ability to track individuals through a crowd and to detect the interactions of groups of people has applications in the areas of homeland security, law enforcement, and defense. Results from this project will be disseminated through collaboration with other scholars, publication of peer-reviewed articles, presentations at professional meetings, introduction of course modules into the graduate and undergraduate computer science curriculum, and through public release of source code."
"1211059","SoCS: Geodeliberation: Enabling Democratic Decision-Making in Local Communities Through Place-Based Deliberative Dialogues","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2012","07/29/2013","Guoray Cai","PA","Pennsylvania State Univ University Park","Continuing grant","William Bainbridge","08/31/2015","$755,797.00","John Carroll","cai@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367, 7953","7367, 7953, 9251","$0.00","This project seeks to discover new knowledge required to support geodeliberation in community geospatial decision-making contexts. Geodeliberation refers to democratic deliberation (within local communities) on complex and controversial geographically-defined problems and involves the use of geographical information and online, asynchronous deliberative technologies. This research addresses two key knowledge gaps. One is the lack of understanding about human information and interaction behavior while engaging online asynchronous geodeliberation, and the methodological challenges of supporting community-scale deliberation of complex geospatial problems over sustained engagements. A more formidable gap is between the desirable level of public involvement and the practical level of participation that can be supported by the current social-technical solutions. To address these gaps, the research applies an ethnographically-guided participatory research approach to: (1) identify opportunities and barriers in using geodeliberation to empower communities; and (2) investigate visual-computational methods to enable human participation and facilitation of geodeliberation processes. <br/><br/>This research will contribute to the foundations of a science of geodeliberation, including both an understanding of key processes and a set of design techniques for social and visual-computational support of geodeliberation. It will focus on issue-related narratives about personal experiences, sensemaking with respect to synthesizing disparate geo-planning views and issues, and the development of public judgment and common ground for mutual understanding and collective action. These research activities are integrated around a prototype - GeoDeliberator. The approach will incorporate methods from three domains: cognitively-motivated design of visual representations and interfaces; models of deliberative discourse and decision-making in communities; and active facilitation of large-scale geodeliberation towards better coherence and effectiveness.<br/><br/>The research addresses broader impacts of three kinds. First, this project will demonstrate the potential of using information technology to improve civic engagement in community-level. Second, the design research investigation of socio-technical support for geodeliberation will provide a concrete model for local governments across the nation. Third, this project will prepare a generation of undergraduate and graduate students with consciousness and career potentials in applying social-technical solutions in the practice of democratic decision-making."
"1248076","INSPIRE: Symmetry Group-based Regularity Perception in Human and Computer Vision","IIS","INFORMATION TECHNOLOGY RESEARC, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE, INSPIRE","10/01/2012","09/09/2012","Yanxi Liu","PA","Pennsylvania State Univ University Park","Standard Grant","Jie Yang","09/30/2015","$800,000.00","Anthony Norcia, Rick Gilmore","yanxi@cse.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","1640, 7252, 7495, 8078","8653","$0.00","This INSPIRE award is partially funded by the Robust Intelligence (RI) Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering, and the Perception, Action and Cognition (PAC) Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral and Economic Sciences.<br/><br/>This research integrates theoretical, experimental and algorithmic thrusts to construct a novel conceptual framework for predicting and understanding the full range of regularity perception, both in humans, by measuring human brain activation and behavior, and in machines, through a computational framework for adaptive symmetry detection in computer vision. The ability to detect patterns in natural scenes serves critical biological needs while posing substantial computational difficulties for machine intelligence. Research on human and computer perception of pattern regularity has primarily focused on bilateral symmetry, despite a wide variety of regular patterns beyond reflection. A unique feature of the proposed project is to use symmetry group theory as an organizing principle for the study of both human and computer perception of patterns. Symmetry group theory, instantiated by its subgroup hierarchy, provides a formal and exhaustive categorization of all regular patterns. <br/><br/>The project sits at an interdisciplinary nexus between computer science, psychology, neuroscience, and mathematics. The outcomes of this research could potentially transform the theory of human pattern perception and make a quantum leap in robust automatic detection of real world regularities. Because patterns are ubiquitous, this research impacts all information processing systems challenged by large digital datasets that are hard to explore manually. Its impact is strengthened further by a systemic outreach to the respective research communities through interdisciplinary workshops, publications, data sharing, classroom lectures, postdoc and student training. Applications include anomaly detection in medicine and surveillance data; mobile robot localization in man-made environments; and generic pattern indexing and retrieval."
"0844947","CAREER: Collaborative Information Behavior: Exploring and Supporting Collaboration during Information Seeking and Retrieval Activities","IIS","Cyber-Human Systems","02/01/2009","02/11/2013","Madhu Reddy","PA","Pennsylvania State Univ University Park","Continuing grant","Ephraim P. Glinert","01/31/2015","$551,475.00","","mreddy@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","1045, 1187, 7367, 9215, 9251, HPCC","$0.00","With the advent and continuing spread of the Internet and the World-Wide Web, information resources are becoming more and more widely available. As people in all walks of life try to use these resources to find answers to questions about issues ranging from finance to personal health, there is a general recognition that it is very difficult for individuals to find relevant information. One approach to dealing with this problem is to combine the abilities and experiences of multiple information seekers. Future information retrieval systems will therefore have to focus not only on how individuals can access and search the volumes of available information, but also on how they can collaborate with each other to find the most relevant information that meets their needs. The mounting evidence that collaborative information behavior (CIB) plays an important role in organizational work notwithstanding, most information retrieval systems (and their underlying conceptualizations of information behavior) still adopt the individual user's perspective. Focusing solely on individual information behavior has led to processes and technologies that often constrain CIB, which can be acutely problematic in settings where teams and team work are important. The PI argues that while individual information behavior cannot be ignored, we must strive to develop processes that equally support CIB, because effective integration of information retrieval technology into collaborative environments requires us to incorporate not eliminate collaboration in these technologies. His goal in this project is to address our current inability to do that, by improving our theoretical understanding of the CIB process and by advancing the design of information retrieval systems as well, in the hope of thereby alleviating the impediments to team success in critical domains. To these ends, the PI will investigate CIB in team settings within the healthcare and education domains. He will develop a model of CIB, design and implement a collaborative information retrieval prototype system, and conduct both laboratory and field evaluations of it. Project outcomes will include a better understanding of how and why people collaborate when searching for information, and how to design technologies that effectively support that collaboration.<br/><br/>Broader Impacts: This research will lead to the development of new processes and technologies that will allow people to share their knowledge, techniques, and results with each other in order to quickly and effectively meet their information needs."
"1017247","HCC: Small: Collaborative Privacy Practices: Exploring Privacy in Information Intensive Environments","IIS","Cyber-Human Systems","09/01/2010","07/30/2013","Madhu Reddy","PA","Pennsylvania State Univ University Park","Standard Grant","Ephraim P. Glinert","08/31/2015","$507,981.00","Heng Xu","mreddy@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7923, 9251","$0.00","Information privacy and security has long focused on the individual. Most technological safeguards and policies have been oriented towards individual privacy practices (IPP). Yet, many organizational settings are highly collaborative where team work is the norm. Consequently, project researchers will investigate why and how people enact collaborative privacy practices (CPP) and provide design recommendations to develop more effective mechanisms to assure privacy during these activities. <br/>Specifically the project will<br/>1. Improve the conceptual understanding of CPP by investigating these practices in highly collaborative and information-intensive domain where information privacy is essential (e.g., healthcare)<br/>2. Develop a conceptual model of CPP using a multi-method research approach<br/>3. Examine privacy-enhancing technical features that can most effectively support CPP<br/>This project will make three contributions to our knowledge of privacy and security. First, it will advance the theoretical understanding of the collaborative nature of privacy practices. Second, this project will advance the design of privacy enhancing technologies to focus on collaborative privacy practices. Third, it will help foster more effective design interventions by understanding the users? collaborative privacy practices that are often ignored in technical and organizational specifications of privacy and security.<br/>The future development of privacy-enhancing features in information systems must not only focus on privacy assurance for individual users but also privacy assurance during collaborative activities. That is the central thrust of this project. Its broader impact lies in the development of new processes, policies, and technologies to support privacy in collaborative environments without hindering people?s activities in these environments."
"0915268","HCC-Small: DHH Cyber-Community - Supporting Deaf and Hard of Hearing Students in STEM Fields","IIS","Cyber-Human Systems","07/15/2009","05/14/2014","Richard Ladner","WA","University of Washington","Standard Grant","Ephraim P. Glinert","06/30/2015","$523,889.00","Caroline Solomon, Edward Clymer","ladner@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7923, 9215, 9251, HPCC","$0.00","Succeeding in mainstream universities (at all levels) involves extra challenges for deaf and hard of hearing students. Skilled sign language interpreters and captioners with advanced domain knowledge are often difficult to find, multiple visual channels of information in the classroom can be hard to juggle, and collaboration both inside and outside the classroom is often strained due to language barriers. Furthermore, translation of advanced STEM (Science, Technology, Engineering, and Mathematics) topics into American Sign Language (ASL) is far from standardized, and often requires discussion between students and interpreters to devise consistent signs. Better access to classroom activities and a consistent, conceptually clear signing system for STEM topics are both vitally needed in order for deaf and hard of hearing students to advance in the sciences. Thus, in this project the PI will design, implement, and evaluate two distinct yet interconnected technologies. The first of these is ClassInFocus, a classroom platform to help students access remote interpreters and captioners, avoid visual dispersion, and facilitate interaction in the classroom. ClassInFocus will utilize the existing high bandwidth internet connections at multiple universities to create more opportunity for finding the best qualified interpreter or captioner for specific STEM topics. Designing, implementing, and evaluating technological solutions that best meet the educational needs of deaf and hard of hearing students is a challenging research problem; this immersive technology that brings many different technical and human resources into the classroom in an accessible and unobtrusive way is new to the field. ASL-STEM Forum, the second thrust of this work, will be an on-line video forum to facilitate discussion about signing for STEM topics. Visual collaboration between members of the community, in this case the Deaf Community, is important to ensure natural, conceptually correct, and community approved language progression. Designing, implementing, and evaluating a cyberinfrastructure solution to facilitate discussion about ASL vocabulary and grammar for STEM content, that will eventually serve as a resource for students, teachers, and interpreters involved in ASL for STEM fields, is another challenging research problem. Using social networking techniques to engage the deaf and hard of hearing community in discussions about ASL topics and vocabulary in STEM fields is entirely new to the field. This research will involve collaboration with the National Technical Institute for the Deaf at Rochester Institute of Technology, Gallaudet University, and the Shodor Education Foundation.<br/><br/>Broader Impacts: The new technologies to be developed as outcomes of this research will enable deaf and hard of hearing students to better access the STEM fields by improving the learning environment and the linguistic access to STEM content. Not only does this increase the likelihood that deaf people will attain college and graduate degrees, it will increase the participation of deaf and hard of hearing people in the development and research of new technology. Other students may also benefit from this technology, as digital notes and captions provide alternative access for students with learning disabilities and create opportunities for searchable archives of class content."
"1018865","III: Small: EntityEngine: A Query Engine for Entity-Relationship Queries Over Web Text","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","03/24/2011","Chengkai Li","TX","University of Texas at Arlington","Standard Grant","Sylvia J. Spengler","08/31/2015","$515,713.00","Gautam Das","cli@uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7364","7923, 9251","$0.00","The continuous evolution of the Web has made itself the primary<br/>knowledge source for many people. It has become an information<br/>repository full of entities (material or virtual) and descriptions<br/>of their properties and relationships. In discovering and exploring<br/>the entities that fascinate them, the users are in need of<br/>structured querying facilities, coupled with text retrieval<br/>capabilities, that explicitly deal with the entities, their<br/>properties, and relationships.<br/><br/><br/>In this project, the PIs investigate a novel declarative query<br/>mechanism, entity-relationship queries (ERQ), for users to discover<br/>and explore the rich structured and entity-centric information on<br/>the Web. The research objective is to produce general methods for<br/>efficient processing and optimization of entity-relationship<br/>queries and automatic ranking of query results, and to<br/>systematically develop a query engine for such queries. The<br/>methodology is to exploit the evidence of the co-occurrence of<br/>entities and keyword constraints, through the integration of DB and<br/>IR methods. A systematic approach will be taken to produce automatic<br/>ranking function formulation method, efficient entity-centric index<br/>and index selection methods, and top-k query processing algorithms.<br/><br/><br/>The research results will have broader impacts on the higher<br/>education system, high-tech industries, the scientific community,<br/>and the general public. The educational goal of the project is to<br/>be achieved by integrating research and educational efforts through<br/>these activities: broadening database curriculum; involving<br/>under-represented students and undergraduates in research;<br/>outreach; and publicly releasing the online demo, software,<br/>datasets, publications, and course materials.<br/><br/><br/>For further information see the project web page:<br/>URL: http://idir.uta.edu/erq"
"0954088","CAREER: Interacting with Cyberinfrastructure in the Face of Changing Science","IIS","CAREER: FACULTY EARLY CAR DEV, Cyber-Human Systems","03/15/2010","05/13/2014","Charlotte Lee","WA","University of Washington","Standard Grant","William Bainbridge","02/28/2015","$577,583.00","","cplee@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","1045, 7367","1045, 7367, 9215, 9251, HPCC","$0.00","This research will develop a framework to understand the set of sociotechnical relationships that comprise cyberinfrastructure (CI). Cyberinfrastructures are distributed organizations supported by such technologies as supercomputers and high-speed networks. Scientific cyberinfrastructures, or eScience projects, are multiplying rapidly because they can be brought to bear on some of the world's most important problems in energy, the environment, health, and security. The technical challenges of cyberinfrastructure are already so demanding that projects often have little time to engage reflexively on how cyberinfrastructures are used and created in the current state of rapid scientific change in which the necessity of data sharing and multidisciplinary approaches is putting pressure on disciplinary boundaries. While the ability to pool data can enable scientists to answer questions that no single investigator or laboratory could answer individually, large-scale databases also bear the significant burden of supporting scientific sub-domains with different priorities and requirements. <br/><br/>This project will use ethnographic methods, including participant-observation and semi-structured interviews, to investigate: How scientists and engineers decide which cyberinfrastructure resources (e.g. databases and tools) to use and under what circumstances; Under what circumstances do scientists and engineers decide to create their own resources; How are scientists and engineers mixing disciplinary practices within their own laboratories; When do scientists and engineers adopt hybrid identities (e.g. computational biologists and bioinformaticists). <br/><br/>This project will make empirical and conceptual contributions to research in areas such as computer supported cooperative work, science and technology studies, and the study of CI. It will provide a corpus of material describing how local concerns shape the use of CIs and the development and use of alternative local resources. By contributing to a more sophisticated understanding of how eScience is dependent on both technical and social transformation, this research will stimulate and support the development of future eScience research. This project will benefit cyberinfrastructure users and developers, funding bodies and policy makers, by creating a typology of change related to scientific practice, training, and technological change. The education components will give students hands-on involvement in research including developing research instruments, collecting and analyzing data, and writing papers. Diverse students from undergraduate to postdoctoral level, including women and minorities, will emerge with practical skills as well as exposure to theoretical issues related to collaboration and eScience."
"1250340","EAGER: Quick Draw Semantics","IIS","INFO INTEGRATION & INFORMATICS","09/15/2012","05/12/2014","Lois Delcambre","OR","Portland State University","Standard Grant","Sylvia J. Spengler","08/31/2015","$226,499.00","","lmd@cs.pdx.edu","1600 SW 4th Ave","Portland","OR","972070751","5037259989","CSE","7364","7364, 7916, 9251","$0.00","This project is developing methods and tools for ordinary web content creators to indicate the structure inherent in their content by drawing a few simple lines or figures over their web site. Their motivation for doing so is to use enhanced browsing and searching capabilities in their local site based on these mappings. These new browsing and searching capabilities are based on the definition of canonical structures (i.e., data model fragments) and domain patterns (a set of instantiated canonical structures) with associated navigation and access paths where domain patterns are easily recognizable by content creators and easily articulated using a simple drawing approach. This work is complementary to yet distinct from much existing effort to transition to a more semantic Web; the focus here is on (simple) local specification (drawing) of mappings with local benefit. This project uses a form of crowd-sourcing to create ontology mappings and (indirectly) create ontologies. This project applies decades of work on data modeling and schema mapping but with structural fragments rather than complete schemas/ontologies, without view update problems (because of the focus on browsing/searching), and with immediate local benefit. The research is motivated by and will be showcased in a series of websites that support public access to instructional materials. In general, this work is expected to contribute (nearly effortlessly yet in a high-quality way) to achieving the vision for the semantic web."
"1339666","NRI-Small: A Novel Light-weight Cable-driven Active Leg Exoskeleton (C-ALEX) for Training of Human Gait","IIS","SPECIAL STUDIES AND ANALYSES, CONTROL SYSTEMS, ROBUST INTELLIGENCE","01/01/2013","07/22/2013","Sunil Agrawal","NY","Columbia University","Continuing grant","Satyandra Gupta","09/30/2015","$659,000.00","","Sunil.Agrawal@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","1385, 1632, 7495","7923, 8086","$0.00","Motorized exoskeletal orthoses are being actively researched today for gait training of stroke patients. These machines are typically designed to apply assistive/resistive forces on the impaired leg to help human subjects to improve walking, similar to what therapists do during training. While a number of such machines have been developed and used for gait training, these studies have only yielded ""mixed"" results in benefiting stroke patients clinically. The reasons for these disappointing results are the high inertia of the mechanisms, a mis-match in constraints between human and machine, and misalignment of the mechanism joints with the human joints. The proposed work investigates a novel and ground-breaking design of a cable driven exoskeleton to address these shortcomings. Based on extensive study of mechanisms and therapeutic control methods, cables will actuate the moving limbs and will also serve as structural members in tension. The design will consist of an inertial fixed cuff attached to the pelvis and three lightweight cuffs on the thigh, shank, and foot of each leg. This results in an order-of-magnitude reduction in the inertia of the links and eliminates rigid joints which, in turn, eliminates the mis-match and misalignment. Yet, the fact that cables can only pull and not push raises many scientific and design challenges that will be addressed theoretically and experimentally.<br/><br/>Broader Impact: Each year, about 700,000 people in the U.S. have an incidence of a stroke and currently there are 4.5 million people in the U.S. living with the after-effects of stroke. This research can directly impact the quality of life of these individuals with potentially better rehabilitative equipment and better rehabilitative results for retraining of their gait. This project will broaden the application of cable-driven robots to the emerging field of ""neuro-rehabilitation"" and ""functional learning."" This project will also involve close co-operation with Professor Clement Gosselin's research group at Laval University, who along with the PI, is credited with fundamental developments to the field of ""cable robots."" The project will also encourage undergraduate involvement in research as well as provide training and examples for a high school teacher/student to incorporate into the local curriculum. The PI has active links with high schools through a college-wide NSF-funded RET program. Several high school teachers and students have worked in the PI's laboratory to identify technologies to improve quality of life of neural impaired subjects."
"1320078","III: Small: Collaborative Research: Supporting Efficient Discrete Box Queries for Sequence Analysis on Large Scale Genome Databases","IIS","INFO INTEGRATION & INFORMATICS, Big Data Science &Engineering","09/01/2013","05/12/2014","Qiang Zhu","MI","University of Michigan Ann Arbor","Standard Grant","Sylvia J. Spengler","08/31/2016","$230,277.00","","qzhu@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364, 8083","7364, 7433, 7923, 8083, 9251","$0.00","This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets (i.e., overlapping k-length subsequences obtained from genome sequences) for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, including error correction, variant detection, and assembly, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. The approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are explored. The results from this research will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial. <br/><br/>This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. In particular, a new index tree, named the BoND-tree, specially designed for a non-ordered discrete data space characterized by k-mer data sets is developed. The unique properties of the space are exploited to develop new node splitting heuristics for the index tree, and theoretical analysis is performed to show the optimality of the proposed heuristics. Besides the BoND-tree, which is based on data partitioning, space-partitioning based index schemes for box quieres in such a space are also developed. To support a more flexible type of query (i.e., hybrid box and range queries), hybrid index schemes integrating strengths of both box query indexes and range query indexes are studied. To facilitate an efficient index construction for large scale k-mer data sets, bulk loading techniques are also developed for the proposed index trees. In addition, the approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are also explored. The research in the project will result in the discovery of fundamental properties of the data space for sequence data in bioinformatics, the development of a number of novel storage, indexing and retrieval techniques exploiting the properties of such a data space, and the applications of the proposed techniques for solving important problems in sequence analysis. These results will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial."
"1444754","19th Annual SIGART/AAAI Doctoral Consortium","IIS","ROBUST INTELLIGENCE","05/15/2014","05/09/2014","Matthew Taylor","CA","American Association for Artificial Intelligence","Standard Grant","James Donlon","04/30/2015","$17,610.00","","taylorm@eecs.wsu.edu","2275 E BAYSHORE RD STE 160","Palo Alto","CA","943033224","6503283123","CSE","7495","7495, 7556","$0.00","Support to student travel for select students participating in the 19th Annual SIGART/AAAI Doctoral Consortium. AAAI (Association for the Advancement of Artificial Intelligence) is the major professional association for AI. This year it holds its yearly conference in Quebec City, Canada, where this DC will also take place. At the Doctoral Consortium (DC), PhD students who are pursuing work on AI-related topics present their proposed research and receive feedback from a panel of established researchers, as well as from other student participants. This provides the students with invaluable exposure to outside perspectives on their work at a critical time in their research and also enables them to explore their career objectives.<br/><br/>The DC program includes interactive sessions for feedback on dissertation topics from authorities in the field, collaboration-building sessions, early career advice, and well-placed networking opportunities. It is held this year in the venue of several important, co-located conferences: 28th AAAI Conference on Artificial Intelligence (AAAI-14), the 5th Symposium on Educational Advances in Artificial Intelligence (EAAI-14), and the 36th meeting of the Cognitive Science Society (CogSCI-14). Participation in a doctoral mentoring opportunity such as this one raises the potential to bring in participants who might not have attended an AI conference out of lack of habit or resources. This is especially true for those at smaller institutions and those which have less developed AI programs. Engaging such participants has the potential to draw more talent into AI research, improve research ideas in their formative stage, and engender collaborations across the breadth of disciplines associated with intelligent systems."
"1216347","HCC: Small: Copyright and Online Communities: An Empirical Study of Social Norms and User Conceptions","IIS","Cyber-Human Systems","09/01/2012","04/25/2014","Amy Bruckman","GA","Georgia Tech Research Corporation","Continuing grant","William Bainbridge","08/31/2015","$388,946.00","","asb@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923, 9251","$0.00","This research will develop a detailed understanding of interactions between copyright law, social norms, and user behavior in online communities where people create and share content. Recent work has found that the following five things are typically different: (1) what the law says; (2) what people think the law says; (3) what people think is ethical; (4) community norms; and (5) what people actually do. How can we better understand users, how they engage with copyrighted content online, and how they interact with one another in environments of creative sharing? To fully answer these questions, it is necessary to address all five dimensions, and their complex interactions. This research takes up the task of understanding how these dimensions function within different online communities, how community norms evolve, and what lessons can be derived for online community management and design.<br/><br/>The Internet is a rich medium for a vast spectrum of creative activity. People make original art, write stories, make videos, and share them with others online. The raw material for this wealth of creativity is a combination of original ideas and existing content, including the remix of copyrighted material created by corporations or other Internet users. As a result, while the nuances of copyright law were once something that largely mattered only to commercial producers of content, technology has changed all of this. With both copying and wide dissemination made orders of magnitude easier thanks to digital content and the Internet, copyright is now something that touches the average computer user on almost a daily basis. This is particularly true for the large number of online amateur content creators. However, just because the law is more relevant to more people does not mean it is more easily understandable.<br/><br/>The same confusions that have always existed in applications of the law have been exacerbated by technological advances. Social norms that form within these communities of creators do not necessarily track exactly to the law, but represent shared understandings and constructions, as well as ethical intuitions. These norms interact in intricate ways with other sources of order in online communities - legal rules, site policies, and technology-imposed control - and only together provide a complete picture of user behavior.<br/><br/>This study will gather data from three sources: (1) current online community policies; (2) public conversations about intellectual property occurring on current online sites and archives from older communities; and (3) interviews with creators of online creative content. The analysis will focus on teasing out the norms that exist within different communities, how they have evolved, and how they interact with the law as written and as enacted by community policies.<br/><br/>The results of this research will better inform online community design, and more broadly contribute to our fundamental understanding of how social norms operate in complex sociotechnical systems. It will provide evidence-based guidance for online community designers, and for policy makers tasked with helping the law adapt effectively to new technologies. Broader educational impacts of this research include the training of two graduate students in this interdisciplinary field of study. Additionally, this research will enrich the curriculum for the required undergraduate class CS 4001 ""Computers, Society, and Professionalism."""
"0747369","CAREER: Computational Tools for Population Biology","IIS","INFO INTEGRATION & INFORMATICS, CI REUSE","05/01/2008","08/21/2012","Tanya Berger-Wolf","IL","University of Illinois at Chicago","Standard Grant","Sylvia J. Spengler","04/30/2015","$620,930.00","","tanyabw@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364, 6892","1045, 1187, 7364, 9102, 9215, HPCC, 9251, 6892, 7433","$0.00","Computation has fundamentally changed the way we study nature. Recent breakthroughs in data collection technology, such as GPS and other mobile sensors, gene sequencing, and microsatellite genotyping, are giving biologists access to data about wild populations, from genetic to social interactions, that are orders of magnitude richer than any previously collected. Such data offer the promise of answering some of the big questions in population biology: How do animals form social groups and how do genetic ties affect these processes? Which individuals are leaders and to what degree do they control the behavior of others? How do social interactions affect the survival of a species? Unfortunately,in this domain,our ability to analyze data lags substantially behind our ability to collect it. There are three major drawbacks with currently available techniques for analysis of both genotypic and social structure data. First, most traditional methods are aggregate and numeric, thus they are inappropriate for identifying infrequent yet critical events, such as response to predation. Second, the newer approaches focus on human populations and are not directly applicable in the context of wildlife biology. Finally, current analysis techniques are essentially static in that all information about the time and order of social interactions or the concurrency of gene expressions is discarded. Thus, they lack the expressive and computational power to answer the questions outlined above. <br/><br/>Intellectual Merit<br/>The goal of this interdisciplinary research is to develop a robust and scalable computational framework for the emerging field of computational population biology. Ultimately, this research will enable biologists in their scientific inquiry to take advantage of new data by focusing on its underlying qualitative (rather than numerical) and explicitly dynamic structure. This research will use combinatorial techniques to extract that structure. In the scope of this project the following will be developed:<br/>1. Techniques for inferring genetic relationships in wildlife populations and using them to predict genetic diversity.<br/>2. Novel computational methodologies and tools for analyzing dynamic social interactions, focusing on prediction of interaction patterns and dynamic processes within populations.<br/>3. Techniques for combining the genetic and the social structures of a population and across species to identify global ecological processes. <br/><br/>Broader Impacts<br/>Many students, especially female, turn away from computer science in part because of the perceived lack of its applicability to real-world issues and impact on the society. This project has the potential to attract those who would otherwise be lost to computing by providing the view of its larger impact and connection to science. A comprehensive interdisciplinary education and outreach plan will be developed which bridges the traditional pipeline from K-12 to graduate education. The standard views of mathematics and computing will be broadened to include ""puzzle-solving"" combinatorial thinking by introducing hands-on outreach activities. The unique conflation of wild life biology and computing will continue to be presented at various forums aimed at attracting minorities and girls to science and computer science. Finally, through introduction of biological motivation in computer science courses and the computational methodology in biology courses, this research will provide the students in both disciplines with experiences in asking and answering biological questions by developing new applications of computer science. The methodologies, concepts, and tools developed as part of this interdisciplinary research will be useful to scientists in diverse fields such as behavioral ecology, conservation biology, and disease ecology. Techniques for analysis of social structures have broader relevance to human societies, especially in the context of epidemiology, dissemination of ideas, and crisis management."
"1406750","CAREER: Understanding and Analyzing User-Prosthesis Interaction for Designing a Volitional Controller for Powered Lower Limb Prostheses","IIS","Cyber-Human Systems","06/30/2013","05/09/2014","He Huang","NC","North Carolina State University","Continuing grant","Ephraim P. Glinert","01/31/2017","$259,436.00","","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","1045, 7367, 9251","$0.00","Although volitional control of prosthetic arms has been studied intensively in recent years, similar technology has not yet been developed for lower limb prostheses, due in part to the lack of control capability in current passive prosthetic legs. Two emerging technologies, powered lower limb prostheses and neural-machine interfaces (NMI), have opened up new possibilities for allowing leg amputees to operate prostheses intuitively and to perform various activities in a natural way. It remains, however, to demonstrate the feasibility of volitional control for powered prosthetic legs. This is the PI's goal in the current project: to develop and implement a novel volitional controller that allows users with transfemoral amputations to operate a multifunctional, powered prosthetic leg intuitively and safely. To this end, she will systematically investigate and quantify the interaction effects between lower limb amputees and powered artificial legs. Intrinsic control (i.e., control based on intrinsic mechanical feedback) for a prototype powered transfemoral (TF) prosthesis will be developed with finite-state machine and impedance control mechanisms so that it can assist amputees in performing various activities in weight bearing and non-weight bearing situations. The design of the volitional control will be based on a multi-model engineering framework that integrates intent decoders with intrinsic prosthesis control so as to create feed-forward control in a powered TF prosthesis while ensuring amputee safety. Finally, a proof-of-concept prototype of a volitionally-controlled, powered TF prosthesis will be implemented and evaluated in real time on patients with TF amputations. <br/><br/>Broader Impacts: Project outcomes will significantly advance lower limb prostheses technology, which will in turn lead to quality of life improvements for the large and growing population of lower limb amputees. Similar technology should be applicable to control of powered orthotics, which would benefit patient populations with neuromotor deficits. The experimental data collected in the project will shed light on human motor control mechanisms, which should benefit diverse fields such as kinesiology and neuroscience. The new technologies developed in this research (including sensors, communication, algorithms, control, etc.) should help advance research across human-centered computing (including, for example, exoskeleton control and wearable sensors for health monitoring). Through integration of her research into comprehensive education and outreach programs, the PI will help educate the next generation of engineers and scientists, who will impact the future of science and technology."
"1337691","RI: Small: Collaborative Research: Statistical Learning of Language Universals","IIS","ROBUST INTELLIGENCE","01/01/2013","02/05/2014","Luke Zettlemoyer","WA","University of Washington","Standard Grant","Tatiana D. Korelsky","07/31/2015","$109,887.00","","lsz@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7923","$0.00","As modern technology infrastructure spreads throughout the world, the quantity of electronic text, written in hundreds of different languages, continues to grow in size and diversity. Building effective information retrieval, extraction, and translation systems across this vast array of languages currently requires time-consuming and expensive linguistic annotations for each language. Generic, fully unsupervised, methods are unlikely to provide a language independent solution to this problem.<br/><br/>Focusing on part-of-speech prediction, this project undertakes a novel approach, combining elements of supervised and unsupervised learning without assuming any specific knowledge of the target language. Instead of treating individual languages as closed systems, language-independent ""universals"" are statistically estimated from dozens of languages for which annotated corpora exist, and these learned universals are used to predict the part-of-speech categories of unannotated languages. At the heart of the project is a data-driven exploration of language-independent corpus characteristics that relate cross-lingual linguistic categories to surface statistics of text. These learned patterns are incorporated into expressive structured prediction models using novel approximate learning and inference methods developed by the Principal Investigators of the project.<br/><br/>Of the world?s spoken languages, hundreds are at risk of immediate extinction and thousands more are likely to disappear over the coming decades. By facilitating the rapid creation of language-independent linguistic analysis tools, the technology developed under this project has the potential to revolutionize the documentation of endangered languages. In the long-term, this research direction will also help realize the full social benefits of the global technology infrastructure by creating intelligent text processing tools for hundreds of low-resource languages."
"1249488","EAGER: Therabot - A Robotic Therapy Support System","IIS","Cyber-Human Systems","07/15/2012","05/09/2014","Cindy Bethel","MS","Mississippi State University","Standard Grant","Ephraim P. Glinert","06/30/2015","$218,681.00","","cbethel@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7367","7367, 7916, 9251, 9150","$0.00","An issue of growing concern in the United States is the prevalence of sexual violence for women on college campuses, where up to one in four women report experiencing an attempted or completed rape while a student. It is important for these women to obtain therapeutic counseling to help them cope with the aftermath of these traumatic events. Research indicates that traditional therapy is beneficial in some instances, and additional benefits have been discovered with the use of animal-assisted therapy (AAT); however, there are limitations to AAT (e.g., training costs, availability, phobias, and allergies). <br/><br/>In this project the PI will explore an alternative called the Therabot, a lightweight socially assistive robotic support system. The goal is to design, implement and evaluate the efficacy of a prototype, which will improve upon the benefits discovered with AAT. To this end, the Therabot will have the appearance of a stuffed animal/toy and will exhibit affective behaviors (including head and arm movements, and animal-like or rhythmic sounds), to provide comfort and support during therapeutic interventions for the trauma associated with sexual violence. It will be convenient and easy for patients to use, not only in the clinic or lab but also in the home to provide support and encourage home therapy practices, something which is not offered by current forms of supplemental therapy support such as therapy animals.<br/><br/>This preliminary research will have three phases: design and construction of the Therabot system; validation that the system works as intended with human participants; and field testing with patients at the Department of Outreach and Sexual Assault Services at the PI's institution. Three hypotheses will be evaluated as part of this exploratory research: that patients who use the Therabot in counseling will be more likely to communicate with the therapist, and will feel more supported and comfortable during counseling, compared to patients who do not use the Therabot or who use an identical-looking but non-robotic Therabot in counseling; that patients will be more likely to perform home therapy practice using the Therabot than patients who do not use the Therabot or who use an identical non-robotic Therabot in home therapy practice; and that patients using the Therabot will experience improved therapeutic outcomes compared to those who are not using the Therabot or who use an identical non-robotic Therabot.<br/><br/>Broader Impacts: If the PI's hypotheses are supported, this research will not only impact survivors of sexual violence but will also be applicable to other therapeutic situations such as soldiers returning from the battlefield with PTSD and survivors of natural and man-made disasters. The PI expects that a lightweight socially assistive technology system like the Therabot will provide beneficial support and companionship to patients in hospitals, hospice facilities, and long-term care environments. It will be easy to incorporate the Therabot into the curricula of both undergraduate and graduate computer science, mechanical engineering, and clinical psychology courses, and also to use it for class projects. The many expected practical applications and potential societal impacts of the Therabot will make it a tremendous resource for K-12 outreach activities whose goal is to encourage interest in science and technology careers."
"1218170","CGV: Small: Toward Objective, In-Situ, and Generalizable Evaluation of Visual Analytics by Integrating Brain Imaging with Cognitive Factors Analysis","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","09/01/2012","05/09/2014","Remco Chang","MA","Tufts University","Standard Grant","Ephraim P. Glinert","08/31/2015","$515,381.00","Robert Jacob, Caroline Ziemkiewicz","remco@cs.tufts.edu","20 Professors Row","Medford","MA","021555807","6176273417","CSE","7367, 7453","7453, 7923, 7367, 9251","$0.00","Evaluating complex, interactive visual analytics systems is challenging for many reasons. The exploratory nature of using visualization makes quantitative measurements of individual components of the visualization task infeasible. The range of potential users and their differing goals render standardized metrics too restrictive. And environmental conditions can influence experimental outcomes, making it difficult to compare and generalize the results of separate evaluations. Although numerous methods have been proposed for evaluating visualizations and HCI, few can be readily applied to objectively evaluate visual analytics systems in real-world settings. In this project the PI will address this open challenge by developing a method to evaluate complex, interactive visual analytics systems using objective measures that can be performed in-situ to yield reproducible, generalizable results. His approach is to integrate noninvasive brain imaging using functional near-infrared spectroscopy (fNIRS) and cognitive factors measurements. The PI argues this will allow him to address issues in visual analytics evaluation by explaining the user's cognitive processes at a deeper level. Lightweight, noninvasive brain imaging techniques such as fNIRS have become more mature and reliable in recent years. fNIRS is easy to set up, robust to movement, and has been demonstrated in studies to be effective in determining a user's cognitive load, preferences, and perception when using a visualization. Cognitive factors such as locus of control, spatial visualization ability, and perceptual speed have recently been shown to correlate with a user's ability to interact with a visualization, and can be generalized to predict the behavioral patterns of users with different cognitive profiles. Both approaches aim to better understand the user's cognitive state and abilities. In this research cognitive factors measurements will provide low-level, baseline information about the user which is stable and unchanging (""traits""), while fNIRS provides immediate, real-time feedback on the user's current cognitive state when interacting with a visualization (""states""). In practice, without accounting for the individual user's traits, it is difficult to generalize the signals provided by fNIRS (for example, right- and left-handed subjects produce very different brain signals). By combining information on both ""traits"" and ""states,"" evaluation results can generalize to a larger population based on cognitive profiles. The PI and his team have conducted two preliminary experiments that demonstrate the feasibility of the approach. They have replicated the classic experiment by Cleveland and McGill using fNIRS, and successfully distinguished participants' brain signals when using bar charts versus pie charts. In another experiment, they successfully correlated participants' locus of control with their ability to use hierarchical visualizations with different visual metaphors.<br/><br/>Broader Impacts: The results of this work will have both immediate and long term impact on the field of visualization. In the short term, project outcomes will provide a robust and reliable evaluation mechanism for measuring the effectiveness of complex, interactive visual analytics systems. Ultimately, the findings of this research will help open the human-cognition ""black box"" and illuminate how interacting with a visualization helps a user gain insight. Such an understanding may in turn lead to the realization of insight-based evaluation and the emergence of a new visualization theory that is based on human cognitive processing. Finally, by integrating real-time fNIRS into visual analytics systems, effective adaptive mixed-initiative visual analytics systems can become one step closer to reality."
"1211071","SoCS: Collaborative Research: Focusing Attention to Improve the Performance of Citizen Science Systems: Beautiful Images and Perceptive Observers","IIS","SOCIAL-COMPUTATIONAL SYSTEMS, Cyber-Human Systems","09/01/2012","05/09/2014","Carsten Oesterlund","NY","Syracuse University","Standard Grant","Tatiana D. Korelsky","08/31/2015","$337,099.00","","costerlu@syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","7953, 7367","7953, 7367, 9251","$0.00","The goal of this project is to develop a next-generation socio-computational citizen science platform that combines the efforts of human classifiers with those of computational systems to maximize the efficiency with which human attention can be used. Dealing with the flood of digital data that confronts researchers is the fundamental challenge of twenty-first century research. New techniques, tools and strategies for dealing with massive data sets, whether they consist of vast numbers of base-pair DNA sequences or terabytes of data from all-sky astronomical surveys, present an opportunity to establish a new paradigm of scientific discovery, but the task is not easy. In many areas of research, the relentless growth of data sets has led to the adoption of increasingly automated and unsupervised methods of classification. In many cases, this has led to degradation in classification quality, with machine learning and computer vision unable to replicate the successes of human pattern recognition. The growth of citizen science on the web has provided a temporary solution to this problem, demonstrating that it is possible to recruit hundreds of thousands of volunteers to make an authentic contribution to results, boosting human analysis through the collective wisdom of a crowd of classifiers. However, human classifiers alone will not be able to cope with expected flood of data from future scientific instruments. <br/><br/>This research will be carried out by a partnership between computer and social scientists, addressing research problems both in automated data analysis and social science through systems implementation, alongside field research and experiments with project participants. The intellectual merit of this project lies in its contribution to advancing knowledge and understanding in multiple domains of science. First, the work will contribute to developing new methods of computational data analysis, initially with analysis of astronomical images, and later extending to additional fields. Second, the project includes social science research to test and apply theories of human motivation and learning in an online context, which can then be applied to a broad range of social-computational problems. By mixing human and computational elements, the planned system has the potential to transform the application of citizen science and its approach to data analysis. <br/><br/>This project will advance science while promoting teaching, training and learning. One of the most significant broader impacts for its citizen science activities is enabling a community of hundreds of thousands of volunteers to participate in research, a powerful and rapidly developing form of informal science education. By choosing the relatively generic topic of image classification, beginning with astronomy but not limited to that field of science, the techniques developed under this grant will be of significant value to future investigations in similar research areas, thus enhancing the infrastructure for research and education."
"1124827","Collaborative CDI-Type II: Cyber Enabled Discovery System for Advanced Multidisciplinary Study of Humanitarian Logistics for Disaster Response","IIS","CDI TYPE II, Cyber-Human Systems","01/01/2012","05/09/2014","Jose Holguin-Veras","NY","Rensselaer Polytechnic Institute","Standard Grant","William Bainbridge","12/31/2015","$1,524,299.00","John Mitchell, Malik Magdon-Ismail, Sanmay Das","jhv@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7751, 7367","7721, 7722, 7751, 7367, 9251","$0.00","This research will develop a cyber-enabled discovery system, integrating state of the art thinking and methodologies from computer, transportation, mathematical, and social sciences, for management of logistics in humanitarian responses to disasters. It will (1) create new paradigms of humanitarian logistic models that explicitly consider two key aspects not studied by the current techniques: non-hysteretic deprivation costs (lack of access to a given good or service), and materiel convergence (physical movement of supplies and equipment); (2) develop appropriate models to represent human suffering as a deprivation cost; (3) develop analytical models to quantify and influence the amount, type, and arrival patterns of donations; (4) gain insight into the links between media framing of needs and materiel convergence; (5) define mechanisms to modify donor behavior; and, (6) develop algorithms and heuristics to solve these formulations. This will lead to models that correctly consider the impacts of logistic decisions on the impacted populations, more effective delivery strategies, more coordinated and effective relief flows, and less congestion at entry points.<br/><br/>This research is an ambitious and transformative effort to build a holistic, quantitative understanding of how humanitarian logistics should consider deprivation costs and emergent donor response to disasters. This is based on state of the art economic, logistic, and social science research into the impacts of delivery actions, media portrayal of disaster events, and response needs. The core impact of this research will be improved allocation and delivery of critical supplies during disaster response, as well as better coordination with emergent distributed donor sites, leading to improvement of the nation?s emergency response capabilities. The research team will maximize the broader impacts through: (1) the integration of research into undergraduate and graduate courses; (2) the involvement of undergraduate and graduate students as research assistants; (3) the use of outreach events to communicate research results to undergraduate and high school students and stimulate them into research; (4) the recruitment of women and minority students; and (5) the dissemination of project findings among professionals and researchers with interest in humanitarian logistics and disaster response."
"1145152","EAGER: Combining Knowledge with Data for Generalizable and Robust Visual Learning","IIS","ROBUST INTELLIGENCE","10/01/2011","04/15/2014","Qiang Ji","NY","Rensselaer Polytechnic Institute","Standard Grant","Jie Yang","09/30/2015","$226,421.00","","qji@ecse.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7495","7916, 9251, 7495","$0.00","Computer vision has made tremendous progress in the past decades, partially enabled by the advanced machine learning techniques. But compared with human perception, computer vision remains primitive. One contributing factor for this is the data-driven nature of the current learning algorithms and their inability to incorporate any related knowledge. The data-driven methods tend to be database-specific and cannot generalize well to unseen data. This project addresses this issue through the introduction of a knowledge-augmented statistical learning framework. Within this framework, knowledge and data can be systematically exploited, captured, and are principally integrated to jointly train a vision algorithm. Developing such a framework, however, is challenging since the domain knowledge often exists in different and diverse formats, typically inaccessible to the data-driven statistical machine learning methods. To overcome this challenge, the research team systematically converts domain knowledge into either the constraints on the model or into pseudo-data, whereby they can be incorporated into the statistical learning methods. The project includes systematic identification of knowledge from different sources and concrete mechanisms to capture the knowledge and to convert them into formats easily accessible to the automatic machine learning methods. The project also involves demonstrating the effectiveness of the proposed framework for certain computer vision problems.<br/><br/>The project provides the training for graduate and undergraduate students, and the research results are disseminated through publications and organization of the related workshops."
"1117740","III: Small: Uncovering the Myths of Unlikelihood: Granger Graphical Models for Anomaly Detection in Multivariate Time-Series Data","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/22/2011","Yan Liu","CA","University of Southern California","Standard Grant","Sylvia J. Spengler","07/31/2015","$499,999.00","","yanliu.cs@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7364","7923","$0.00","The project aims to develop effective approaches to anomaly detection from high-dimensional time series data, motivated by applications such as oil drilling, semiconductor fabrication, and railroad operation.<br/>The proposed approach takes advantage of Granger Graphical models, which uncover the temporal dependencies between variables, to efficiently compute a robust correlation anomaly score for each variable and obtain insights regarding the causes of anomalies. The project develops effective approaches to addresses several specific challenges that arise in real-world applications of anomaly detection, including (1) nonlinear temporal dependencies; (2) hidden variables; and (3) massive amounts of data. The resulting algorithms will be evaluated on two real production systems: an oil-field mechanical system and a semi-conductor fabrication system.<br/><br/>The project is expected to advance the state of the art in anomaly detection for high-dimensional time series data that arise in many application domains. It offers research-based training opportunities at the intersection of machine learning, data mining, and intelligent production management, as well as operational research in general.Workshops and mini-courses will be organized to introduce advanced machine learning techniques to students, practitioners, and researchers in production management. The anomaly detection code and data sets will be freely disseminated to the broader research and educational community. Additional information about the project can be found at: http://www-bcf.usc.edu/~liu32/ggm.htm."
"0952718","CAREER: Nonuniform-Magnetic-Field Control of Medical Microrobots","IIS","ROBUST INTELLIGENCE","04/01/2010","05/02/2014","Jake Abbott","UT","University of Utah","Continuing grant","Satyandra Gupta","03/31/2015","$552,043.00","","jake.abbott@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7495","1045, 1187, 9150, 9251, 7495","$0.00","Magnetic microrobots that navigate the natural pathways of the body have the potential to revolutionize minimally invasive medicine and biomedical research. Current magnetic manipulation systems utilize massive magnets to produce a uniform magnetic field over a relatively small area. Uniform magnetic fields are used to simplify control, but this simplified control comes at a huge cost, and it is difficult to scale up most laboratory field-generation systems to the size required for clinical use. The use of nonuniform magnetic fields makes it possible to place magnets nearer to the patient, which permits the use of smaller, less-expensive magnets, while simultaneously improving actuatable degrees of freedom and force levels that systems can render. The hypothesis being tested is that using nonuniform magnetic fields to wirelessly control medical microrobots results in superior systems?in terms of size, cost, and performance?compared to using uniform fields. This research consists of two thrusts: control of magnetically tipped continuum microrobots, which provide distal dexterity in hard-to-reach locations, and control of fully untethered magnetic helical microrobots, which swim and crawl through fluids, lumens, and soft tissue using a method inspired by bacterial flagella. Understanding how to use nonuniform magnetic fields for wireless control may be the key to translating nearly every previously developed method for microrobot propulsion into clinical practice. Magnetic microrobots may be the ideal platform from which to deploy the numerous BioMEMS devices and magnetic sensors and actuators that have been designed in recent years."
"1217761","RI: Small: Agent-Assisted Trading in Real-World Auctions","IIS","ROBUST INTELLIGENCE","09/01/2012","05/08/2014","Amy Greenwald","RI","Brown University","Standard Grant","James Donlon","08/31/2015","$465,990.00","","amy@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","7923, 7495, 9251, 9150","$0.00","In many large economic markets, goods are sold through auctions. Examples include eBay, wireless spectrum auctions, the New York Stock Exchange, and the Dutch flower auctions. This project focuses on one particular real-world auction domain: the Dutch flower auctions (DFA). The project will perform an in-depth analysis of this domain both from the point of view of the bidders and from the point of view of the auctioneers.<br/><br/>This project involves several component tasks. (1) Creation of a configurable auction server, comprised of basic auction building blocks, like simultaneous and sequential auctions, and sealed-bid, ascending, and descending auctions. (2) Construction of an interactive DFA simulation using the configurable auction server that is capable of handling decisions made by both human bidders and autonomous agents; this simulation will model DFA bidder preferences, which will be learned automatically using inverse reinforcement learning techniques from historical data and manually by surveying and interviewing DFA experts. (3) Creation of autonomous DFA bidding agents and comparison of their performance to that of expert human DFA bidders using the interactive simulation. (4) Further simulation of these agents to empirically find game-theoretic equilibria under various settings of the auction parameters so that those parameters can be optimized. The project will also develop a prototype of a mixed-initiative system that can be used to assist DFA bidders.<br/><br/>Potential broader impacts of this research include increased knowledge and understanding of how to design and implement artificially intelligent agents that can effectively assist humans with their decision-making efforts, particularly in information-rich and time-critical environments. Although this project focuses on DFA-type auctions, methodologies developed here will transfer to other domains that use auction mechanisms, such as automated bidding for resource allocation in smart grids. Detailed focus on the DFA provides a concrete starting point for the study of various auction-related topics, for instance, how to build mixed-initiative decision support tools to improve the quality of bidding practices, rigorous comparison of various auction mechanisms and parameter choices, and advancing bidding agent design from a heuristic approach to one that is theoretically grounded.<br/><br/>The project research team includes both graduate and undergraduate students whose participation in this research will strengthen their understanding of the various fields that are critical to the development of decision support systems (e.g., autonomous agents, preference elicitation and representation, machine learning, software engineering) and provide them experience collaborating across disciplines, and working on a real-world application. In addition, there are plans to develop introductory lessons on the general topic of autonomous bidding agents for use in the Artemis project, a five week summer program in which female rising ninth graders are exposed to the breadth of applications of computer science, and are introduced to a variety of technologies underlying computing."
"1350983","CAREER: New Representations of Probability Distributions to Improve Machine Learning --- A Unified Kernel Embedding Framework for Distributions","IIS","ROBUST INTELLIGENCE","05/15/2014","05/07/2014","Le Song","GA","Georgia Tech Research Corporation","Continuing grant","Todd Leen","04/30/2019","$89,322.00","","lsong@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","1045, 7495","$0.00","Computational intelligence touches our lives daily. Web searches, weather prediction, detecting financial fraud, medicine and education benefit from this ubiquitous technology. Problems in computational intelligence such as image classification and predicting properties of new materials produce copious amounts of high-dimensional, complex data. Many algorithms in computational intelligence rely on probability distributions, and such data can carry unusual distributions that challenge traditional methods of modeling. (For example, they are typically not textbook distributions such as the Gaussian.) In some applications, the data input to the algorithms are themselves probability distributions. Existing techniques are cannot both capture unusual distributions and scale to millions of data points without stalling the computation. There is a pressing need for a flexible, efficient framework for representing, learning, and reasoning about datasets arising from these problems.<br/><br/>This project will address these challenges by developing a novel and unified framework to represent and model, learn, and use probability distributions in computational intelligence. To evaluate the utility of the new techniques, the project will test them on difficult real-world problems in computer image analysis, materials science, and flow cytometry (a biotechnology technique used for cell counting, cell sorting, and protein engineering).<br/><br/>The project, an NSF CAREER award, will integrate the research results with several education intiatives. New curricula will be designed for both undergraduate and graduate students, with empahsis on students from under-represented groups. A new online course will be created to make the results accessible to massive online masters students. Finally, advanced high school math teachers will be engaged to design problems related to the reserach for use in a math competition for advanced high school students.<br/><br/>This project will (1) create a novel and unified nonparametric kernel framework for distributional data and distributions with fine-grained statistical properties, and (2) develop principled and scalable algorithms for nonparametric analysis of big data. The unified kernel embedding framework will advance large scale nonparametric data analysis significantly, and play an important synergistic role in bridging together traditionally separate research areas in data analysis, including kernel methods, graphical models, optimization, nonparametric Bayesian methods, functional analysis and tensor data analysis. In addition to advances in algorithmic methods, the applications to large-scale image classification, flow cytometry, and materials property prediction have the potential for transformative impact on society."
"1339880","EAGER: NSF-JUST Program on Robotic for Rehabilitaion and Medicine","IIS","Cyber-Human Systems, IIS SPECIAL PROJECTS","06/30/2013","05/07/2014","Sunil Agrawal","NY","Columbia University","Standard Grant","Satyandra Gupta","08/31/2015","$46,484.00","","Sunil.Agrawal@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367, 7484","7916","$0.00","This joint program reviews the state-of-the-art of the field of model-based assistive robotic technologies for medicine and rehabilitation in the USA and Japan, outlines the fundamental science and technologies in this area, and proposes models for future collaborative research between Japan and USA by building on the mutual strengths. In particular, gait training for stroke patients using exoskeletons is studied.<br/><br/>The field of medical and rehabilitation robotics offers much in terms of broad societal impact. In addition, the project exposes graduate students and faculty to the culture of research in Japan, and more broadly, Asia. Today, Japan leads in many areas of robotics and automation. The students in the NSF-JST program interact with researchers in Japan and visit prominent universities and research laboratories. This exposure provides excellent training for the students and prepares them for careers in industry and academia globally."
"1115872","HCC: Small: Collaborative Research: Gestural and Linguistic Expressivity and Entrainment in Dialogue","IIS","Cyber-Human Systems","09/01/2011","05/05/2014","Michael Neff","CA","University of California-Davis","Continuing grant","William Bainbridge","08/31/2015","$297,899.00","","neff@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7367","7367, 7453, 7923, 9251","$0.00","This research will advance the state of the art in conversational character systems (Intelligent Virtual Agents) in two ways. First, it seeks to better understand the interplay of gesture and language in both generating the perception of personality and allowing participants to adapt to the ongoing conversational context. Second, it will use this understanding to build novel computational models for gesture and language generation that provide fine grained control over the perception of personality and support agent adaptation in response to the conversational context. The theoretical basis for the personality-based modeling in this project is the well-established ""Big Five"" model of personality, which consists of five orthogonal dimensions of individual variation.<br/><br/>The work on adaptation will be couched in the collaborative theory of language use and communication accommodation theory, which predict that communicative behavior varies based on partner specificity. Initial work will form a motion capture, video and audio corpus of three kinds of exchanges. This will be used to both study gestural entrainment during human interactions, determining if audio-based findings extend to the gestural domain, and to enhance scientific understanding of the relationship between gesture and personality. This will inform the modeling work which will build a joint model for personality-based language and gesture production. The model will extend a pilot study on gesture generation for extraversion to three Big Five traits and integrate it with personality-based language generation. An experimental stage will validate these models and study the interactions of movement and language. The research will also study the role of adaptation. Questions to be answered include: (1) whether people gesturally entrain with computers, or indeed produce any gestures while communicating with a computer, (2) whether computers? gestural entrainment promotes similar levels of affiliation as observed with vocal entrainment, and (3) whether changing gestural entrainment over the course of an interaction is more powerful than aligning gestures from the outset of an interaction. <br/><br/>Character systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior like entrainment, has a direct impact on the effectiveness of the applications in which they are used. For example, it will have a direct impact on student learning. As these applications become more ubiquitous in society, particularly among children, it is important to be able to harness their full benefit, and indeed, avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent interactions."
"0845282","CAREER: Generalized Image Understanding with Probabilistic Ontologies and Dynamic Adaptive Graph Hierarchies","IIS","ROBUST INTELLIGENCE","07/01/2009","03/19/2014","Jason Corso","NY","SUNY at Buffalo","Standard Grant","Jie Yang","06/30/2015","$539,086.00","","jcorso@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7495","1045, 1187, 7495, 9215, HPCC, 6890","$539,086.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>From representation to learning to inference, effective use of high-level semantic knowledge in computer vision remains a challenge in bridging the signal-symbol gap. This research investigates the role of semantics in visual inference through the generalized image understanding problem: to automatically detect, localize, segment, and recognize the core high-level elements and how they interact in an image, and provide a parsimonious semantic description of the image.<br/><br/>Specifically, this research examines a unified methodology that integrates low- (e.g., pixels and features), mid- (e.g. latent structure), and high-level (e.g., semantics) elements for visual inference. Adaptive graph hierarchies induced directly from the images provide the core mathematical representation. A statistical interpretation of affinities between neighboring pixels and regions in the image drives this induction. Latent elements and structure are captured with multilevel Markov networks. A probabilistic ontology represents the core knowledge and uncertainty of the inferred structure and guides the ultimate semantic interpretation of the image. At each level, rigorous methods from computer science and statistics are connected to and combined with formal semantic methods from philosophy.<br/><br/>A symbiotic education plan involving graduate and undergraduate mentoring and education, professional tutorial courses at the boundary of vision and ontology, and K-12 outreach is incorporated into the research plan. The research and education, disseminated broadly through both the applied science and semantics/philosophy literatures, lays a foundation on which to both utilize and automatically extract rich semantic information from images and other signal data for critical application areas such as internet vision, autonomous navigation, and ambient biometrics."
"1111542","RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","IIS","ROBUST INTELLIGENCE","09/01/2011","01/02/2014","Kimberly Kendricks","OH","Central State University","Standard Grant","Satyandra Gupta","08/31/2015","$219,757.00","Yu Liang","kkendricks@centralstate.edu","P.O.Box 1004","wilberforce","OH","453840000","5133766011","CSE","7495","7495, 7925","$0.00","This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br/><br/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering."
"1018314","RI: Small: Acquiring Domain Knowledge from Text through Cooperative Bootstrapping","IIS","ROBUST INTELLIGENCE, INFO INTEGRATION & INFORMATICS","07/01/2010","05/06/2011","Ellen Riloff","UT","University of Utah","Continuing grant","Tatiana D. Korelsky","06/30/2015","$391,845.00","","riloff@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7495, 7364","7923, 9150, 9251","$0.00","Some of the most pressing needs for natural language processing (NLP) technology come from specialized domains where broad-coverage solutions are not sufficient, such as clinical medicine and molecular biology. This project focuses on the development of bootstrapped learning techniques to rapidly create domain-specific semantic analyzers, and the automatic harvesting of domain knowledge from unstructured text.<br/><br/>This project establishes a new cooperative bootstrapping paradigm to learn semantic analyzers for different tasks simultaneously by allowing classifiers for different tasks to learn from each other.<br/>These analyzers then populate a domain event graph with semantic information extracted from a domain-specific text collection. New knowledge harvesting algorithms acquire domain-specific facts and inference rules from the graph. This project explores the domain of veterinary medicine using message board posts by veterinarians to acquire real-world knowledge for the purposes of animal health surveillance.<br/><br/>This work will advance the state-of-the-art in natural language technology by developing a new bootstrapping framework to rapidly create semantic analysis tools for specialized domains. This technology will impact many NLP applications, including information extraction, question answering, and summarization. The knowledge harvesting tools will be made publicly available to allow for direct impact across many disciplines that have a need to extract knowledge from unstructured text collections. This project will also benefit society by creating new tools for animal health surveillance, which could provide early warning signs of zoonotic disease outbreaks (such as bird flu and mad cow disease), exposures to toxic substances, and contamination in the food chain."
"1054541","CAREER:The Symbiosis of Graphical Models and Games","IIS","ROBUST INTELLIGENCE","06/01/2011","05/05/2014","Luis Ortiz","NY","SUNY at Stony Brook","Continuing grant","Todd Leen","05/31/2016","$407,322.00","","leortiz@cs.stonybrook.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7495","1045, 1187, 7495, 9251","$0.00","Many natural, social and engineered systems exhibit or facilitate complex behavior. Such behavior often results from the deliberate actions of, and interactions between, a large number of individuals. The need to study behavior in complex systems of network-structured interactions in large populations promotes interest in computational game-theoretic models.<br/><br/>Graphical games build on classical models in game theory, as well as compact, structured representations in probabilistic graphical models. The result is a practical and computationally amenable model to handle networked large-population systems.<br/><br/>The creation of technology for scientists and policy makers to study and work with large real-world complex systems of (strategic) interactions requires further advances in graphical games and models. The project seeks to fill knowledge gaps by advancing computational aspects of game theory, graphical models and machine learning, and laying the foundation for a systematic two-way knowledge transfer between computational game theory and graphical models.<br/><br/>The research program strengthens the connection between graphical models and game theory by casting probabilistic inference problems as equilibrium computation, creating algorithms to learn games from behavioral data, and characterizing equilibrium structure and computation.<br/><br/>The educational program includes the infusion of research results into general education, at all levels, via development of new courses and integration into existing ones; and a concerted effort to bridge the Departments of Economics and Computer Science at Stony Brook. Collaborations through the Center for Game Theory in Economics and the International Summer Festival on Game Theory, held annually at Stony Brook, serve as conduits for outreach and dissemination."
"1025498","VOSS: Design Collaborations as Sociotechnical Systems","ACI","VIRTUAL ORGANIZATIONS, Cyber-Human Systems, ENGINEERING EDUCATION, EDUCATION AND WORKFORCE","09/01/2010","05/05/2014","Geraldine Gay","NY","Cornell University","Standard Grant","Kevin Crowston","08/31/2014","$410,022.00","","gkg1@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7642, 7367, 1340, 7361","7642, , 9251, 7367","$0.00","Design methods are rapidly being incorporated into many sectors of the economy and reshaping the ways in which we visualize and understand science and engineering. Focusing on design work at four firms in three countries, this project studies hybrid virtual teams to identify which phases of the design process can be performed virtually and which require face-to-face interaction. In addition, it will build a prototype to aid in collaborative design activities by improving trust, building a social network, and providing visualization tools. Relying on theories from communications, information science and science and technology studies, the research team will use ethnographic observation and qualitative interviews with participants in cross-cultural design collaborations that include design professionals and under-served urban populations addressing issues of social innovation and sustainability. <br/><br/>Through this research, we will gain a better understanding of the degree to which culture, context and environment play a key role in the adoption and use of information and communication technologies to facilitate interaction and trust-building in virtual organizations. Understanding the issues underlying media choice and design is of theoretical and practical concern as the variety of media expands to include previously unavailable social media and as advanced features are added to existing media. A well-developed tool to improve collaboration among designers engaged in community development efforts would be of considerable value to this community. In addition, design methods would be useful to the research planning phases in multiple scientific disciplines to uncover new sets of problems, relationships and models. The interdisciplinary and international reach of this project will enhance its broader impact through significant exposure to and input from a wide variety of perspectives and cultures. The research involves undergraduate and graduate students and will result in their further training and education in interdisciplinary research."
"1117000","RI: Small: Collaborative Research: Learning to perform consistently in human/multi-robot teams","IIS","ROBUST INTELLIGENCE","08/01/2011","04/26/2013","Susan Epstein","NY","CUNY Hunter College","Standard Grant","James Donlon","07/31/2015","$223,412.00","","susan.epstein@hunter.cuny.edu","695 Park Avenue","New York","NY","100655024","2127724020","CSE","7495","7923, 7495, 9251","$0.00","This project focuses on practical deployment of human/multi-robot teams in situations where robots can explore regions that are unsuitable for humans. For example, a team of ""rescue"" robots can sweep through a collapsed building searching for victims and transmit their positions to human first-responders outside. Managing a human/multi-robot team in a dynamic environment is a challenging problem. Not only is the world mutable, but also the team can experience altered membership because a robot gets lost or a human operator needs rest---the world is changing, and so is the team that is exploring that world.<br/><br/>The goal of this research is to develop strategies for human/multi-robot teams to learn to perform consistently and effectively. Three primary aims will be pursued: first, to mitigate changes in team composition via a practical framework for institutional memory that remembers and uses past experiences; second, to model and record expertise for later use by learning behaviors performed by a human operator; and third, to distribute tasks among team members efficiently by providing a balanced mechanism for social choice. The novel approach of this project is applicable to a broad spectrum of human/multi-robot, and human/multi-agent teams, by integrating institutional memory, learning from human teammates, and resolving conflict among differing perspectives. The strategies will be evaluated using a human/multi-robot testbed comprised of one human operator plus a heterogeneous set of inexpensive, limited-function robots. Although each individual robot has restricted mobility and sensing capabilities, together the team members constitute a multi-function, human/multi-robot facility.<br/><br/>This project addresses important challenges in robust intelligence, including behavior modeling, learning from experience, making coordinated decisions, and reasoning under uncertainty. Expected outcomes include strategies for human/multi-robot teams that learn to collaborate effectively under a variety of conditions and can maintain their performance despite run-time changes in team membership, as well as knowledge about how people interact with robot teams. Broader impacts include providing access to a networked experimental testbed for remote collaborators; publishing proven curricular materials on multi-robot teams addressed to graduate, undergraduate and high school students; involving undergraduates in research activities; and working with existing contacts at local museums to demonstrate results to the general public."
"1017817","RI: Small: RUI: Evolution of Robustly Intelligent Computational Systems","IIS","ROBUST INTELLIGENCE","09/01/2010","08/19/2010","Lee Spector","MA","Hampshire College","Standard Grant","Todd Leen","08/31/2015","$423,288.00","","lspector@hampshire.edu","893 West Street","Amherst","MA","010023372","4135595378","CSE","7495","7923","$0.00","This project is extending the science of automatic programming, using concepts derived from evolutionary biology and software engineering, to permit the evolution of general and robust computational systems with multiple interacting functionalities and interfaces. The project uses the PI's Push programming language as the target language for evolved programs. Push programs are syntactically unconstrained, which facilitates evolution, but they can make use of arbitrary control and data structures; this supports the evolution of complex, modular programs.<br/><br/>This project will add new features to the Push language and develop new methods that allow requirements specifications and tests, of the type employed in software engineering practice, to be transformed into fitness functions that drive evolution. The cumulative effect of these extensions will be to support the evolution of significantly more general and robust computational systems.<br/><br/>The effectiveness of the technologies developed in this project will be demonstrated in two application areas: the automatic programming of small but complete productivity software applications and the automatic programming of robustly intelligent software agents for complex, time-varying economic games. The project is contributing to long-standing goals in computer science of building robustly intelligent systems and automatic synthesis of useful computer programs."
"0953219","CAREER: Using Machine Learning to Understand and Enhance Human Learning Capacity","IIS","ROBUST INTELLIGENCE","06/01/2010","05/05/2014","Xiaojin Zhu","WI","University of Wisconsin-Madison","Continuing grant","Todd Leen","05/31/2015","$465,586.00","","jerryzhu@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","1045, 1187","$0.00","Understanding and enhancing human learning are important challenges in the 21st century. Existing human category learning models cannot quantify important capacities such as people's (in)ability to generalize from training to test, to learn from imperfect data, or to learn by actively asking questions. <br/><br/>This research project studies human learning using machine learning. It first develops machine learning theory and algorithms to quantify these human learning capacities: It establishes learning-theoretic error bounds on human generalization performance; It models human learning from an imperfect teacher with non-parametric Bayesian methods; It models human's ability to ask informative questions with active learning theory. The project then studies computational approaches to enhance human learning: It develops ""machine teaching"" algorithms when the computer knows the target concept, and selects the optimal training examples to teach a human learner; It develops ""human machine co-learning"" algorithms when the computer does not know the target concept, but instead learns alongside the human and suggests better learning strategies to her. Each topic is verified by human experiments.<br/><br/>The project advances machine learning with new learning theory and algorithms on tasks where humans excel. It advances cognitive psychology with new models of human learning. It has broader impacts in understanding human intelligence, and in benefiting students with new educational tools. This research project is integrated with an educational plan that incorporates undergraduate and graduate teaching and mentoring, developing a new course and a book on machine and human learning, organizing seminars, tutorials and workshops, and sharing all results on a website."
"1218920","HCC: Small: Multimodal Technology Tools for Universal Access to STEM Education under the Common Core Curriculum","IIS","Cyber-Human Systems","09/01/2012","05/02/2014","Bruce Walker","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","08/31/2015","$599,248.00","","bruce.walker@psych.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923, 9260","$0.00","Given the importance of interpreting data, educators have made the teaching of graph concepts a core component of primary and secondary mathematics education. Unfortunately, the visual nature of a typical number line or graph presents a major disability for those with visual impairment. In current practice in the United States, blind students learn graphs with tactile graphics, which often represent a graph using raised dots (similar to Braille) embossed on paper. Tactile graphics are useful and have their place, but are increasingly marginal for two reasons. First, most visually impaired students now are in ""mainstream"" classes with their sighted peers. Mainstreaming can be beneficial in many ways, but makes it less convenient to provide alternative formats to the student; furthermore, teachers and other students will typically be unable to read Braille. Second, many classrooms are using computers for learning mathematics and graphs. Tactile graphics are generally not compatible with computers, and the very few current tools that are compatible are rudimentary or extremely expensive.<br/><br/>On a standard desktop computer, a natural alternative to visuals is audio. The use of auditory displays for mathematical data and graphs is not a new concept, however much still needs to be done in order to make these auditory graphs useful in the school curriculum. In this project, the PI seeks to address this need by exploring the upcoming Common Core Standards for the teaching of graphs in middle school classrooms and establishing a software system to allow visually impaired and sighted middle school students to author and explore graphs using sound. The software system will go through an ecological validation process based on the identified goals and operations of the Common Core Standards, and will include optimal auditory display designs based on the PI's findings from planned auditory graph perception experiments in multiple data sets and conveying concepts such as uncertainty.<br/><br/>Broader Impacts: This project opens a whole new field within assistive technology, making software-based accommodations possible and effective in the classroom. Students with vision loss stand to directly gain increased access to STEM materials from project outcomes; a solid STEM education will increase employability, which in turn will positively impact general income levels and quality of life for the members of this community. More broadly, however, it is clear that nearly all persons will benefit from appropriately designed and validated multimodal information displays. Thus, the background scientific knowledge that will be gained from this research will have foundational utility not only in this field but in many other disciplines as well, while the advances in curriculum-driven auditory graphing tools should lead to all manner of new uses for the technology in the field of education, HCI and beyond."
"0845336","CAREER: Computational Tools for Evolutionary Analysis of Biological Interaction Networks","IIS","INFO INTEGRATION & INFORMATICS","07/15/2009","05/02/2014","Luay Nakhleh","TX","William Marsh Rice University","Continuing grant","Sylvia J. Spengler","06/30/2015","$508,104.00","","nakhleh@rice.edu","6100 MAIN ST","HOUSTON","TX","770051827","7133484820","CSE","7364","1045, 1187, 7364, 9216, HPCC, 9251","$0.00","Intellectual Merit<br/><br/>Rapid advances in biotechnologies are amassing biological interaction data, such as protein-protein and gene-gene interaction networks, at unprecedented pace and rate, presenting a new powerful resource and allowing the reformulation of old, yet important, biological questions in a new context. The size and complexity of these new types of data pose great challenges for experimental and computational biologists alike. Addressing these challenges has been a primary focus of much research under the umbrella term of systems biology. However, almost no work has been done on providing tools for simultaneous evolutionary analysis of genomic and interactomic data. This project will delineate the signi&#64257;cant impact such a simultaneous analysis can have on understanding and analyzing biological interaction networks, and will explore new methodologies for conducting computational analyses. In particular, two areas will be addressed that will help shed light on interaction networks and their complexity:<br/><br/>1. Novel genome-interactome evolutionary models. Coalescent theory has been one of the central models for establishing the relationships among gene genealogies and species phylogenies. In its current form this theory neither allows for modeling events that arise in genomic studies, such as gene duplication and loss, nor has it been used to explain interaction network evolution. This research will extend coalescent theory to model genome-scale evolutionary events, and develop a new uni&#64257;ed framework for modeling the simultaneous evolution of genomic and interactomic data. <br/><br/>2. Novel stochastic modeling and inference using graph grammars. Stochastic models, such as hidden Markov models and stochastic context-free grammars, have been used extensively in the analysis of biological sequence data. However, no equivalent models have been introduced for analysis of interaction networks. This research will explore new applications of stochastic graph grammars, as well as ways in which these stochastic models can be used to provide insightful analyses of these networks. <br/><br/>Broad Impact<br/><br/>Situated at the intersection of cellular, molecular, and evolutionary biology, this work will have a signi&#64257;cant impact on the development and applications of computational tools such as stochastic graph grammars and dissimilarity measures. The project will provide opportunities for training students in an interdisciplinary area, and will result in the development of new courses focused on evolutionary analysis of biological networks. The interdisciplinary nature of the proposed work will help successfully recruit students to computer science from traditionally under-represented groups. The project methodologies will be implemented in software packages and made available through open-source mechanisms."
"1443097","WORKSHOP: Doctoral Consortium at the ACM International Conference on Multimodal Interaction 2014","IIS","Cyber-Human Systems","09/01/2014","05/02/2014","Jeffrey Cohn","PA","University of Pittsburgh","Standard Grant","Ephraim P. Glinert","08/31/2015","$21,496.00","","jeffcohn@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","CSE","7367","7367, 7556","$0.00","This is funding to support participation by about 8 graduate students from U.S. institutions, along with about 5 senior members of the ICMI community who will serve as mentors, in a Doctoral Consortium (workshop) to be held in conjunction with and immediately preceding the 16th International Conference on Multimodal Interaction (ICMI 2014), which will take place November 12-16, 2014, at Bogazici University in Istanbul, Turkey, and which is organized by the Association for Computing Machinery (ACM). The ICMI conference series is the premier international forum for multidisciplinary research on multimodal human-human and human-computer interaction, interfaces, and system development. The conference focuses on theoretical and empirical foundations, component technologies, and combined multimodal processing techniques that define the field of multimodal interaction analysis, interface design, and system development. Topics of special interest to the conference this year include: multimodal interaction processing; interactive systems and applications; modeling human communication patterns; data, evaluation and standards for multimodal interactive systems; and urban interactions. ICMI 2014 will feature a single-track main conference which includes: keynote speakers, technical full and short papers (including oral and poster presentations), special sessions, demonstrations, exhibits and doctoral spotlight papers. The ICMI 2014 proceedings will be published by ACM Press and included in the ACM Digital Library. As a further incentive for high-quality student participation ICMI 2014 will be awarding outstanding paper awards, with a special category for student papers. More information about the conference may be found online at http://icmi.acm.org/2014/. <br/><br/>The goal of the ICMI Doctoral Consortium is to provide PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers interested in designing multimodal interfaces. Student participants will present their ongoing thesis research as a short talk at the Consortium and also as a poster at the conference Doctoral Spotlight Session. Following the fruitful experience of last year's ICMI conference and doctoral consortium, and with the goal of providing more opportunities for interaction between the students and senior members of the field, the program will once again include a lunch on the day of the workshop for students and mentors, a career panel that will provide the students and mentors the opportunity to ask and answer questions and discuss challenges and opportunities in the field, and a dinner that will provide the students with the opportunity to hold informal conversations among themselves as well as with the organizers and mentors. <br/><br/>The Doctoral Consortium will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. The organizers will take steps proactively to achieve a diversity of research topics, disciplinary backgrounds, methodological approaches, and home institutions among the students. To further increase diversity, the organizers have committed that no more than two students will be invited from any given U.S. institution of higher learning, and when two are accepted one of them must be a woman."
"1150223","CAREER: Modeling and Design of Composite Swarming Behaviors","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","03/01/2012","05/02/2014","Nikolaus Correll","CO","University of Colorado at Boulder","Continuing grant","Satyandra Gupta","02/28/2017","$340,258.00","","ncorrell@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7495, 8013","1045, 9251, 7495, CL10","$0.00","This project, developing models for complex swarming behaviors by incrementally starting from the properties of an individual agent, which includes noisy sensors and actuators and stochastic behavior, and validating the models by systematic experimentation with physical systems, will bridge the gap between analysis by simple primitives and their composition into complex swarming behaviors. Specifically, this research will consist of a comprehensive study of containment, partitioning, and re-configuration swarming primitives, and then show how they can be composed into complex swarming behaviors such as pattern recognition, sensor-based motion, and adaptive shape change. These primitives and behaviors have been chosen because they challenge existing modeling approaches and lead to independent contributions addressing grand challenge applications by themselves.<br/><br/>Inspired by the robust and scalable operation of bees, termites, ants and multi-cellular organisms, the funding of this proposed work will lead to a methodology to compose stochastic swarming behaviors in a principled way using probabilistic models. These models will be grounded in the probabilistic behavior of an individual agent's sensing, actuation, communication and computational properties by modeling the system at multiple levels of abstraction going back and forth from physical experimentation, kinematic models, and stochastic simulations to macroscopic difference equations. By grounding the models in physical experiments, models will be able to serve as design tool for not only the computational, but also the physical properties of an individual agent.<br/><br/>Broader Impacts: A principled methodology for modeling and designing swarming systems will create the foundation for designing and deploying swarm robotic systems for search and rescue, environmental response, precision agriculture, and surveillance, among others. At the same time, the ability to design swarms might also shed light on the workings of biological and chemical systems, such as social insects, multi-cellular systems, and self-assembly, enabling the design of complex multi-cellular systems with arbitrary functionality. Finally, algorithms and systems resulting from this research lend themselves to artistic installations, drawing a broad public into the fascination of swarming systems and nurture an understanding for the distributed nature that is common to all living systems. The proposed research will be deeply integrated with education. Specific offerings developed in this integrated research and education plan include: a modular robotic activity that introduces computational thinking to 4th graders, a crash-course on embedded systems geared at 1st year students from under-represented groups, a comprehensive robotics curriculum for upperclassmen, and an interdisciplinary graduate seminar on ""Swarm Intelligence"" and ""Self-Assembly"" that will actively involve students from other disciplines and encourage them to apply the proposed multi-level modeling methodology to their research."
"1116886","III: Small: Exploring Social and Behavioral Contexts for Information Retrieval","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","05/02/2014","Hongyuan Zha","GA","Georgia Tech Research Corporation","Continuing grant","Sylvia J. Spengler","08/31/2015","$508,025.00","","zha@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7364","7923, 7364, 9251","$0.00","Web Search engines have become indispensible for people from all walks of life for locating information on a broad range of topics. Data from user's interactions with the search engines, web pages, and among each other provide a rich source of information for understanding and profiling users. This project develops a novel probabilistic framework and the associated machine learning algorithms for modeling users and their behavior on the web to improve the ranking of results returned in response to user queries. <br/><br/>This project addresses three closely related technical topics in behavioral and social data modeling, covering the underlying theory, algorithm development and evaluation on real-world data: 1) Developing rich models of user interactions with search engines, information sources, with each other that can handle multiple types of relationships among the entities; 2) Exploiting the resulting models of user behavior to improve the ranking of web pages returned in response to a user query; 3) Modeling the temporal dynamics of user behavior to detect and respond tp changes in the social environment of the user or context-dependent changes in the user's behavior. The resulting algorithms will be evaluated using (i) real-world data available in the public domain (ii) real-world data sets from industrial collaborators and (iii) simulated data that preserve the relevant statistical properties of their real-world counterparts.<br/><br/>The project advances the current state of the art in information retrieval, with potentially large impact on web search and related applications. Collaborations with industry leaders in Web search and e-commerce such as Yahoo!, Microsoft, Tencent and Alibaba can potentially lead to significant impact on information retrieval, web search and ranking, recommender systems, and related areas. The project offers enhanced research-based training opportunities for graduate and undergraduate students at Georgia Tech. Additional information about the project can be found at: http://www.cc.gatech.edu/~zha/socialL2R.html"
"1443673","RESNA Student Design Competition 2014","IIS","Cyber-Human Systems","05/01/2014","05/02/2014","Michael Brogioli","VA","Rehabilitation Engineering and Assistive Tech Society of NA","Standard Grant","Ephraim P. Glinert","04/30/2015","$20,146.00","","mbrogioli@resna.org","1700 North Moore Street","Arlington","VA","222091903","7035246686","CSE","7367","7367, 7556","$0.00","This is funding to support the undergraduate Student Design Competition (SDC), which will be part of the 2014 annual RESNA conference to be held June 11-15 in Indianapolis. Today, over 54 million people in the United States report some degree of disability, a number which will likely grow in coming years due to the baby boomer generation. RESNA, the Rehabilitation Engineering and Assistive Technology Society of North America, is the one organization with an international focus that is devoted solely to technology for individuals with disabilities. RESNA's membership consists of individuals and institutions covering a range of disciplines (including researchers, clinicians, suppliers, manufacturers, consumers and educators who work in both non-profit and for-profit settings), all of whom are dedicated to promoting the exchange of ideas and information for the advancement of assistive technology. In addition to its annual conference, RESNA conducts a variety of credentialing program for assistive technology practitioners, rehabilitation engineering technologists and suppliers, while the organization's Technical Standards Board is the U.S. Technical Advisory Group to ANSI, the official U.S. representative to the International Organization for Standardization (ISO), for the development of ISO standards pertaining to assistive technology and other products for persons with disabilities. More information about RESNA and its annual conference is available online at http://www.resna.org while information specific to the SDC may be found at http://aac-rerc.psu.edu/wordpressmu/RESNA-SDC and student team entry abstracts are included on the AT Wiki http://atwiki.assistivetech.net/index.php/ATWiki_Home. <br/><br/>The RESNA Student Design Competition fosters innovation and creativity with the ultimate goal of producing technology that can contribute to the independence of individuals with disabilities. The first SDC was held in 1980 as part of the inaugural RESNA conference; since then over 254 designs have been identified as winning entries from among over 788 submitted by students from over 125 different universities and institutes of higher learning. Both undergraduate and master's level graduate candidates are eligible to submit entries, which must represent the work of students only; no faculty or professionals may be included as co-authors, although faculty may be mentioned as advisors and/or mentors. NSF has been a supporter since 2005. This year's funding will enable the SDC to be further expanded and enhanced, so as to include more entries and support for more design teams, especially from minorities, women, and individuals with disabilities. A call for participation has been posted on the conference website, and also distributed electronically to a large number of colleges and universities with engineering and design schools. A team of 5 judges will pre-select up to 8 semi-finalist teams, from which two members each will be invited to attend the conference fully supported with travel and hotel funds as well as complimentary registration (NSF funds will cover the costs associated with 6 of the semi-finalist teams). On Thursday, June 12, during the pre-conference activities these teams will make presentations and show off their working prototypes to the judges before a public audience, and 5 finalist teams will be selected. Judges will have an opportunity to ask questions and make suggestions and recommendations to the design teams. The conference schedule includes a platform session on Sunday, June 15 in which the finalists will present their designs to the general conference audience; in addition, finalists will have an opportunity to present their projects during the Annual Developers' Forum on Friday evening, June 13, which highlights new products under development (some past SDC student team designs have been patented and are now available commercially).<br/><br/>The annual RESNA Conference and the Student Design Competition combine to create a forum for interaction between working and experienced rehabilitation engineers and students who are about to enter the field. Unique in its primary focus on undergraduates, the event provides participants with experience and skills that help them succeed in their engineering and design careers. It encourages and mentors students in various disciplines to become involved in the assistive technology and rehabilitation engineering fields, and provides an opportunity for the students to network with their peers as well as participants in previous SDCs, many of whom are now leaders in service, research, and educational areas related to technology for people with disabilities. Furthermore, continuing a practice started a few years ago, all participants (not just the finalists) will create blog posts that capture and archive their submissions, and these will remain accessible indefinitely through the RESNA website and the AT Wiki. Thus, those who teach will be able to share this information with their students as examples of projects that others have done, while service providers and people with disabilities will be able to search for unique solutions to barriers they may face."
"1302272","HCC: Medium: Scientists and their Software: A Sociotechnical Investigation of Scientific Software Development and Sharing","ACI","Cyber-Human Systems, VIRTUAL ORGANIZATIONS, Software Institutes, EDUCATION AND WORKFORCE","08/01/2013","05/02/2014","Charlotte Lee","WA","University of Washington","Standard Grant","Kevin Crowston","07/31/2016","$515,635.00","","cplee@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367, 7642, 8004, 7361","7367, 7433, 7642, 7924, 8004, 8005, 9102, 9179, 9251","$0.00","Scientific research is increasingly reliant on advanced social and technical infrastructures called cyberinfrastructure (CI). In turn, the cornerstone of scientific cyberinfrastructure is Scientific Cyberinfrastructure Software (SCIS) that enables data collection from digital instruments, analysis of data through the execution of mathematical algorithms, data visualization and sharing of data through standardized file formats and widely accessible databases. Despite the importance of SCIS for data-intensive research, too little is known about how scientists actually use, adopt and develop scientific software. More research is needed to explore how software, software development and software sharing practices are, and can be, community products, resources or practices. <br/><br/>This research project will examine how scientists develop SCIS as part of their day-to-day research practice through a qualitative, ethnographic study of 6 research groups using observations, semi-structured interviews, and document analysis. The researchers will investigate how decisions about SCIS are made; document, classify and analyze actual practices for using, adopting, developing or sharing software; identify scientists' incentives and disincentives to share software at the local, organizational and community levels; and discern the impacts, intentional and unintentional, that SCIS systems have on scientific data and the scientific research process.<br/><br/>Understanding SCIS development and sharing is necessary to ensure continued integrity of datasets shared within and among communities, facilitate the sharing of the tools and practices that are developed using national research funds and most importantly, support a fundamental tenet of scientific research: the open communication of the processes and practices behind published research findings. Furthermore, understanding these practices will support the education and training of our nation's future generations of scientists and engineers. This project will thus benefit domain scientists, SCIS developers, Computer Supported Cooperative Work (CSCW) and Software Engineering (SE) scholars and policy makers by providing conceptual tools that will provide guidance when considering how and when software can be designed and supported to be accessible and useful to the broader research community."
"1443104","Workshop: Support for doctoral students and junior researchers at The Digital Societies and Social Technologies Summer Institute","IIS","Cyber-Human Systems","05/01/2014","05/02/2014","Sean Goggins","MO","University of Missouri-Columbia","Standard Grant","Kevin Crowston","04/30/2015","$30,000.00","","gogginss@missouri.edu","310 JESSE HALL","COLUMBIA","MO","652111230","5738827560","CSE","7367","7367, 7556, 9150","$0.00","This is funding to support the ""Digital Societies and Social Technologies Summer Institute"" (DSST-SI), a five-day interdisciplinary training workshop designed to bring graduate students and young faulty together with established scholars working at the socio-technical interface between computer science, human-computer interaction, design studies, management information systems, and cyber-social science. The Consortium will enhance the scientific workforce in this emerging research area by developing a group of promising young researchers interested in socio-technical research and building a ""community of inquiry and practice"" that can address the mixture of technical, social and organizational challenges that characterize today's increasingly digital workplaces. <br/><br/>Today's emerging information and communication technologies (ICTs) promise significant advances across many domains of social and scientific interest; however, these technologies stand at an uncomfortable intersection of multiple scholarly and policy fields, ""useful to many but central to none."" The DSST Summer Institute seeks to convene and reinforce the community of social scientists, computer scientists, design researchers, and computational methods and data specialists, to begin building the missing intellectual and institutional infrastructure for sustained scholarship in this crucial but underdeveloped no-man's-land. NSF funding allows 30 doctoral students and early faculty to participate in the DSST Summer Institute program and become better integrated into the emerging DSST community.<br/><br/>In particular, the 2014 DSST Summer Institute will focus on problems that are limiting the sociotechnical community's ability to build coherent interdisciplinary dialogues, develop collaborative research agendas, and nurture new generations of emerging scholars. The 2014 Institute will also equip participants with the cyberinfrastructure concepts, theories and tools needed to enlist computational and big-data research methods in pursuit of new and transformative agendas in sociotechnical design science. Beyond raising awareness of advances in tools and techniques, the DSST Summer Institute will also develop interdisciplinary networks of sociotechnical scholars focused on critical ICT challenges and on realizing the transformative potential of emerging computational methods and big data resources within the ICT studies domain. In addition, the workshops will also serve an educational purpose, providing graduate students and other early-career researchers with training, feedback, and opportunities to build collegial and mentorship ties beyond their home departments. Moreover, beyond these direct contributions to strengthening the community for sociotechnical ICT Studies, the Summer Institute will also contribute to the infrastructure for computational and data-enabled science and engineering more generally, by enhancing understanding of the continuities and transformations that occur when work processes -- including scientific work practices -- move from physical to virtual settings."
"1433589","ACM BCB 2014: Conference on Bioinformatics and Computational Biology","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","05/02/2014","Catherine Welsh","TN","Rhodes College","Standard Grant","Sylvia J. Spengler","04/30/2015","$24,800.00","Pierre Baldi, Wei Wang","welshc@rhodes.edu","2000 North Parkway","Memphis","TN","381121624","9018433958","CSE","7364","7364, 7556, 9102, 9150","$0.00","The Annual ACM International Conference on Bioinformatics and Computational Biology is the premier ACM conference in the areas of bioinformatics, computational biology, and biomedical informatics, and the main flagship conference of the ACM SIGBio. The ACM BCB conference is in its fifth year. The 2014 ACM BCB conference, to be held in Los Angeles, CA September 20-23, 2014, is aimed at providing a better platform to bridge important interdisciplinary research areas in computer science, mathematics, statistics, biology, bioinformatics and biomedicine, and broaden the participation from underrepresented groups. While the development of the synergy of the research on bioinformatics and computational biology has proven to be very difficult, it is particularly challenging for female and minority students. ACM BCB is dedicated to exploring and developing such synergies. ACM BCB 2014 is expected to be a large annual gathering of researchers and students in computer science, computer engineering, applied computing, biology, medicine, biophysical sciences and life sciences. It will assemble a spectrum of affiliated research workshops, keynote and tutorial lectures, and special interest research sessions into a coordinated research meeting. To promote broad participation in this event, we plan to continue in our ?women in bioinformatics? initiative, which was created to recruit and engage young female students and researchers in this interdisciplinary area. In continuing this initiative, we plan to invite a distinguished female scientist as a keynote speaker whose experience and success may inspire many students.<br/><br/>The biggest beneficiaries of the conference will be the graduate students. Through their participation at the ACM BCB conference, graduate students will have great opportunities to meet distinguished researchers in the related fields, exchange ideas with other peers and foster more robust interdisciplinary research. Each supported student will participate in the PhD forum which will afford them an opportunity to interact with peers and mentors about their research. The travel supports requested will allow us to provide underrepresented minorities and female students with opportunities to meet the invited distinguished speakers, to present their own research ideas, to discuss any new research problems, and to foster new collaborations within a joint community of computational and biological researchers."
"1054585","CAREER: Nanosystems Enabled Intelligent End-effectors for Nanorobotic Manipulation","IIS","ROBUST INTELLIGENCE","01/15/2011","05/02/2014","Lixin Dong","MI","Michigan State University","Continuing grant","Satyandra Gupta","12/31/2015","$402,644.00","","ldong@egr.msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7495","1045, 7495, 9251","$0.00","Functionalized end effectors are built from nanosystems to support intelligent nanorobotic manipulation. This is achieved using segment-nanostructure-based nanoelectromechanical systems (NEMS) and nonophotonic systems. Internal electron tunneling and optical coupling are used as the common base of these end effectors for achieving high resolution while keeping to nano scale. Specific problems investigated include (1) the internal electron tunneling and optical coupling between the segmented elements in a nanostructure such as carbon nanotube shells, peapod nanowires, head-to-head positioned nanotube tips and dimmer nanospheres, (2) the development of sub-nanometer position/displacement sensors, picoNewton force sensors, and attogram mass detectors using the segmented nanostructures, (3) integrating these sensors onto transmission electron microscope compatible chips, atomic force catilevers, and rolled up helical nanobelts, and (4) the application of these systems.<br/><br/>The project impacts the development of new nanotechnology for nanorobotics including theory and processes for actual construction of systems. This leads to new tools for manufacturing and other technology fields such as the electronics and microscopy industries. Optical nanoantennas have the potential to remarkably enhance energy adsorption for solar cells. Applications are found in single molecule manipulation in biology, material characterization and inter-molecule interactions in supramolecular chemistry. General applications include the potential application of intelligent nanosystems in health care. Broad outreach is achieved through lectures, workshops, courses and websites for K-12 students and teachers, as well as for the public who have an interest in this emerging field."
"1351049","CAREER: Microscopy Image Analysis to Aid Biological Discovery: Optics, Algorithms, and Community","IIS","EXP PROG TO STIM COMP RES, ROBUST INTELLIGENCE","05/01/2014","05/01/2014","Zhaozheng Yin","MO","Missouri University of Science and Technology","Standard Grant","Jie Yang","04/30/2019","$488,149.00","","yinz@mst.edu","300 W 12th Street","Rolla","MO","654096506","5733414134","CSE","9150, 7495","1045, 9150, 7495","$0.00","This project develops image analysis algorithms and systems to process microscopy images that record the proliferation history of biological specimens and evaluate their behaviors that respond to different culturing conditions, therefore, deciphering complex biological processes and accelerating the advance of biological discovery. The research combines techniques of physical optics, computer vision and crowdsourcing to bring a breakthrough to microscopy imaging and microscopy image analysis. The developments of such technologies transform the image-based biology research from subjective to a rigorous, quantitative, and efficient manner. The research team also seeks to promote interdisciplinary collaboration between biological imaging and computer vision, integrate the research outcomes into education activities, and disseminate the project to a wide audience via web, K-12 group, conferences and industry collaborations.<br/><br/>Previous microscopy image analysis methods do not consider the particular image formation process and treat them in the same manner as general natural images, causing many difficulties or failures in the image analysis. This project addresses the challenges in a principally different way by investigating the theoretical foundation of microscopy optics. The computational imaging models of microscopes are derived and used to restore artifact-free images and extract optics-oriented image features, which makes the automated image analysis fundamentally correct and easy. The models are further used to enhance the microscope's functionalities including calibration and virtual microscopy. A cyber-enabled research community is being established within which active learning and crowd-computing are leveraged to improve the algorithm performance and biological discovery.<br/><br/>Updates are available from http://web.mst.edu/~yinz/."
"1347119","CAREER: Learning from Observational Data with Knowledge","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","05/01/2014","Samantha Kleinberg","NJ","Stevens Institute of Technology","Continuing grant","Sylvia J. Spengler","04/30/2019","$421,644.00","","samantha.kleinberg@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7364","1045, 7364","$0.00","Large observational datasets from social networks, climatology, finance, and other areas have made it possible for researchers to test complex hypotheses that previous studies would have been under-powered to tackle. This is especially true in biology and health, with the proliferation of new methods for gathering long-term population data, such as from electronic medical records, and real-world health data from body-worn sensors. However, the number of complex hypotheses that can be tested in datasets with hundreds or thousands of variables far surpasses what humans can propose and reason about. Exhaustively testing all possible relationships is not computationally feasible, and after this testing a researcher must still examine a non-trivial number of seemingly significant findings to determine which still need to be validated experimentally. This project aims specifically to infer causal relationships, as these provide insight into not only how a system behaves, but also why it behaves as it does, enabling the development of successful interventions. Results from this work will be incorporated into education at three levels (high school, undergraduate, and graduate) through university courses and summer programs for high school students. In addition to communicating the core concepts of causal inference, the summer programs will also introduce potential computer scientists to key areas of computer science research. Applications of the methods developed to data from stroke and diabetes may lead to new knowledge about the physiologic processes underlying recovery in stroke, and the complex interaction of factors affecting glucose in people with diabetes.<br/><br/>This work will lead to more robust and efficient inference of causal relationships from large-scale datasets, through a feedback loop between experiments and prior knowledge. Current approaches require users to specify the set of variables and hypotheses to be tested, but these limit findings to the set a user chose to explore. Instead this work will develop methods that can use prior knowledge in the form of causal relationships as well as prior experimental results to constrain what will be tested and generate new hypotheses. Causes provide information about their effect that are not contained in other variables, so this work will develop measures of how explanatory a cause is and how much information it yields, and use changes in this measure to guide generation of complex relationships in the constrained hypothesis space. The proposed approach differs from stochastic heuristics in that the new method will be deterministic, and will evaluate relationships individually, thus addressing the computational challenge and reducing the impact of incorrect inference. Second, the work will lead to algorithms that can automatically evaluate how findings relate to prior knowledge, whether they are, for example, consistent, novel, or contradictory. This will allow researchers to focus more in depth on findings likely to be significant or interesting, rather than those that simply confirm prior knowledge. It also provides a feedback loop between knowledge and inference."
"1253917","CAREER: A New Paradigm in Control and Coordination of Robot Teams in Geophysical Flows","IIS","ROBUST INTELLIGENCE","02/01/2013","05/01/2014","M. Ani Hsieh","PA","Drexel University","Standard Grant","Satyandra Gupta","01/31/2018","$255,999.00","","mhsieh1@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7495","1045, 7495, 9251","$0.00","Little prior work in unmanned underwater vehicles (UUVs) has addressed the tight coupling that is inherent between the fluid dynamics of the body of water and the vehicle itself. In fact, the fluid dynamics of large, open bodies of water can be quite complex and this proposal addresses large coherent structures that naturally occur in the flow structure of these large bodies of water. The goals of this project are to extend the PI's ONR YIP award into the realm of 3-D, expanding the mathematical and control framework for distributed autonomous sensing and tracking of geophysical fluid dynamics and to understand the long-term impact of geophysical fluid dynamics to improve the autonomy of underwater vehicles. The key idea exploits the capability of the team to cover large regions to increase the spatio-temporal sampling resolution of the flow field. The data will then be processed in a distributed fashion to obtain a global description of the flow dynamics that can be maintained and updated in real-time. The specific objectives that expand prior proposals include not only the 3-D modeling, but the development of an energy efficient stochastic pulse controller for tracking the ridges of the coherent structures and expanding the estimation of the structures through stochastic approaches that allow the fusing of larger teams of sensing entities. The intellectual merit of the proposed work stems from the synthesis of nonlinear dynamical systems theory, transport theory, and robotics to develop a modeling, control, and analysis framework for collaborative unmanned systems operating in dynamic and uncertain environments. The information gleaned from the coherent structures will be used to refine motion control and resource allocation strategies to determine minimum-effort stochastic control policies for long-term operation in GFD environments. To the PI's knowledge, this is the first attempt to use robots to track and map unstable coherent structures in the ocean, and to exploit knowledge of them to improve the autonomy of AUVs/ASVs.<br/><br/>Broader Impact: Success of these endeavors will improve the forecast of weather-climate systems, underwater transport dynamics, and the modeling and prediction of various other physical phenomena in geophysical flow environments. Since the proposed methods are very general and developed for continued operation in dynamic and uncertain environments, success of the proposed activities will likely increase the maneuverability and energy-efficiency of existing AUVs/ASVs; enable teams of AUVs/ASVs to continuously adapt to changing environmental conditions as they execute their assigned tasks; and provide greater situational awareness for various scientific, commercial, and military applications in the ocean. In addition, the proposed educational activities include a comprehensive plan to integrate the study of GFD into robotics through online educational modules for general K-12 audiences; an interdisciplinary undergraduate and graduate curriculum; and contributions to the robotics community in the form of open source software and hardware development tools."
"0803565","HCC-Medium: Personalized Socially-Assistive Human-Robot Interaction: Applications to Autism Spectrum Disorder","IIS","Cyber-Human Systems","08/01/2008","05/01/2014","Maja Mataric","CA","University of Southern California","Standard Grant","Ephraim P. Glinert","07/31/2015","$996,964.00","Shrikanth Narayanan","mataric@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7367, 9215, HPCC, 9102, 9251, 7924, 7218","$0.00","Robotics is currently at the forefront of technologies with recognized potential for impacting quality of human life. In response to the large need for personalized one-on-one care for the growing populations of elderly individuals and those with special cognitive and social needs throughout life, great strides must be made in the domain of human-robot interaction (HRI) in order to bring robotics into such application domains in human everyday life. This interdisciplinary project identifies a specific set of HRI research questions in socially assistive robotics, the study of robotic systems capable of providing help through social rather than physical interaction. The research focus is on two key issues: (1) the role of the robot's physical embodiment in the interaction; and (2) the use of expressive embodied communication and user modeling toward personalized time-extended assistive interaction. A specific consideration is given to interactions under the challenges of socio-communicative heterogeneity and deficits. A novel assistive robot control architecture is developed, based on multi-modal perception, embodied expression and communication, and on-line user modeling, implemented in three different types of real-world socially assistive systems. To give a realistic context to the research, the experimental testing and evaluation are performed with children drawn from a typical population and a population with Autism Spectrum Disorders (ASD), a family of disorders that have already been identified as amenable to technological, and in particular robotic, intervention and therapy. A key contribution of the research lies in the unified and tightly integrated end-to-end approach that jointly studies embodiment and multimodal expressive communication, grounded in data from hypothesis-driven experiments, and the development and use of novel signal processing and user modeling methods for human-machine interaction design. <br/><br/>This project, by its very nature, aims to impact the large and growing population affected by Autism Spectrum Disorders. With the support of the large and unique corpus of data that will be collected and analyzed, the expected scientific impact will go well beyond novel insights toward a better understanding of the fundamentals of HRI and its relevance for diverse user populations and for socialization of children with ASD. In addition to the basic research, two complementary educational outreach programs broaden the impact of the work: (1) a novel K-12 outreach and teacher training program specifically aimed at special education through the use of robotics for teaching STEM topics; and (2) undergraduate research training and pipelined role-modeling from pre-university to undergraduate to graduate students. The education programs dovetail with the research plan, resulting in integrated activities involving all participants in the research team."
"1438913","Group Travel Grant for the Doctoral Consortium of the IEEE Conference on Computer Vision and Pattern Recognition 2014","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC","06/01/2014","05/01/2014","Philippos Mordohai","NJ","Stevens Institute of Technology","Standard Grant","Jie Yang","05/31/2015","$15,050.00","","Philippos.Mordohai@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7495, 1640","7495, 7556","$0.00","This grant partially supports 20 students at institutions across the U.S. to participate in the Doctoral Consortium at the IEEE Conference on Computer Vision and Pattern 2014 Recognition (CVPR). CVPR is the premier annual conference with about 2000 senior and student participants in computer vision, held in North America and attended by members of the international research community. The Doctoral Consortium is to highlight the work of senior Ph.D. students, who are close to finishing their degrees, or recent graduates, and to give these students the opportunity to discuss their research with senior researchers matched with their expertise.<br/><br/>This project enables top-quality Ph.D. students to present, discuss, and receive feedback on original research within the broader community are all critical components of graduate student development. The opportunity to receive advice on their research and career plans from experts from different institutions, and with potentially different perspectives, in many cases is not available internally within one's own institution. This project supports the career development of some of the brightest junior researchers in computer vision, contributes to the computer research community and related fields in general by drawing attention to an important aspect of graduate student development, and potentially increasing the number of active researchers and teachers in STEM."
"1430651","EAGER: Simplification as Machine Translation","IIS","ROBUST INTELLIGENCE","05/01/2014","04/30/2014","Chris Callison-Burch","PA","University of Pennsylvania","Standard Grant","Tatiana D. Korelsky","04/30/2015","$99,663.00","","ccb@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7495","7495, 7916","$0.00","This EArly Grant for Exploratory Research aims to advance the text simplification technology that automatically rewrites complex English texts into simpler English texts. Research into this topic has many potential practical applications. It can provide reading aids for people with disabilities, low-literacy, non-native backgrounds or non-expert knowledge. It can also help with many other computer technologies that need to process difficult words and complicated sentences. This one-year exploratory project focuses on simplification for children with different reading levels. If this technology is successful, it could help make knowledge accessible to all children and gradually help to improve their reading skills.<br/><br/>Simplification can be thought of as a monolingual translation task, where the output is equivalent in meaning to the input, but its surface form is constrained by a readability or grade-level requirement. Prior work has drawn the connection between machine translation and text simplification, but has treated the SMT technology as a black box. Going beyond previous work, this study provides an extensive exploration of adapting key parts of the statistical machine translation pipeline to simplify text. It aims to tailor simplification to different readability levels. The three research activities being undertaken in this study are: (1) constructing a ""parallel corpus"" consisting of complex sentence paired with several different levels of simplification, (2) developing automatic metrics for targeted simplification, and (3) designing features for targeted simplification."
"0812687","RI-Small: Stochastic Learning: Modeling in Machines and Brains","IIS","ROBUST INTELLIGENCE","12/01/2008","05/01/2014","Peter Jacobs","OR","Oregon Health and Science University","Standard Grant","Jie Yang","08/31/2014","$290,721.00","","jacobsp@ohsu.edu","3181 S W Sam Jackson Park Rd","Portland","OR","972393098","5034947784","CSE","7495","7495, 9215, HPCC","$0.00","The discovery that synaptic plasticity is mediated by processes sensitive to the precise relative timing of pre- and post-synaptic events overturned models of synaptic change based on average activity levels (so-called rate-dependent models). This experimental discovery contradicted the conceptual framework that has dominated since the work of Donald Hebb (1949), and requires different theoretical and computational tools.<br/><br/>Individual synaptic events have inherent random variability, so computational synaptic dynamics in the new paradigm must be based in the theory of stochastic processes. Previous work modeling the stochastic dynamics of neural systems uses approximation tools -- the nonlinear Fokker-Planck equation (FPE) -- known to be deeply flawed and potentially misleading. The situation recalls the use of the FPE by machine learning theorists in the early to mid 1990s; indeed the dynamics of spike-timing-dependent plasticity in neural systems and those of stochastic approximation algorithms in the machine learning literature are very similar.<br/><br/>This project establishes rigorous tools for treating the stochastic dynamics of learning systems based on spike-timing-dependent synaptic plasticity. It develops well-grounded approximation techniques (and exact solutions where available) and applies them to synaptic dynamics in natural and artificial learning systems. The new methods are compared to those employed in the recent literature to provide insight into the accuracy and appropriateness of the various methods. The project is relevant to both computational neuroscience and machine learning, and will also provide interdisciplinary research training for graduate and undergraduate students."
"0905220","III: Medium: Collaborative Research: Computational Methods to Advance Chemical Genetics by Bridging Chemical and Biological Spaces","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","05/01/2014","George Karypis","MN","University of Minnesota-Twin Cities","Continuing grant","Sylvia J. Spengler","09/30/2015","$854,732.00","Michael Walters","karypis@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","7364, 7924, 9216, HPCC","$0.00","The recent development of various government and University funded screening centers has provided the academic research community with access to state-of-the-art high-throughput and high-content screening facilities. As a result, chemical genetics, which uses small organic molecules to alter the function of proteins, has emerged as an important experimental technique for studying and understanding complex biological systems. However, the methods used to develop small-molecule modulators (chemical probes) of specific protein functions and analyze the phenotypes induced by them have not kept pace with advances in the experimental screening technologies. Developing probes for novel protein targets remains a laborious process, whereas experimental approaches to identify the proteins that are responsible for the phenotypes induced by small molecules require a large amount of time and capital expenditure. There is a critical need to develop new methods for probe development and target identification and make them publicly available to the research community. Lack of such tools represents an important problem as it impedes the identification of chemical probes for various proteins and reduces our ability to effectively analyze the experimental results in order to elucidate the molecular mechanisms underlying biological processes. <br/><br/>Intellectual Merit <br/>This project will develop novel algorithms in the areas of cheminformatics, bioinformatics, and machine learning to analyze the publicly available information associated with proteins and the molecules that modulate their functions (target-ligand activity matrix). These algorithms will be used to develop new classes of computational methods and tools to aid in the development of chemical probes and the analysis of the phenotypes elicited by small molecules. The key hypothesis underlying this research is that the target-ligand activity matrix contains a wealth of information that if properly analyzed can provide insights connecting the structure of the chemical compounds (chemical space) to the structure of the proteins and their functions (biological space). Novel methods will be developed to: (i) better analyze the screening results and identify high affinity and selective hits, (ii) build models that can predict the compounds that are active against a novel protein target and select a set of compounds to be included in a high-throughput screen that will be enriched in actives, (iii) virtually generate a set of core molecules (scaffolds) for a given protein target that can be significantly different from those currently available in the various libraries and have a high probability of being active against the target, and (iv) identify the proteins being targeted by compounds in phenotypic assays. In addition, the research will be facilitated by creating a database to integrate a large portion of the publicly-available target-ligand binding data along with information about the targets and the compounds involved. The successful completion of this research will transform the &#64257;eld of chemical genetics by establishing a new methodology by which the increasing amount of target-ligand activity information is used in a systematic way to explicitly guide the discovery of new probes and the analysis of phenotypic assays. <br/><br/>Broader Impact <br/>The ability to discover chemical probes for a wide range of novel protein targets will make it possible to identify drugs for pharmaceutically relevant proteins, positively impacting the rate of drug discovery. In addition, it will greatly increase the set of proteins that can be selectively modulated via small organic molecules, expand the various biological processes that can be investigated via chemical genetics approaches, and allow researchers to use chemical genetics techniques to gain insights on the mechanisms of action associated with certain phenotypes. This will provide a better understanding of the dynamics of these processes and will supplement existing approaches based on molecular genetics. To further aid in the broad dissemination of the results and enhance scientific understanding, the computational methods developed will be made freely available via stand-alone or web-based services to aid researchers working in the area of chemical genomics. Finally, the project integrates the research with an educational plan that focuses on interdisciplinary undergraduate, graduate, and post-graduate education in the areas of Computer Science, Medicinal Chemistry, and Chemical Genetics. <br/><br/>Key Words: supervised learning; semi-supervised learning; cheminformatics; structural bioinformatics; data mining; graph algorithms"
"1442208","Workshop: Doctoral Consortium for HCOMP 2014","IIS","Cyber-Human Systems","05/01/2014","04/28/2014","Matthew Lease","TX","University of Texas at Austin","Standard Grant","Kevin Crowston","04/30/2015","$24,966.00","","ml@ischool.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) of promising doctoral students and distinguished research faculty to be held in conjunction with the HCOMP 2014 Conference on Human Computation & Crowdsourcing, sponsored by the Association for the Advancement of Artificial Intelligence (AAAI). The Consortium will enhance the scientific workforce in this emerging research area by developing a group of promising young researchers interested in human computation and crowdsourcing. The award will also enable these young researchers to attend the HCOMP 2014 conference, thus allowing them to interact with other researchers and conference events; to learn of potential career paths within academia and industry; to access an international network of researchers who can support their professional development; and to observe the interdisciplinary nature, diversity and interrelationships of research in human computation.<br/><br/>The HCOMP 2014 Doctoral Consortium will be a research-focused meeting of an international group of selected Ph.D. candidates with a panel of distinguished research faculty. The Doctoral Consortium Chairs will select six additional distinguished researchers to serve as faculty mentors; this group also will serve as the review committee for student applications. Students will be selected based on a paper giving an overview of the student's dissertation research, an explanation of why the students wants to participate in the Doctoral Consortium, a CV, and an advisor's letter of support. The PIs will give preference to students who are most in need of mentoring and joining a peer group. <br/><br/>The full-day workshop event will include activities to guide the research of these promising young researchers. The Consortium will allow participants to interact with established researchers and with other students, through presentations, question-answer sessions, panel discussions, and invited presentations. Each participant will give a short presentation on their research and will receive feedback from at least one faculty mentor and from fellow students. The Consortium will include activities led by the faculty, such as a panel discussion, to give students more information about the process and lessons of research and life in academia and industry. To further integrate the Doctoral Consortium participants into the conference itself, students will have a chance to present their work as posters in an interactive poster session and their papers will be posted online on the workshop webpage. These activities will benefit the participants by offering each fresh perspectives and comments on their work from researchers outside their own institution, both from faculty and other students; providing a supportive setting for mutual feedback on participants' current research and guidance on future research directions; and enabling participants to form a cohort of new researchers."
"1361690","HRI: Collaborative Research: Establishing and Breaking Conceptual Pacts with Dialog Partners","IIS","Cyber-Human Systems","09/02/2013","04/14/2014","Joy Hanna","NY","Daemen College","Continuing grant","Ephraim P. Glinert","09/30/2014","$16,321.00","","joy.hanna@oberlin.edu","4380 Main Street","Amherst","NY","142263544","7164805119","CSE","7367","7367, 7632","$0.00","Dialog-based technologies play an ever-increasing role in our lives. The interest in conversational interfaces stems not only from their importance for universal access, but also because they can be used in settings in which traditional hands-on interface devices are not practical. Efforts are underway to extend the use of dialog systems into new roles, including: becoming companions to help seniors remain independent; moving some aspects of healthcare outside of the clinical setting; providing entertainment and interactive theater experiences; and improving disaster response. In many of these systems, the computer conversational partner is presented as a talking head or graphical persona. Although designers of dialog systems aim to make them simple and natural to use, major gaps in our understanding of human-computer interaction create obstacles to achieving this goal.<br/><br/>Some of these gaps are likely to be filled by examining recent psycholinguistic models of human conversational interaction. These models explore the time-course with which information coming from the context of conversation affects language processing. This context includes the shared information, or common ground, between interlocutors, as well as the processes by which reference to items in common ground is coordinated. One property of negotiated reference concerns the establishment of conceptual pacts, which are a (usually implicit) agreement to refer to an item in common ground from the same conceptual perspective. Recent psycholinguistic findings have examined whether conceptual pacts in conversation are speaker-specific, and how quickly this information is used during comprehension. To the extent that speaker-specific conceptual pacts have significant and immediate effects on the interpretation of reference in human-human interaction, dialog systems utilizing computer-based partners should take these characteristics into account in human-computer interaction."
"1115220","III: Small: Algorithmic Tools for Spatial Positioning Studies in the Cell Nucleus","IIS","INFO INTEGRATION & INFORMATICS, ALGORITHMIC FOUNDATIONS","08/01/2011","07/22/2011","Jinhui Xu","NY","SUNY at Buffalo","Standard Grant","Sylvia J. Spengler","07/31/2015","$499,968.00","Ronald Berezney","jinhui@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7364, 7796","7923, 7929","$0.00","Spatial positioning has emerged as a fundamental principle governing nuclear processes. Research on chromosome territories has indicated that the 3-D arrangement of these territories within the architecture of the cell nucleus may be closely linked to genomic function, regulation and cell differentiation. Despite this progress, the degree of non-random arrangement of chromosome territories remains unclear and no overall model at the global level has been proposed. In addition, little is known about the gene positioning inside the chromosome territories and its relationship to gene expression. This project is for developing algorithmic tools to facilitate the study of three important spatial positioning problems, (1) topology of chromosome territory, (2) chromosomes associations and spatial positioning, and (3) topological structures of associated chromosomes territories. The focus of this project is on designing efficient algorithms for several challenging computational problems which are essential for the spatial positioning problems, such as chromatic cone clustering, realization, maximum median graph, and optimal surface extraction.<br/><br/><br/>The project will use computational geometry techniques and optimization methods to develop a set of efficient algorithmic tools for the proposed problems. The designed and tested algorithms and techniques will be used as automatic (or semi-automatic) tools to accurately and reliably determine the spatial positioning information of genes and chromosome territories, and further elucidate the coordination of genomic expression. Algorithms from this project are also likely to be used in many other areas as information integration tools and positively impact them. This project could lead to several long term impacts. It could yield a much needed global model for studying the spatial positioning of chromosome territories and genes. The obtained algorithmic and biological results will be used to study and compare the difference of various cancer and normal cells in topological structures and associations of chromosome territories and genes. This could potentially lead to significant biological discoveries and help better understanding the mechanism of diseases (such as cancers) and their relationship to chromosome structures and associations."
"1149745","CAREER: Individual Attributes and Social Participation: Designing for Citizen Science","IIS","Cyber-Human Systems","03/01/2012","04/25/2014","Oded Nov","NY","New York University","Continuing grant","William Bainbridge","02/28/2017","$329,125.00","","on272@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7367","1045, 7367, 9251","$0.00","This project seeks to transform the study of technology-mediated social participation through the human-centered computing equivalent of genetically targeted medicine. Just as advances in medicine enable us to use information about a person's genetic profile to target medical treatment to his needs, information about a user's personal attributes such as his motivations and personality traits can be used to target individually-tailored, theory-driven design aimed at increasing the user's participation in technology-mediated social efforts. The research focus is on technology-mediated citizen science, which offers an ideal laboratory for studying issues that are important in many other fields. The project will involve three citizen science modalities: distributed analysis, distributed data gathering, and volunteer computing. The research will test the effectiveness of design features informed by social psychology theory and human-computer interaction research, and develop a rigorous theoretical understanding of individually-tailored design.<br/><br/>The project seeks to advance human-centered computing theory and practice. The intellectual merits of the research therefore include: 1) advancing technology-mediated social participation theory by developing a theoretical framework that combines personal attributes and design; 2) developing and testing empirically a novel technique and specific design guidelines to enhance technology-mediated social participation, with application to citizen science projects.<br/><br/>The unique setting of this research within the citizen science domain promises long-term benefits to society and science. In particular, the broader impacts of the research include: 1) leveraging technology-mediated social participation and citizen science to engage members of the public in science and scientific work, and in particular, members of disadvantaged communities to whom traditional science-related activities may otherwise not be accessible; 2) enhancing the infrastructure for scientific research through effective citizen science; and 3) integrating technology-mediated citizen science in outreach programs."
"1116384","HCC: Small: Building Audio Interfaces with Crowdsourced Concept Maps and Active Transfer Learning","IIS","Cyber-Human Systems","09/01/2011","08/16/2011","Bryan Pardo","IL","Northwestern University","Standard Grant","Ephraim P. Glinert","08/31/2015","$499,804.00","Darren Gergle","pardo@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7923","$0.00","The United States is a world-leader in software and in multimedia content (e.g. music, film). To remain so, we must continually raise the bar in both software and media production. Software tools for media production (e.g. the audio production suite Protools) often have complex interfaces, conceptualized in ways that makes it difficult for any but the most expert to realize the power of these tools. Complex interfaces and steep learning curves can discourage creative people from doing their best work with such tools. Here, we focus on audio production tools. We propose a user-centered approach to remove the great disconnect between existing audio production tools and the conceptual frameworks within which many people work, both expert musicians and the broader public. The tools we develop will automatically adapt to the user's conceptual framework, rather than forcing the user to adapt to the tools. Where appropriate, the tools will speed and enhance their adaptation using active learning informed by interaction with previous users (transfer learning). The tools will also automatically build a crowdsourced audio concept map. This will help provide facilities for computer-aided, directed learning, so that tool users can expand their conceptual frameworks and abilities. By letting people manipulate audio on their own terms and enhancing their knowledge of such tools with directed learning, we expect to transform the interaction experience, making the computer a device that supports and enhances creativity, rather than an obstacle.<br/><br/>This work will have a number of broader impacts. The tools developed will be directly usable by practicing musicians and will also facilitate learning and creativity for the general public. These techniques will also be applicable to personalization of hearing aids and new diagnostic systems for audiologists. Our approach to tool personalization is core work in human-computer interaction and should generalize to other creative activities (e.g. image manipulation). Resulting advances in active and transfer learning will be of great value to machine learning researchers. Finding the relationships between quantifiable parameters of audio and the language and metaphors used by practicing musicians to describe sound is central to this work. This is of great interest to cognitive scientists, linguists, artificial intelligence researchers, and engineers. Concept maps for audio terms should also prove useful for machine translation. Broad application of techniques to map human descriptive terms on to machine-manipulable parameters will change expectations for both artists and scientists. Artists will be able to explore new lines of creativity that currently require significant investments of time in vastly disparate fields (e.g. signal processing and painting). This has the potential to transform information science and lead to new cognitive models of creativity, forming the basis for new approaches to education and research in both technology and in art."
"1350553","CAREER: Holistic Scene Understanding with Multiple Hypotheses from Vision Modules","IIS","ROBUST INTELLIGENCE","09/01/2014","04/25/2014","Dhruv Batra","VA","Virginia Polytechnic Institute and State University","Continuing grant","Jie Yang","08/31/2019","$93,038.00","","dbatra@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7495","1045, 7495","$0.00","This project develops algorithms and techniques for holistic scene understanding from images. The key barrier to building the next generation of vision systems is ambiguity. For example, a patch from an image may look like a face but may simply be an incidental arrangement of tree branches and shadows. Thus, a vision module operating in isolation often produces nonsensical results, such as hallucinating faces floating in thin air. This project develops a visual system that jointly reasons about multiple plausible hypotheses from different vision modules such as 3D scene layout, object layout, and pose estimation. The developed technologies have the potential to improve vision systems and make fundamental impact - from self-driving cars bringing mobility to the physically impaired, to unmanned aircrafts helping law enforcement with search and rescue in disasters. The project involves research tightly integrated with education and outreach to train the next generation of young scientists and researchers. <br/><br/>This research addresses the fundamental challenge in joint reasoning by extracting and leveraging a small set of diverse plausible hypotheses or guesses from computer vision modules (e.g. a patch may be a {sky or a vertical surface} x {face or tree branches}). This project generates new knowledge and techniques for (1) generating a small set of diverse plausible hypotheses from different vision modules, (2) joint reasoning over all modules to pick a single hypothesis from each module, and (3) reducing human annotation effort by actively soliciting user feedback only on the small set of plausible hypotheses. <br/><br/>Project Webpage: http://computing.ece.vt.edu/~dbatra"
"1440662","Grant for Doctoral Consortium of the 2014 IEEE International Conference on Robotics and Automation (ICRA 2014)","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC","05/01/2014","04/25/2014","Uchechukwu Wejinya","AR","University of Arkansas","Standard Grant","Satyandra Gupta","04/30/2015","$25,000.00","","uwejinya@uark.edu","210 Administration Building","FAYETTEVILLE","AR","727011201","4795753845","CSE","7495, 1640","7495, 7556, 9150","$0.00","This award supports U.S. Ph.D. student travel to a doctoral consortium held at ICRA 2014 in Hong Kong, China, from May 31 to June 7, 2014. The goal of the doctoral consortium is to highlight the research work of US Ph.D. students. This gives an opportunity for the students to interact with senior faculty and get feedback on their work. Participants and recipients of this travel support will be selected by the 2014 ICRA organizing committee based on their thesis work. Participating in a conference is a critical component of graduate student development. This award aims to have a diverse representation of participants in terms of gender, ethnic background, academic institution, and geographic location."
"1117956","RI: Small: Towards Practical Tractability in Constraint Processing","IIS","ROBUST INTELLIGENCE","08/01/2011","06/10/2013","Berthe Choueiry","NE","University of Nebraska-Lincoln","Standard Grant","James Donlon","07/31/2015","$419,564.00","","choueiry@cse.unl.edu","2200 Vine St, 151 Whittier","LINCOLN","NE","685830861","4024723171","CSE","7495","7923, 9150, 9251, 7495","$0.00","Many problems in artificial intelligence, engineering, and management can be advantageously modeled and solved as Constraint Satisfaction Problems, but scalability remains in practice a major obstacle to the successful deployment of Constraint Solvers. The goal of this project is to design algorithms and strategies that enable computers to overcome, in practice, the scalability barrier. To this end, the proposed research targets the two fundamental mechanisms in Constraint Processing that are the most promising for breaking the complexity barrier, namely, enforcing consistency and detecting and breaking symmetry. This project aims to design new algorithms for those two mechanisms and develop strategies for intertwining them. <br/><br/>The tractability of a problem is guaranteed by a relationship between a structural parameter of the problem and its level of consistency. This project aims to design algorithms that enforce the needed level of consistency without adversely modifying the structure of the problem. Symmetries can be detected and exploited to dramatically reduce the cost of problem solving. This project aims to (1) design algorithms for detecting symmetries, and (2) develop approximation strategies for exploiting them without sacrificing the soundness and completeness of problem solving. A key observation is that algorithms for enforcing consistency and those for locally detecting symmetry are based on the same atomic operations. Furthermore, they seem to be effective under complementary operating conditions. This project further aims to design strategies for intertwining the operation of the two types of algorithms so that the application of the one type enables and facilitates that of the other type, in order to yield new opportunities to control the combinatorial explosion. The approach will be validated on applications of practical importance and extended to address similar combinatorial problems in other areas of Computer Science such as Databases and Software Engineering.<br/><br/>The proposed activities contribute to the progress of the research on two fundamental aspects of Constraint Processing. From a practical perspective, this research directly benefits many combinatorial problems of practical importance. From a scientific standpoint, this project will identify connections and build new bridges with other areas of Computer Science, such as Databases and Software Engineering. The insight gained from these investigations will be used to improve the scope and content of introductory and advanced courses on Constraint Processing. The opportunities and research avenues will be heavily exploited to involve undergraduate students in research and to give them experience in using the project's insights on problems that they find engaging (e.g., Sudoku) and for understanding the operation of algorithms in Computer Science courses; the goal is to motivate students to conduct research in Constraint Processing and to transfer results from this field to other students and researchers in Computer Science, Mathematics, Engineering, to entice high-school students to study Computer Science, and in addition, to explain to the general public some of the fundamental mechanisms at the heart of complex problem solving."
"1253393","CAREER: On the identification of collections with complex objectives","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","04/23/2014","Evimaria Terzi","MA","Trustees of Boston University","Continuing grant","Sylvia J. Spengler","02/28/2018","$180,541.00","","evimaria@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364","1045, 7364","$0.00","In many domains, there is an increasing reliance on Recommender Systems for helping identify products, services and people that meet some user-specified criteria. Given a pool of entities (e.g., movies, books, experts) and an objective function such systems have to identify a collection (i.e., a subset) of entities from the pool that optimizes the objective function. For example, in movie-recommendation systems (e.g., Netflix) the goal is to identify subsets of movies to recommend to registered users. Analogous problems arise in social networks and social media (e.g., Twitter, Facebook), where advertisers need to identify a small set of targets for their advertisements. Finally, project management teams in large organizations often use expertise management systems to identify the subset of experts needed to complete a specific project.<br/><br/>Current Recommender Systems suffer from severe limitations in settings where (i) the users multiple interactions with the system over time and the recommendations provided to a specific user at any given time need to take into account the past recommendations given to the same user or (ii) The entities that make up the recommended collections are rational entities, e.g., participants in a social network, or members of a project team, that have their own goals and preferences that influence their behavior as members of the collection. This project aims to address these two shortcomings of current Recommender Systems by designing, implementing, and evaluating combinatorial algorithms for identifying (a) sequences of collections, rather than a single collection and (b) collections of rational entities with individual goals, preferences, or objectives.<br/><br/>In addition to developing a suite of novel combinatorial algorithms and heuristics for recommending sequences of collections and collections of rational entities, the project aims to develop and deploy two application-specific testbeds: (i) a personalized meal planner provides to its users weekly meal recommendations to guide them towards healthy eating choices; and (ii) A crowdsourcing platform with support for virtual team formation to allow students registered in some of the courses at Boston University, to form teams online to collaborate on class projects (when appropriate). <br/><br/>Broader impacts of this research include: new models and methods that signficantly advance the current state of the art in Recommender Systems, with broad applications in a number of domains including social networks (e.g., LinkedIn, Facebook, etc.), online recommendation systems (e.g., Amazon, Netflix, etc.), and daily-deal sites (e.g., Groupon, LivingSocial, etc.). The project contributes to the education and advanced research-based training of graduate and undergraduate students in Computer Science at Boston University. Wide dissemination of software implementations of the algorithms can be expected to benefit the larger research community.<br/><br/>Additional information about the project, including links to project personnel, publications, and software can be found at: http://www.cs.bu.edu/~evimaria/recommendations.html"
"1151305","EAGER: A General Ethical Dilemma Analyzer","IIS","Cyber-Human Systems","09/01/2011","07/12/2013","Michael Anderson","CT","University of Hartford","Standard Grant","Ephraim P. Glinert","05/31/2015","$76,243.00","","anderson@hartford.edu","200 Bloomfield Avenue","West Hartford","CT","061171545","8607685938","CSE","7367","7367, 7916","$0.00","Systems that are capable of producing change in the environment require particular attention to the ethical ramifications of their behavior. The determination and mitigation of the ethical concerns of such systems has to date been charged to their designers and has largely been accomplished by simply preventing systems from engaging in ethically unacceptable behavior in a predetermined, ad hoc manner, which can unnecessarily constrain the set of possible behaviors. Although this may have been considered ""best practice"" in the past, the coupling of computational intelligence to such systems is likely to provide better options. This is especially true of autonomous systems, which not only produce change in the environment but are capable of monitoring this environment to determine the effect of their actions as well as what the next action should be. Ethical questions concerning the behavior of such complex and dynamic systems are likely to exceed the grasp of their designers and elude simple static solutions. Autonomous systems will therefore need tools and methodologies to help codify ethical principles pertinent to their behavior, principles which form the basis for the autonomous selection and justification of ethically preferable actions.<br/><br/>In this research, the PI and his team will develop and implement a general methodology for the discovery of ethical principles, abstracted from their previous work, which incrementally constructs representations that characterize ethical dilemmas and discovers decision principles necessary to resolve them. They will use this system to codify representation schemes and principles of ethical decision-making in domains that are of particular significance to autonomous systems in their interaction with human beings. And they will evaluate the discovered representations and principles through independent consultation. The PI expects project outcomes will provide evidence that ethical principles and decision-making can be computed and function effectively in domains where machines are likely to interact with human beings.<br/><br/>Broader Impacts: This research will lay the foundations for providing autonomous systems across multiple domains with the principles required to choose the most ethically correct actions and justify these choices. Thus, the work should alleviate concerns with autonomous systems and bolster society's support for their development in a wide range of domains. An important by-product of the research is that breakthroughs in ethical theory are likely to result as representations and principles for resolving ethical dilemmas are discovered."
"1018641","RI: Small: Convex Architecture for Human Movement Understanding","IIS","ROBUST INTELLIGENCE","08/01/2010","05/09/2011","Hao Jiang","MA","Boston College","Continuing grant","Jie Yang","12/31/2015","$380,193.00","","hjiang@cs.bc.edu","140 Commonwealth Avenue","Chestnut Hill","MA","024673800","6175528000","CSE","7495","7923, 9150","$0.00","This project focuses on convex methods for human movement understanding, the task of estimating and quantifying human motion and movement in videos. Compared with previous approaches, the convex methods explicitly model complex inter-component correlations and global constraints and are able to achieve more reliable results. The convex formulations are automatically generated using learning methods. By taking advantage of their special structures, efficient algorithms are devised. This project studies human movement understanding from different perspectives and provides convex solutions to global movement estimation, body part tracking, and local patch motion trajectory estimation. The key research components include convex articulated graph matching with complexity decoupled from the sizes of target candidate sets, convex structure learning and efficient decomposition methods for solving large-scale problems. With robust movement estimation, this project further addresses performance recognition, a new application that quantifies the style and performance of actions.<br/><br/>This project benefits surveillance, robotics, human computer interaction, entertainment, sports and medical applications. The convex framework developed in this project can also be extended to many other areas to construct optimal models for information retrieval, control systems, scheduling and network analysis, and to solve large-scale problems in operational research and simulation. <br/><br/>This project develops a new technology for understanding human movements; a benchmark dataset is also developed. The results are disseminated by peer reviewed publications, web page downloads, and by university courses."
"1250627","EAGER: T2K: From Tables to Knowledge","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/24/2012","Anupam Joshi","MD","University of Maryland Baltimore County","Standard Grant","Sylvia J. Spengler","08/31/2014","$200,000.00","Timothy Finin","joshi@cs.umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7364","7916","$0.00","The Web has made humans smarter, providing ready access to vast amounts of knowledge and facts. The Semantic Web has the capacity to similarly enhance computer programs and devices by giving them access to enormous volumes of data, facts and knowledge. This project is exploring the feasibility of automatically extracting new knowledge directly from data found in spreadsheets, database relations, and document tables and representing it as highly interoperable linked open data (LOD) in the Semantic Web language RDF. The extraction is guided by probabilistic graphical models that use statistical information mined from current LOD knowledge resources. To demonstrate the potential payoff of the research, the system is used to extract knowledge from tables collected from medical journals and tables from web sites like data.gov. <br/><br/>While the W3C semantic web languages RDF and OWL are used to represent the knowledge, the results are applicable to other semantic data frameworks such as Microdata (Search Consortium), Freebase (Google), Probase (Microsoft) and the Open Graph (Facebook). The open sourced prototype software allows other researchers to experiment with automatically producing semantically enriched data from tables for their domains.<br/><br/>If successful, such software extraction systems are expected to become part of a new online knowledge ecology -- both consuming existing LOD knowledge to understand the intended meaning implicit in a table and producing new facts and knowledge that will become part of Web. This represents a dramatic increase in the breadth and depth of public semantic data that can make ""big data"" analytics more effective."
"1116676","RI: Small: Collaborative Research: Statistical Learning of Language Universals","IIS","ROBUST INTELLIGENCE","08/01/2011","07/26/2011","Benjamin Snyder","WI","University of Wisconsin-Madison","Standard Grant","Tatiana D. Korelsky","07/31/2015","$339,978.00","","bsnyder@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","7495, 7923","$0.00","As modern technology infrastructure spreads throughout the world, the quantity of electronic text, written in hundreds of different languages, continues to grow in size and diversity. Building effective information retrieval, extraction, and translation systems across this vast array of languages currently requires time-consuming and expensive linguistic annotations for each language. Generic, fully unsupervised, methods are unlikely to provide a language independent solution to this problem.<br/><br/>Focusing on part-of-speech prediction, this project undertakes a novel approach, combining elements of supervised and unsupervised learning without assuming any specific knowledge of the target language. Instead of treating individual languages as closed systems, language-independent ""universals"" are statistically estimated from dozens of languages for which annotated corpora exist, and these learned universals are used to predict the part-of-speech categories of unannotated languages. At the heart of the project is a data-driven exploration of language-independent corpus characteristics that relate cross-lingual linguistic categories to surface statistics of text. These learned patterns are incorporated into expressive structured prediction models using novel approximate learning and inference methods developed by the Principal Investigators of the project.<br/><br/>Of the world?s spoken languages, hundreds are at risk of immediate extinction and thousands more are likely to disappear over the coming decades. By facilitating the rapid creation of language-independent linguistic analysis tools, the technology developed under this project has the potential to revolutionize the documentation of endangered languages. In the long-term, this research direction will also help realize the full social benefits of the global technology infrastructure by creating intelligent text processing tools for hundreds of low-resource languages."
"1116656","RI: Small: Intelligent Autonomous Video Quality Agents","IIS","ROBUST INTELLIGENCE, COMM & INFORMATION FOUNDATIONS","09/01/2011","08/29/2011","Alan Bovik","TX","University of Texas at Austin","Standard Grant","Jie Yang","08/31/2015","$499,944.00","Joydeep Ghosh","bovik@ece.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495, 7797","7923, 7936","$0.00","Determining the perceptual quality of video transmitted through complex networks and viewed on heterogeneous platforms, from cell phones to Internet-based television, is a key problem for the YouTube generation. It is also central to a variety of vision applications including face detection, face recognition and surveillance. Video is subject to numerous distortions: blur, noise, compression, packet/frame drops, etc. Quality assessment is non-trivial when an undistorted video is not available, and unsolved for multiple distortion types and in distributed, non-stationary viewing environments.<br/><br/>This project designs and creates intelligent video ""quality agents"" that learn how to determine perceptual video quality in heterogeneous networks, and assesses its impact on decision tasks such as face detection and recognition, all without the benefit of reference videos. It uses statistical properties of natural scenes, perceptual principles, machine learning, and intelligent adaptive agent collectives to handle videos simultaneously impaired by multiple distortion types. A primary application is novel face-salient quality assessment agents and quality-aware face detection algorithms. Multiple, co-operative video and face quality agents are trained using active learning based feedback mechanisms on mobile devices. This project yields adaptive, robust video Quality of Service assessment in real-life networks and provides new insights into human visual quality perception and visual distortion detection. The research team also creates two large, unique video quality databases: (a) A Mobile Video Quality Database of raw and distorted mobile videos and (b) A Distorted Face Database of undistorted and distorted face images, as gold standards for research and development in this area."
"1115678","RI: Small: Ultra-Sparsifiers for Fast and Scalable Mapping and 3D Reconstruction on Mobile Robots","IIS","ROBUST INTELLIGENCE","07/01/2011","06/29/2011","Frank Dellaert","GA","Georgia Tech Research Corporation","Standard Grant","Satyandra Gupta","06/30/2015","$448,645.00","","dellaert@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7923","$0.00","This project develops and realizes efficient and large scale mapping and 3D reconstruction on mobile robots. We develop a new optimization paradigm which combines the advantages of both direct and iterative methods by (1) investigating a novel class of optimization methods for robot mapping problems: subgraph-preconditioned conjugate gradients (SPCG) that combine the advantages of direct and iterative methods while minimizing the disadvantages, (2) investigating subgraph preconditioner selection and quality analysis, (3) applying the above techniques to large-scale 3D reconstruction problem mobile robots, and (4) investigating on-line versions of these algorithms. We adapt the SPCG for this setting by incrementally building the graph sparsifier that gives us a good preconditioner.<br/><br/>Beyond robotics and vision, we show that similar bounds can be derived for the general problem of approximating distributions. A concrete deliverable of the proposed work is a software package that embeds the new hybrid approach to solving the mapping/reconstruction non-linear optimization problem, and is easily deployable to a wide range of mobile robotic platforms: terrestrial, aerial, underwater, or underground, acting individually or in teams. The robotics research community has access to this technology, which provides great improvement over the capabilities of current mapping/reconstruction software, both in terms of the size of the problem, as well as in terms of speed and online applicability. Finally, at a more local level, this research impacts education of both graduate and undergraduate students at Georgia Tech."
"1302393","RI: Medium: Collaborative Research: Decision-Making on Uncertain Spatial-Temporal Fields: Modeling, Planning and Control with Applications to Adaptive Sampling","IIS","ROBUST INTELLIGENCE","06/01/2013","04/22/2014","Dylan Shell","TX","Texas Engineering Experiment Station","Continuing grant","Satyandra Gupta","05/31/2017","$113,625.00","","dshell@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495","7495, 7924","$0.00","Inland bodies of freshwater are a resource that is critical for the Nation's health and safety. This project is developing a new spatio-temporal field representation suitable for modeling, planning and control under uncertainty in order to improve monitoring of such water systems. The project's focus is on a reconfigurable aquatic sensor-actuator network designed to capture data from coupled physical, chemical, and biological processes that occur across space and time-scales. The key advantages of this sensor-actuator network in its application to this domain include synoptic volume coverage, adaptive sampling, flexible control and robustness to component failure. The research objective is to build models of dynamic processes for which high resolution sampling is necessary at special locations. Toward this end, this project is contributing new methods, data-structures, algorithms, and implementations validated by field testing a heterogeneous system consisting of stationary and mobile (robotic) underwater node. <br/><br/>This project provides unique interdisciplinary opportunities for education of both graduate and undergraduate students via new course work that blends projects and research topics directly into courses and newly developed seminars. It provides a multi-disciplinary experience for students while developing their engineering skills. Relevant components of computer science, computer engineering, and mechanical engineering are integrated together by using the project's aquatic platform and experimental scenarios as a focal point. <br/><br/>The project advances the state-of-the-art for such systems because it integrates low-level dynamic processes with high-level planning and distributed optimization. The research represents a change in the scale of robotic aquatic sampling away from immense bodies of water in oceanographic research, toward bodies of water that have a more immediate affect on our well-being as they are sources and stores of drinking water. The impact of datasets which lead to better understanding of managed and natural inlets, differing topography including dam walls and man-made structures, regions of turbulence, and seasonal algal growth are immense."
"1054984","CAREER: Document Layout and Formatting Helper for Blind Authors","IIS","Cyber-Human Systems","03/01/2011","04/22/2014","Sri Kurniawan","CA","University of California-Santa Cruz","Continuing grant","Ephraim P. Glinert","02/29/2016","$433,953.00","","srikur@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","1045, 7367, 9251, 1187","$0.00","Most work on computer interaction for blind people focuses on these users as consumers, rather than creators, of information. Work on document creation specifically intended for blind people mainly concentrates on supporting general tasks associated with writing documents rather than on document formatting and layout, even though there is evidence that blind authors' documents are treated dismissively when they do not live up to ""expected"" standards of document presentation. Many blind authors therefore rely on sighted people to check their documents; consequently, they cannot be as productive as their sighted peers. The PI's goal in this project is to facilitate independence for blind authors in producing documents that meet the presentation standards expected by sighted readers. To these ends, the PI will develop an impact-weighted taxonomy of common document presentation errors of blind authors. She will explore blind authors' mental models and strategies for learning and coping, and how these models and strategies contribute to the success of independent document formatting and layout activities. And she will investigate the content-sharing and voting dynamics of blind authors. These findings will enable her to implement an integrated solution to document preparation for blind authors in the form of a Microsoft Word compatible formatting and layout checker, as well as a fix to the compatibility problems between Word's grammar and spell checkers and commonly used screen readers. And she will develop an accessible content-sharing environment for blind authors with an interface for sighted help from Amazon Mechanical Turk. To achieve her goals the PI will employ, among other techniques, participatory design with blind users and controlled experiments for investigating real-time non-visual presentation of grammar, spelling, formatting and layout statuses, errors and corrections (including through the use of haptic feedback and spatial sound).<br/><br/>Broader Impacts: This research will naturally involve blind persons at almost all stages. Project outcomes will reduce the necessity for blind authors to rely on sighted help, thus affording increased independence and productivity to members of this community. The work will likely prove of value to the general population as well, for whom non-visual document presentation information can be of benefit in eyes-busy or phone-based interactions. The PI will conduct numerous educational and outreach activities in conjunction with this project, including distribution of the software tools developed to centers and schools for blind and visually impaired persons, and development of a multidisciplinary and multilevel (undergraduate and graduate) course aimed at both psychology and computer engineering students on ""Designing Socio-technical Systems for People with Special Needs."""
"1117313","RI: Small: Reinforcement Learning for Realistic Statistical Spoken Dialogue Systems - Beyond Slot-Filling Applications","IIS","ROBUST INTELLIGENCE","08/01/2011","07/22/2011","Kallirroi Georgila","CA","University of Southern California","Standard Grant","Tatiana D. Korelsky","07/31/2015","$449,988.00","David Traum","kgeorgila@ict.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7495, 7923","$0.00","Statistical spoken dialogue systems (SDSs) use reinforcement learning to learn a dialogue policy that decides what to do based on the dialogue context (also called dialogue state). Previous work on this problem has mainly addressed slot-filling dialogue, in which the user presents a complex request (e.g. an appointment booking), and the system tries to fill a set of slots (e.g. date and time) to satisfy the user's request. This project significantly extends and generalizes prior work by allowing automated dialogue policy creation for other genres of dialogue including question-answering and negotiation. The following open research issues are investigated: (1) the extent to which the three very different genres of dialogue (slot-filling, question-answering, and negotiation) can be represented using the same kind of dialogue policy representation; (2) whether state-of-the-art learning techniques, that work well for small state spaces and simple interactions, can scale to the needs of more complex dialogues and larger state spaces; (3) methods for compactly representing the dialogue state and for combining learned and hand-crafted policies; (4) development of automated metrics for measuring the quality of simulated users and learned policies; (5) validation of those metrics with respect to how well they correlate with human evaluations.<br/><br/>Statistical SDSs facilitate easier creation of dialogue systems (less hand-crafting by dialogue system experts) that are more tuned in to user behavior (learning policies from data and simulation). This project broadens the types of systems that can be developed with this kind of approach (not just slot-filling, but also simple question-answering and more complex negotiation). The advances made in the project are encoded in a toolkit (to be publicly distributed) specifically designed for statistical dialogue management. This toolkit allows broader access to this technology, by providing the potential to attract more researchers from academia and industry to the field of SDS, and make the use of statistical techniques available to non-experts; it can also be an excellent resource for teaching statistical dialogue management to students."
"1302302","RI: Medium: Collaborative Research: Decision-Making on Uncertain Spatial-Temporal Fields: Modeling, Planning and Control with Applications to Adaptive Sampling","IIS","ROBUST INTELLIGENCE","06/01/2013","04/21/2014","Srikanth Saripalli","AZ","Arizona State University","Continuing grant","Satyandra Gupta","05/31/2017","$124,147.00","","Srikanth.Saripalli@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7924","$0.00","Inland bodies of freshwater are a resource that is critical for the Nation's health and safety. This project is developing a new spatio-temporal field representation suitable for modeling, planning and control under uncertainty in order to improve monitoring of such water systems. The project's focus is on a reconfigurable aquatic sensor-actuator network designed to capture data from coupled physical, chemical, and biological processes that occur across space and time-scales. The key advantages of this sensor-actuator network in its application to this domain include synoptic volume coverage, adaptive sampling, flexible control and robustness to component failure. The research objective is to build models of dynamic processes for which high resolution sampling is necessary at special locations. Toward this end, this project is contributing new methods, data-structures, algorithms, and implementations validated by field testing a heterogeneous system consisting of stationary and mobile (robotic) underwater node. <br/><br/>This project provides unique interdisciplinary opportunities for education of both graduate and undergraduate students via new course work that blends projects and research topics directly into courses and newly developed seminars. It provides a multi-disciplinary experience for students while developing their engineering skills. Relevant components of computer science, computer engineering, and mechanical engineering are integrated together by using the project's aquatic platform and experimental scenarios as a focal point. <br/><br/>The project advances the state-of-the-art for such systems because it integrates low-level dynamic processes with high-level planning and distributed optimization. The research represents a change in the scale of robotic aquatic sampling away from immense bodies of water in oceanographic research, toward bodies of water that have a more immediate affect on our well-being as they are sources and stores of drinking water. The impact of datasets which lead to better understanding of managed and natural inlets, differing topography including dam walls and man-made structures, regions of turbulence, and seasonal algal growth are immense."
"1254071","CAREER: Estimation and Decisions in Graphical Models","IIS","ROBUST INTELLIGENCE","07/01/2013","04/20/2014","Alexander Ihler","CA","University of California-Irvine","Continuing grant","Todd Leen","06/30/2018","$152,796.00","","ihler@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","1045, 7495","$0.00","Probabilistic graphical models are central to automated reasoning. The past decade has seen significant progress on two basic reasoning tasks: combinatorial optimization (maximization or minimization) and marginalization (summation) tasks. Maximization queries are often used to generate predictions from a given model, such as image denoising or finding stereo correspondence. Summation queries are common in model learning, for computing and optimizing the data likelihood during fitting. <br/><br/>A key point is that for these tasks the model is treated homogeneously; all variables are either maximized (or minimized) or summed over. However, many important reasoning and inference tasks require a mixture of these where some variables are maximized (or minimized), while others are summed over. Such mixed problems occur in optimal estimation, decision making in single- and multi-agent systems, and worst-case or antagonistic problems that arise in robust estimation and games. Far less progress has been made on these more difficult query types.<br/><br/>The goals of this Faculty Early Career Development (CAREER) award are to develop a new framework for exact and approximate methods for such advanced computational reasoning problems. The project includes both theoretical and practical algorithm pieces, and studies their use in estimation and learning from data. The project extends the abilities of intelligent systems to reasoning and decision-making under uncertainty. It applies and tests these methods on a variety of application domains, including sensor networks and computer vision. The project supports graduate, undergraduate, and high-school student research, and it contributes to open and online course development. The project increases impact and algorithm adoption by deploying open-source tools, developing open standards and benchmark problems in these domains, and it encourages additional progress through open comparisons and competitions."
"1352924","EAGER: Enhancing Mobile Device Users' Levels of Situational Awareness through Tactile Feedback","IIS","Cyber-Human Systems","09/15/2013","09/04/2013","Ravi Kuber","MD","University of Maryland Baltimore County","Standard Grant","Ephraim P. Glinert","08/31/2015","$96,001.00","","rkuber@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7367","7367, 7916","$0.00","In this project the PI will explore a novel approach to allowing individuals to monitor their wider environment for potential obstacles and threats while engaged in a task where the eyes are occupied. Specifically, he will focus on mobile device users, who often perform visually-demanding tasks such as composing and reading text messages while ambulatory, so that they may fail to notice the presence of pedestrians, approaching vehicular traffic or other objects which they are at risk of encountering. The PI's approach is to present tactile feedback via a head-mounted interface in order to communicate the presence of obstacles. While situational awareness technologies have been designed to assist ambulatory users, alerts are often presented using visual or auditory feedback. But if the user is engaged with a mobile task precious time may be taken to identify the presence of graphical indicators, whereas auditory alerts may be masked by environmental sounds to that the user misses vital cues. The PI argues that tactile feedback offers considerable advantages when the user's other senses are blocked or restricted, and there is the additional benefit that tactile alerts can be presented discreetly without drawing attention by others. To test these hypotheses, the PI will conduct a sequence of studies to determine whether it is possible to design tactile cues that are effective in supporting informed decisions by the user. Project outcomes will include design of a head-mounted interface prototype using object-recognition and sensor-based technologies to track obstacles in the user's vicinity, along with innovative tactile interface design guidelines. <br/><br/>Broader Impacts: This research will advance our understanding of issues relating to situational awareness among mobile device users, and it will also contribute to the body of knowledge on presenting tactile feedback to locations on the head (a field still in its infancy). The development of a library of tactile icons to convey concepts such as the number of obstacles, their location, and their proximity to the user, will have application across diverse domains."
"1218318","III: Small: Collaborative Research: Finding and Exploiting Hierarchical Structure in Time Series Using Statistical Language Processing Methods","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/28/2012","Tim Oates","MD","University of Maryland Baltimore County","Standard Grant","Sylvia J. Spengler","08/31/2015","$250,000.00","","oates@cs.umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7364","7923, 7364","$0.00","Applications as diverse as manufacturing, medicine, earth science, finance, and entomology generate massive amounts of temporal or spatio-temporal data. More specifically, information about moving objects, events, and atmospheric measurements that are geo-referenced may be derived from high-resolution satellites, sensors, ground and aerial imagery, GPS, and RFID. Such data present challenges to current approaches for mining time series data. For example, shape-based similarity measures used for classification and clustering consistently fail to produce satisfactory results for long sequences, or trajectories modeling objects that move in 2D or 3D space which may often exhibit similar motion patterns but differ in locations and orientations. In addition, algorithms for finding frequent patterns and anomalies assume known, fixed pattern lengths. This project aims to address the limitations of current approaches to time series data analysis by adapting statistical language processing algorithms and approaches. Specifically, fast algorithms for learning context-free grammars can expose hierarchical structure in time series and thus enable efficient discovery of variable length patterns and facilitate human understanding of time series structure. Also, using the hierarchy to populate a ""bag of patterns"" can result in significantly more effective similarity measures for long time series, much like the familiar bag of words representation used with documents is effective for a variety of similarity-based language processing tasks on massive corpora.<br/><br/>Given the ubiquitous nature of time series data, advances in algorithms that can help uncover the structure of such data are likely to impact a broad range of applications. All of the results of this research, including publications, algorithms and software, would be made freely available to the broader research and educational community. The project offers enhanced research-based training opportunities for graduate and undergraduate students. The project leverages existing programs at George Mason University and the University of Maryland at Baltimore County to to increase the participation of women members of other groups that are under-represented in Computer Science."
"1148976","CAREER: Parameterization and Tessellation for Computer Graphics","IIS","GRAPHICS & VISUALIZATION, Cyber-Human Systems","06/01/2012","04/22/2014","Scott Schaefer","TX","Texas Engineering Experiment Station","Continuing grant","Ephraim P. Glinert","05/31/2017","$286,211.00","","schaefer@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7453, 7367","1045, 7367, 7453, 9251","$0.00","The digital age with its widespread availability of cheap computing power has transformed the way we search for information, distribute content and even navigate cities. Computation has also transformed the way we design shapes. Whereas in the past engineers and artists often sculpted objects from clay, today most shapes are designed virtually with computers. Computer-aided design of curves, surfaces and volumetric functions has applications in diverse fields such as industrial design, the entertainment industry and even architectural design. However, in all of these applications the designer is limited by the capabilities of the representations employed. The quality and geometric properties of parametric surface representations such as NURBS and subdivision surfaces are strongly dependent on their parameterization. Yet this is a degree of freedom that few designers use or understand. Furthermore, the connection between parameterization and the geometric properties of these shapes is not well understood. We currently have only rudimentary tools for controlling the parameterization of higher dimensional shapes such as surfaces or volumes. The inability to control this parameterization leads to poor quality shapes and more effort on the part of designers to alleviate these artifacts. In this project, the PI will explore new representations of surfaces and volumes that allow for more geometric freedom in creating the underlying shapes. He will investigate the fundamental connection between parameterization and surface shape/quality for parametric curves, surfaces and volumes. He will expand upon the concept of non-uniform parameterization of surfaces to show that knot spacing (edge lengths) is not sufficient to completely control the parameterization of surfaces or volumes. And he will design new representations that allow the user to control or automatically adapt the parameterization of these shapes during the design process, and incorporate methods of non-uniform parameterization that are currently not possible. As part of this process, he will develop new higher order barycentric coordinates specifically adapted to this problem. Finally, he will investigate the effect and manipulation of parameterization for the purposes of tessellation and rendering of these parametric surfaces, and develop high quality GPU tessellation algorithms.<br/><br/>Broader Impacts: Project outcomes will significantly advance the state of the art not only in computer graphics and geometric modeling, but also in other areas of applied mathematics and computer science where the representation and precise control of smooth freeform shapes play a key role. Approximation theory, architectural design, the entertainment industry and industrial manufacturing will all benefit from the results of this research."
"1350337","CAREER: Active Learning through Rich and Transparent Interactions","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","04/22/2014","Mustafa Bilgic","IL","Illinois Institute of Technology","Continuing grant","Todd Leen","04/30/2019","$132,483.00","","mbilgic@iit.edu","3300 South Federal Street","Chicago","IL","606163732","3125673035","CSE","7364","1045, 7364","$0.00","Machine learning models are trained on data that are annotated (labeled) by humans. The accuracy of the trained models generally improves with the number of annotated data examples. Yet, annotating takes time, money, and effort. Active learning aims to minimize the costs by determining which exemples are most informative and directing the human labeler to them. Improvements in active learning will lower the costs associated with data annotation and lead to faster implementations of intelligent systems for a range of applications including robotics, speech technology, error and anomaly detection (for example in medicine, financial fraud, and condition-based maintenance of infrastructure), targeted advertising, human-computer interfaces, and bioinformatics.<br/><br/>In traditional active learning approaches, algorithms are limited in the types of information they can acquire, and they often do not provide any rationale to the user as to why a particular exemplar is chosen for annotation. This CAREER project develops a new paradigm dubbed ""rich and transparent active learning."" This new paradigm opens a communication channel between algorithms and users whereby they can exchange a rich set of queries, answers, and explanations. By using rich feedback from users the algorithms will be able to learn the target concept more economically, reducing the resources required to build an accurate predictive model. By explaining their reasoning, these algorithms will achieve transparency, build trust, and open themselves to scrutiny. <br/><br/>Towards that end, the project develops methods that allow algorithms to use a rich set of queries for resource-efficient model training, and generate explanations that are informative but not overwhelming for the users. The methods developed build on expected loss minimization, information theory, and principles from human-computer interaction. Approaches are evaluated using publicly available datasets and user studies carried out as part of the project. The project develops case studies on two high-impact real-world problems: detecting fraudulent health-care claims, and identifying patients at risk of disease.<br/><br/>The rich and transparent active learning paradigm provides unique educational opportunities. In contrast to standard machine learning algorithms, operated as black boxes, interactive and transparent machine learning is expected to raise students' interest and motivation for data science. Two PhD and several undergraduate and high school students are being trained under this award. A new graduate course on interactive machine learning is being developed. Finally the PI ensures effective outreach to under-represented groups by partnering with a Chicago public high school whose student population includes 90% minorities."
"1302283","RI: Medium: Collaborative Research: Mobile Microrobot Platform for Advanced Manufacturing Applications","IIS","ROBUST INTELLIGENCE","07/01/2013","04/22/2014","Michael Zavlanos","NC","Duke University","Continuing grant","Satyandra Gupta","06/30/2017","$120,998.00","","michael.zavlanos@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7924","$0.00","The goal of this research is to create a flexible, micro-scale additive manufacturing platform utilizing a team of untethered micro-scale robots and modular, multifunctional building blocks to create smart micro-devices and structures. Externally applied magnetic fields are commonly used for the power and actuation of individual magnetic mobile microrobots. However, in order to achieve different behaviors from individual robots within a team of microrobots, there must be either significant variation in their design or in the magnetic control signals applied to each microrobot.<br/><br/>The intellectual merit of this research, therefore, lies in the novel approach to create a specialized magnetic potential field generating substrate from MEMS-fabricated planar microcoils and the related control methodology to enable truly independent control of multiple mobile microrobots. Thus, the research objectives of the proposal are: the design and fabrication of the micro-coils and related control electronics; motion control for mobile magnetic microrobot swarms; and magnetic microrobot and modular component design and fabrication, based on specialized micro-components with various material properties and functions.<br/><br/>Successful completion of the objectives will result in a transformative mobile microrobot swarm platform capable of executing various advanced additive manufacturing tasks. Potential applications include very high-density energy storage, high strain actuation, energy harvesting, very low power communications devices, and composite structures with integrated sensors. Further broader impacts of this project reside in disseminating the research output in industry and academia along with an educational agenda spanning related outreach activities from the K-12 through graduate levels."
"0964420","RI: Medium: Collaborative Research: Recognition of Materials","IIS","ROBUST INTELLIGENCE","07/01/2010","06/18/2013","Ko Nishino","PA","Drexel University","Continuing grant","Kenneth C. Whang","06/30/2015","$392,638.00","","kon@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7495","7924","$0.00","We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.<br/><br/>The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums."
"1358446","RI: Medium: Collaborative Research: Mobile Microrobot Platform for Advanced Manufacturing Applications","IIS","ROBUST INTELLIGENCE","08/01/2013","04/21/2014","David Cappelleri","IN","Purdue University","Continuing grant","Satyandra Gupta","06/30/2017","$274,148.00","","dcappell@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495","7495, 7924","$0.00","The goal of this research is to create a flexible, micro-scale additive manufacturing platform utilizing a team of untethered micro-scale robots and modular, multifunctional building blocks to create smart micro-devices and structures. Externally applied magnetic fields are commonly used for the power and actuation of individual magnetic mobile microrobots. However, in order to achieve different behaviors from individual robots within a team of microrobots, there must be either significant variation in their design or in the magnetic control signals applied to each microrobot.<br/><br/>The intellectual merit of this research, therefore, lies in the novel approach to create a specialized magnetic potential field generating substrate from MEMS-fabricated planar microcoils and the related control methodology to enable truly independent control of multiple mobile microrobots. Thus, the research objectives of the proposal are: the design and fabrication of the micro-coils and related control electronics; motion control for mobile magnetic microrobot swarms; and magnetic microrobot and modular component design and fabrication, based on specialized micro-components with various material properties and functions.<br/><br/>Successful completion of the objectives will result in a transformative mobile microrobot swarm platform capable of executing various advanced additive manufacturing tasks. Potential applications include very high-density energy storage, high strain actuation, energy harvesting, very low power communications devices, and composite structures with integrated sensors. Further broader impacts of this project reside in disseminating the research output in industry and academia along with an educational agenda spanning related outreach activities from the K-12 through graduate levels."
"1253942","CAREER: Differentially-Private Machine Learning with Applications to Biomedical Informatics","IIS","ROBUST INTELLIGENCE, Secure &Trustworthy Cyberspace","07/01/2013","04/20/2014","Kamalika Chaudhuri","CA","University of California-San Diego","Continuing grant","Todd Leen","06/30/2018","$201,854.00","","kamalika@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7495, 8060","1045, 7434","$0.00","Machine learning on large-scale patient medical records can lead to the discovery of novel population-wide patterns enabling advances in genetics, disease mechanisms, drug discovery, healthcare policy, and public health. However, concerns over patient privacy prevent biomedical researchers from running their algorithms on large volumes of patient data, creating a barrier to important new discoveries through machine-learning. <br/><br/>The goal of this project is to address this barrier by developing privacy-preserving tools to query, cluster, classify and analyze medical databases. In particular, the project aims to ensure differential privacy --- a formal mathematical notion of privacy designed by cryptographers which has gained considerable attention in the systems, algorithms, machine-learning and data-mining communities in recent years. The primary challenge in applying differentially-private machine learning tools to biomedical informatics is the lack of statistical efficiency, or the large number of samples required.<br/><br/>The project will overcome this challenge by drawing on insights obtained from the PI's expertise to develop differentially-private and highly statistically-efficient machine learning tools for classification and clustering. The proposed research will advance the state-of-the-art in privacy-preserving data analysis by combining insights from differential privacy, statistics, machine learning, and database algorithms. <br/><br/>The proposed research is closely tied to the development of the undergraduate and graduate curricula at UCSD, feeding into the PI's new undergraduate machine learning class, a new graduate learning theory class, and updates to an algorithm design and analysis class. The corresponding materials will be publicly disseminated through the PI's website. The PI is strongly committed to increasing the participation of women and minorities, and will engage in outreach activities to attract and retain women in computer science."
"1161282","RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","IIS","ROBUST INTELLIGENCE","06/01/2012","04/19/2014","Pedro Felzenszwalb","RI","Brown University","Continuing grant","Jie Yang","05/31/2015","$330,000.00","","pff@brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","7924, 7495, 9150","$0.00","Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection. <br/><br/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers."
"1053768","CAREER: Large-Scale Recognition Using Shared Structures, Flexible Learning, and Efficient Search","IIS","ROBUST INTELLIGENCE","05/01/2011","04/19/2014","Derek Hoiem","IL","University of Illinois at Urbana-Champaign","Continuing grant","Jie Yang","04/30/2016","$400,986.00","","dhoiem@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","1045, 1187, 7495","$0.00","This research investigates shared representations, flexible learning techniques, and efficient multi-category inference methods that are suitable for large-scale visual recognition. The goal is to produce visual systems that can accurately describe a wide range of objects with varying precision, rather than being limited to identifying objects within a few pre-defined categories. The main approach is to design object representations that enable new objects to be understood in terms of existing ones, which enables learning with fewer examples and faster and more robust recognition.<br/><br/>The research has three main components: (1) Designing appearance and spatial models for objects that are shared across basic categories; (2) Investigating algorithms to learn from a mixture of detailed and loose annotations and from human feedback; and (3) Designing efficient search algorithms that take advantage of shared representations. <br/><br/>The research provides more detailed, flexible, and accurate recognition algorithms that are suitable for high-impact applications, such as vehicle safety, security, assistance to the blind, household robotics, and multimedia search and organization. For example, if a vehicle encounters a cow in the road, the vision system would localize the cow and its head and legs and report ``four-legged animal, walking left'', even if it has not seen cows during training. The research also provides a unique opportunity to involve undergraduates in research, promote interdisciplinary learning and collaboration, and engage in outreach. Research ideas and results are disseminated through scientific publications, released code and datasets, public talks, and demonstrations for high school students."
"1253614","CAREER: PRUGC---Phylogenetic Reconstructions with Unequal Gene Contents","IIS","INFO INTEGRATION & INFORMATICS","02/01/2013","01/29/2013","Max Alekseyev","SC","University of South Carolina at Columbia","Standard Grant","Sylvia J. Spengler","01/31/2018","$549,529.00","","maxal@gwu.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","CSE","7364","1045, 9150","$0.00","The proposed project addresses the problem of reconstruction of ancestral genomes and evolutionary history of genomes that may deviate in gene content, resulting from genome rearrangements as well as gene duplications and deletions evolutionary events. It will close the gap between steadily growing number of sequenced genomes and incapability of existing phylogenetic reconstruction tools to process diverse varieties of genomes.<br/><br/>The new PRUGC software will employ the framework of multiple breakpoint graphs that will be extended to address new algorithmic challenges arising from genomes having unequal gene contents. As some of these challenges may be hard and have no computationally feasible solutions, instead of focusing on a fixed evolutionary model and attempting to fit biological problems into it, the PI will let the model be flexible and problem-driven. In the course of PRUGC development, the PI plans to address the following particularly important biological problems (listed in the order of growing complexity): the primate-rodent-carnivore split controversy in mammalian evolution (featuring relatively small number of duplications); phylogenetic analysis of a diverse variety of yeast genomes including genomes that undergone whole genome duplications; and evolutionary problems in plant evolution rich in segmental duplications. Solutions to these problems will help to better understand the mechanisms behind chromosome evolution across variety of genomes. The reconstructed ancestral genomes will provide insights to functional significance of particular gene orders, help to rigorously estimate the rate of genome rearrangements and gene duplications/deletions in different organisms, and allow testing hypotheses about their mechanisms and influence on shaping genomic architectures. It is important to emphasize that the PRUGC software will have a wide range of applications, not limited to the aforementioned problems. The PRUGC software will be helpful in various phylogenomic studies within projects like ""Tree of Life"", ""Genome 10K"", and ""i5k"". It will be released as both a standalone open-source tool and an online web-server application readily accessible for use by biologists.<br/><br/> The project will support research activities in the PI's research lab. In particular, it will help to prepare a new generation of researchers in bioinformatics by providing the opportunities to have hands-on experiences in both computer science and biology. One undergraduate student and two Ph.D. students will be recruited with the support of this project, and the PI will mentor these students and prepare them for building their careers in academia or industry. The PI will make every effort to help the students gain first-hand experience of biology, including short-term visits to our local, national, and international collaborators. Such experience will also help the students to develop and enhance their ability to communicate with researchers in other areas, an important skill in interdisciplinary research.<br/><br/> The project will also offer an excellent opportunity for computer science students to learn about experimental and theoretical research in the interdisciplinary area of bioinformatics. Detailed explanation of the whole process of multiple genomes comparison will perfectly fit into a timeframe of a bioinformatics course. The PI plans to lecture this material within the bioinformatics course CSCE 555 offered for undergraduate and graduate students at the University of South Carolina. As a member of the Bioinformatics Education Alliance developing ""Bioinformatics for Biologists"" (B4B) textbook, the PI coordinated with the editors preparation of a new chapter module and web-based educational materials for the next edition of B4B that will expand the current chapter on genome rearrangements and illustrate their applications with a number of biological problems within the PRUGC project."
"1028746","Collaborative Research: Understanding Climate Change: A Data Driven Approach","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2010","09/09/2012","Nagiza Samatova","NC","North Carolina State University","Continuing grant","Christopher Clifton","08/31/2015","$1,815,739.00","Fredrick Semazzi","samatova@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","1640, 7364","7969, 9218, 7925, 7723, 9251, ","$0.00","Understanding Climate Change: A Data Driven Approach<br/><br/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br/><br/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br/><br/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br/><br/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br/><br/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br/><br/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to analyze physical processes. This project will also contribute to efforts in education, diversity, community engagement, and dissemination of tools and computer and atmospheric science findings."
"1218056","HCC: Small: Collaborative Research: Real-Time Captioning by Groups of Non-Experts for Deaf and Hard of Hearing Students","IIS","Cyber-Human Systems","08/01/2012","04/17/2014","Raja Kushalnagar","NY","Rochester Institute of Tech","Standard Grant","Ephraim P. Glinert","07/31/2015","$113,554.00","","rskics@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757525","CSE","7367","7367, 7923, 9251","$0.00","Many deaf and hard of hearing students use real-time captioning to participate in education. Generally, real-time captions are provided by skilled professional captionists (stenographers) who use specialized keyboards or software to keep up with natural speaking rates of up to 225 words per minute. But professional captionists are expensive and must be arranged in advance in blocks of at least an hour. Automatic speech recognition (ASR) is improving, but still experiences high error rates in real classrooms. In this collaborative effort involving the University of Rochester and Rochester Institute of Technology, the PIs will address these issues by blending human- and machine-powered captioning to produce captions on demand, in real time, for low cost. The PIs' approach is for multiple non-experts and ASR to collectively caption speech in under 5 seconds, with the help of interfaces which encourage quick, incomplete captioning of live audio. Because non-experts cannot keep up with natural speaking rates, new algorithms will merge incomplete captions in real time. (While the sequence alignment problem can be solved exactly with dynamic programming, existing approaches are too slow, are not robust to input error, and do not incorporate natural language semantics.) Systematically varying audio saliency will encourage complete coverage of speech. Non-expert captions will train ASR engines in real time, so that ASR may improve during a lecture. (Traditional approaches for ASR training assume that training occurs offline.) The quikCaption mobile application will embody these ideas and will be iteratively designed with deaf and hard of hearing students at the National Technical Institute of the Deaf (NTID) via design sessions, lab studies and in-class deployments. Non-expert captionists can be drawn from broad sources: volunteers willing to donate their time, classmates with relevant domain knowledge, or always-available paid workers. They may be local (in the classroom) or remote. Captionists may have experience from prior quikCaption sessions, or novice crowd workers recruited on demand from existing marketplaces (e.g., Mechanical Turk). A flexible worker pool will allow real-time captions to be available on demand at low cost and for only as long as needed.<br/><br/>Broader Impacts: This research will dramatically improve education for deaf and hard of hearing students by enabling access to serendipitous opportunities, such as conversations after class or last-minute guest lectures for which no interpreter or captionist was arranged. Real-time captioning will also be useful in other settings such as school programs, artistic performances, and political events. Older hard of hearing adults usually prefer captioning, and represent a sizable and growing population; hearing people may benefit because captioning is a first step in automatic translation of aural speech. The algorithms developed as part of this project for real-time merging of incomplete natural language will likely be adaptable for other applications such as collaborative translation or communication over noisy mediums."
"1441998","WORKSHOP: Doctoral Consortium at ASSETS 2014","IIS","Cyber-Human Systems","04/15/2014","04/16/2014","Jinjuan Feng","MD","Towson University","Standard Grant","Ephraim P. Glinert","03/31/2015","$22,872.00","","jfeng@towson.edu","8000 York Road","Towson","MD","212520001","4107042236","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) of approximately 10 promising graduate students from the United States and abroad (no more than 3 expected to be from outside the country), along with 5 distinguished research faculty. The event will take place on Sunday, October 19, immediately preceding and in conjunction with the 16th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2014), to be held Monday-Wednesday, October 20-22, in Rochester, NY. The ASSETS conferences are the premier forum for presenting innovative research on the design and use of both mainstream and specialized assistive technologies. This includes the use of technology by and in support of: individuals with hearing, sight and other sensory impairments; individuals with motor impairments; individuals with memory, learning and cognitive impairments; individuals with multiple impairments; older adults; and professionals who work with these populations. Researchers and developers from around the world in both academia and industry will meet to exchange ideas and present their latest work. More information about the conference may be found at http://www.sigaccess.org/assets14. <br/><br/>A key component of building this community is through its youth. The ASSETS 2014 Doctoral Consortium will provide an opportunity for graduate students from diverse backgrounds (computing, engineering, psychology, architecture, etc.) to come together and explore their research interests in an interdisciplinary workshop, under the guidance of the PI and a panel of other distinguished experts in the field, so that they can appreciate the broader spectrum of research and development approaches to assistive technologies and universal usability, and also experience the community in which they can pursue their endeavors. Student participants will make formal presentations of their work during the consortium, and will receive constructive feedback from the faculty panel. The feedback is designed to help students understand and articulate how their work is positioned relative to related research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Thus, the consortium will help shape ongoing and future research projects aimed at assistive technologies and universal access, will promote scholarship and networking among new researchers in this emerging interdisciplinary area, and will also expose these promising young researchers to a larger community. In an effort to further integrate Doctoral Consortium participants into the conference itself, a (poster) session has been set aside in the technical program to allow all Doctoral Consortium participants to present their research to the full conference. In addition, one student from the Doctoral Consortium will be selected to deliver the closing plenary presentation. An evaluation of the consortium will be conducted and the results made available to the organizers of future such events. <br/><br/>The Doctoral Consortium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality/cultural and scientific discipline, the students' horizons are broadened to the future benefit of the field. The organizers will take special steps to promote participation from institutions with relatively large numbers of students from under-represented groups; to further increase diversity, participation will be limited to at most one male and one female student from the same institution."
"1352207","EAGER: Using Crowdsourced Virtual Students to Create Intelligent Tutors","IIS","Cyber-Human Systems, Cyberlearning&FutureLearn Tech","09/01/2013","08/26/2013","Andrew Olney","TN","University of Memphis","Standard Grant","Kevin Crowston","08/31/2015","$163,830.00","","aolney@memphis.edu","Administration 315","Memphis","TN","381523370","9016782533","CSE","7367, 8020","7916, 8045, 7367, 9150","$0.00","This project will develop and evaluate the potential of a new human-computer system that bridges the roles of virtual student and virtual teacher to allow humans and computers to take turns teaching and learning from each other. The key insight is that reading comprehension activities (e.g., vocabulary building, summarizing, question generation, concept mapping) closely parallel the knowledge engineering required to create virtual teachers for intelligent tutoring systems (ITSs). The system links these activities so that when students read online, they engage a virtual student in educational tasks that both improve their reading comprehension and simultaneously contribute to the creation of ITSs for future students. An important aspect of the proposed research is to find the optimum balance between student learning (which benefits the individual) and the creation of ITS knowledge representations (which benefits many). Specific research objectives are: (1) to develop a baseline platform (called BrainTrust) such that students can create ITS knowledge representations by teaching a virtual student; (2) to study the relationship between the student's ability, the virtual student's ability, the student's learning outcomes, and the quality of knowledge representations produced. A distinctive characteristic of the proposed research is the study of these questions in ecologically valid conditions, as students engage in authentic study, while also participating in randomized experiments.<br/><br/>The research may lead to the development of systems that improve reading comprehension, which may have broad benefits given the centrality of reading comprehension to all learning. In particular, problems with reading comprehension have been linked to first-year college student dropout that disproportionately affects African-American students. The research will also enhance infrastructure for research and education through the development and dissemination of the BrainTrust platform, a next-generation computing infrastructure to rapidly create and deploy ITSs tailored to specific needs. If this exploratory project demonstrates that the dual outcomes of human learning and high-quality knowledge representations can be achieved, it will open a new area of research that brings teaching these virtual students full circle with learning from their derived intelligent tutoring systems."
"1057521","Multi-Media Services","LPA","PROGRAM EVALUATION, OFFICE OF MULTIDISCIPLINARY AC, Manufacturing Machines & Equip, ENGINEERING EDUCATION, Research Investment Comm(RIC), OFFICE OF SPECIAL PROGRAMS-DMR, PROJECTS, EPSCOR OUTREACH, Cyber-Human Systems, CreativeIT, ENVIRONMENTAL RESEARCH & EDUCA, IN-HOUSE PRODUCTION SUPP SVCS, SPECIAL STUDIES AND ANALYSES, UNDISTRIBUTED PANEL/IPA FUNDS, UNDIST PANEL/IPA FNDS-PLNT GEN, GRANT OPP FOR ACAD LIA W/INDUS, GRADUATE RESEARCH FELLOWSHIPS, COMMS, CIRCUITS & SENS SYS, Gen & Age Rel Disabilities Eng, , , IGERT FULL PROPOSALS, , EFRI RESEARCH PROJECTS, PLANT GENOME RESEARCH PROJECT, BM Gates Foundation, , TUES-Type 1 Project, ENGINEERING RESEARCH CENTERS, INDUSTRY/UNIV COOP RES CENTERS, RES EXP FOR TEACHERS(RET)-SITE, NEES RESEARCH, OPERATIONS RESEARCH, CONTROL SYSTEMS, SERVICE ENTERPRISE SYSTEMS, ARCTIC RESEARCH PROJECTS, REAL, SBIR Outreach & Tech. Assist, CROSS-DIRECTORATE ACTIV PROGR","08/01/2010","04/15/2014","Nancy Mahoney","DC","ACQUISITION SERVICES DIRECTORATE NATIONAL BUSINESS CENTER","Contract Interagency Agreement","Judy Ann Hayden","08/31/2015","$17,608,103.00","","nancy.mahoney@aqd.nbc.gov","1951 CONSTITUTION AVE NW","Washington","DC","202450003","7037747613","O/D","7261, 1253, 1468, 1340, 7957, 7222, 1978, 9168, 7367, 7788, 7273, 097P, 1385, 9199, 9100, 1504, 7172, 7564, 5342, Lx20, 0636, 1335, 0608, 7633, 1329, 8288, 1798, 7513, 1480, 5761, 1359, 7396, 5514, 1632, 1787, 5201, 7625, 8091, 1397","1079, 7259, 7957, 9162","$0.00",""
"0953837","CAREER: Investigating the Ultimate Mechanisms of Embodied Cognition","IIS","ROBUST INTELLIGENCE","05/15/2010","04/16/2014","Joshua Bongard","VT","University of Vermont & State Agricultural College","Continuing grant","Kenneth C. Whang","04/30/2015","$499,999.00","","jbongard@uvm.edu","85 SO. PROSPECT ST.","BURLINGTON","VT","054050160","8026563660","CSE","7495","1045, 1187, 9150","$0.00","To date, relatively little success has been achieved in realizing machines that continually perform simple yet adaptive behaviors in unstructured environments (compared to a structured environment such as a factory). The prevailing approach to create such machines is to copy physiological and neurological systems observed in animals, and build them into robots. This raises the issue however of what from among the infinitude of existing biological structures should be copied. Research under this award is pursuing an alternative approach: rather than copy existing biological systems, evolutionary dynamics are copied and connected in a virtual space. The resulting evolutionary algorithm optimize virtual robots' neurological structures that control behavior and their body plans. Importantly, evolution in these studies is task and behavior specific.<br/><br/>The research is intended to make important contributions to robotics and biology. For roboticists, this work will enable computers to automatically design the body plans and neural controllers for robots that are more adaptive and robust than robots designed manually. Automatically-designed virtual robots can then be built as physical devices and deployed into real-world environments, to include those that are dangerous to humans. For biologists, our studies will provide insight into why and how particular structures evolved in nature. For example, if legged robots originally evolved for locomotion are then selected to locomote and grasp objects, computational evolution may re-purpose the robot's front legs into arms and grippers; or, it may add manipulatory appendages onto the existing body plan. Either outcome would be of great interest to evolutionary biologists.<br/><br/>Finally, experiments are being housed in online tools that will allow graduate, undergraduate and K-12 students to run evolutionary simulations passively on their own machines, as well as actively participate in the process: they may design novel virtual environments in which the robots must evolve. This active participation is intended to motivate students to understand the physics, biology, engineering and computational processes underlying evolution."
"1218801","HCC: Small: AccessMath: Improving Mathematics Lectures for Low Vision Students through Integrated Video, Note-Taking and Search","IIS","Cyber-Human Systems","09/01/2012","04/17/2014","Stephanie Ludi","NY","Rochester Institute of Tech","Standard Grant","Ephraim P. Glinert","08/31/2016","$518,813.00","Roger Gaborski, Richard Zanibbi, Anurag Agarwal","salvse@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757525","CSE","7367","7367, 7923, 9251","$0.00","Access to mathematics education is critical to facilitating careers in the sciences, engineering, technology, and in many professions, as well as to providing the mathematical literacy needed in everyday life. The PI's goal in this project is to increase real-time access in the classroom to mathematical material for low vision students (who are visually impaired but not blind), which is currently mostly lacking as these students must primarily rely on assistive technology and human note takers to provide access to course materials after the class meeting. The PI's approach is to bring together expertise in computer science, mathematics, and accessibility to provide a useful and usable solution to this problem for the iPad. Called AccessMath, the prototype application will provide zoom-able camera views as well as a view of notes written at the whiteboard (captured by a Mimio), which may be altered through magnification and contrast adjustment features. The system will support consulting and searching course content during lecture, including textbooks, handouts, notes written at the whiteboard, and audio in video (e.g., to find the word ""eigenvalue"" in recorded lectures for the course). A novel note-taking facility will be employed, where notes are represented on note ""cards"" that can be attached to a specific location in the current view (e.g., at a spot in the whiteboard view), then manually moved, resized, rotated, stacked, and ""flicked"" out of view, providing a natural means for interacting informally with notes created during lecture. Notes are created as blank cards, or as cards containing views of whiteboard data, video excerpts, or existing notes. Notes are also used in constructing search queries. Linear algebra (in particular matrices) is the pilot scope for the project, due to the many challenges in conveying a matrix, individual items within the matrix, following derivations, and the scale of the matrix needed when completing non-trivial problems. AccessMath users will have a single iPad which connects to a server providing video feeds and recognition and retrieval services.<br/><br/>Broader Impacts: AccessMath will assist low-vision students with mathematical instruction in and out of class, at the high school and university levels, by providing immediate access to lecture materials, including searches for mathematical content in whiteboard notes, handouts, textbooks, and lecture videos (through word spotting in audio). The system will afford student ownership in note taking and customizing access, which will be significantly better than current solutions, and will reduce or eliminate the extent to which visually impaired students fall behind their sighted peers in the classroom setting. The project will also advance the state-of-the-art in recognition and retrieval for mathematical notation, and will create a novel note-taking model using the metaphor of photos on a tabletop, which should be applicable to domains other than mathematics."
"1064505","III: Medium: Collaborative Research: Database-As-A-Service for Long Tail Science","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","07/23/2013","Bill Howe","WA","University of Washington","Continuing grant","Sylvia J. Spengler","07/31/2015","$343,024.00","Dan Suciu","billhowe@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7364","7924","$0.00","With tremendous amounts of data existing in scientific applications, database management becomes a critical issue, but database technology is not keeping pace. This problem is especially acute in the long tail of science: the large number of relatively small labs and individual researchers who collectively produce the majority of scientific results. These researchers lack the IT staff and specialized skills to deploy technology at scale, but have begun to routinely access hundreds of files and potentially terabytes of data to answer a scientific question. This project develops the architecture for a database-as-a-service platform for science. It explores techniques to automate the remaining barriers to use: ingesting data from native sources and automatically bootstrapping an initial set of queries and visualizations, in part by aggressively mining a shared corpus of data, queries, and user activity. It investigates methods to extract global knowledge and patterns while offering scientists access control over their data, and some formal privacy guarantees. The Intellectual Merit of this proposal consists of automating non-trivial cognitive tasks associated with data work: information extraction from unstructured data sources, data cleaning, logical schema design, privacy control, visualization, and application-building. As Broader Impacts, the project helps scientists reduce the proportion of time spent ""handling data"" rather than ""doing science."" All software resulting from this project are open source, and all findings are disseminated broadly through publications and workshops. Sustainable support for science users of the software is coordinated through the University of Washington eScience Institute. The research is incorporated in both undergraduate and graduate computer science courses, and the software is also incorporated into domain science courses as well. The project's outreach activities include advising students through special programs geared toward under-represented groups such as the CRA-W DREU. More information about this project is found at http://escience.washington.edu/dbaas."
"1253302","CAREER: Designing An Information Savvy Society: Assessable Participatory Information Environments","IIS","Cyber-Human Systems, INFORMATION TECHNOLOGY RESEARC","02/01/2013","04/16/2014","Andrea Forte","PA","Drexel University","Continuing grant","Kevin Crowston","01/31/2018","$252,316.00","","aforte@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7367, 1640","1045, 7367, CL10, 1640","$0.00","This project addresses the design of participatory systems to enable assessment of information quality and to encourage contributions. It does so by designing system interfaces that allow people to better see into processes of information production to better assess their products and, by extension, to identify valued forms of contribution. The project includes (1) construction of models of how people with different kinds and levels of expertise in information production understand and assess the quality of information in participatory environments and how these understandings intersect with patterns of participation; (2) creating experimental interfaces that support information assessment; (3) studying these interfaces in iterative deployments to develop a design framework and guidelines for assessable participatory information environments; and (4) validating this design framework through summative evaluation in a novel context. The project also includes the design and implementation of participatory information literacy education activities for students that encourage participation in public information production.<br/><br/>The results of this research will advance scientific understanding of information assessment habits among users of participatory media. The development of novel interfaces for well-known and familiar systems will provide design framework and guidelines that are accessible and extensible from both a scholarly and technical perspective. <br/><br/>The design framework and guidelines that result from this project will improve design and educational practice in an area of critical national importance, namely information literacy. Improving information literacy skills is important, as they affect citizens' ability to function in a technologically rich, free and democratic society and to make informed decisions about scientific, medical, educational and other issues."
"1017199","RI: Small: 3D Nonrigid Object Reconstruction from Large-Scale Unorganized 2D Images","IIS","ROBUST INTELLIGENCE","09/01/2010","02/18/2011","Song Wang","SC","University South Carolina Research Foundation","Standard Grant","Jie Yang","08/31/2015","$216,000.00","","songwang@cec.sc.edu","901 Sumter Street","COLUMBIA","SC","292080001","8037777093","CSE","7495","7923, 9251","$0.00","Reconstructing the 3D shape of an object from multiple 2D images is a fundamental problem in computer vision. Prior work on this problem usually requires the object of interest to be rigid or the available 2D images to be well organized, such as consecutive frames in a video. This project investigates the challenging problem of reconstructing a nonrigid 3D object from a large number of unorganized 2D images, which may be taken at different times, with different backgrounds, from different perspectives, under different lighting conditions, and/or using different cameras.<br/><br/>The research team develops new algorithms of combining object localization, feature matching, and partial shape matching across the images to segment the 2D object of interest from the input images. The segmented 2D objects are organized into clusters to recover the underlying 3D nonrigid deformation. Pieces of the 3D object are reconstructed from these clusters and finally assembled to obtain the complete 3D object by removing the in-between nonrigid deformations. An image database with 2D images of selected nonrigid objects is constructed for performance evaluation.<br/><br/>This research benefits many applications in computer vision, computer graphics, computer gaming, zoology, microbiology, marine science, and medical research, which all involve the modeling of 3D norigid objects. Progress made on object localization, feature matching and partial shape matching has immediate applications in object detection, object recognition, image search, surveillance, tracking, and segmentation. This research also provides an excellent setting for the training of both undergraduate and graduate students."
"1314778","HCC: Large: Social-Computational Support of Civic Engagement in Public Policymaking","IIS","Cyber-Human Systems","09/15/2013","04/15/2014","Claire Cardie","NY","Cornell University","Standard Grant","William Bainbridge","08/31/2016","$2,239,876.00","Susan Fussell, Gilly Leshed, Cynthia Farina","cardie@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7925, 9251","$0.00","The overarching goals of this work are to understand and to provide socio-computational support for improving the entire cycle of technology-enabled civic engagement: (1) recruitment of people with a stake in the issues; (2) deliberative discussion in which they learn about the policy issues, engage with each other, voice questions and recount experiences; and (3) consensus building in which participants move toward collaborative content-creation, summarization of the knowledge that has emerged in discussion and the development of agreement around key points. In practice, efforts to use social media for citizen policy consultations often fell far short of their knowledge-generating and democracy-reinforcing goals. There thus is a crucial need to discover how to design civic engagement spaces that leverage the potential of social media, so that they support not simply more participation but rather better participation that will benefit both the policymakers seeking input and the citizens who participate in the discussion. <br/><br/>To achieve this goal, the project integrates computer science research on natural language learning for social-computational systems, human-computer interaction research on online communities, social media design, and social science research on motivation and individual and group deliberative processes. The research will advance behavioral science understanding of the relationship between individual characteristics and successful e-deliberation; the communicative processes that characterize successful e-deliberation; and the group processes and moderator behaviors that promote a shift from open discussion to consensus building. It will advance the state-of-the-art in natural language processing by developing joint human-computer text analysis techniques to (1) promote on-line civic engagement in policy discussions and (2) facilitate deliberative moderation in this collaborative online setting. It will add to human-computer interaction by advancing recommender systems, online communities, and social media research to support mentoring activities and engagement with alternate points of view. Finally, it will extend scientific understanding of how to motivate and support broader, better citizen participation in public policymaking.<br/><br/>The work will have at least five broader impacts: (1) increase understanding of, and infrastructure for, e-participation in policy-making, and provide annotated datasets of civic deliberations for use by other researchers; (2) enhance education through graduate and undergraduate mentoring and development of a new interdisciplinary course on Online Civic Engagement; (3) promote STEM education diversity with programs for middle and high school girls; (4) provide community and government outreach activities; (5) benefit society by improved civic engagement in policymaking in general."
"1254117","CAREER: Human Behavior Assessment from Internet Usage: Foundations, Applications and Algorithms","IIS","Cyber-Human Systems","02/01/2013","04/16/2014","Sriram Chellappan","MO","Missouri University of Science and Technology","Continuing grant","Ephraim P. Glinert","01/31/2018","$179,060.00","","chellaps@mst.edu","300 W 12th Street","Rolla","MO","654096506","5733414134","CSE","7367","1045, 7367, 9150","$0.00","Human interaction with computers, and especially with the Internet, is ever increasing. As a consequence the field of cyber-psychology, which studies the thinking, behavior and attitudes of the person using the computer, is of growing importance. To date, studies in cyber-psychology have collected Internet usage data by means of self-reported surveys only, an approach which suffers from a number of drawbacks including human error, bias due to user concerns relating to social desirability, and limits on the volume and dimensionality of the data obtained. The PI's vision in this project is to advance human behavior assessment based on real Internet usage data, that is to say Internet usage data collected continuously, passively and unobtrusively without manual intervention while carefully maintaining user privacy expectations. To these ends, the PI will develop practical foundations, create two Internet enabled applications (one relating to online mental healthcare and the other to online socializing), and leverage results in behavioral psychology to design classification algorithms that demonstrate the ability to achieve significant insights and to detect behavioral similarities (relating to symptoms of depression and preferences in social contacts) based on Internet usage. The project builds on the PI's preliminary work that exploited real Internet usage data collected from Cisco NetFlow records to identify fine-grained Internet usage features associated with symptoms of depression, and will be executed with college students as primary subjects. The PI will collaborate in the current project with experts from the psychological and social sciences, clinical psychiatry, and the FBI's cyber crimes division. Outcomes will include an accurate characterization of Internet usage minimally affected by error and bias, and a large number of Internet usage features of high granularity for assessing human behavior, which together will yield insights and conclusions readily adaptable for practical utility.<br/><br/>Broader Impacts: This research will advance our ability to assess human behavior based on Internet usage data. The online mental healthcare application will yield Internet enabled proactive, early and cost -effective mental health care to complement care in existing clinical settings, while the online socializing application will lead to improved online social experiences by leveraging mutual social preferences. Applications of the research to mitigating Internet fraud and detecting cyber bullying are immediate. The PI will collaborate with HBCU and RUI institutions as well as K-12 schools to further enhance project outreach."
"1110868","Collaborative Research: Cyber-Collective Movements: Novel Socio-Computational Approaches in Studying the Blogosphere","IIS","SOCIAL-COMPUTATIONAL SYSTEMS, Cyber-Human Systems","09/01/2011","08/30/2011","Rolf Wigand","AR","University of Arkansas Little Rock","Standard Grant","William Bainbridge","08/31/2015","$402,191.00","Nitin Agarwal","rtwigand@ualr.edu","2801 South University","Little Rock","AR","722041099","5015698474","CSE","7953, 7367","7367, 7953, 9150","$0.00","Using the global female Muslim blogosphere, this research aims to understand the complexity of cyber-collective action and factors contributing to its success or failure. Despite the exponential growth of Internet users in Muslim countries, there is a lack of empirical study of socio-political uses of the technology for expressing opinions and mobilizing individuals in these countries. The female Muslim blogosphere was selected as a test-bed for two reasons: First, while research shows that three of four females online are active social media users, very little research attempts to understand social, cultural and political roles of female bloggers and collectivity among female social groups. Second, the domain epitomizes an important contrast deserving attention, between socio-political systems where women are frequently denied freedom of expression and active political uses of social media by female Internet users. Female Muslim bloggers find the blogosphere as a digital recourse to exercise their freedom of speech if compared to their physical and repressively controlled spaces.<br/><br/>This longitudinal study will develop the theoretical underpinnings and experimental tools to examine the factors that govern the success and failure of cyber-collective movements more generally. It will develop novel algorithms modeling cyber-collective movements by utilizing existing social theories on collective action and computational social network analysis and basing the analysis upon three central tenets of individual, community, and transnational perspectives. Essential questions to be addressed in this study are: What transforms individual sentiments into collective sentiments? What are the dynamics of various socio-cultural dimensions in the evolution of opinion leaders? What social or organizational factors help transcend the nation-state barriers? Several independent validation strategies will be investigated, including monitoring the manifestation of cyber-collective movements as physical social movements, human evaluation, and crowdsourcing initiatives to bridge the gap between qualitative and quantitative evaluation measures.<br/><br/>The lessons learned from this research will create greater synergies between social science and computational science. Data collected from this research will be made publicly available due to its efficacy for various interdisciplinary research endeavors, especially in human-computer interaction, game theory, political communication, social network analysis and mining, and social computing, among others. Members of underrepresented groups, especially female bloggers will play an essential role in the project, lending insights into the idiosyncrasies of their socio-technical behavior advancing our understanding of the female demographics, thus making a significant impact on society at large. Educational impacts include the creation of much-needed interdisciplinary courses and training undergraduate, graduate and doctoral students by involving them at all stages of the research."
"0747428","CAREER: A Multimodal Mixed-Initiative Research Notebook for Information Discovery","IIS","Cyber-Human Systems, COMPUTER SYSTEMS","04/01/2008","04/15/2014","Andruid Kerne","TX","Texas Engineering Experiment Station","Continuing grant","Ephraim P. Glinert","03/31/2015","$638,000.00","","andruid@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7367, 7354","1045, 1187, 1707, 9215, HPCC, 7367, 9251, 9178","$0.00","While search engines address the problem of helping people find particular information, they are not directly built to support people developing creative ideas. This research supports people engaged in sustained information discovery tasks, such as invention and thesis development, in which the goal is to create new knowledge by forming ideas while finding and assembling information. New modalities of human computer interaction will be developed to support people engaged in assembling their building blocks of invention, utilizing information semantics, dynamic organization, and visualization. The approach is based on the form of composition, which visually and conceptually integrates elements to represent a collection. The research notebook will support sustained innovation, in which people need to connect and integrate key findings in the collections they create while conducting research and invention over time. Physically-based techniques, such as mass-spring and flocking models, will be applied and extended to facilitate human manipulation of collections as compositions. New modalities of interaction, such as pen-based, will improve sensory feedback and engagement by enabling participants to literally get their hands into digital information. The physically-based techniques and new interaction modalities will be integrated with the combinFormation mixed-initiative composition platform to provide a basis for augmenting the research notebook beyond the desktop metaphor. Our principal hypothesis is that mixed-initiative composition and physically-based multimodal interaction will improve the emergence of new ideas during individual and team-based information discovery tasks. Using the research notebook on assignments by over 1,000 undergraduate students developing new inventions each year in The Design Process course will catalyze innovative education, while also generating evaluation data on information discovery.<br/><br/>The proposed research is innovative in its interdisciplinary approach, expected to yield significant outcomes: (1) new techniques for physically-based interaction with information; (2) new multimodal techniques for interaction with information; (3) new integrated semantic, visual, and interactive methods for supporting human discovery of connections among ideas; (4) a research notebook infrastructure for supporting sustained interaction with digital information by students and researchers; (5) new data about how students and researchers develop ideas over time in practice; (6) new understanding of creative processes that make up research and invention; and (7) new methods for supporting research and invention in education. Advanced learning technologies developed by this proposal will be implemented and distributed through the Research Notebook and the combinFormation platform. Software technologies will be made available to the students and the public through the web. A multimodal interaction lab will make integrated software/hardware systems available to some of the students. The Research Notebook methods, techniques, and cyberinfrastructure can amplify the productivity of scientists. The new interactive techniques for discovery and semantics can transform how students, researchers, knowledge workers, and the public experience the internet and digital repositories. The integration into education of research issues, designs, and implementations, with a learner-centered approach, will contribute to the development of a new generation of creativity-oriented human-centered computing researchers and practitioners."
"1321102","HCC: Small: Designing and Understanding Technology Mediated Reflection to Improve Well-Being","IIS","Cyber-Human Systems","08/01/2013","04/15/2014","Steve Whittaker","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","07/31/2016","$515,828.00","","whittak@ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","7367, 7923, 9251","$0.00","This is a multidisciplinary research program combining medical informatics, human-computer interaction and behavioral science exploring effective user-centric technology mediated reflection (TMR) to promote psychological well-being. It will design, develop and evaluate a radically new class of user-centric TMR system, thereby creating methods that will have much wider applications as well. People currently experience problems of memory and compliance in carrying out TMR. However these problems are addressable by computational intervention using mobile tools for user-centric TMR to capture data about personal events and support reflection about emotional reactions to those events. These mobile augmentation tools will overcome critical limitations of unaided reflection, by being lightweight, user tailored and context-aware, and they will support adaptive reminding about positive and negative events. Novel visualizations should also improve people?s ability to infer general patterns in emotional behavior in order to promote long-term behavior change.<br/><br/>Using predictions derived from prior social science, this research will test the efficacy of TMR for improved well-being when users remind themselves about positive events, adaptively deal with negative past experiences, and modify long-term behavioral patterns in response to events. The research will then contribute fundamental new scientific knowledge to the social and psychological sciences, in part because collection of data about memory states during real life experiences goes beyond what it is possible to measure within the confines of academic laboratories. In addition, the project will develop techniques to analyze how reminiscences about the same event change over time. This will allow the development of new psychological and clinical models concerning the relations between memory, emotions and well-being.<br/><br/>A significant fraction of the population experiences a major depressive episode at least once in their life, and other problems such as anxiety are also common, yet many people respond poorly to conventional forms of treatment, and the exact boundaries of these problems are poorly defined. Effective TMR can address these pressing problems, by providing new tools and an experimental platform that will enable the rigorous testing of TMR interventions, addressing calls for disruptive interventions in mental healthcare. It may be that one limitation of some current forms of treatment is that the benefits do not transfer well from the help-giver's office to the client's daily life, and mobile TMR may bridge that gap. Diaries composed with mobile devices can also contribute to more formal accounts of historical events, thereby facilitating the emergence of citizen science in which ordinary users collaborate with each other scholars and social scientists, to complete valuable projects and experience the enrichment of life-long learning. This project will also train undergraduates and graduate students in an interdisciplinary area of human computer interaction, medical informatics, and psychology."
"0953943","CAREER: A Multi-Disciplinary Approach to the Next Generation of Collaborative Technologies","IIS","Cyber-Human Systems","01/01/2010","04/15/2014","Darren Gergle","IL","Northwestern University","Continuing grant","William Bainbridge","12/31/2014","$501,918.00","","dgergle@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","1045, 7367, 9251, 1187, 9215, HPCC","$0.00","This research aims to enable the development of the next generation of collaborative technologies and to study their effects on human collaboration. It does so by improving our theoretical understanding of how various features of shared visual context affect communication, coordination and collaboration. The research develops and makes available the code for a new dual eye tracking methodology that can be used to study coordination and collaboration. It also develops a new set of metrics that can be more generally used to understand coordinated eye movements as they relate to dialogue and conversation. The results of this work will add to knowledge in a number of disciplines, including human-computer interaction, language technologies, computer science, computational linguistics, communication studies, cognitive science, and social and cognitive psychology.<br/><br/>As recent efforts in telemedicine, distance education, and remote training and repair attest, there exists enormous potential for technologies to support these activities at a distance, ultimately resulting in widespread benefits such as equal access to quality education and medical care. The education activities in this research include: (1) developing a new Ph.D. course that teaches a theory-driven design approach; (2) developing a series of course modules that use the dual eye tracking methodology to teach behavioral coding, statistics and machine learning; (3) developing a publicly available multimodal corpus with a set of tutorials, and (4) developing a series of international workshops on dual eye tracking. Finally, the research will simultaneously advance discovery and understanding while training both graduate and undergraduate students in interdisciplinary research methods and will contribute to the development of traditionally underrepresented individuals in the fields of computer and information sciences."
"1217904","RI: Small: Dexterous Manipulation Using Predictive Thin-Shell Modeling","IIS","ROBUST INTELLIGENCE","09/01/2012","04/15/2014","Peter Allen","NY","Columbia University","Standard Grant","Satyandra Gupta","08/31/2015","$506,894.00","Eitan Grinspun","allen@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7923, 7495, 9251","$0.00","Grasping and manipulation of deformable objects presents a host of new research challenges that are much more demanding than for rigid objects. A particular challenge is to fully understand the physics of deformation and to model deformable objects in a way that can be used by real robotic systems in the presence of noise and uncertainty and with real-time constraints. This project will use offline simulation to predict states of deformable objects modeled as thin-shells (i.e. cloth, fabric, clothing) that can then be recognized by a robotic vision/grasping system to pick up and manipulate these objects. The Intellectual Merit includes a significant step forward in the synthesis of state-of-the-art numerical computation of plasto-elastica with a database-driven manipulation approach to allow robots to manipulate deformable objects. This includes fabric simulation technology that provides the requisite level of accuracy at speeds amenable to online computation parallel to the robotic grasping task. <br/><br/>The Broader Impacts of this research include 1) creation of an open source, extensible, 3-D database of deformable objects for dissemination to the robotics and graphics communities, 2) extending the range of working environments for the emerging field of personal robotic assistants, and 3) developing and educating a new class of scientists who bridge the fields of computer graphics, computational mechanics, and robotics."
"1217143","HCC: Small: A Joint Action Approach to Understanding and Supporting Interpersonal Attention In Virtual Organizations","IIS","Cyber-Human Systems","09/01/2012","04/15/2014","Jeremy Birnholtz","IL","Northwestern University","Continuing grant","William Bainbridge","08/31/2015","$514,364.00","","jeremyb@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7923, 9251","$0.00","This project will develop a theoretical and practical framework for understanding and supporting processes of interpersonal attention management in virtual organizations of geographically distributed individuals. Research on virtual organizations (VOs) - aggregations of individuals, facilities and resources that span geographic and institutional boundaries - is critical because VOs are an increasingly common work structure. They enable interaction between individuals who might not otherwise work together, the sharing of scarce resources, and allow novel ways of solving problems. Despite these advantages, members of VOs often cannot work together as effectively as those who are collocated. One reason for this is the difficulty of opportunistic, informal interactions in VOs. These interactions are critical to troubleshooting and coordination, as when co-workers ask quick questions or respond to others' requests, exchange information about the task or environment, or make spur-of-the-moment decisions. <br/><br/>While many virtual organizations provide basic communication tools such as instant messaging or video conferencing, members often cannot use these effectively because the tools lack support for the subtlety and nuance of managing one's availability and attention to others. As a result, many people only sporadically attend to messages from collaborators, or may abandon technologies altogether. One problem limiting research progress in this area is that prior work has not considered attention management as a form of joint action in which both parties act in response to each other. This research addresses this problem by developing a theoretical and practical framework for understanding the joint and adaptive nature of attention management. Through a combination of field and laboratory efforts, this work addresses three issues: (1) What information do people seek, and what are they willing to share as they jointly convey attention in today's VOs and distributed collaborations? (2) How does the relationship between gathering and display impact people's task performance, social relationships with others, their use of awareness information, and their attitudes toward privacy and sharing? (3) How do we integrate asynchronous and synchronous attention behaviors? <br/><br/>This work builds on research in the area of interpersonal awareness and fostering interaction in geographically distributed groups. It makes several contributions: (1) developing and testing a joint action framework for attention management in VOs, (2) examining joint attention management in synchronous and asynchronous activities, and (3) developing novel tools using next-generation technologies to facilitate analysis of attention management, such as eye and gesture tracking. <br/><br/>This work will improve our ability to support more natural and effective collaboration in virtual organizations, which have been identified as critical to national competitiveness and can improve interaction with aging, disabled and otherwise isolated individuals. Computer-supported cooperative work and other forms of computer-mediated communication can benefit. Results will be incorporated into classroom learning activities, and work will be carried out by students from multiple behavioral and technical disciplines, thus drawing a broader population of students to the science and engineering disciplines."
"1162114","HCC: Medium: Enhancing Social Translucence in Systems to Support Virtual Teaming","IIS","Cyber-Human Systems","04/01/2012","04/15/2014","Mark Zachry","WA","University of Washington","Continuing grant","William Bainbridge","03/31/2015","$890,659.00","David McDonald","zachry@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7924, 9251","$0.00","This project investigates the nature and work of self-managed, voluntary teams operating in virtual spaces. The investigation is designed to provide a research basis for designing systems that will support advances in voluntary virtual teaming, and social computing more generally. The research addresses four high-level, interrelated questions: (1) How can social translucence be realized in systems to support the work of virtual teaming? (2) How can current models of self-organized and self-managed work teams be extended to address key features of voluntary teams working in virtual spaces? (3) What inter-group and intra-group characteristics of voluntary virtual teams enable meaningful understanding of a team's collaborative work and activities? (4) How can these characteristics be composed into socially translucent, system-generated views of teams?<br/><br/>The availability of rich data associated with voluntary project groups operating in Wikipedia provides the basis for this investigation. The research will combine model development, model testing, system design, and deployment to develop an understanding of virtual teaming in support of a larger vision of social translucence in online communities. The research focuses on broad, rich categories of interaction - within team and outside team - to elaborate the dimensions of virtual teaming that can productively be exposed through socially translucent design. The research is inherently structured as cycles of basic research and exploration, followed by design activities, design evaluations, development, and deployment. Through this process, the research will identify features of group interactions that can support views of project teams that are inspectable in a visualization system, which will be made available to the community itself. <br/><br/>The intellectual merit of the project lies in the elaboration of models of volunteer virtual teams and in the design and development of principles for group-oriented, socially-translucent systems. The research will extend social translucence as a framework for the development of systems in which virtual teaming occurs, and it will develop a robust model of voluntary virtual teaming, realizing relevant sociotechnical dimensions for potential community members, project managers, and social analysts. The broader impacts of this project include research-based improvements to systems supporting the interaction, contribution, and sensemaking activities engaged in by an ever increasing population of people collaborating online. The approach deploys socially translucent tools in the systems where people work collaboratively, allowing those who will benefit from such views to manipulate, extend, and refine such tools to realize greater potential in their endeavors."
"1350253","CAREER: Mental Models and Critical Mass: Shaping the Success of Online Communities","IIS","Cyber-Human Systems","01/15/2014","04/15/2014","Richard Wash","MI","Michigan State University","Continuing grant","William Bainbridge","12/31/2018","$113,537.00","","wash@msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7367","1045, 7367, 9251","$0.00","As new computing and communication technologies become mainstream, online communities are transforming journalism and other industries to support more interactive, community-driven work. This project will study how mental models of online communities are formed, how they shape expectations about the future of the community, how they co-evolve with the community over time, and how they aggregate to form a critical mass that is essential for successful work and community survival. In many such online communities, participation is voluntary: each person must look at the community, develop a mental model of what that community is, how it works, and what it means for them to join, and then make a decision about whether they want to participate. And then, as the community evolves and changes, they need to continually decide whether and how to participate.<br/><br/>This research will triangulate three research methods to understand how individuals form mental models of online communities, and how mental models of multiple individuals interact and aggregate to form a larger community. First, it will use qualitative interviews to understand how individuals make sense of a new online community and how they make continuing participation decisions in communities they are already part of. Second, it will use a series of human subjects lab experiments to characterize how people form mental models of both the content available in an online community, and the other users of an online community. These experiments will also help to understand how a user's mental model helps her interpret the community's reactions to her participation. Finally, this project will use statistical analysis and formal mathematical modeling of existing online communities to understand how online communities grow over time and when people choose to leave online communities.<br/><br/>Results of this research will be of general value in designing, managing, and participating in many kinds of online communities, as well as contributing to education in the information, cognitive, and social sciences. A unique, cross-disciplinary education program will be created that trains students to use this research to build special-purpose online communities. This program will include a joint class linking a School of Journalism with a department of Telecommunication, Information Studies and Media. This class will form cross-disciplinary teams who spend the semester creating and growing an online community. This partnership will teach students to apply social science and computer science research for real-world applications, and work on collaborative, cross-disciplinary teams that include technical people, creative people, and topic experts. It represents a new type of education in journalism that will bring students into new, community-driven methods of doing journalism, based more on curating content and facilitating discussion than on original, unidirectional reporting."
"1117684","III: Small: Compression-Aware Algorithms for Massive Datasets","IIS","INFO INTEGRATION & INFORMATICS","07/01/2011","07/17/2012","Gabriel Robins","VA","University of Virginia Main Campus","Continuing grant","Sylvia J. Spengler","06/30/2015","$499,984.00","Abhi Shelat","robins@cs.virginia.edu","P.O. BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","CSE","7364","7923","$0.00","As many application domains continue to generate data at exponentially increasing rates, much of the data that is gathered is stored in a compressed format. However, very few classic data processing algorithms have been updated to handle compressed data. This project aims to address this gap by developing (i) algorithms for massive data sets that can directly operate on compressed data; and (ii) compression schemes that are aware of the algorithms that would operate on the data. <br/><br/>In many settings, algorithms that manipulate very large composite objects while interacting only with their succinct descriptions can substantially reduce the time and memory requirements relative to their counterparts that have to work with uncompressed representations of the same data. These performance gains are realized by leveraging highly repetitive or parametrically specified input structures, to enable algorithms to manipulate very large composite objects while interacting only with their compressed descriptions. Anticipated results of the project include new geometric algorithms that solve problems such as convex hull, Voronoi diagrams, nearest points and earth-mover distances when the inputs are in compressed format; new graph algorithms that compute minimum spanning trees, shortest paths, and network flows on compressed input graphs; and new compression-aware data structures that support efficient storing, querying and processing of compressed data. All the algorithmic contributions will be validated with experiments on real and synthetic massive data sets. The resulting algorithms are likely to find application in many different domains including networks, genomics, databases, computer graphics, artificial intelligence, geographic information systems, integrated circuit design, and computer-aided engineering. <br/><br/>Broader Impacts: Compression-aware data processing algorithms and algorithm-aware data compression schemes have applications across a wide range of tasks that involve processing of massive data sets consisting of large data objects (e.g., images, sequences, graphs). The formulations, algorithms, codes, and theories <br/>that will be developed and disseminated by this project are likely to contribute to the development of efficient and practical algorithms and data structures that could impact the way in which organizations collect, store, process, such data. The project offers enhanced research based training opportunities for students in an area of considerable theoretical as well as practical significance. Additional information about the project can be found at: http://www.cs.virginia.edu/robins"
"0708952","CRI: CRD A Richly Annotated Resource for Language Processing and Linguistics Research","CNS","COMPUTING RES INFRASTRUCTURE, ROBUST INTELLIGENCE, SPECIAL PROJECTS - CISE","08/01/2007","04/14/2014","Nancy Ide","NY","Vassar College","Continuing grant","Tatiana D. Korelsky","12/31/2014","$1,173,089.00","","ide@cs.vassar.edu","124 Raymond Avenue","Poughkeepsie","NY","126040657","8454377092","CSE","7359, 7495, 1714","9218, HPCC, 9215, 9251, 9102, 9178, 7359","$0.00","This project is annotating a corpus of American English for a variety of linguistic features, including syntactic structures and semantic information. The semantic information includes frame information based on FrameNet together with sense information based on WordNet. <br/>The annotations in the corpus are manually assigned by human annotators to ensure their reliability. Bootstrapping methods, using portions of the hand validated annotations, are being used to improve the performance of automatic annotation tools. The corpus is drawn from the materials in the American National Corpus, which consists of written data and speech transcriptions generated y native speakers of American English and representing a broad range of genres. All of the annotations are represented in a common format to enable merging different annotation layers, so that interactions among different linguistic phenomena can be studied.<br/><br/>The manually annotated corpus will provide an unparalleled resource for computational linguists and linguists who seek to identify patterns of syntactic and semantic usage that can feed the development of language models. This information can be used to train software to automatically annotate unseen data, which in turn enhances applications such as information retrieval and extraction and machine translation. Usage patterns for American English are also invaluable for the development of materials and tools to support English language learning. The resulting corpus and its annotations, together with tools for manipulating the data, will be made freely available for research purposes through the Linguistic Data Consortium."
"0964512","RI:Medium: Collaborative Research: Creating Organizationally Adept Software Agents and their Organizations","IIS","ROBUST INTELLIGENCE","06/15/2010","04/30/2012","Edmund Durfee","MI","University of Michigan Ann Arbor","Continuing grant","James Donlon","12/31/2014","$359,999.00","","durfee@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7924","$0.00","The centerpiece of this project is the design, development, and evaluation of computational representations and algorithms for making software agents that are organizationally adept. An organizationally-adept agent is not only aware of its role(s) in an organization, but can also monitor how well it is fulfilling its organizational responsibilities and can proactively adapt its behaviors to meet organizational needs better. Organizationally adept agents evaluate their behaviors based not on their (agent-centric) self-interests but rather on their (organization-centric) responsibilities to each other, and autonomously adapt to achieve organizational objectives emergently.<br/><br/>Elaboration and adaptation by organizationally adept agents means that the ultimate organization design is formed by a combination of top-down design (to produce a ""ballpark"" organization) and emergent refinement processes. Further, this combination can be iterative and ongoing, where organizationally adept agents can detect tension between top-down and emergent influences, and inform the design processes of runtime interaction patterns and environmental tendencies that suggest useful top-down organization restructurings.<br/><br/>The intellectual problems being pursued are central to practical issues in scaling multi-agent systems to help solve complex, long-term, global problems. Many critical challenges facing society including climate change, health care, and sustainable energy|require a prolonged commitment to monitoring and managing distributed activities. Networked computer systems populated by software agents, which can be constantly measuring, comparing, and interpreting information to understand and respond to wide-scale phenomena, promise to address such challenges, but need the kinds of innovations proposed in this project. Second, while the project is specifically looking at organizations for computational agents, our results will inform, and be informed by, research on human organizations. To stimulate sharing insights and results, the investigators will organize a multi-disciplinary symposium on organization-centric reasoning, and will train an inter-disciplinary cohort of graduate students."
"0747520","CAREER: Anywhere Augmentation: Practical Mobile Augmented Reality in Unprepared Physical Environments","IIS","Cyber-Human Systems","04/01/2008","06/29/2012","Tobias Hollerer","CA","University of California-Santa Barbara","Continuing grant","Ephraim P. Glinert","03/31/2015","$500,000.00","","holl@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7367","1045, 7367, 9215, HPCC","$0.00","The PI introduces the term Anywhere Augmentation to refer to the idea of linking location-specific computing services with the physical world, making them readily and directly available in any situation and location. This project embodies a novel approach to Anywhere Augmentation based on efficient human input for wearable computing and augmented reality (AR), through both sketch-based interfaces on hand-held devices and direct-overlay 3D user interfaces. Mobile augmented reality is a powerful interface for wearable computing. If computer users are enabled to place arbitrary annotations in 3D space wherever they go, the physical world becomes the user interface. Instead of embedding computing and display equipment in the environment as in the case of ubiquitous computing, graphical annotations are overlaid on top of the environment by means of optical see-through glasses or video overlay. Robust registration between the physical world and the augmentations is necessary. Current approaches rely on the availability of a 3D model of the environment or on its instrumentation with active or passive markers. The PI's approach is novel in that he proposes to emphasize, support, and utilize the expertise of the human in the loop to make Anywhere Augmentation feasible. Human users generally have a clear grasp of the layout of the scene in front of them, and they can easily identify the physical objects with which information should be linked. The PI plans to enable users to transfer their intuitional scene understanding to the computer through intelligently constrained and assisted user interfaces. Current real-time computer vision techniques and algorithms, while far from being able to facilitate automatic scene understanding, are very well suited to constrain and guide a user?s informed input for scene analysis and augmentation, delivered in the form of a few simple point selections, stroke gestures, and common classifications. As a main source of input, the PI will employ video feeds from small head-worn or palm-top-device cameras. The devices, algorithms and interaction techniques will be applicable to novel settings and application scenarios (e.g., visualization of occluded infrastructure, navigational guidance, and social and educational applications for high-school students).<br/><br/>Broader Impact: The PI will use this research as a case study and platform for projects supporting the teaching of human-computer interaction fundamentals. As a first step towards actively furthering the inclusion of minority students in the benefits of the research, the PI has partnered with Jackson State University, MS, and will also collaborate with outreach programs supporting local underrepresented K-12 students, where he will enhance the after-school programs and field trips with carefully planned AR experimentation and mentoring. The goal of Anywhere Augmentation will be tested by making research products (new devices, tools, and interfaces) available to students and field scientists in a wide variety of environments (e.g., as a campus navigation and inventory tool, for an emergency response scenario, at UCSB lab open houses, and at international conferences). The PI will also introduce innovations in three courses in the curriculum of the UCSB Computer Science Department (an undergraduate elective on HCI which he established, the undergraduate senior CS design project course cycle, and a new graduate course on 3D user interfaces), so they include hands-on experiences on effective UI design and programming for mobile devices, including mobile AR interfaces. To this end, the PI will also involve the UCSB Allosphere, a 3-story spherical surround-view 3D immersive space, as a mobile AR simulator."
"1414931","RI: Medium: Collaborative Research: Teaching Computers to Follow Verbal Instructions","IIS","ROBUST INTELLIGENCE","07/01/2013","04/09/2014","Michael Littman","RI","Brown University","Standard Grant","Todd Leen","08/31/2014","$514,356.00","","mlittman@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","7924","$0.00","The goal of this research is to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language on behalf of a user. It will study each of these components in isolation, but a significant focus will be on integrating them into a coherent system. The project will also leverage this technology to provide an entry point to educate non- or pre-computer science students about the capabilities and utility of computers as tools.<br/><br/>Our approach uses three main subcomponents, each of which requires innovative research to solve its portion of the overall problem. In addition, the integrated architecture is a novel contribution of this work. The three components are (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning, (2) translating instructions to task specifications using novel techniques in the area of natural language processing, and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing abstractions.<br/><br/>The goal of the work is develop technology for an improved ability for human users to interact with intelligent agents, the incorporation of novel AI research insights and activities into education and outreach activities, and the development of resources for the AI educator community. In addition to permitting intelligent agents to be developed and trained in the future for a broad range of complex application domains, the interactive agents that we will develop will be used for outreach and student learning."
"0845268","CAREER: Beyond Perspective Cameras: Multi-perspective Imaging, Reconstruction, Rendering, and Projection","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","04/01/2009","08/20/2012","Jingyi Yu","DE","University of Delaware","Continuing grant","Jie Yang","03/31/2015","$400,001.00","","yu@cis.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7495, 9150","1045, 7495, 9150, 9215, HPCC","$0.00","A perspective camera captures the spatial relationships of objects in a scene as they would appear from a single viewpoint. In contrast, a multi-perspective camera combines what is seen from several viewpoints into a single image and provides a potentially advantageous imaging system for understanding the structure of observed scenes. However, most existing computer vision and graphics algorithms are not directly applicable to multi-perspective cameras. The goal of this project is to develop a complete framework to characterize and design new multi-perspective cameras and displays and to use these systems for computer vision and graphics applications.<br/><br/>On the vision front, the PI explores two types of real multi-perspective cameras: the first extends existing catadioptric mirrors and the second uses specially-shaped apertures. To categorize these cameras, a ray geometry analysis is applied to identify important ray structures and study their implications on image distortions. The PI also investigates several new 3D reconstruction methods, such as epsilon stereo matching, ray-curvature analysis, and curvature-from-distortions, for a broad class of multi-perspective cameras. On the graphics front, the PI explores practical multi-perspective display architectures by combining a consumer projector with specially-shaped mirrors/lenses. Such displays can offer an unprecedented level of flexibility in terms of aspect ratio, size, field of view, etc. The PI also investigates real-time multi-perspective rasterization and frustum culling algorithms by modifying the traditional rendering pipeline. <br/><br/>The project contributes to education by involving undergraduate and graduate students in self-contained projects with both theory and application components, and attracting under-represented students through the pre-engineering program between the University of Delaware and the Delaware State University."
"0846024","CAREER: Health Bridge: Motivating Personal Health Record Adoption by Low -Income Communities","IIS","Cyber-Human Systems","07/01/2009","03/19/2014","Katie Siek","CO","University of Colorado at Boulder","Standard Grant","William Bainbridge","06/30/2015","$608,962.00","","ksiek@indiana.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","7367","1045, 1187, 6890, 7367, 9215, HPCC","$608,962.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). The increase in obesity and related chronic illnesses has motivated academic, government, and commercial sectors to address this epidemic. Assistive technology interventions provide an inexpensive method to disseminate information, track health metrics, and give personalized feedback on outcomes for individuals. However the effectiveness of these interventions is limited for low-income communities because the interventions have been designed with little consideration for the social and environmental context of health-related behaviors. Personal Health Records (PHRs) can assist individuals receive personalized feedback and authoritative health information, but have not been widely adopted because of privacy, usability, and updating issues. The research objectives of this proposal are to discover how to integrate PHRs into everyday life and empower individuals to confidently secure their PHR data with privacy interfaces. The research is relies upon community-based, iterative, participatory design activities including contextual interviews, design workshops, shadowing, and iterative evaluation of prototypes to develop a integrative PHR framework called Health Bridge.<br/><br/>The research supporting Health Bridge includes community building, curriculum design, and K-12 outreach activities. Research methodology and results will be integrated into the PI?s established health related course and specialized undergraduate curriculum in health related informatics. In addition, the PI and her students will help increase the pipeline of future informaticians by developing outreach materials that will be distributed by the National Center for Women & IT and the Computer Science Teachers Association Roadshow initiatives."
"1135389","NSF EAGER: Data-Driven Framework for Analyzing User Interactions in Social Media","IIS","INFO INTEGRATION & INFORMATICS","05/01/2011","04/27/2011","Divyakant Agrawal","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","04/30/2015","$199,934.00","Andrew Flanagin, Amr El Abbadi, Bassam Bamieh, Stacy Patterson","agrawal@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7484, 7916, 7924","$0.00","With hundreds of millions of users worldwide, social networks provide incredible opportunities for social<br/>interactions, entertainment, learning, and political and social change. Hence, there is a growing interest in understanding information diffusion over online social networks. Because many social interactions currently take place in online networks, social scientists have access to unprecedented amounts of information about social interaction. Prior to the advent of such online networks, these investigations required resource-intensive activities such as random trials, surveys, and manual data collection to gather even small data sets. Now, massive amounts of information about social networks and social interactions are recorded. This wealth of data can allow social scientists to study social interactions on a scale and at a level of detail that has never before been possible. However, Social scientists are not traditionally trained in techniques to deal with the massive amounts of data produced by online social networks. Computer scientists that specialize in databases and knowledge discovery have experience with querying and analyzing enormous amounts of data in a scalable fashion, but they may not be aware of the types of information that are most relevant to understanding social processes. Moreover, it is often necessary to alter theories and models developed in research of traditional social networks to incorporate new features of interactions in online networks, or even develop entirely new models of social processes. To create and validate these new models requires familiarity with social science techniques for modeling of social interactions, as well as knowledge of techniques for modeling and analysis of complex networks that can scale to the size of millions or even billions of users.<br/><br/>The project brings together an interdisciplinary team consisting of computer scientists with expertise in databases and data mining, network modeling and analysis, and social media led by Dr. Divyakant Agrawal at the University of California-Santa Barbara to develop computational approaches to model and predict a number of important phenomena in social networks: information diffusion, opinion formation, etc. The team is developing new algorithms and analytical and computational tools that can effectively cope with the massive size of social networks and the data produced within such networks. These tools are being designed account for the complex nature of human behavior by incorporating the spatial, temporal, and relationship-based aspects of social interactions. The long-term goals of this project are to develop tools that help better understand social interactions in online networks, to develop reliable and scalable models to predict the outcomes of such social processes, and to create applications that can shape such outcomes. The project advances the current state of the art in: Querying and analysis of massive datasets, Modeling and analysis of complex networks, and Analysis of social media and social interactions, including in particular, the interplay between multiple simultaneous information diffusion processes. This is a high-risk, potentially high payoff research effort due in part to the challenges associated with obtaining and analyzing data from social networks and social media. In order to model social network entities and interactions, the research team needs access to datasets from online social networks to build, verify and validate models. Similarly, discovering information, knowledge, and user behavior in online social networks require access to social network datasets. In general, acquiring such datasets is a significant challenge due to privacy issues and the proprietary nature of many social network sites. <br/><br/>This Early Concept Grant for Exploratory Research (EAGER) project provides a rich set of data repository and evaluation metrics for conducting large-scale investigations involving social networks and social media. The project addresses the data challenge by assembling large data sets from weblog postings and Twitter messages from millions of users, as well as appropriately anonymized data that capture the interactions between participants in social networks such as Facebook. The broad dissemination of the resulting datasets and tools will lower the barrier to (and reduce the risk associated with) entry into Social Informatics and Computational Social Sciences for researchers with diverse backgrounds and expertise. The resulting datasets and tools are likely to stimulate fundamental advances in several subdisciplines within Computer Science including algorithm design, network modeling and analysis, and data mining and knowledge discovery (among others). The project provides unique opportunities for broadening the participation of underrepresented minorities and women in Computer and Information Sciences, and especially those motivated by real-world applications in social sciences (e.g., understanding social interactions). The results of the project will be disseminated through the project web pages at http://cs.ucsb.edu/~dsl/?q=content/data-driven-framework-analyzing-user-interactions-social-media."
"1439741","IEEE Health Innovation and Point-of-Care Technologies 2014 Conference Student Scholarships","CNS","INFORMATION TECHNOLOGY RESEARC, COMPUTER SYSTEMS, INFO INTEGRATION & INFORMATICS","04/01/2014","04/08/2014","Clifford Dacso","TX","Baylor College of Medicine","Standard Grant","Theodore Baker","03/31/2015","$24,000.00","","cdacso@bcm.edu","ONE BAYLOR PLAZA","HOUSTON","TX","770303411","7137981297","CSE","1640, 7354, 7364","7556, 1640, 7354, 7602","$0.00","This award supports student involvement in the 2014 IEEE Conference on Healthcare Innovations and Point-of-Care Technologies to be held in Seattle, WA, on October 8-10, 2014. This conference is focused on potential innovative technology solutions to challenges associated with care delivery. It includes panel discussions, scientific and clinical presentations, and breakout sessions. The conference will also offer students the opportunity to participate in an IDEO design innovation workshop in which students will work with clinicians and engineers to develop and conceptualize innovative ideas for healthcare applications. The goal of this project is to involve students in all facets of the conference, from meeting planning to presentations, the IDEO workshop and session leadership to post-conference evaluation."
"1218177","RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications","IIS","ROBUST INTELLIGENCE","09/01/2012","06/17/2013","Jingyi Yu","DE","University of Delaware","Continuing grant","Jie Yang","08/31/2015","$204,431.00","","yu@cis.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7495","7923, 9150","$0.00","Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair. On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br/><br/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms."
"0709296","CRI: IAD - Computing Research Infrastructure for Human-Robot Interaction and Socially Assistive Robotics","CNS","SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE, Cyber-Human Systems","07/01/2007","04/07/2014","Maja Mataric","CA","University of Southern California","Standard Grant","Ephraim P. Glinert","06/30/2015","$189,254.00","Shrikanth Narayanan","mataric@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","1714, 7359, 7367","7218, 7359, 9102, 9178, 9215, 9218, 9251, HPCC","$0.00","Proposal #: CNS 07-09296 <br/>PI(s): Mataric, Maja J.<br/> Narayanan, Shrikanth S. <br/>Institution: University of Southern California<br/> Los Angeles, CA 90089-1147 <br/>Title: IAD:Computing Research Infrastructure for Human-Robot Interaction and Socially Assistive Robotics <br/><br/>This project, acquiring infrastructure for socially assistive robotics (SAR), enables interdisciplinary integrative research covering a broad spectrum of human robot interaction (HRI) topics. SAR studies a unique series of problems related to utilizing robot embodiment to provide social assistance to users in a variety of convalescence, rehabilitation, education, and training settings. The infrastructure consists of richly interactive humanoid robot platforms and state-of-the-art data collection equipment. The work enables the growth of SAR, providing grounding for a major area of HRI research by requiring realistic validation with human subjects/users for studies that include embodiment, affect/attitude modeling and recognition, mixed initiative interactions, user modeling, modeling personality and empathy, and engagement and learning through imitation. The facility is expected to produce a large corpus of data that will be made available to the community.<br/><br/>Broader Impact: Socially accepted robotics research aims to improve quality of life. Enabling the acquisition of pilot data necessary for NIH funding, this research brings new expertise through an interdisciplinary team that includes CS, EE, kinesiology, pediatrics, and development of disorder experts. Furthermore, the infrastructure impacts human resource development through educational and K-12 outreach programs that reach hundreds of students."
"1319598","HCC: Small: Head Activated Technology for Off-the-Shelf Mobile Devices","IIS","Cyber-Human Systems","09/15/2013","09/09/2013","Kenneth Barner","DE","University of Delaware","Standard Grant","Anthony Hornof","08/31/2016","$496,020.00","Jingyi Yu","barner@eecis.udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7367","7367, 7923, 9150","$0.00","Mobile computing devices offer increasingly rich human-computer interaction opportunities through the use of new sensor technology such as multi-touch surfaces, microphones, and cameras. These advances provide users with richer sets of interaction modalities and motivate new and novel human-centric interfaces. Among the new input modalities, touch-based interaction is the most advanced and widely deployed, while speech is gaining increased attention. However, even with recent breakthroughs in computer vision and depth and motion sensing technology, the imaging modality remains the least developed for mobile devices. And yet image-based sensing (a) would permit richer interaction opportunities for a general user population and (b) holds special promise for individuals with disabilities who find touch-based interfaces very challenging to use.<br/><br/>This project focuses on the development of Head-Activated Technology for off-the- shelf Mobile Devices (HAT-MD). HAT-MD systems will employ the next-generation imaging technology that will be included in a wide array of mobile devices. Advanced algorithms will detect and track user head and facial features, and map specific movements to specific interface controls and application actions. HAT-MD is initially targeted towards individuals with physical disabilities, and will both (a) extend to mobile platforms the head control interaction techniques that are often employed on desktop computers and (b) broaden the set of head and face movements that can be employed.<br/><br/>Project deliverables include: (a) HAT-MD Algorithms: Next-generation imaging sensors will be used for detection, tracking, and 3D reconstruction. Head position and facial features will be detected, tracked, and mapped to interface controls. Computation will be distributed between the mobile devices and cloud computing services. (b) HAT-MD Applications: Head activated interfaces will be developed to address the challenges that individuals with physical disabilities have when using contemporary mobile platforms. (c) HAT-MD Evaluations: Rigorous human subject studies will evaluate the effectiveness and ease-of-use of the general HAT-MD methodology as well as specific interface and applications that are developed. Algorithms will be benchmarked to current state-of-the-art detection, tracking, and reconstruction methods.<br/><br/>Broader Impacts: The increased accessibility provided by the HAT-MD project will create new opportunities for people to interact with mobile devices, especially for individuals with physical disabilities who currently have limited independent control of such devices. The project will also feature direct involvement by individuals with disabilities at the research, development, and evaluation phases in order to focus the intellectual development in a truly useful direction that will complement the broader impact."
"1117314","TC: Small: Secure the Electrical Power Grid: Smart Grid versus Smart Attacks","CNS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE, TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace","09/01/2011","07/27/2012","Haibo He","RI","University of Rhode Island","Continuing grant","Jeremy Epstein","08/31/2015","$524,360.00","Yan Sun","he@ele.uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018745138","CSE","7298, 7495, 7795, 8060","5936, 5979, 7795, 7923, 9150","$0.00","Growing energy demands and environmental concerns have significantly increased the interest of academia, industry, and governments in the development of a smart electric power grid. Security is one of the key aspects of power systems. The objective of this research is to advance methods of vulnerability analysis and to develop innovative responses to maintain the integrity of power grids under complex attacks (both cyber attacks and physical failures). This research will contribute to developing robust, secure, and reliable future smart grid systems. <br/><br/>Unlike many of the existing efforts that focuses on abstract topological structure or load-based analysis, this project considers both network topology and intrinsic power flow characteristics to understand system behavior in complex power grid attacks. This includes single-node and multiple-node vulnerability analysis, development of new risk-aware metrics, spatial-temporal attacks with consideration of timing and location, and multifaceted attacks augmented by link failures. Knowledge of power grid system behavior under attack scenarios will allow us to develop new defense strategies. <br/><br/>As power and energy systems have become one of the key technology and economic development focuses across the world, this project will have far-reaching impacts at different levels. This includes enhancing national power system security, providing technical support to government agencies and policy-makers for the U.S. energy sustainability community, and student education and workforce preparation in this field. The integrative educational and outreach approaches will also provide a unique platform to encourage women and minority students to the critical Electrical/Computer Engineering disciplines."
"1361274","CAREER: Semantic Interpretation with Monolingual and Cross-lingual Evidence","IIS","LINGUISTICS, ROBUST INTELLIGENCE","09/01/2013","09/26/2013","Rada Mihalcea","MI","University of Michigan Ann Arbor","Continuing grant","Tatiana D. Korelsky","05/31/2015","$116,141.00","","mihalcea@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","1311, 7495","0000, 1045, 1187, 7495, 9215, HPCC, OTHR","$0.00","Word meanings are central to the semantic interpretation of texts.<br/>Although much work to date has focused on statistical approaches that often ignore the explicit understanding of the text, recent research work has begun to challenge this simplification, demonstrating that semantic interpretation is indeed essential for a number of language processing applications.<br/><br/>The key observation underlying this CAREER project is that word meaning distinctions differ from one lexical resource to another and that the optimality of word meaning representations should be dictated by the target application. The project is exploring rich and flexible word meaning representations that combine the benefits of multiple monolingual and cross-lingual lexical resources and that can be adapted to the context and to the target application. In particular, the multilingual nature of these representations allows for an effective exploitation of the knowledge and resources available in different languages. The project also explores the role played by these word meaning representations and the corresponding monolingual and cross-lingual knowledge sources in several natural language processing tasks including lexical substitution, word and text translation, and text-to-text semantic similarity.<br/><br/>Another aim of the project is to integrate natural language processing into educational applications, and explore the use of the word meaning interpretation models to build a comprehension-assistant tool for students of English as a second language (ESL) and English as a foreign language (EFL). The educational program also fosters increased awareness about research in multilingual natural language processing among college, undergraduate, and graduate students, through a college outreach program and a new course on multilingual computational linguistics, as well as increased exposure of students to international experiences through international collaborations."
"1236983","EAGER: Collaborative Research: Computational Public Drug Surveillance","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","04/04/2014","Donald Adjeroh","WV","West Virginia University Research Corporation","Standard Grant","Sylvia J. Spengler","08/31/2014","$91,040.00","Arun Ross, Marie Abate, Wanhong Zheng","don@csee.wvu.edu","P.O. Box 6845","Morgantown","WV","265066845","3042933998","CSE","7364","7364, 7916, 8018, 9251, 9150","$0.00","Adverse drug reactions (ADR) (undesired or excessive responses drugs) have been linked with significant morbidity and mortality, and account for as much as 5% of all admissions. A drug-drug interaction (DDI) is a type of ADR involving two or more drugs. Reports suggest that 50% percent of the drugs withdrawn in the U.S. by the Food and Drug Administration (FDA) from 1999 to 2003 were linked with significant DDIs. The ADR profile of a given drug is rarely complete at the time the drug is approved by FDA. Hence, after a drug has been in use by the general population (with significant diversity in race, gender, age, lifestyle), often previously unidentified DDIs are discovered. To complicate matters, certain populations of patients, e.g., psychiatric patients, are often concurrently treated with multiple medications. The potential interactions between multiple drugs are neither well understood nor completely characterized. Voluntary reporting, the basic mechanism used by the FDA to monitor new drugs, suffers from underreporting, delayed reporting, uneven quality of reports, and even lack of reports of rare DDIs.<br/><br/>Against this background, this collaborative project aims to explore the feasibility of a novel computational approach to the problem of drug-drug interaction surveillance. It seeks to develop new methods for predicting molecular level interactions between drugs from data gleaned from online sources and digital social media. The project aims to test the hypothesis that such online data, in combination with with data from traditional drug related databases can be used to reliably predict potential DDIs much sooner than possible using current methods. The effectiveness of the approach is assessed through verification of predictions against future reports. <br/><br/>If successful, the project could lead to effective, proactive computational approaches to drug interaction surveillance, with benefits to federal, local and public health agencies, drug companies, clinical practitioners, the patients, and the public at large. Early detection of adverse DDIs could lead to improved patient care, and significant reduction in healthcare costs and lawsuits involving DDIs. The project offers enhanced opportunities for collaboration among investigators with expertise in computational and health sciences. It also offers research-based training opportunities to students at West Virgina University and the University of Virginia. Results of the research will be freely disseminated to the broader academic and research community."
"1054903","CAREER: Scalable Bayesian learning for multi-source and multi-aspect data","IIS","INFO INTEGRATION & INFORMATICS","01/01/2011","04/04/2014","Yuan Qi","IN","Purdue University","Continuing grant","Frank Olken","12/31/2015","$397,564.00","","alanqi@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","1045, 1187, 7364","$0.00","Data of growing complexity come from multiple sources with multiple aspects. These data present us with unprecedented opportunities to integrate them with predictive models to extract complex relationships among natural and man-made objects.<br/><br/>The PI brings together models and techniques encountered in various areas, such as Bayesian statistics, computational science, and systems biology, to develop new methodologies and tools for multi-source and multi-aspect data analysis. The intellectual merit includes (i) new constrained sparse Bayesian models to make interpretable predictions in their application domains, (ii) nonparametric multi-view and multi-way models to reveal unknown complex relationships between different data sources and aspects, and (iii) scalable inference to make advanced Bayesian methods practical data analysis tools.<br/><br/>The PI collaborates with domain experts to model online user behavior, facilitate neurologists to elucidate brain functions and help pharmaceutical researchers identify key biomarkers for drug discovery. The PI incorporates the research results into new courses he teaches, organizes workshops, and recruits graduate and undergraduate students to conduct research for this project.<br/><br/>For further information see the project web site at the URL: http://www.cs.purdue.edu/~alanqi/projects/learning-multi-source-aspect-data"
"1441415","HCC: Small: The role of social network sites in facilitating collaborative processes","IIS","Cyber-Human Systems","10/31/2013","04/03/2014","Nicole Ellison","MI","University of Michigan Ann Arbor","Continuing grant","Kevin Crowston","09/30/2014","$112,899.00","","enicole@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7367, 7923, 9215, HPCC","$0.00","Collaboration, when it works, optimizes the contributions of individuals, often resulting in better decisions, outcomes, and experiences than individuals working alone. Social network sites (SNSs) offer new opportunities for collaboration due to their social and technical affordances. SNS profiles enable the display of identity information, which can act as a social lubricant and help individuals initiate conversations and find common ground. Within SNSs, contact lists lower the transaction costs associated with interaction. Finally, SNSs enable access to a larger pool of individuals (and their wider and more diverse knowledge base) while also providing a context in which social capital processes serve as a mechanism for encouraging collaboration, advice-giving and information-sharing. This project will develop and test a model of SNS-enabled collaboration motivated by the following research questions: What forms of collaboration are enabled by SNSs? How do the features of SNSs affect these processes? Who uses these sites to collaborate and why?<br/><br/>This study will examine SNS-facilitated collaborative instances using quantitative and qualitative data to provide insight into users motivations, perceptions, and conceptual frameworks. First, we will examine examples of ad-hoc collaboration among college undergraduates to explore how relationship initiation and collaboration occur, both in SNS and face-to-face contexts. Second, aggregate behavioral patterns on Facebook will be analyzed to discover and investigate modes of collaboration on the site."
"1055062","CAREER: Large Vocabulary Gesture Recognition for Everyone: Gesture Modeling and Recognition Tools for System Builders and Users","IIS","Cyber-Human Systems","04/01/2011","04/02/2014","Vassilis Athitsos","TX","University of Texas at Arlington","Continuing grant","Ephraim P. Glinert","03/31/2016","$505,937.00","","athitsos@uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7367","1045, 7367, 9251, 7218","$0.00","The PI's goal in this project is to develop new methods for automatically annotating, recognizing, and indexing large vocabularies of gestures, and to use these methods to create an integrated set of tools for sign language recognition. Current state-of-the-art methods for recognizing large vocabularies of gestures have significant limitations that impact both system design and the user experience. Many methods assume the existence of a near-perfect hand detector/tracker; that is a limiting assumption, which prevents deployment of these methods in complex real-world settings where such accuracy is unachievable. In the absence of perfect hand detectors, system design may involve a large investment in manual annotation of training videos (e.g., specifying hand locations), so as to provide sufficiently clean information to training modules. The user experience is affected by the limited accuracy and robustness of existing applications. In this research the PI will address these issues by explicitly designing recognition and indexing methods that require neither perfect hand detectors nor extensive manual annotations, thus making it substantially easier to deploy accurate and efficient gesture recognition systems in real-world settings. The PI will achieve these objectives through theoretical advances in the current state of the art in computer vision, pattern recognition, and database indexing. The unifying theme in the project is the integration of low-level tracking modules that produce imperfect output, with recognition and indexing methods that are designed to take as input this imperfect output from the tracking modules. Novel articulated tracking methods will be developed that utilize probabilistic graph models to provide fully automatic long-term tracking, while improving upon the excessive time complexity that probabilistic graph models currently incur. New methods will be designed for extracting and exploiting information from hand appearance. As these novel modeling and recognition methods will violate standard assumptions made by existing indexing methods, new indexing methods will be formulated which will improve the efficiency of search in large databases of dynamic gestures and static hand shapes within the proposed framework.<br/><br/>Broader Impacts: Project outcomes will significantly improve the ability of sign language users around the world to search databases of sign language videos and to perform tasks such as looking up the meaning of an unknown sign or retrieving occurrences of a sign of interest in videos of continuous signing. These search tools will have an impact in educational settings, facilitating both learning a sign language and accessing arbitrary information available in a sign language. To these ends, the PI will make his software freely available to the public online. He will also work with experts in American Sign Language to implement key applications using his tools, which will be made available to Deaf students. The PI will furthermore develop a publicly available package of gesture recognition source code, applications, and datasets that will help student researchers at all levels engage in gesture recognition research. As an additional outreach activity intended to attract young people to careers in science, the PI will co-organize summer camps that educate junior high and high school students in computer science."
"0845997","CAREER: Educational Data Mining for Student Support in Interactive Learning Environments","IIS","ROBUST INTELLIGENCE, CAREER: FACULTY EARLY CAR DEV","07/01/2009","12/03/2013","Tiffany Barnes","NC","University of North Carolina at Charlotte","Standard Grant","Kenneth C. Whang","06/30/2015","$646,982.00","","tiffany.barnes@gmail.com","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","7495, 1045","1045, 1187, 7495, 9102, 9215, HPCC, 6890","$646,982.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>Creating intelligent learning technologies from data has unique potential to transform the American educational system, by building a low cost way to adapt learning environments to individual students, while informing research on human learning. This project will create the technology for a new generation of data-driven intelligent tutors, enabling the rapid creation of individualized instruction to support learning in science, technology, engineering, and mathematics (STEM) fields. This has the potential to make individualized learning support accessible for a broad audience, from children to adults, including students that are traditionally underrepresented in STEM fields.<br/><br/>This project will (1) develop computational methods to derive cognitive models from data that can be used to support individual learners through guidance, feedback, and help; (2) develop approaches to providing student support that leverage data to provide hints and guidance based on information such as frequency of student responses, probability of future errors, and solution efficiency; (3) develop interactive visualization tools for teachers to learn from student data in real time, to allow teachers and instructional designers to tailor instruction to address actual, rather than perceived, student problem areas; and (4) conduct formal empirical evaluations of pedagogical effectiveness. <br/><br/>The new software will construct adaptive support for teaching and learning in logic, discrete mathematics, and other STEM domains using a data-driven approach. From the extensive but tractable student performance data in computer-aided learning environments, student cognitive models will be automatically constructed. These cognitive models will build on the investigator's prior work using Markov Decision Processes and dimensionality reduction methods that leverage past data to assess student performance, direct a student?s learning path, and provide contextualized hints. Machine learning techniques will be used to expand problem-specific models into more general cognitive models to bootstrap the construction of new tutors and learn about student learning. For teachers and learning researchers, web-based visualization and analysis tool will be developed to graphically and interactively model student solutions annotated with performance data that reflect frequency, tendency to commit future errors, and closeness to a final solution. Through these new tutors and tools, experiments will be conducted to investigate student learning in a variety of contexts and domains, including logic, algebra, and chemistry. A team of diverse students and colleagues will be engaged to bring interdisciplinary expertise to this research and share findings broadly."
"1217635","HCC: Small: Haptic Realism versus Haptic Utility","IIS","Cyber-Human Systems","09/01/2012","04/01/2014","Allison Okamura","CA","Stanford University","Standard Grant","Ephraim P. Glinert","08/31/2015","$412,386.00","","aokamura@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7367","7367, 7923, 9251","$0.00","While numerous studies have focused on the design of novel controllers and devices to enhance the user experience of teleoperated and virtual environments, our general understanding of what makes a haptic interface acceptable to human operators is limited. The addition of haptic feedback to a computer-mediated task, such as training to perform a surgical procedure in a virtual environment or teleoperating a robot to dispose of explosive ordnance, has been hypothesized to improve the speed, accuracy, and precision of task performance. However, the benefits of haptic feedback have been insufficient to motivate inclusion of haptics in many mission-critical systems. Recent publications in the haptics literature have shown confusing results regarding the role of haptic feedback, such as haptic teleoperators that have high user acceptance and realism ratings but do not have any effect on user performance, as well as haptic teleoperators that are disliked by users yet lead to significant improvements in performance. The PI's goal in this project is to identify the salient parameters of haptic systems leading to haptic realism and haptic utility, their trade-offs, and - hopefully - their complementary features that lead to haptic systems that are realistic and useful, and therefore acceptable to human operators in high-risk scenarios. She plans to approach this problem by examining manipulation and exploration with bilateral teleoperators, where haptic feedback consists of vibrotactile and kinesthetic feedback mediated by a tool. System parameters of interest include feedback gain and frequency content, device mechanical properties, and time delay. For each parameter, the PI will examine its effect on realism and utility, specifically: how users subjectively rate realism and their own performance, and objective measures and theoretical predictions of user perception and performance. In addition, she will survey user acceptance and measure affect, and compare these to measures of realism and utility. Based on these results, she will design and test haptic feedback systems that should maximize user acceptance. This framework will allow her to answer relevant questions such as: What is the spectrum of cost-benefit ratios in bilateral teleoperation, considering the role of device performance in defining the limits of haptic realism and utility? How does the level of risk in a task affect user acceptance of haptic interfaces? Can we design ""haptic cartoons"" analogous to medical illustrations, which are not completely realistic but display the most important haptic features in order to maximize task performance? And is there a haptic ""uncanny valley"" in which slightly unrealistic haptic feedback is particularly disturbing to operators?<br/><br/>Broader Impacts: Effective haptic feedback systems will improve human health and well being through applications such as surgery and explosive ordnance disposal. This project will provide the field of computer-mediated haptics with a theoretical and experimental framework to describe the effects of system design choices on user acceptance of tool-based haptic teleoperators. The framework will likely apply to other forms of haptic display (such as sensory substitution and spatially distributed tactile feedback) and in other haptic feedback scenarios (e.g., medical training and the transfer of learning in simulation to real-world tasks). Project outcomes will be disseminated through software and data made publicly available on the PI's laboratory website, a conference workshop, and a new course on haptic design. Outreach programs, public lab tours, and mentoring of female and minority graduate students, undergraduates, and high school students will broaden participation of underrepresented groups in engineering."
"0845484","CAREER: Using Rich Information from Speech and Text for Meeting Summarization","IIS","ROBUST INTELLIGENCE","07/01/2009","06/16/2013","Yang Liu","TX","University of Texas at Dallas","Continuing grant","Tatiana D. Korelsky","06/30/2015","$408,077.00","","yangl@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","1045, 1187, 9102, 9215, HPCC, 9251","$0.00","Recent advances in text summarization and speech recognition have not been paralleled by similar advances in speech summarization. This project on meeting summarization has three focuses. First, it investigates two different summarization task definitions, generic extractive summarization, and query-based summarization. Second, it addresses the core challenges that arise when simply applying text summarization techniques to speech recognition output. It evaluates the impact of low-level structural information (such as sentence boundaries and disfluencies), uses high-level meeting structural information (such as topics and meeting structure, speaker interaction), and uses rich recognition output (confidence measures in the recognition hypotheses, n-best and lattices) for summarization. Finally, various measurements are used to evaluate the effectiveness of summarization approaches, including comparing to human summary references, extrinsic metrics (e.g., based on a question-answering task), and human evaluation for the usefulness of the query-based summaries.<br/>This project employs advanced algorithms to combine well-motivated rich information from both speech and text for meeting summarization. An important outcome will be the findings about the usefulness of the summarization task for the meeting domain and development of new approaches to measuring success for this task. This work will advance the frontier of our understanding of human interactions and improve our ability to automatically process human speech. The annotated data and evaluation tools developed in this project will be shared with the community. This project is multidisciplinary, involving speech processing, natural language processing, and conversation analysis. The tight integration of research and education will significantly enhance the excellence of next-generation researchers."
"1064871","HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics","IIS","Cyber-Human Systems","06/01/2011","04/01/2014","Patricia Shewokis","PA","Drexel University","Continuing grant","Ephraim P. Glinert","05/31/2015","$280,810.00","","pas38@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7367","7367, 7924, 9251","$0.00","This research involves collaboration among investigators at four institutions. Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning. While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms. For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control. The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions. These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof). The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags. The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date. In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics. To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR). An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis. Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder. To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined. <br/><br/>Broader Impacts: This research will revolutionize the control and interface of upper limb prosthetics. The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease. The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research. The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering."
"1149882","CAREER: New Directions for Metric Learning","IIS","ROBUST INTELLIGENCE","03/01/2012","04/02/2014","Kilian Weinberger","MO","Washington University","Continuing grant","Todd Leen","02/28/2017","$305,043.00","","kilian@wustl.edu","ONE BROOKINGS DRIVE, CAMPUS BOX","SAINT LOUIS","MO","631304899","3148895100","CSE","7495","1045, 9251, 7495","$0.00","Quantifying similarity is a fundamental challenge in artificial intelligence and machine learning which - if performed perfectly - would reduce many tasks to a trivial nearest neighbor search. For example, determining whether an email were spam would be as simple as searching a labeled database of emails and assigning it the same label (spam or not) as the email considered most similar to it. But how can one measure the similarity of two email messages? Does the same measurement still apply when comparing medical images? How does our understanding of similarity depend on the problem specification? Metric learning optimizes distance functions specifically for a given task, taking into account both the learning problem and the data. Initial successes with linear metrics show great improvements on many ""k-nearest neighbors""-based learning tasks. <br/><br/>This project pursues four research directions that strengthen the theoretical understanding of metric learning within the research community, broaden its impact and significantly improve the current state-of-the-art: <br/><br/>1. Are there non-linear transformations that lead to equally elegant and efficient optimization problems as existing linear metrics? As data sets grow and become increasingly complex, linear metrics are no longer sufficient to capture similarity relations. By exploring the use of non-linear metrics, this research can substantially improve the impact of metric learning and the accuracy of similarity relations. <br/><br/>2. Can the impact of metric learning be extended to machine learning frameworks beyond nearest neighbors? Designing new metric learning algorithms that explicitly optimize distances for a broad variety of machine learning algorithms will significantly increase the number of applications and learning methods that can directly benefit from metric learning. <br/><br/>3. Can metrics be learned from weak supervision? Removing the dependency on labeled data will reduce the cost of metric learning and increase its applicability. <br/><br/>4. Can one develop a solid theoretical framework to explain preliminary empirical successes and to direct future research? This will strengthen the theoretical understanding of metric learning within the research community. <br/><br/>Successful resolution of the proposed problems will lead to novel learning methods which will be immediately applicable to ongoing high-impact medical research collaborations of the principal investigator. In conjunction with these research directions, the principal investigator will also pursue educational goals, including the co-development of a K-12 curriculum module estimated to impact 2,500 high-school students. Many topics in the proposed research plan have components ideal for introducing the research process to undergraduate and graduate students, and the principal investigator plans to use his research as a vehicle to instruct and inspire future computer scientists and next-generation researchers."
"1318899","HCC: Small: Understanding and Supporting Communication Across Language Boundaries","IIS","Cyber-Human Systems","09/01/2013","04/02/2014","Susan Fussell","NY","Cornell University","Standard Grant","Kevin Crowston","08/31/2016","$512,039.00","","sfussell@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923, 9251","$0.00","Computer-mediated communication (CMC) tools and social media have the potential to allow people to interact fluidly across national boundaries but linguistic boundaries still pose challenges to communication. Advances in machine translation (MT) and other technologies have resulted in new tools that could allow people to communicate with one another using their native language, but translation errors create sizeable misunderstandings when MT is used in conversational settings. The goal of the proposed research is to better understand and support communication between people who speak different native languages by enhancing MT output with other information, such as keyword highlighting or pictorial representations. To achieve this goal, the project will (a) explore how the use of MT vs. English affects inter-lingual communication and coordination; (b) iteratively develop and test new tools that provide additional representations of meaning to smooth gaps in MT output; and (c) assess the value of these enhanced MT tools for communication and collaboration in a series of carefully controlled laboratory studies. The results will help delineate the design and technical space for new tools for inter-lingual communication. <br/><br/>The project will contribute to the fields of computer-mediated communication and computer-supported cooperative work by developing new theories and understandings of how people use technology to communicate and collaborate across language boundaries. It will contribute to human-computer interaction and related fields through the development of new techniques and tools for enhancing the output of machine translation. The annotated inter-lingual dialogues generated in experiments will also enrich the development of machine translation systems. Finally, the work will explore new technical issues around real-time keyword highlighting and multilingual picture retrieval. The project will also provide new tools and knowledge for communication across language boundaries that will be made widely available to the research community and general public, thus improving people's ability to engage with others across language boundaries, in global organizations and at the personal level, on social network sites and other international forms of new media."
"0952631","CAREER: Graphics: Gaze Manipulation","IIS","GRAPHICS & VISUALIZATION, Cyber-Human Systems","04/15/2010","04/02/2014","Reynold Bailey","NY","Rochester Institute of Tech","Standard Grant","Ephraim P. Glinert","03/31/2015","$565,427.00","","rjb@cs.rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757525","CSE","7453, 7367","1045, 7367, 7453, 9251, 9215, HPCC","$0.00","This research continues and extends work on subtle gaze direction - a novel technique that combines real-time eye- tracking with image-space modulation to direct a viewer's gaze about a digital image. This proposed project aims to pursue research in subtle gaze direction for dynamic scenes. This is a natural extension of viewers gaze pattern for static scenes. The work will seek improvement in search task performance. Advances in this area are important for many applications from locating anomalies in medical images to identifying camouflaged targets in a scene. The approach will use automatic feature detection algorithms. The project will also address issues relevant to improving information recall. This will involve studies to determine the impact of subtle gaze direction on spatial information recall for images and spatial-temporal information recall for dynamic scenes. The work will also explore gaze direction in the presence of more overt stimuli. <br/><br/>The project is designed to enable high quality interdisciplinary research that links technology design with health-based applications. The topics addressed are highly interdisciplinary and will require interaction with faculty and mentors from a number of disciplinary areas. The program will create new opportunities for undergraduates to study health and human behavior using the technology. The PI will pursue two curriculum development projects that are closely related to this research endeavor aimed at computer science and non- computer science majors. The courses are continually refined by inclusion of state-of-the- art computer graphics research and techniques. The Principal Investigator also plans to develop a new course on applied perception in graphics and visualization. In both cases, students are exposed to a broad topical area that draws upon human vision, computer graphics and visualization. The courses are expected to attract students from Rochester Institute of Technology's many programs in imaging related science."
"1217473","HCC: Small: Passive Tactile Learning and Rehabilitation Using Wearable Computers","IIS","Cyber-Human Systems","09/01/2012","04/01/2014","Thad Starner","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","08/31/2015","$523,998.00","","thad@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923, 9251","$0.00","Mobile Music Touch (MMT), developed in prior work by the PI and his colleagues, is a lightweight, wireless tactile music instruction system consisting of fingerless gloves and a Bluetooth-enabled mobile phone. Piano passages to be learned are loaded into the mobile phone and played repeatedly in the user's earpiece while s/he performs other tasks. As each note of the song plays, a vibrator on the appropriate finger in the gloves activates, indicating which finger is used to play the note. MMT users showed significant improvement in their ability to reproduce simple piano melodies, even though they were actively engaged in a reading comprehension task during practice. The PI terms this effect Passive Tactile Learning (PTL). He also has initial evidence for a related effect, Passive Tactile Rehabilitation (PTR), where tactile stimulation of the hand correlates to improvements in dexterity and sensation for people with tetraplegia resulting from incomplete spinal cord injury. In this project, the PI will explore PTL/PTR effects in a variety of applications, develop procedural and device design guidelines to best elicit these effects, and illustrate methods and metrics that are sensitive to detecting these effects.<br/><br/>Using MMT, he will compare users' learning of piano melodies while being distracted by a math-intensive test in four conditions: vibration stimulation with accompanying audio, vibration alone, audio alone, and no stimulation. This study will quantify the PTL effect and establish if vibration alone is sufficient to cause a learning effect. In an effort to broaden the applicability of the method, he will study the use of PTL to aid in learning stenographic typing and dance steps. To explore the possibility of PTR, he will run a 12-18 person controlled study with participants with tetraplegia due to partial spinal cord injury. This ""in-the-wild"" PTL/PTR study will compare active practice on a piano with active practice augmented with MMT. Participants will wear the glove during their everyday lives for at least 2 hours a day. The PI will compare learning rates as well as changes in participants' scores on standard sensation and dexterity tests. And he will also conduct a wearability study on MMT for persons with spinal cord injury to better accommodate their needs.<br/><br/>Broader Impacts: Establishing guidelines for the use and effectiveness of PTL and PTR will enable others to apply the concepts in different domains, e.g., learning sign language or manual procedures such as a pre-flight checklist or training users of prosthetic limbs in how to trigger different actions in their limb. Beyond partial spinal cord injury, PTR might also be exploited for recovery from damage from stroke or lesions due to Multiple Sclerosis.<br/><br/>The PI maintains an aggressive outreach program. Beyond professional publication of results in both the Human Computer Interaction and Rehabilitation literature, he will leverage his contacts to present the work in mainstream press and media (e.g., CNN), as well as more niche communities such as the Georgia Radio Relay Service. One of his focuses is exposing children in Georgia area schools for the deaf to his research, as there is a distinct need for encouraging deaf children in STEM areas. This effort will also be part of the undergraduate ""Device Thread"" in Georgia Tech's College of Computing, which exposes undergraduates to the rigors of designing computing for situations with physical device limitations, such as mobile phones, wearable devices, and robotics. Graduates and undergraduates in these classes will help investigate and fabricate new PTL/PTR devices. Finally, the PI intends to use this effort in his Computing4Good campaign, which inspires students to think of computing as a means for enabling social change."
"1253465","CAREER: Towards HCI Theory for Technical and Gender Identity","IIS","Cyber-Human Systems","02/01/2013","04/01/2014","Jennifer Rode","PA","Drexel University","Continuing grant","Ephraim P. Glinert","01/31/2018","$217,591.00","","jennifer.a.rode@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7367","1045, 7367, 9251","$0.00","The PI's long-term goal is to create theory to inform HCI design practices, to ensure the production of egalitarian designs that reflect all users' values. In particular, she aims to create feminist theory for HCI , which she hopes will close the gap in women's participation in computing. Previously, the PI has shown how approaches to designing for women are questionable when viewed in light of feminist theory. Feminist scholars argue that the lack of women in computing further discourages women from pursuing programming-related careers, and that women are also excluded because technologies created by men better address male needs. The PI believes the problem lies not only in who is excluded but in that the design processes inherently alienate women. Her approach is to address the problem by bridging previously unrelated aspects of the learning sciences, human-computer interaction, and the science and technology studies of gender, which will be combined with findings from a multi-year ethnographic study to acquire a deep understanding of how girls co-construct their gender and technical identities, how technologies come to be associated with one gender or the other, and how this affects girls' career choices. These results will be used as the basis for participatory design with the girls to create technologies in keeping with their gender identity. In doing so the PI expects to learn about girls' needs, enabling her to develop best practices for gender-sensitive design ensuring equitable access to technology. By bridging previously unconnected literatures, the project will reframe the problem of gender-equity in computer science from a pipeline issue to one requiring improved design and evaluation practices in HCI. The multi-year ethnographic study, to be conducted both in school and at after school programs, will provide a longitudinal understanding of how young women co-construct their gender and technical identities, what appeals to them about technical careers, and the process by which technology artifacts acquire symbolic gender. Participatory design will allow theory to be applied to understand what appeals to girls in the technology design process. While the project is not itself an education intervention, by building on both the empirical and theoretical contributions this research will explore how design practices themselves can be used to increase female participation in computing.<br/><br/>Broader Impacts: This research will directly impact women's training in computing, as well as lead to changes in the design process to be more inclusive for women. The project will create grounded theory on gender and technical identity that will inform participatory design, which in turn will allow the identification of needed changes to the software development process so that it results in more technologies that empower young women to use technology. As a consequence, the pool of qualified computer scientists will ultimately expand to include more women, which in the long turn will increase workforce thereby making the United States more globally competitive in business and more able to pursue scientific national security efforts. Furthermore, the project will directly benefit the group of young women involved in the ethnographic study, increasing their practical experiences with technology by teaching them software design, HCI, programming skills, and a foundation in computational thinking. Through participatory design the project will also expose middle and high school teachers to ubiquitous computing technologies, providing teacher development."
"1253285","CAREER: Supporting Fast-Response Medical Teams Through Interactive Information Displays","IIS","Cyber-Human Systems","02/01/2013","04/01/2014","Aleksandra Sarcevic","PA","Drexel University","Continuing grant","Ephraim P. Glinert","01/31/2018","$160,786.00","","aleksandra.sarcevic@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7367","1045, 7367, 9251","$0.00","Modern society increasingly depends on the work of interdisciplinary teams using information and communication technology (ICT) to control complex systems with high reliability (for example, in airplane cockpits, traffic control rooms, and nuclear power plants). Engineered systems such as these are deterministic, with well-defined states and parameters of normal operation which allow control teams to achieve their goals through direct interaction with ICT. But when the focus is a natural (i.e., social or living) system rather than a machine, the control task imposes quite different cognitive demands which make the design, development, and integration of ICT more challenging. High-risk, fast-response medicine is an example of a work environment that deals with a natural system (the patient), where the need for effective ICT support is as high as for engineered systems. The goal of this research is to develop innovative approaches for real-time information presentation to support situation awareness and collaborative work by fast-response, interdisciplinary medical teams. In particular, the PI will examine how context-specific information should be presented to support such teamwork while accounting for team members' perceptual and cognitive limitations. To this end, she will focus on the team-dependent and information-intensive processes of evaluating critically ill patients in the high-risk medical domains of pediatric trauma and emergency resuscitation. The research will involve field studies, video review of medical events, design and development of display prototypes, and evaluation. Project outcomes will include conceptual and empirical understanding of awareness in fast-response medical teamwork, approaches for augmenting distributed cognition through interactive displays, lessons from the development of display prototypes for improving awareness of rapidly unfolding events and their progression, and lessons from evaluating such prototypes in real-world settings.<br/><br/>Broader Impacts: The research will contribute to and inform diverse scientific fields, including information presentation in dynamic environments that rely on interactive information presentation, human-computer interaction where work conditions limit direct interaction with information systems, and the automatic capture and integration of data arriving from multiple sources. Because this research crosses many disciplinary boundaries, it will serve as a platform for an integrated and interdisciplinary education and outreach program."
"1115352","RI: Small: Model-Directed Hybridization: Principled Design of Hybrids of Model Building, Metaheuristics and More Traditional Optimization Techniques","IIS","ROBUST INTELLIGENCE","08/15/2011","04/05/2013","Martin Pelikan","MO","University of Missouri-Saint Louis","Standard Grant","Todd Leen","07/31/2015","$446,022.00","","pelikan@cs.umsl.edu","ONE UNIVERSITY BLVD","SAINT LOUIS","MO","631214400","3145165897","CSE","7495","7923","$0.00","This project focuses on the principled design, enhancement, analysis and application of model-directed hybrids, which combine model-directed optimization and traditional optimization techniques. The key idea is to use models of the problem landscape constructed by model-directed optimization techniques to facilitate decisions about the nature and likely effectiveness of particular local search procedures and appropriate neighborhood structures for those procedures. The importance of the developed techniques will be demonstrated in a broad spectrum of applications, including problems in computational physics, biology, chemistry and operations research.<br/><br/>The project will have transformative effects on computational optimization mainly because it will automate the design of advanced neighborhood structures and problem-specific operators applicable to broad classes of optimization problems, including problems with noise, dynamic landscape, complex structure and multiple conflicting objectives. Besides advancing computational optimization, the project will have a strong impact on a variety of other disciplines in science, engineering and commerce because it will provide practitioners in these disciplines with tools that allow practical solutions of problems intractable with current techniques. Furthermore, the project will provide methodology for development of advanced techniques for landscape analysis as well as theoretical study of advanced hybrids of metaheuristics and traditional optimization techniques.<br/><br/>To complement the research goals, the project puts a strong emphasis on broader impacts with the focus on advising student researchers, facilitating graduate mentoring of undergraduates, participating in multidisciplinary and collaborative projects, ensuring effective dissemination of research outcomes, organizing student competitions, boosting the local research infrastructure, and supporting groups underrepresented in science and engineering."
"1147912","SI2-SSI: The Language Application Grid: A Framework for Rapid Adaptation and Reuse","ACI","Software Institutes, SPECIAL PROJECTS - CCF, IIS SPECIAL PROJECTS, SPECIAL PROJECTS - CISE, ROBUST INTELLIGENCE","08/01/2012","04/01/2014","James Pustejovsky","MA","Brandeis University","Standard Grant","Daniel Katz","07/31/2015","$1,398,790.00","Marc Verhagen, Eric Nyberg, Christopher Cieri","jamesp@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","CSE","8004, 2878, 7484, 1714, 7495","7433, 8009, 1714, 2878, 7484, 8004","$0.00","The need for robust language processing capabilities across academic disciplines, education, and industry is without question of vital importance to national security, infrastructure development, and the competitiveness of American business. However, at this time a robust, interoperable software infrastructure to support natural language processing (NLP) research and development does not exist. To fill this gap, this project establishes an large international collaborative effort involving key international players to develop an open, web-based infrastructure through which massive and distributed language resources can be easily accessed, in whole or in part, and within which tailored language services can be efficiently composed, disseminated and consumed by researchers, developers, and students. <br/><br/>The goal of this project is to build a comprehensive network of web services and resources within the NLP community. This requires four specific activities: (1) Design, develop and promote a service-oriented architecture for NLP development that defines atomic and composite web services, along with support for service discovery, testing and reuse; (2) Construct a Language Application Grid (LAPPS Grid) based on Service Grid Software developed in Japan; (3) Provide an open advancement (OA) framework for component- and application-based evaluation that enables rapid identification of frequent error categories within modules, thus contributing to more effective investment of resources; (4) Actively promote adoption, use, and community involvement with the LAPPS Grid. <br/><br/>By providing access to cloud-based services and support for locally-run services, the LAPPS Grid will lead to the development of a massive global network of language data and processing capabilities that can be used by scientists and engineers from diverse disciplines, providing components that require no expertise in language processing to use. Research in sociology, psychology, economics, education, linguistics, digital media, and the humanities will be impacted by the ability to easily manipulate and process diverse language data sources in multiple languages."
"1258500","EAGER: An Exploratory Pilot Project to Build Human-Centric Physical Activity Monitoring Tools for Enhancing Rehabilitation Therapy Engagement and Assessment","IIS","Cyber-Human Systems","11/01/2012","04/01/2014","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Ephraim P. Glinert","10/31/2014","$170,026.00","Heng Huang, Vangelis Metsis","makedon@cse.uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7367","7367, 7916, 9251","$0.00","There are many types of disabilities caused by arthritis, where systematic physical activity and physical therapy are essential to preventing further deterioration. The challenge here is that periods of severe pain are an obstacle to such activities. The relationship between pain and physical activity is very tricky; it typically involves all joints (e.g., hands, wrists, feet, knees) and is a major cause of reduced quality of life and disability. This is the case with Rheumatoid Arthritis (RA), a chronic systemic inflammatory disease, where preserving functional range of motion and enhancing cardiovascular health are primary goals of physical therapy. Persons with RA who exercise regularly show not only improvements in muscle strength and overall physical and health function, but also reduced mortality. But it has been shown that long-term engagement in exercise among patients with RA is poor and does not exceed 50% when patients are not supervised. This results in a huge cost to national health care and to national productivity. <br/><br/>The PI argues that computer technology (tools and interfaces) can help the RA patient remain motivated and maintain movement. In this exploratory project her team will develop some of the components for motion capture and data integration that will eventually be integrated into a system called RPLAY which will enable patients with RA to perform physical therapy at home while the system accurately monitors their joint motions, motor performance and other physiological indicators. Specific objectives include: development of preliminary tools for human-centric adaptive remote monitoring, including facial, hand, arm, and body motions, and range of motion; development of prototype interactive games to encourage patient rehabilitation, and of a prototype user interface through which the patient and therapist can communicate via avatars to promote physical activity; and development of tools for validating the physical therapy monitoring and assessment results and their integration into a visualization and report system. <br/><br/>Broader Impacts: This project addresses issues of human joint pain and physical inactivity, which adversely affect the everyday lives of millions of people. It will lay the foundations for integrating disparate human data of persons in similar conditions, which will advance and extend the relationship between engineering innovation and computational analysis. The project will provide a training experience for computer science PhD students in modeling human motion in innovative ways. The project will also lead to an interdisciplinary course for physical therapy and computer science students on improving health delivery and rehabilitation practices."
"1118055","RI: Small: Large-Scale Machine Learning for Connectomics","IIS","ROBUST INTELLIGENCE","09/01/2011","08/30/2011","Pieter Abbeel","CA","University of California-Berkeley","Standard Grant","Kenneth C. Whang","08/31/2015","$450,000.00","","pabbeel@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","7923","$0.00","Large-scale image data analysis has in recent years become a key bottleneck in natural science research, particularly in the field of neuroscience. Technological advances in automated data acquisition have enabled the collection of terabyte and petabyte-size datasets. Extracting the rich information contained in these datasets manually would require an inordinate amount of human labor; reconstructing the neural connectivity in a complete fruitfly brain or cortical column of a mouse from electron microscopy data, key tasks of interest, would require ten thousand years of human labor using current state-of-the-art manual and semi-automated approaches. Improved automated image analysis tools are likely to be directly useful to the neuroscience community, enabling large-scale dense reconstruction of neural circuits from microscopy data, in which the morphology of every neuronal process is traced and all chemical synaptic connections between cells are identified, thereby mapping the complete ""wiring diagram"" of the circuit contained in the neural tissue. Such reconstructions have the potential to fundamentally impact the understanding of neural circuits by enabling competing models of brain architecture to finally be rigorously verified or falsified experimentally.<br/><br/>The large size of the datasets, the need for high accuracy to avoid incorrect scientific conclusions being drawn about the data, and the need for well-calibrated confidence measures in order to limit the time that must be spent manually verifying the output of algorithms, are all substantial challenges not well-addressed by existing segmentation methods. The investigators propose to (i) Develop efficient algorithms for convolutional locality-sensitive hashing, a novel generalization of locality-sensitive hashing techniques to the highly applicable setting of dense overlapping patches from a larger data volume. (ii) Develop efficient algorithms for the overlapping patch and convolutional variants of sparse coding designed to scale to very large datasets, filter sizes and numbers of filters. The proposed convolutional locality-sensitive hashing approach will be employed to enable this. (iii) Develop algorithms that leverage (i) and (ii) to segment electron microscopy data, and compare empirically to existing segmentation methods. All of the proposed methods are highly scalable to executions on large compute clusters in order to handle large training and test datasets. Furthermore, since the proposed methods allow explicit representation of the data, they are expected to be better calibrated than parametric methods such as the existing neural network-based methods for segmentation of electron microscopy data that currently achieve the best accuracy."
"1253196","CAREER: Towards Extensible Performance Management for Cloud Data Services","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","03/28/2014","Olga Papaemmanouil","MA","Brandeis University","Continuing grant","Frank Olken","02/28/2018","$175,637.00","","olga@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","CSE","7364","1045","$0.00","While existing cloud services reduce the application development time, data management applications still require significant effort by cloud tenants, for often their deployment involves a number of challenges including performance monitoring, resource provisioning and workload allocation. These tasks strongly depend on application-specific performance objectives, therefore developers often rely on ad-hoc solutions for addressing them. However, such solutions eventually hinder the application's implementation and maintainability.<br/><br/>This proposal is developing declarative mechanisms that allow application developers to express custom performance criteria for data processing tasks and exploits the properties of these mechanisms to design extensible resource, workload and Service-Level-Agreement (SLA) management services for cloud databases. The project also includes the design and development of an extensible cloud-based service platform, named XCloud, which unifies these services into a usable cloud utility.<br/><br/>The expected results include the design of declarative interfaces for the specification of performance criteria and performance models. Subsequently, by building upon properties of these interfaces, it will result in new extensible services for resource provisioning, workload allocation as well as in the support of customizable application-based SLAs for cloud databases.<br/><br/>The above results will have a significant impact on the quality of cloud-based data management applications. XCloud will allow developers to declaratively incorporate existing performance modeling techniques. The combination of declarative specifications and customizable modules will allow XCloud to act as a test-bed for new performance models for cloud databases, as well as QoS-driven approaches for workload, resource and SLA management, facilitating research and innovation in this emerging domain. Finally, the research of this proposal will be integrated into the development of courses and research projects for both graduate and undergraduate students providing them with background on the fundamentals and practices of building web information systems and cloud data services."
"1433228","HCC: Small: Collaborative Research: Mobile Gesture Interaction for Kids: Sensing, Recognition, and Error Recovery","IIS","Cyber-Human Systems","08/15/2013","03/28/2014","Lisa Anthony","FL","University of Florida","Standard Grant","Ephraim P. Glinert","08/31/2015","$197,100.00","","lanthony@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7367","7367, 7923","$0.00","Though many children use mobile applications to support their learning and entertainment, the devices and underlying interactions were not designed specifically for children. The goal of this project is to make touch and gesture interactions more accessible and user-friendly to young users. This research will yield new understanding about the appropriate and successful ways to sense, recognize, and recover from errors in touch-based interactions with children. The approach involves studying children interacting with mobile applications that gather data on their touch and gesture interactions, as well as conducting design sessions with children to elicit their preferences for mobile device interactions and error feedback and recovery strategies. This approach will result in design guidelines for those creating applications and tools for young users. The proposed research contributes towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. <br/><br/>Broader impacts: The broader impacts of this project lie in contributions towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. This work also will develop and validate an approach for investigating such interaction issues and designing improvements for them that can be used in future work with other populations such as older individuals or those with varying physical abilities. The grant will support two female young investigators, and will fund research experiences to benefit computer science students attending Bowie State University, a minority serving institution."
"0747522","CAREER: Automated Support for Novice Authorning of Interactive Drama","IIS","Cyber-Human Systems","04/15/2008","04/18/2011","Michael Mateas","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","03/31/2015","$516,000.00","","michaelm@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","1045, 1187, 7367, 9215, HPCC, 9251","$0.00","The goal of this project is to enable novices (non-programmers and non-expert storytellers) to create interactive dramas (IDs), artificial intelligence (AI) based interactive story experiences with autonomous characters and dynamic plot progression. Accomplishing this goal requires answering the following research question: how can one incorporate storytelling and character creation theories from the theory of dramatic writing, as well as theories of storyboard layout from comics, into an AI model of story generation and character creation that collaborates with a human author to create an ID. Most research work in ID has focused on individual components, such as autonomous character architectures or story managers/generators, not on fully integrated systems with engaging content. This is primarily due to the difficulty of authoring; creating IDs currently requires large, interdisciplinary teams of AI researchers, story authors and domain experts. This project will address the authoring problem by combining novel work in story generation, novel work in visual interfaces for programming, and authoring insights from the only publicly fielded, complete ID (Facade).<br/><br/>Enabling novice authoring of ID will have significant impact: as a new and powerful mode of personal expression, in applications of ID technology to education and training, and for engaging middle school and high-school students in computational expression. Unlike traditional videogames, ID focuses on interpersonal interaction, enabling rich and powerful game-like experiences that focus on meaningful social interaction with autonomous characters within a dynamically generated, changing story. Such technology is essential for serious games (games for education and training) that focus on people-to-people interaction, such as management training, and public service games that tackle complex topics such as racism. Currently, the construction of IDs requires teams of experts, putting them out of reach of individuals and organizations who are not technology and game design experts, but who wish to harness this powerful new medium. The goal of the project is to take the construction of ID out of the hands of experts, and make it available to everyone."
"0964457","RI: Medium: Collaborative Research: Optimizing Policies for Service Organizations in Complex Structured Domains","IIS","ROBUST INTELLIGENCE","07/01/2010","04/25/2012","Roni Khardon","MA","Tufts University","Continuing grant","Todd Leen","06/30/2015","$418,228.00","","roni@cs.tufts.edu","20 Professors Row","Medford","MA","021555807","6176273417","CSE","7495","7495, 7924","$0.00","This project studies an important class of complex structured planning <br/>domains called ``service domains'' using simulators and probabilistic<br/>action models. Examples of service domains include optimizing emergency <br/>response in a typical city, scheduling doctors and nurses in a <br/>hospital, administering tasks in a typical office, optimally delivering <br/>products to shops from distribution centers. These domains <br/>share many characteristics such as relational structure, parallel actions, <br/>multi-time-scale decision making, exogenous events, and the need for <br/>human interpretable solutions that make them highly challenging.<br/>The project develops scalable and principled planning algorithms for <br/>service domains through a variety of techniques including a novel<br/>hierarchical framework of multi-time-scale optimization, new<br/>model-free simulation-based planning algorithms, and model-based <br/>planning via composition of first-order decision diagrams. These <br/>techniques are applied to the real-world problem of optimizing <br/>the fire and emergency response in cities through a collaboration<br/>with the fire department of Corvallis, Oregon. <br/><br/><br/>The results of the project include new algorithms and frameworks to solve <br/>service domains, prototype implementations of the algorithms<br/>in the emeregency response domain, and new testbeds of service domains <br/>for research. The broader impact of the work includes more cost-effective <br/>emergency response systems, and development of new research-oriented courses, <br/>tutorials and special workshops on the next generation decision support <br/>systems for service domains."
"1210863","SoCS: Collaborative Research: Novel Algorithms and Interaction Mechanisms to Enhance Social Production","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","08/01/2012","07/16/2013","Loren Terveen","MN","University of Minnesota-Twin Cities","Standard Grant","Kevin Crowston","07/31/2015","$543,140.00","Susan Walker","terveen@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367, 7953","7367, 7953, 9251","$0.00","Millions of people used social media technologies to organize themselves to produce information and artifacts of value, such as Wikipedia, GNU/Linux, and PatientsLikeMe. However, these communities have significant problems: (1) They work so well to let people maintain existing relationships and find others who are similar to them that they can promote self-segregation and opinion polarization. (2) Knowledge production has been democratized, but at the price of devaluing expert participation. (3) They open people to fresh ideas from far-off places, but few sites incorporate the rich local knowledge of home communities. This project addresses these problems by creating algorithms and user interfaces that nudge individuals and communities into more effective patterns of social connections and interaction. <br/><br/>The intellectual merit includes: (1) Identification of principles people use to build their social networks, the range of potential contacts they consider, and the contexts in which they encounter potential contacts. (2) Empirical knowledge of the effectiveness of different social network structures for solving a range of realistic decision-making tasks. (3) Novel social recommendation algorithms that maximize network effectiveness and that recommend interaction opportunities that serve as contexts for communication and connection.<br/><br/>Broader impacts: This research will be performed in the context of two domains of societal interest, parenting and bicycling, enabling significant broader impacts. Providing people information that gives them confidence to bicycle more increases their personal health, decreases air pollution, and improves community cohesion. Research shows that parents with larger and more diverse social networks make better parenting decisions, and that parents also seek expert advice for specific issues. Therefore, a system that helps people form effective social networks and that provides access to expert educators offers direct benefits to parents. Better parents also tend to be more involved in their communities; thus, improved community health is a bonus effect. Finally, through the research team's connections with parent educators, the project will explicitly target parents from low-income families, who have the greatest needs for support and information."
"1248269","EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","IIS","Cyber-Human Systems","09/01/2012","08/25/2012","Jaideep Srivastava","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","08/31/2014","$123,840.00","","srivasta@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7916","$0.00","This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess. <br/><br/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams. <br/><br/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs."
"1208245","NRI-Small: Expert-Apprentice Collaboration","IIS","ROBUST INTELLIGENCE, INFO INTEGRATION & INFORMATICS, National Robotics Initiative","10/01/2012","09/19/2012","Carlo Tomasi","NC","Duke University","Standard Grant","Sylvia J. Spengler","09/30/2015","$746,924.00","Ronald Parr","tomasi@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495, 7364, 8013","7923, 8086","$0.00","Recent advances in robot platforms have outpaced our ability to effectively program robots to accomplish useful tasks, often in complex environments that they share with humans. In order for flexible, general purpose robots to become widespread e.g., in teaching skills to children, assisting the elderly, there must be a way of interacting with them beyond programming. Teaching by demonstration offers a potentially powerful and practical approach to realizing the promise of large scale personal robotics in a wide range of applications. In teaching by demonstration, the expert (human), demonstrates the task on different hardware than what the apprentice or student (robot) uses. <br/><br/>The project aims to develop visual feature-based methods that allow robots to teach humans and learn from them by unifying apprenticeship learning, learning by demonstration (or by imitation) and teaching humans, taking into account the differences between experts and apprentices. The resulting system will be evaluated on a PR2 robot (mostly on grasping and manipulation tasks). The scientific advances resulting from the project in learning from demonstration and imitation learning, both general techniques with broad applicability, will greatly simplify the programming of robots which would make it easier for non-expert users to perform this important task which currently requires considerable expertise in robotics as well as computer science. <br/><br/>Broader impacts of the research include development of new robotics curricula, enhanced opportunities for research-based interdisciplinary training at the intersection of computer vision, machine learning, and robotics, outreach activities (including participation in a public school robotics instruction program). All of the results of the research, including publications, open-source software and datasets, will be made freely available to the larger scientific and academic community."
"1416888","WORKSHOP: IEEE VR 2014 Doctoral Consortium","IIS","Cyber-Human Systems","12/15/2013","12/19/2013","Daniel Keefe","MN","University of Minnesota-Twin Cities","Standard Grant","Ephraim P. Glinert","11/30/2014","$15,609.00","Victoria Interrante","keefe@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7367, 7556","$0.00","This is funding to support participation by approximately 12 graduate students (9 domestic and 3 international), along with 5 senior members of the community (faculty and industry researchers), in a Doctoral Consortium (workshop) to be held in conjunction with IEEE Virtual Reality 2014 conference that will take place March 29-April 2 in Minneapolis, and which is collocated with the IEEE Symposium on 3D User Interface. Virtual reality (VR) is a multidisciplinary field involving human-centered computer simulations that seek to imitate or augment real world senses (usually sight, sound, and touch) and experiences. VR research includes developing and assessing methods and systems, and facilitating and understanding user perceptions, beliefs, and behaviors. First organized by the IEEE Computer Society in 1993 and held annually since 1995, IEEE Virtual Reality is the premier international conference and exhibition in this field and includes technical paper presentations, workshops, tutorials, research demonstrations, and exhibits from industry. The IEEE Symposium on 3D User Interfaces has been held annually and colocated with IEEE VR since 2006. Based on prior year numbers, the combined 2014 conferences are expected to attract 350-400 registrants, 15-20 exhibitors, and 30 student volunteers. More information may be found online at http://www.ieeevr.org/2014.<br/><br/>This year's IEEE VR Doctoral Consortium is inspired by and similar in format to last year's successful inaugural event, which was also supported by NSF. The main activities of the DC will take place on Sunday, March 30, immediately prior to the start of the IEEE VR conference proper and in parallel with the second day of the IEEE Symposium on 3D User Interfaces; additional smaller activities will take place at scattered times over the rest of the week. The workshop will include morning and afternoon sessions in which each student presents his/her work to the other student participants and a panel of senior VR researchers, with sufficient time set aside after each talk for discussion and constructive feedback that addresses the strengths of the work, challenges and issues that may arise, and implications of the results. A group working lunch attended by all the students and mentors will be particularly valuable for unifying the individual goals and projects presented within the group as part of a ""big picture"" envisioning of the future of the field over the next 10-20 years. Each student will also be asked to prepare a poster on his/her research that will be on display during the conference as part of the poster sessions, and to submit a short (2-page) abstract to be archived in the IEEE Digital Library.<br/><br/>Broader Impacts: The goal of the Doctoral Consortium is to provide an interactive and supportive mentoring opportunity for mid-level graduate students in virtual reality, to afford these students a valuable opportunity to get independent perspectives on their research from senior individuals with a wide collective breadth and depth of knowledge, and to build a cohort of young researchers within the VR community. The organizers will make a special effort to recruit participants from groups traditionally underrepresented in computer science, including women, persons of color, and persons with disabilities. They will take steps to achieve diversity among the students with respect to research topics, disciplinary backgrounds, methodological approaches, and home institutions (for example, no more than one graduate student will be accepted from any given institution)."
"1317788","NRI: Small: Collaborative Research: Active Sensing for Robotic Cameramen","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/15/2013","09/12/2013","Ibrahim Isler","MN","University of Minnesota-Twin Cities","Standard Grant","Jie Yang","08/31/2015","$292,000.00","","isler@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495, 8013","7923, 8086","$0.00","With advances in camera technologies, and as cloud storage, network bandwidth and protocols become available, visual media are becoming ubiquitous. Video recording became de facto universal means of instruction for a wide range of applications such as physical exercise, technology, assembly, or cooking. This project addresses the scientific and technological challenges of video shooting in terms of coverage and optimal views planning while leaving high level aspects including creativity to the video editing and post-production stages. <br/><br/>Camera placement and novel view selection challenges are modeled as optimization problems that minimize the uncertainty in the location of actors and objects, maximize coverage and effective appearance resolution, and optimize object detection for the sake of semantic annotation of the scene. New probabilistic models capture long range correlations when the trajectories of actors are only partially observable. Quality of potential novel views is modeled in terms of resolution that is optimized by maximizing the coverage of a 3D orientation histogram while an active view selection process for object detection minimizes a dynamic programming objective function capturing the loss due to classification error as well as the resources spent for each view.<br/><br/>The project advances active sensing and perception and provides the technology for further automation on video capturing. Such technology has broader impact on the production of education videos for online courses as well as in telepresence applications. Research results are integrated into robotics and digital media programs addressing K-12 students."
"1218826","HCC: Small: Tools and Mechanisms to Support Civic GeoCampaigns","IIS","Cyber-Human Systems","10/01/2012","09/27/2013","Loren Terveen","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","09/30/2015","$515,399.00","Mark Snyder","terveen@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7367, 7923, 9251","$0.00","This project will create software infrastructure and sociotechnical mechanisms that let agencies engage the efforts of citizens in order to gather data and even take on small tasks in their local communities. Realizing this aim requires filling significant technological gaps: (1) no robust software infrastructure that enables a broad range of community activities, (2) no general set of incentive mechanisms that organizers can use to attract and motivate citizen participation, and (3) no software tools for organizers to monitor effectiveness and make necessary adjustments.<br/><br/>This project takes on these challenges through research on four central topics. First, it will create a general ontology of tasks, coordination mechanisms, incentives, and user interfaces for organizers to define goals. Second, it will develop algorithms to match participants and tasks, and user interfaces for participants to find tasks of interest. The third topic is automated mechanisms and visualization tools for organizers to monitor progress and adjust parameters such as incentives or participation qualifications. Fourth, it will create interfaces for participants to visualize their contributions and view incentives they have earned or are eligible to earn, based on techniques to model users based on their participation. The technical results will be embodied in a software infrastructure which will be deployed and used as a platform for empirical evaluation of the developed algorithms and interaction techniques. <br/><br/>The key scientific outcomes of this project will be a general and integrated software infrastructure for social participation efforts, a diverse catalog of incentive mechanisms and guidelines for use, a novel set of task matching and participant recruiting techniques, automated and semi-automated techniques to monitor and dynamically adjust progress, and empirical knowledge of how these novel algorithms and interaction techniques work in practice. <br/><br/>The infrastructure developed through this research has great potential for enabling local government agencies to gather much more, accurate, and timely data to inform their decisions. It also can help citizens to become involved with their communities, finding constructive tasks to take on that require differing amounts of skill and time commitments. An even broader potential impact is that the products of this research can help renew the relationship between local governments and citizens, making government more responsive to citizens and giving citizens greater faith in their governments."
"1111638","RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","IIS","CI REUSE, ROBUST INTELLIGENCE","09/01/2011","09/14/2011","Ibrahim Isler","MN","University of Minnesota-Twin Cities","Standard Grant","Satyandra Gupta","08/31/2015","$1,495,428.00","Stergios Roumeliotis, Peter Sorensen","isler@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","6892, 7495","7925","$0.00","This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br/><br/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering."
"1236970","EAGER: Collaborative Research: Computational Public Drug Surveillance","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","03/25/2014","Ahmed Abbasi","VA","University of Virginia Main Campus","Standard Grant","Sylvia J. Spengler","08/31/2014","$65,417.00","","abbasi@comm.virginia.edu","P.O. BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","CSE","7364","7364, 7916, 8018, 9251","$0.00","Adverse drug reactions (ADR) (undesired or excessive responses drugs) have been linked with significant morbidity and mortality, and account for as much as 5% of all admissions. A drug-drug interaction (DDI) is a type of ADR involving two or more drugs. Reports suggest that 50% percent of the drugs withdrawn in the U.S. by the Food and Drug Administration (FDA) from 1999 to 2003 were linked with significant DDIs. The ADR profile of a given drug is rarely complete at the time the drug is approved by FDA. Hence, after a drug has been in use by the general population (with significant diversity in race, gender, age, lifestyle), often previously unidentified DDIs are discovered. To complicate matters, certain populations of patients, e.g., psychiatric patients, are often concurrently treated with multiple medications. The potential interactions between multiple drugs are neither well understood nor completely characterized. Voluntary reporting, the basic mechanism used by the FDA to monitor new drugs, suffers from underreporting, delayed reporting, uneven quality of reports, and even lack of reports of rare DDIs.<br/><br/>Against this background, this collaborative project aims to explore the feasibility of a novel computational approach to the problem of drug-drug interaction surveillance. It seeks to develop new methods for predicting molecular level interactions between drugs from data gleaned from online sources and digital social media. The project aims to test the hypothesis that such online data, in combination with with data from traditional drug related databases can be used to reliably predict potential DDIs much sooner than possible using current methods. The effectiveness of the approach is assessed through verification of predictions against future reports. <br/><br/>If successful, the project could lead to effective, proactive computational approaches to drug interaction surveillance, with benefits to federal, local and public health agencies, drug companies, clinical practitioners, the patients, and the public at large. Early detection of adverse DDIs could lead to improved patient care, and significant reduction in healthcare costs and lawsuits involving DDIs. The project offers enhanced opportunities for collaboration among investigators with expertise in computational and health sciences. It also offers research-based training opportunities to students at West Virgina University and the University of Virginia. Results of the research will be freely disseminated to the broader academic and research community."
"1218168","III: Small: Towards Spatial Database Management Systems for Flash Memory Storage","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","06/27/2013","Mohamed Mokbel","MN","University of Minnesota-Twin Cities","Continuing grant","Sylvia J. Spengler","08/31/2015","$500,000.00","Shashi Shekhar","mokbel@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","7923","$0.00","The goal of this research project is to design and develop highly efficient spatial and spatio-temporal database systems on flash memory storage. More specifically, this project conducts research, develops requisite scientific knowledge, builds software infrastructure, and integrates teaching activities with research for four specific aims: (1) Supporting efficient spatial indexing on flash memory, which includes data- and space-partitioning index structures, (2) Supporting efficient spatial query processing and optimization, which includes supporting various forms of the spatial join operation and query cost estimation, (3) Supporting spatio-temporal indexing and querying, which includes extending the spatial index data structures and the query processor to support the high update frequency common in spatio-temporal applications, and (4) Exploiting a storage hierarchy of flash and magnetic disks where spatial and spatio-temporal indexing, query processing, and optimization can exploit the full potential of both storage media. Besides its impact on industry, this project will have significant broader impact across multiple segments of society that include enhancing productivity, graduate and undergraduate student education, curriculum development, and tutorial presentations. Publications, technical reports, open-source software, and experimental data from this research are disseminated via the project web site (http://www.cs.umn.edu/~mokbel/flash)."
"1319585","III: Small: Wavelet-Based Representations for Hyperspectral Data Processing and Interpretation","IIS","INFO INTEGRATION & INFORMATICS","10/01/2013","03/25/2014","Marco Duarte","MA","University of Massachusetts Amherst","Standard Grant","Sylvia J. Spengler","09/30/2016","$508,651.00","Mario Parente","mduarte@ecs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","7923, 9102, 9251, 7364","$0.00","Hyperspectral imaging systems play an important role in scientific research, especially in planetary and terrestrial geology, environmental monitoring, military and security surveillance, and mineralogy. With current advances in imaging systems technology, large datasets at higher resolutions are being produced and research on automated analysis of these datasets is becoming critical. The goal of this project is to formulate mathematical models for hyperspectral datasets that capture the types of structure commonly identified by practitioners as informative and leveraged semantically in existing ad-hoc methods. The focus is on models based on wavelet representations for spectral signatures in order to provide features that represent the desired multiscale structural information. The features will leverage the wavelet's multiscale time-frequency analysis properties, and will be tested on several labeling, classification, and retrieval problems from a broad range of application areas that are expected to attract underrepresented groups in engineering. This proposal is centered on the application of the proposed models to hyperspectral signal processing and machine learning. The overall goal is to formulate and study new geometric signal models for high-dimensional data and new performance metrics for parameter estimation to be leveraged by new computationally feasible estimation algorithms that (i) are amenable to compressive signal processing due to the use of geometric structure to capture relevant signal information and (ii) overcome the performance shortcomings observed in existing approaches. The formulation of a semantic model for spectral signatures is expected to increase the acceptance of universal representations in applications where processes driven by ad-hoc rules are commonplace. The project broadens participation of underrepresented groups by considering applications areas that have the potential to appeal to diverse communities and constituencies in order to attract interest from a diverse class of populations underrepresented in engineering. Student researchers will be exposed to collaborators from a diverse set of scientific backgrounds and cultures. Opportunities for undergraduate research and high-school teacher research experience will be offered in this project with a particular emphasis on venues serving groups underrepresented in engineering."
"1439555","WORKSHOP: ThinkTank (Doctoral Consortium) at ICAD 2014","IIS","Cyber-Human Systems","04/01/2014","03/25/2014","Stephen Ruthmann","NY","New York University","Standard Grant","Ephraim P. Glinert","03/31/2015","$22,403.00","","sar17@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7367","7367, 7556","$0.00","This is funding to support a ""ThinkTank"" (workshop) of approximately 16 promising scholars from the United States plus up to 4 from abroad, for a total of 20, along with distinguished research faculty, in conjunction with the 2014 International Conference on Auditory Display (ICAD 2014), which will be held June 22-25 at the PI's institution in New York City. ICAD is the premier international forum for presenting research on the use of sound to display data, monitor systems, and provide enhanced user interfaces for computers and virtual reality systems. It is unique in its singular focus on auditory displays and the array of perception, technology, and application areas that this encompasses; this includes, for example, data sonification, auditory wayfinding, auditory graphs, speech interfaces, virtual environments, and associated perceptual, cognitive, technical, and technological research and development. Many of the interdisciplinary research and development efforts are of direct relevance to persons with perceptual disabilities, especially visual impairments; for example, developing wayfinding systems for the blind requires research into effective distance cues and object identifiers used in auditory displays. Research into the efficacy of auditory graphs may be used to help visually impaired students and scientists participate more fully in science. Even household devices can have more effective auditory displays that provide richer information than the basic ""beeps"" they presently tend to have. A common approach in this field is universal design, wherein a display strategy is developed once, to be used by all kinds of users, including those with and without specific access issues. This year's conference theme is Big Data; more details about the conference are available online at http://steinhardt.nyu.edu/icad2014/. <br/><br/>The ICAD ThinkTank, a full-day event which will take place on Saturday, June 21 immediately preceding the conference, is open to graduate students at all stages of their educational program, including both Masters and PhD students. Exceptional undergraduates who have demonstrated interest in pursuing this field in their graduate careers may also be considered. Ten U.S.-based scholars will have their attendance fully supported by this award, while 6 more scholars local to the greater New York City area will be partially supported. The ThinkTank will bring together students from diverse backgrounds (e.g., engineering, computing, music, and psychology), so that they can experience the broad spectrum of approaches to auditory displays, assistive technologies and universal design. The ThinkTank will develop a supportive community of scholars and a spirit of collaborative research, by providing participants with a friendly and open, yet rigorous, scientific forum in which to present their research ideas, to listen to ongoing work from peer students, and to receive constructive feedback from a panel of distinguished experts. Panel feedback is designed to help students understand and articulate how their work is positioned relative to related research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. The ThinkTank will also offer invited speakers and discussion groups (e.g., to provide students with relevant information about important issues for doctoral candidates, whether they are considering academic or industrial career paths). Each student participant will furthermore present his/her work in a special poster session during the conference proper. An evaluation of the ThinkTank will be conducted, and the findings made available to the organizers of future conferences and consortia. <br/><br/>Broader Impacts: The ICAD ThinkTank will promote scholarship and networking among new researchers in an important emerging interdisciplinary area, and will help shape ongoing and future research projects that have clear and important implications for development of assistive technologies and universal access. The doctoral consortium will afford participants exposure to a larger community, allowing them to bond among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality and culture, scientific discipline, and institution (no more than two per university, and usually just one), the students' horizons are broadened to the future benefit of the field."
"1433104","WORKSHOP: Doctoral Symposium at the 2014 Recommender System Conference","IIS","Cyber-Human Systems","09/01/2014","03/25/2014","Yi Zhang","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","08/31/2015","$13,240.00","","yiz@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","7367, 7556","$0.00","Eight graduate students will be supported to participate actively in the Graduate Symposium at the 2014 Recommender Systems conference of the Association for Computing Machinery in Silicon Valley, RecSys-2014. This doctoral symposium is structured to provide a non-threatening environment for students, in particular for those who may be attending a major international meeting for the first time. To do so, the organizers will depart from the usual conference structure and give students exposure to their research community by presenting their own work and receiving feedback from peers and experienced researcher, by two invited talks about career and life in academia versus industry, and by observing and interacting with other professionals in the field during the conference.<br/><br/>Students selected for funding will receive registration, shared hotel accommodation, and need-based airfare support to attend the conference. A carefully-developed evaluation system has been set up to allocate the funds most effectively. Among the priorities are supporting students from different institutions, students who have prepared the most substantial papers to present, students from under-represented groups, and students with financial need. In this area, students require multidisciplinary training. The conference plans a strong program of papers by scientists from both academia and industry researchers around the world, internationally known invited speakers, and a variety of demos and other academia and industry activities.<br/><br/>The ACM RecSys conference and the Doctoral Symposium will advance the state of art in recommender systems by proving an open and friendly environment for both junior and senior researchers to explore creative, original, or potentially transformative concepts in the area. Recommender systems exploit past user behaviors and user similarities to generate information items that are personally tailored to an end-user's preferences. They have quickly become among the most useful tools available for accessing information available on the document web, social web sites, ecommerce systems, mobile systems, entertainment systems and more. In the future, they are likely to revolutionize other domains such as education and health care. As RecSys brings together the main international research groups working on recommender systems, along with many of the world?s leading companies, it has become the most important annual conference for the presentation and discussion of recommender system research, and thus a crucial step in a student's career."
"1049398","WORKSHOP: Social-Computational Systems (SoCS) PI Meeting","IIS","Cyber-Human Systems","09/01/2010","12/11/2013","John Riedl","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","08/31/2014","$44,697.00","","riedl@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7556","$0.00","Systems in which people and computers work together in a socially intelligent manner represent a new form of computing that brings together the challenges of traditional computing (e.g., algorithms, information representation, information acquisition, data quality) with those of human interaction (e.g., cognition, social interaction, culture, learning) and indeed a whole host of new challenges related to the combination of humans and computers (e.g., computer reasoning about human knowledge and abilities, socially-intelligent human-computer interaction, social computing). <br/><br/>This award supports meeting of SoCS Principle Investigators (PIs) (June 9-11, 2011) and will facilitate much needed interaction among researchers using the wide range of topics, methods and techniques. This PI meeting is designed to build on and leverage two other SoCS related workshops that will be temporally and physically co-located. PIs with active SoCS awards will be invited to participate in the meeting through a poster session where on-going SoCS research will be presented. The meeting also includes panels and discussions where best practices can be discussed. Many of the biggest challenges in successfully deploying computer systems in organizations come down to the difficulty of adapting technology to human organizations and vice versa.<br/><br/>The development of the SoCS field will directly create new knowledge and understanding in how to more successfully manage the relationship between social (human) organizations and the computer tools they use to work together more effectively."
"1017697","HCC: Small: Net Fishing: Pulling Valuable Tweets, Feeds, and Blogs from the Online Message Stream","IIS","Cyber-Human Systems","09/15/2010","12/04/2013","John Riedl","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","08/31/2014","$499,999.00","","riedl@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7367, 7923, 9150","$0.00","In the past two years we have observed an explosion in the use of online message streams. With an abundance of information comes information overload and a scarcity of attention: Active message stream users now face thousands of unread messages every day in their personal streams. To date, we are aware of little academic research dedicated to this stream consumption problem, despite the enormous interest among users and businesses.<br/><br/>This research will establish scientific foundations for our understanding of the consumption of message streams, and engineer, deploy, and evaluate new tools for users built on those foundations. This research has two principle aims. First, construct computational models that characterize the individual preferences of stream readers and predict for each reader the value provided by specific messages, and, in aggregate, specific stream contributors. The second aim is to design novel, personalized and intelligent user interfaces that facilitate better digestion and management of online message streams, and evaluate those designs in large-scale field studies on the popular platforms Twitter, Facebook and Google Reader. The proposed research is among the first to examine online message streams broadly and to characterize message streams from the perspective of consumption. Our modeling will give insights into the nature of online message stream consumption and provide a theoretical framework for further investigation.<br/><br/>Hundreds of millions of users worldwide are ?voting with their fingers? to spend time creating, commenting on, communing over, and consuming tweets, wall posts, status updates, and blog posts. The research proposed here promises to deepen our understanding of the purpose, value, and social mechanisms underlying message streams, and to create new computational resources for modeling the contributors, their contributions, and the process of consumption. Based on these computational models, innovative visualizations, recommendations, and interfaces will be developed to reshape the user experience, and inform the design of future message stream services."
"1355072","EAGER: Building and analyzing dynamic brain functional networks","IIS","INFO INTEGRATION & INFORMATICS","10/01/2013","03/24/2014","Vipin Kumar","MN","University of Minnesota-Twin Cities","Standard Grant","Sylvia J. Spengler","09/30/2014","$116,000.00","Michael Steinbach, James Faghmous","kumar@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","7364, 7916, 9251, 7327","$0.00","Funtional Magnetic Resonance Imaging (fMRI) offers a rich source of data for understanding brain structure and function. There is an urgent need for computational approaches to eliciting brain structure-function relationships from such data. While current approaches that rely on network representations of fMRI data offer useful insights into brain connectivity, they have significant limitations in terms of discovering and validating complex functional mechanisms that underly brain function: the very notion of a node in the functional network is difficult to define, inter- and intra- subject variability leads to network representations that vary a great deal within and among subjects; and static representations of correlations between activities of different brain regions offer only a partial picture of brain activity which is inherently dynamic. <br/><br/>This exploratory research project aims to introduce dynamic network analysis techniques to discover functional brain regions and study their evolution over time and across subjects. It leverages the research team's experience in the analysis of continuous and highly variable spatio-temporal climate data to address several of the outstanding challenges in analyzing brain networks built from fMRI data. A key goal of this exploratory study is to explore the feasibility of analyzing network representations of fMRI data to answer questions such as the following: Do nodes changes dynamically with time during an fMRI scan? What community detection techniques work best for dynamic networks? What patterns arise in dynamic brain networks? What is the statistical validity of the observed patterns?<br/><br/>Broader Impact: If successful, the project could establish the feasibility of research directions that could eventually lead to computational tools that enable better characterization of normal and abnormal brain function; better understanding of the variation of brain function within and across individuals over time, including patterns that characterize the brain activities of different populations e.g., adolescents, those suffering from specific brain disorders, etc. The project offers enhanced opportunities for interdisciplinary collaborations between neuroscientists and computer scientists, and research-based advanced training of graduate and postdoctoral students at the University of Minnesota. Free dissemination of open source implementations of the algorithms resulting from the project to the larger research community contribute to its broader impact."
"0952977","CAREER: Extensible Personalization of Spatial and Spatio-temporal Database Management Systems","IIS","INFO INTEGRATION & INFORMATICS","03/15/2010","02/19/2014","Mohamed Mokbel","MN","University of Minnesota-Twin Cities","Continuing grant","Maria Zemankova","02/28/2015","$530,000.00","","mokbel@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7364","1045, 1187, 7364, 9215, ","$0.00","The goal of this research project is to allow database users to enjoy high quality personalized answers for their spatial and spatio-temporal queries, without sacrificing the query execution efficiency. As the concept of personalization is subjective, there are plethora of approaches that define the meaning and contents of a high quality personalized answer. This project does not aim to provide more definitions of personalization, instead, it provides a system-oriented approach that can accommodate most of the existing and future definitions in one highly efficient database engine. <br/><br/>To achieve its goal, this project employs an extensible approach where core database modules for personalized queries are realized only once inside the database engine, and used many times in different ways to support a wide variety of personalized queries. The project provides such extensible core modules for:<br/>(a) single-table operations, e.g., selection and aggregations,<br/>(b) multi-table operations, e.g., join, <br/>(c) operations with adaptive cost that can only be computed online, and <br/>(d) handling uncertain data. <br/>With these extensible modules, registering a new personalization definition becomes as easy as plugging few modules in an easy-to-use interface. Once plugged in, the new personalized definition lives in the database engine, and enjoys the power of the extensible modules for query processor, optimizer, and indexing. <br/><br/>Such extensible approach is highly attractive to industry as it gives minimal changes in the database engine to support wide variety of personalized queries, as well as orders of magnitude performance over existing approaches that are built on top of database systems. Besides its impact on industry, this project will have significant broader impact across multiple segments of society that include enhancing productivity, graduate and undergraduate student education, outreach to K-12 students, curriculum development, and tutorial presentations. Publications, technical reports, open-source software, and experimental data from this research are disseminated via the project web site (http://www.cs.umn.edu/~mokbel/career)."
"0917676","CAREER: Mobility Control for Robotic Sensor Networks","IIS","ROBUST INTELLIGENCE","08/15/2008","04/11/2012","Ibrahim Isler","MN","University of Minnesota-Twin Cities","Continuing grant","Satyandra Gupta","08/31/2015","$445,964.00","","isler@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","0000, 1045, 7495, 9215, 9251, HPCC, OTHR","$0.00","This project focuses on the development of mobility strategies for<br/>Robotic Sensor Networks (RSNs) which are networks of robots equipped<br/>with communication, computation and sensing capabilities. For RSN<br/>technology to be utilized in critical applications such as emergency<br/>response and environmental monitoring, mobility algorithms for<br/>operation in dynamic and complex environments are needed.<br/><br/>In this project, three novel mobility problems which arise in many RSN<br/>applications are introduced. These problems are general enough to<br/>capture the interplay between communication, sensing and<br/>mobility. Yet, they can be succinctly formulated as geometric<br/>optimization problems. This work will focus on solving these mobility<br/>problems which will yield provably correct solutions for numerous RSN<br/>applications. In addition, bounds on the performance of a given RSN in<br/>fundamental problems such as tracking, collaborative sensing and<br/>estimation will be established.<br/><br/>The output of this research will be a significant step toward enabling<br/>the use of fully autonomous RSNs for crucial applications in emergency<br/>response, energy and environmental monitoring, and health care<br/>automation. Sensing and actuation play important roles in the<br/>evolution of information technology. The project will contribute to<br/>this evolution through the development of novel distributed sensing<br/>and control algorithms."
"0964695","HCC: Medium: Collaborative Research: Guiding Folksonomy Development to Enable Novel Tagging Applications","IIS","Cyber-Human Systems","04/15/2010","07/01/2011","Loren Terveen","MN","University of Minnesota-Twin Cities","Standard Grant","William Bainbridge","03/31/2015","$981,788.00","John Riedl","terveen@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7367","7367, 7924, 9215, 9251, HPCC","$0.00","This is a study of tagging, the assignment of labels to information objects by users, and the ""folksonomy"" categorization systems that can result. By the 19th Century, increasing amounts of information were being published, and it was clear that efficient methods of organization were needed for the information to be accessible. In response, categorization schemes like the Library of Congress Classification and the Dewey Decimal System were invented. The overall information dissemination system contained clear roles and divisions of labor: editors decided what got published, information professionals categorized published works, and most people simply consumed the results. The Internet has toppled this traditional approach. There is no publication barrier, so orders of magnitude more information is available online and information professionals cannot keep up. However, new technologies have arisen that work in this context, notably tagging. Any user can associate tags with items such as documents, movies, or photos, and the tags serve as keys for retrieval. Since tags can be created by any user, the number of tags contributed scales with a community's size: thus, tagging works at Internet scale. Tagging lets users represent their own perspectives, which aids retrieval.<br/><br/>However, tagging is a young technology, with significant challenges and unmet potential. Individual tags are often of poor quality, and many tagging systems are globally incoherent. Empirical evaluations of tagging systems in use are few, and formal comparisons to traditional approaches have not been done. Tagging applications have been limited mainly to search. This project addresses these challenges. It will develop a firmer scientific understanding of the strengths and weaknesses of tagging as a categorization method. It will explore the potential of tagging to enable powerful applications beyond information retrieval. The project consists of three main research activities: (1) Creating a set of metrics to quantify the value of a categorization structure; using these metrics in formal and empirical comparisons of tagging systems to traditional categorizations; (2) Designing mixed-initiative interaction techniques for computational agents and people to detect, evaluate and resolve problems in tagging systems; (3) Developing novel tag-based applications for users to express their preferences and navigate complex information spaces.<br/><br/>This research will create both information-theoretic and usage-based metrics to measure the value of a categorization structure. Studies will be done to show relations between the two types of metric, letting designers predict, for example, how many tags per item are required for effective user search. Systematic cost-benefit comparisons of tagging systems to traditional expert categorizations will be done, thus providing empirical data to a debate that has been characterized by heated conjecture. The utility and generality of a set of mixed-initiative interaction techniques and novel applications will be established by (a) implementing them in multiple platforms, and (b) evaluating them in careful field experiments.<br/><br/>Improving the effectiveness of tagging will help millions of users find the information, products, and services they seek. More directly, the techniques of this project will be implemented in four working online communities, for movie viewers, cyclists, ethics researchers, and politically interested citizens. Collectively these sites have tens of thousands of users, all of whom will benefit directly. Many students will be trained, learning multiple research methods and gaining valuable experience with real online communities. Finally, the software will be developed under an open source license and datasets will be published, thus facilitating other researchers and web site developers in their work."
"0916750","RI: Small: Statistical Modeling of Dynamic Covariance Matrices","IIS","ROBUST INTELLIGENCE","09/01/2009","08/21/2009","Arindam Banerjee","MN","University of Minnesota-Twin Cities","Standard Grant","Todd Leen","08/31/2014","$455,000.00","Daniel Boley","banerjee@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7923, 9215, HPCC","$0.00","Suitable models for dynamic covariance matrices can be extremely useful in several application domains, such as in text mining and topic modeling, where one can study the evolving correlation between topics; in financial data ranging from stock/bond returns to interest rates and currencies, where the paramount importance of tracking evolving covariances has been widely acknowledged; in environmental informatics to study trends in dynamic covariance among disparate variables from the atmosphere as well as the biosphere. In such domains, it is not sufficient to simply compute the sample covariance at each time step; the goal is to discover any trends there may be in the evolution of the covariance structure.<br/><br/>This project introduces and investigates a novel family of Dynamic Wishart Models (DWMs), which has the same graphical model structure as the Kalman filter, but tracks evolution of covariance matrices rather than state vectors. Similar to the use of multivariate Gaussians in Kalman filters, the models use the Wishart and inverse Wishart family of distributions on covariance matrices. Unlike Kalman filters, an analytic closed form filtering may not be possible in DWMs, but the models still have enough structure to allow efficient approximate inference algorithms. The project focuses on approximate inference for filtering, smoothing, and related problems in the context of DWMs; develop suitable numerically stable recursive updates in order to prevent numerical loss in positive definiteness; and investigate generalizations of DWMs including mixture models for tracking complex covariance dynamics. <br/><br/>The development of effective tracking algorithms for covariances will permit the modeling of dynamic systems where the states really represent the varying relationships between multiple entities. The key contribution of the research is in leveraging the existing literature of dynamic latent state vectors to create equally powerful methods for dynamic latent covariance matrices. Such a transformation will have direct impact on applications in text analysis and topic modeling, financial data analysis, social network analysis, environmental informatics, and several other domains, and will spawn new opportunities for bringing together researchers and students across these disciplines, thereby broadening participation in computer sciences."
"0953274","CAREER: Combinatorial Online Learning and its Applications","IIS","ROBUST INTELLIGENCE","04/01/2010","04/30/2013","Arindam Banerjee","MN","University of Minnesota-Twin Cities","Continuing grant","Todd Leen","03/31/2015","$495,804.00","","banerjee@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","1045","$0.00","Several important problems in machine learning, such as maximum<br/>aposteriori (MAP) inference in graphical models, are inherently combinatorial. While extensive research has been devoted to designing approximation algorithms for such problems, existing algorithms do not scale well to large problems. This project focuses on leveraging ideas from online learning with expert advice to develop a novel family of online learning algorithms for combinatorial optimization problems. <br/><br/>Algorithms for combinatorial online learning are efficient and simple to analyze in order to establish guarantees. Unlike existing literature on approximation algorithms for combinatorial problems which rely on suitable real relaxations of the original problem, combinatorial online learning algorithms never use relaxations; they work directly with binary/integer solutions and have global approximation guarantees. The project investigates generalizations of the framework to solve online and batch binary quadratic programming problems, yielding approximation algorithms for a variety of combinatorial problems, including NP-complete problems, and MAP inference in directed and undirected graphical models. The project considers three important real life applications: portfolio selection for effectively investing in the stock market, automating surgical pathology by expediting disease detection in tissue images, and climate change detection for discovering abrupt climate changes from spatiotemporal climate data. <br/><br/>The project is expected to be transformative, especially in the context of surgical pathology and climate change detection, yielding significant long term societal benefits. The research results will be disseminated to the community through research papers, tutorials, open source software, and outreach activities using games based on mock stock markets."
"1437503","Supporting US-Based Students to Attend the 2014 IEEE International Conference on Data Mining (ICDM 2014)","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","04/01/2014","03/24/2014","Wei Wang","CA","University of California-Los Angeles","Standard Grant","Sylvia J. Spengler","03/31/2015","$24,000.00","","weiwang@cs.unc.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","1640, 7364","7364, 7556, 9102, 9179","$0.00","This grant provides international travel support for U.S. based graduate student participants to attend the 2014 International Conference on Data Mining (ICDM 2014), which will be held in Shenzhen, China, on December 14-17, 2014. It is expected to provide scholarships to 16 U.S. based graduate student participants. The award results will be announced at the ICDM 2014 conference website. A strong representation of U.S. researchers at the Conference is useful in maintaining U.S. competitiveness in this important area. The total number of ICDM participants in the past has been in excess of 500, with a majority of the participants from the U.S., then Europe and Asia. This grant will partially support the travel costs for the U.S. based graduate student participants. Participation in international meetings is a key to effective scientific career development for graduate students."
"1439420","III: Student Travel Fellowships for KDD 2014","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","04/01/2014","03/24/2014","Tanya Berger-Wolf","IL","University of Illinois at Chicago","Standard Grant","Sylvia J. Spengler","03/31/2015","$20,000.00","","tanyabw@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","1640, 7364","7364, 7556, 9102, 9179","$0.00","This grant provides international and domestic travel support for U.S. based graduate student participants to attend the 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2014), which will be held in New York NY, from August 24-27, 2014. KDD is the world's premier research conference in data mining. It is an interdisciplinary conference that brings together researchers and practitioners from all aspects of data mining, knowledge discovery, and large-scale data analytics. This year, the conference has a special theme, Data Mining for Social Good, which will highlight how the work of data analytics researchers and practitioners in contributing towards social good as well as how these high impact, social problems provide a rich set of challenges for KDD researchers. Conference proceedings are published by ACM. Besides the technical program, the conference features workshops, tutorials, panels, demonstrations, exhibits, and a data mining contest (KDD Cup). In 2013 the conference also included a Broadening Participation in Data Mining workshop. A strong representation of U.S. researchers, particularly students, at the conference is useful in maintaining U.S. competitiveness in this important area and also contributes to the career development of the students. This grant will partially support the travel costs for up to 20 U.S. based graduate student participants to attend the KDD conference. The award will be advertised and the results will be announced at the KDD 2014 conference website."
"0964468","HCC: Medium: Synthesis and Perception of Speaker Identity","IIS","Cyber-Human Systems, ROBUST INTELLIGENCE","05/15/2010","05/11/2010","Alexander Kain","OR","Oregon Health and Science University","Standard Grant","William Bainbridge","04/30/2015","$914,849.00","Esther Klabbers, Jan van Santen","kaina@ohsu.edu","3181 S W Sam Jackson Park Rd","Portland","OR","972393098","5034947784","CSE","7367, 7495","7924, 9215, HPCC","$0.00","This proposal addresses the problem of synthesizing speaker identity when only a small training sample is available. To achieve the goal of synthesis of speaker identity from a small training corpus the project will address problems including trainable abstract parameterizations of the prosodic patterns that characterize a speaker and voice conversion methods. The project falls into the general category of building Text-to-Speech (TTS) synthesis system in order to generate speech that sounds like that of a specific individual (Speaker Identity Synthesis, or SIS). Systems of this kind have numerous applications, including the creation of personalized voices for individuals with neurodegenerative disorders who anticipate becoming users of Speech Generating Devices (Sods) in the future and many other applications in the consumer products and entertainment industry. Consumer products such as navigation systems and mobile phones are rapidly being developed that make use of linguistic information about generated utterance. The project will also provide new tools and data for human perception of speaker identity. The tools developed in the process and the associated perceptual studies are also relevant for assessment of speaker recognition systems, and the project provides a new generation of concise, trainable characterizations of a speaker?s prosodic patterns that can be incorporated in these systems. The proposed study will elucidate the trade-offs and algorithm issues of the proposed SIS systems and it is likely that the proposed work will have a strong intellectual impact in the field of speech synthesis."
"1115188","III: Small: Query Compilation on Probabilistic Databases","IIS","INFO INTEGRATION & INFORMATICS","08/01/2011","08/05/2011","Dan Suciu","WA","University of Washington","Standard Grant","Frank Olken","07/31/2015","$500,000.00","","suciu@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7364","7923","$0.00","The goal of probabilistic databases is to manage large databases where the data is uncertain. Applications include Web-scale information extraction, RFID systems, scientific data management, biomedical data integration, business intelligence, data cleaning, approximate schema mappings, and data deduplication. Despite the huge demand and the intense recent research on probabilistic databases, no robust probabilistic database systems exist to date. The reason is that the probabilistic inference problem is, in general, intractable. Fortunately, in databases there are two distinct inputs to the probabilistic inference problem: the query and the database instance. This has led recently to the discovery of safe queries, which are queries that can be evaluated efficiently on any input database, and to new probabilistic inference algorithms that exploit the structure of the query. However, unsafe queries remain a major challenge in probabilistic databases.<br/><br/>This project studies novel algorithms for evaluating unsafe queries on probabilistic database, with guaranteed performance. It uses a novel approach, query compilation, which translates the query into one of four targets: OBDDs, FBDDs, d-DNNFs, and circuits using inclusion/exclusion nodes. The project pursues two thrusts: (1) It develops instance-dependent compilation techniques that significantly extend the reach of instance-independent techniques used in safe queries. (2) It develops approximate query compilation techniques , which always run efficiently, even on intractable query, instance pairs, by sacrificing accuracy. These algorithms are conservative, in the sense that they return correct probabilities in all cases when the input query, instance pair is tractable.<br/><br/>The Intellectual Merit of this project consists of new techniques for compiling queries into one of four compilation targets, OBDD, FBDD, d-DNNF, and inclusion/exclusion-based inference, using both exact inference (without performance guarantees), and approximate inference (with performance guarantees). It expands our understanding of probabilistic inference, and leads to practical approaches for probabilistic database engines. As Broader Impact, the project benefits a large class of applications that require general purpose management of uncertain data, ranging from large-scale information extraction systems, to scientific data management, to business intelligence. The project gradually incorporates topics from probabilistic data into into a curriculum for graduate level education; query compilation is already discussed in the PI's book on Probabilistic Databases ( http://dx.doi.org/10.2200/S00362ED1V01Y201105DTM016), a graduate-level textbook.<br/><br/>For further information see the project web site at the URL: http://www.cs.washington.edu/homes/suciu/project-querycompilation.html"
"1116378","HCC: Small: Modeling the Validity and Transfer of Eye-Scanning Patterns for Hazard Perception from Virtual Reality Training Environments to Reality","IIS","Cyber-Human Systems","08/01/2011","08/08/2011","Laura Stanley","MT","Montana State University","Standard Grant","William Bainbridge","07/31/2015","$499,610.00","Erwin Boer, Nicholas Ward","laura.stanley@ie.montana.edu","309 MONTANA HALL","BOZEMAN","MT","597172470","4069942381","CSE","7367","7923, 7367, 9150","$0.00","Visual search skills for hazard perception are critical in many domains. They are used by pilots to maintain situation awareness, by doctors reviewing screen images to diagnose health disorders, and by security screeners inspecting for hazardous materials. They are also critical to a novice driver's ability to detect roadway hazards. For novice drivers, poor visual search skills can increase the risk for traffic fatalities, which are the leading cause of death for teenagers nationwide. <br/><br/>Virtual reality can be used to provide visual search training during driver education. However, the success of these training programs depends on the validity of eye-scanning patterns in the virtual environment and on the simulation parameters employed to elicit those patterns. The overall objective of the research is to assess the validity of search patterns in the virtual world as they apply to the physical realm, and then to identify which simulation parameters are critical for successful simulator-based hazard perception training. <br/><br/>Intellectual merit: The project will integrate theory and data to advance our knowledge of which parameters of virtual reality-based hazard perception training promote the greatest transfer of training to real world driving. Specifically, the project will (a) examine the relationship between visual search in driving simulators vs. that in the real world, using specially equipped vehicles; (b) test which aspects of the driving simulator lead to the best training and transfer of learning; and (c) examine how age and experience influence hazard perception skills. <br/><br/>Broader impacts: The findings from the project will advance scientific understanding of how virtual reality training simulations can be used to improve driver education, thereby leading to better drivers and fewer traffic accidents. The results will also be applicable to other areas in which virtual reality training can be valuable, such as medical diagnosis and security screening. In addition, the project will enable a number of disadvantaged students to take part in engineering and technology research and includes a high school outreach component to engage students in research at an early age."
"0955935","INTEROP: Building Information Sharing Networks to Support Consumer Choice ( I-Choose)","ACI","DATA INTEROPERABILITY NETWORKS, INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","09/01/2010","08/31/2010","Theresa Pardo","NY","SUNY at Albany","Standard Grant","Robert Chadduck","08/31/2014","$710,000.00","Jing Zhang, Holly Jarman, Giri Kumar Tayi","tpardo@ctg.albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","7701, 7364, 7367","7364, 7367, 7701","$0.00","Award: 0955935<br/>PI: Theresa A. Pardo<br/>Title: INTEROP: Building Information Sharing Networks to Support Consumer Choice (I-Choose)<br/><br/>Most products consumed within the North American Free Trade Area (NAFTA) are produced and distributed through low cost supply chains that typically do not reveal certain types of information to end consumers. Without this information it is difficult for consumers to assess the quality of the products they buy or exercise their preferences for safe, environmentally sustainable, and economically just products and services. Producers also have much less of an incentive to provide such goods without an effective, trustworthy way to inform consumers. In order to provide full information about how, when, and by whom manufactured goods were produced, the producers, supply chain operators, and third party certifiers will need to agree on a data architecture that can facilitate exchange and sharing of information that comes from production systems, supply chain distribution systems, and systems used to determine compliance with voluntary and government-mandated product standards. <br/><br/>This project will create I-Choose; a data interoperability framework to support the provision of a wide range of information about how, where, and by whom commodities are manufactured and brought to market. This includes information about ?green? supply chains, production methods, wages paid to producers or workers in the supply chain, working conditions, environmental impact, and a wide range of other information about the products can be delivered to consumers. A data architecture designed to enable interoperability will be generated through a multi-stage iterative process of sequential consensus building activities. These activities will include the stakeholders involved in Mexican coffee production for distribution in Canada and the US, along with researchers from the fields of information science, computer science, economics, and political science. We will explore interoperability with three types of specific information systems: (1) Those designed and maintained by government regulators, (2) Those designed and maintained by consumer advocates using social networking technologies, and (3) proprietary data systems from individual firms in the producer, supply chain, or retail systems. <br/><br/>The I-Choose data interoperability network will be unprecedented in nature as it will involve consumers, producers, government regulatory agencies and supply chain/distribution across multiple domains and countries. It will allow more information into market transactions allowing consumers more informed decision-making that maximize their specific utility preferences and align the strategies of these stakeholder groups through market mechanisms rather than through cumbersome regulation. These diverse stakeholders will collaborate to create a series of technical products of the increasing granularity and specificity (ontology, taxonomy, data architecture) necessary for supporting interoperability while gradually expanding their network. The result of this process will be a fully-formed research and practice network and a high quality set of deliverables produced through the consensus of all relevant stakeholder groups, thus ensuring maximum interoperability of information systems. The knowledge gained through constructing and expanding I-Choose will inform a wide range of future collaborations in terms of how to create a trusted environment where incentives for collaboration and competition are complementary, not mutually exclusive. The study is relevant for a wide range of actors who are already experimenting with new forms of collaboration such as labor, environment, and agriculture departments and agencies in the NAFTA region, interested legislators, businesses, trade unions, environmental NGOs, consumer groups, and agricultural associations."
"1149372","CAREER: G*: A Parallel System for Efficiently Processing Large Graphs","IIS","INFO INTEGRATION & INFORMATICS","02/01/2012","02/20/2014","Jeong-Hyon Hwang","NY","SUNY at Albany","Continuing grant","Frank Olken","01/31/2017","$287,592.00","","jhh@cs.albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","7364","1045","$0.00","Complex networks such as human social groups, transportation networks and the World Wide Web are frequently represented as graphs. The goal of this project is to construct a new system that both conveniently and efficiently executes queries on collections of large graphs. To achieve this goal, the project develops data storage and processing techniques that can effectively use a server cluster.<br/><br/>The project's outcomes include (1) efficient data storage techniques that take advantage of commonalities between graphs, (2) methods that allow simple implementations of parallel graph processing solutions, (3) a framework that accelerates queries on multiple graphs by sharing computations across graphs, (4) techniques that store data on disks in a manner optimized for query execution, (5) methods that optimize query execution by appropriately distributing data over servers, and (6) techniques that mask server failures while balancing recovery speed and required cost.<br/><br/>This project has significant impacts on many application areas where it is critical to understand networks of various types. Examples include national security, social and political studies, transportation and marketing. Programming assignments and term projects based on this research are developed for undergraduate/graduate courses on data management systems, distributed systems and social network analysis. This project also offers research opportunities to both high school and minority students through summer programs at the University at Albany, State University of New York. The software, experimental data and research papers that result from this project will be disseminated through the project website (http://www.cs.albany.edu/~jhh/research/G_star/)."
"0540069","Building and Sustaining an International Digital Government Research Community of Practice","IIS","DIGITAL GOVERNMENT, INFO INTEGRATION & INFORMATICS","09/01/2005","11/22/2013","Sharon Dawes","NY","SUNY at Albany","Continuing grant","Sylvia J. Spengler","12/31/2014","$1,527,799.00","","sdawes@ctg.albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","1706, 7364","1706, 9216, HPCC, 0000, OTHR, 9102","$0.00","ABSTRACT<br/>NSF-0540069<br/><br/>Dawes, Sharon<br/><br/>Over the past decade, growing evidence demonstrates that ""digital government"" (DG) is developing as a global field of inquiry. Because of the relative newness of the DG field, there is insufficient interaction among researchers in different countries compared to what one finds in more established scientific disciplines. Most funded research around the world addresses DG challenges within the context of a single country; only a few investigations have compared results across national boundaries or tackled problems that are transnational in scope. The result of this situation is that comparative and transnational issues in DG, which are of growing importance in an increasingly networked world, are not receiving the attention they deserve. To address this gap, the team will plan, develop, and implement a four-year strategy to create opportunities and venues for international research discussions and to enable U.S. researchers and educators to advance their work through international collaboration. A small international advisory group will be named to help guide the work, connect to research sponsors in other countries, and periodically assess progress toward goals.<br/><br/>The proposed activities will document the development and current state of digital government research and foster relationships and intellectual engagements that will enrich it as a domain of inquiry throughout the world. The results will contribute to innovative research questions and methods, identify gaps in current knowledge that could be the focus of future research, and constitute a useful guide to individual researchers who are interested in forming relationships with international investigators who share their interests. All of these effects create an arena where research problems amenable to international treatment can be identified and investigated. This set of activities would benefit the NSF research community as well as those in other countries by building and sustaining relationships among both researchers and research sponsors around the world in an effort to catalog, compare, and where possible build synergies among funding decisions about digital government research. This project will contribute directly to the ability of US researchers and graduate students to work successfully, and in a sustained way, in international settings. The proposed international summer institute will help to train future generations of digital government scientists."
"1016823","HCC: Small: Contextualized and Automated Usability Testing for Mobile Applications","IIS","Cyber-Human Systems","09/01/2010","09/02/2010","Guanling Chen","MA","University of Massachusetts Lowell","Standard Grant","William Bainbridge","08/31/2015","$499,670.00","","glchen@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7367","7367, 7923","$0.00","The objective of this research is to advance usability testing of mobile applications by integrating contextualized and automated techniques. Unlike the traditional desktop environment, mobile user experience is heavily in&#64258;uenced by user context such as physical location, transport mode, social surroundings, and task intention. The novelty of this project is a model-based usability testing approach that quantitatively integrates user context. The expected outcomes include: 1) a new framework of automated usability analysis to improve the effectiveness of diary studies by jointly modeling user cognition, application state, and user context; 2) a set of operationalized usability rules developed for mobile applications; and 3) a simulation-based development toolkit for automated usability inspection. This project addresses an emerging research theme and an urgent practical usability problem, and is expected to produce technology solutions as well as educational materials.<br/><br/>This project addresses a practical need of the fast-growing mobile application industry. The software artifacts will be made available to both research communities and industry practitioners through open source technology transfer, which can significantly reduce the cost of mobile usability testing. The proposed research will be integrated with three new course modules taught by PI. Women and minority students will be recruited to participate both research and education activities. All the course materials will be made available online."
"0953373","CAREER: A New Statistical Framework for Natural Images with Applications in Vision","IIS","ROBUST INTELLIGENCE","06/01/2010","03/12/2014","Siwei Lyu","NY","SUNY at Albany","Continuing grant","Jie Yang","05/31/2015","$499,596.00","","lsw@cs.albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","7495","1045","$0.00","This project studies natural image statistics, and their applications in diverse fields such as computational neuroscience, image processing, computer vision, and graphics. The centerpiece of this project is a new image representation based on a simple nonlinear transform that is statistically justified and biologically inspired. This representation provides a new language to describe image signals, and forms the basis to build statistical models to more effectively capture statistical properties of natural image. Built upon this new image representation, this project explores new paradigms to model and interpret visual neural responses and high-level perceptual properties, and provides new tools for image restoration, analysis and synthesis. On the other hand, by applying natural image statistics to the forensic analysis of digital images, this project facilitates forensic practitioners in criminal investigations, and contributes to national security and public safety. Moreover, this project contributes to education by making the learning of Computer Science fun and useful for undergraduate students, promoting the participation of women and undergraduate students in research, and improving the early learning of mathematics and sciences for local high school students."
"1017672","RI: Small: Towards Portable Navigational Devices for the Visually Impaired","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","08/01/2010","08/08/2010","Cang Ye","AR","University of Arkansas Little Rock","Standard Grant","Satyandra Gupta","07/31/2015","$320,389.00","","cxye@ualr.edu","2801 South University","Little Rock","AR","722041099","5015698474","CSE","7495, 9150","9150, 7923","$0.00","The objective of this project is to devise computer vision methods that enable a Portable Blind Navigational Device (PBND) to guide a visually impaired person in unstructured environments. The main research question of this project is to answer if the approach of employing a single perception sensor can solve blind navigation problem, including localization of the PBND and object recognition. A distinctive feature of this work is that it addresses blind navigation problem by simultaneously processing the visual and range information of a 3D imaging sensor. <br/><br/>The project consists of four related research endeavors. First, it investigates techniques for accurate and precise pose estimation of the PBND in a GPS-denied environment. Second, it develops an effective 3D data segmentation method to allow scene recognition for wayfinding. Third, it applies the pose estimation method to register 3D range data and devises methods to reduce registration error. Four, it addresses real-time implementation of the methods in the PBND with limited computing power. <br/><br/>The research will result in new algorithms that can improve the lives of the visually impaired in the near term. They will also enable the autonomy of small robots that have wider applications in military situational awareness, firefighting, and search and rescue. The discoveries will revolutionize small robot autonomy and impact the robotics research community as a whole. Broader impacts also include training of undergraduate and graduate students, and educating the public on robotics through workshops and robot exhibits in science museums and technology showcases."
"1065013","HCC: Medium: Collaborative Research: Generating Accurate, Understandable Sign Language Animations Based on Analysis of Human Signing","IIS","Cyber-Human Systems","07/01/2011","06/12/2013","Carol Neidle","MA","Trustees of Boston University","Continuing grant","Ephraim P. Glinert","06/30/2015","$385,957.00","","carol@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7367","7367, 7924","$0.00","American Sign Language (ASL) animations have the potential to make information accessible to many deaf adults in the United States who possess only limited English literacy. In this research, which involves collaboration across three institutions, the PIs' goal is to gain a better understanding of ASL linguistics through computational techniques while advancing the state of the art in the generation of ASL animations for accessibility applications for people who are deaf. To these ends, the PIs will develop linguistically based models of two aspects of ASL production: movements required for head gestures and facial expressions that carry essential grammatical information and frequently extend over domains larger than a single sign, and the timing and coordination of manual and non-manual elements of ASL signing. Preliminary work has shown that these issues significantly affect how well signers understand ASL animations, and that these aspects of current ASL animation technologies require improvement. How should the face of a human or animated character be articulated to perform, with accuracy, the linguistically meaningful facial expressions that are part of ASL grammar? How should the onsets, offsets, and transitions of these movements be produced? How should the facial expressions and hand movements be temporally coordinated so that the ASL production is as grammatically correct and understandable as possible? To answer open questions such as these, the PIs' novel approach will apply techniques from computer vision to linguistically annotated video data collected from human signers, in order to produce models for use in animation-production. The PIs will expand their existing annotated video ASL corpora through new data collection and annotation, and will analyze these data to study the use, timing, and synchronization of manual and non-manual components of ASL production. The annotated videos will be used to train high quality computer vision models for recognition of linguistically significant facial expressions and timing subtleties. Parameters of these computer vision models will be used to hypothesize computational models of ASL timing and facial movements, to be incorporated into ASL-animation generation software and evaluated by native signers. The models will be iteratively refined in cycles of user-based studies and incorporated into ASL animation technologies to more accurately mimic human signing. Project outcomes will include high quality models of the movement of virtual human characters for animations of ASL performance. The analysis of video corpora of ASL will produce new linguistic insights into the micro-facial expressions and the temporal coordination of the face and hands in ASL production, while advances in the analysis of ASL prosody will contribute to an understanding of the fundamental commonalities and modality-specific differences between signed and spoken languages that is essential to a full understanding of the human language faculty. The creation of new modeling approaches and recognition techniques will advance the field of computer vision, by benefiting the identification and tracking of the human face and body in video during the rapid and complex movements of ASL (and other forms of human movement).<br/><br/>Broader Impacts: This research will lead to significant improvements to technology for generating linguistically accurate ASL animations, which will make information, applications, websites, and services more accessible to the large number of deaf individuals with relatively low English literacy. Advances in computer vision techniques for recognizing ASL in videos of humans will have general applicability in human-computer interaction, recognition and animation of facial expressions, and computer vision. The corpora created in this project will enable students and researchers in both linguistics and computer science (including those without access to the requisite technological and human resources to carry out their own data collection from native signers and time-intensive linguistic annotations) to engage in research on ASL. The techniques to be developed will also enable partial automation of the time-consuming creation of annotated ASL video corpora. As in the PIs' earlier work, the proposed research will create opportunities for people who are deaf and members of other underrepresented groups to participate in scientific research."
"0845159","CAREER: Modeling Group Dynamics in Multi-agent Systems","IIS","ROBUST INTELLIGENCE","07/01/2009","03/19/2014","Gita Sukthankar","FL","University of Central Florida","Standard Grant","James Donlon","12/31/2014","$434,943.00","","gitars@eecs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7495","1045, 1187, 9102, 9215, HPCC, 6890","$434,943.00","Predicting the behavior of an individual amidst a large number of other people, such as a player in a multiplayer online game or a pedestrian in an urban scene, poses a difficult challenge. This is because an agent's actions are strongly influenced by others in its environment, even though they do not formally share goals or plans. The majority of prior work on multi-agent behavior recognition has either ignored the influence of an agent's social context or has focused on tightly-coupled agent teams. In contrast, the research supported under this award is making fundamental progress in activity recognition and synthesis for humans in large, loosely-coupled groups by creating computational models of group identity that inform agent action selection. Models are being evaluated on problems such as recognizing group membership in video footage, analyzing player strategies in multiplayer online games, and other social simulations. <br/><br/>This research aims to make strong progress towards a better understanding of group dynamics and processes in human psychology. Educational initiatives of this award are introducing students to the exciting area of socially-interactive agent systems, using agent-based simulations to disseminate information about group bias and stereotypes (raising awareness of these issues has been proven to reduce the impact of bias on decision-making), continued curriculum development on multi-agent systems, the creation of public datasets of multi-agent social interactions, and the expansion of outreach/mentoring programs for women in computer science.<br/><br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."
"1430613","EAGER: Enabling Taskability: Research on Teaching Computers new Tasks","IIS","ROBUST INTELLIGENCE","04/01/2014","03/19/2014","John Laird","MI","University of Michigan Ann Arbor","Standard Grant","James Donlon","03/31/2016","$298,619.00","","laird@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7484, 7495, 7916","$0.00","This study investigates a new line of research into the ""taskability"" of cognitive agents. Taskability is the ability of an agent to accept high level, task-oriented instructions from a human and translate those goal-oriented directives into a suitably decomposed plan of sensing, reasoning, or action. Little to no research has been conducted on this subject to date. This research defines taskability in a manner sufficiently formal to allow for scientific research, establishes some of the initial conditions needed to evaluate taskable agents, and advances theories and prototype agents that meet those requirements. Specifically, the four research activities being undertaken in this study include: 1. A review, analysis, and synthesis of prior work from multiple disciplines that that can lay groundwork for focused cognitive systems research in this area; 2) An analysis of the different types of tasks and their structure, as well as the associated types of knowledge that must be learned by taskable agents; 3) Research on how people use instruction with taskable agents for such activities, performing user studies to determine the required task knowledge and agent capabilities; and 4) An extension of current cognitive agent capabilities to support the behaviors observed in the aforementioned studies, resulting in a software system that can be evaluated and co-developed with theory. <br/><br/>The current state of the art in research for cognitive systems and agents in general allows human handlers to issue directions to agents either in terms of lower level action primitives that correspond to the agent's particular design, or constrained by a higher-order action language (or even visual repertoire) that is engineered to suffice as a shorthand for some sequence of the same kinds of agent-specific behaviors. Taskability requires that an agent be able to interpret a richer, less constrained set of instructions from a user and, despite a lack of precompiled task decomposition instructions, dynamically formulate an accurate representation of the task to be performed, and even learn new tasks via this sort of interaction. Taskable agents would fundamentally change the way humans interact with intelligent agents and robotic systems in a broad range of disciplines and environments, leading to richer interactions with more capable cars, phones, and almost any device containing a computer, all of which might respond to human interaction without resort to preprogrammed interaction modes. This in turn promises transformational advances in a range of application domains such as health care, industry, government, and home automation."
"1054659","RI: CAREER: Predictive Models of Music","IIS","ROBUST INTELLIGENCE","09/01/2011","03/19/2014","Parag Chordia","GA","Georgia Tech Research Corporation","Continuing grant","James Donlon","08/31/2016","$84,554.00","","ppc@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","1045, 1187, 7495","$0.00","The objective of this project is to develop algorithms that can predict future events, in the context of a data stream containing multiple correlated threads with many types of patterns. The domain chosen to explore this research is music. Music is richly patterned, with long-term dependencies, dependencies across time-scales, and correlations between parallel information streams. This makes it an ideal domain for advancing predictive modeling in information streams. When a person is listening to a song, the listener is anticipating, at any given moment, the timing and nature of the next event by decoding the musical signal. Even when analyzing a simple song, the brain utilizes complex correlations between the musical elements to make accurate predictions. <br/><br/>The research will examine the following specific questions: (1) Can prediction be improved by using ensemble methods, such as mixtures-of-experts and product-of-experts, in which the predictions of multiple models are merged? (2) Can novel Probabilistic Graphical Models (PGMs) improve upon standard approaches, such as Hidden Markov Models (HMMs), for predicting events in a musical signal? (3) Can computational predictive models provide testable cognitive hypotheses that help explain how humans form mental schemas of music? A primary education goal of this proposal is to create a series of interactive online learning modules, dealing with the synthesis, analysis, perception, and manipulation of musical sound, in order to investigate how music can be incorporated into core curricula to inspire greater interest in math, physics, and computer science and to teach core STEM concepts to at-risk youth."
"0910664","HCC: Large: Collaborative Research: Design Principles for Information Networks Supporting the Social Production of Knowledge","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","07/15/2009","09/11/2012","Jon Kleinberg","NY","Cornell University","Continuing grant","William Bainbridge","06/30/2015","$2,631,903.00","Lillian Lee, Geraldine Gay, Daniel Huttenlocher","kleinberg@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","1640, 7367","7367, 7925, 9215, HPCC","$0.00","The project seeks to develop design principles for social computing applications in which knowledge is produced by large, loosely coordinated groups of people. The research will be carried out by an inter-disciplinary team that brings together expertise from computing and information science with the social sciences; perspectives from all of these areas will be crucial to developing the next generation of large-scale collaborative information systems on the Internet. A particular focus of the research will be on phenomena that affect the quality of information and discussion in these settings, including deception and the kinds of opinion dynamics that lead to polarization. The research will offer new analysis techniques and computational models for understanding such phenomena, drawing on novel styles of investigation involving large-scale datasets of social interaction and social network activity. Building on this, the research will also formulate design principles (based on ideas from intelligent task routing and games with a purpose) to enable creators of social computing applications to design for particular outcomes in the presence of complex underlying social phenomena.<br/><br/>The project is motivated by a profound transformation taking place in the way knowledge is produced and shared; in particular, the way it emerges in a ""bottom-up"" manner from global social networks that largely self-organize online. This raises profound challenges: at a time when a large proportion of Americans turn first to Internet sources for information about politics, health, commerce, and education, there is still very little understanding among the public as well as within the research community of how to deal with deception and misinformation online, or how to prevent online communities from falling into conflict and polarization. Through its focus on design principles and on these challenges, the project will attempt to create more effective means of online discourse and knowledge production."
"1054309","CAREER: Computational Methods for Analyzing Large-Scale Genomic Changes in Mammalian Genomes","IIS","ADVANCES IN BIO INFORMATICS, INFO INTEGRATION & INFORMATICS","03/01/2011","03/17/2014","Jian Ma","IL","University of Illinois at Urbana-Champaign","Continuing grant","Sylvia J. Spengler","02/29/2016","$433,548.00","","jianma@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","1165, 7364","1045, 1187, 7364, 1165","$0.00","This project will develop new combinatorial and probabilistic algorithms that will unravel the interwoven large-scale genomic changes that have occurred across species in an evolutionary context. The main research thrust is to develop new ancestral genome reconstruction algorithms that handle rearrangements, duplications, and large insertions and deletions at different resolutions in a single unified framework. These methods will be applied to the large number of whole-genome sequence data that have become available to elucidate detailed history of large-scale genomic operations in mammalian genomes. With the reconstructed history, scientists will be able to explain the large-scale genomic changes and assess their phenotypic impact on any lineage, including the human lineage. <br/><br/>The PI considers the problem of ancestral genomes using a parsimony principle based on breakpoint graphs that are consistent with current genomes. For considering more than two genomes, these problems are nearly all computationally intractable. The approach focuses on building better synteny blocks between genomes and using these blocks in a hierarchical method to develop new reconstruction algorithms that are then refined to smaller blocks and dealing with incomplete lineage sorting. <br/><br/>These new software tools and resources will be extremely useful to shed new light on the extraordinary diversity of mammalian forms and capabilities. In addition, the insights from this project will be applied to improve genome assembly methodologies based on next-generation high-throughput DNA sequencing reads. The models and algorithms will also be used to investigate specific genomic regions influenced by large-scale genomic changes, such as complex gene clusters and regions that harbor genome instability in cancer genomes. The project will develop open-source software tools for comparative genomics research, making them accessible to other scientists around the world. In addition, the outcome of the project will be disseminated through online website. Visualization tools from the research will provide scientific education on genome evolution to increase the accessibility of scientific results to the general public.<br/><br/>As part of his CAREER plan, the education components are closely integrated with the research program. The educational objectives include the development of new bioinformatics courses; training graduate students with interdisciplinary expertise necessary for the post-genomic era and providing them with meaningful international research experience through collaboration; getting undergraduate students involved in research projects; and participating in the G.A.M.E.S. camp at the University of Illinois to inspire pre-college girls to develop careers in science and engineering."
"1149383","CAREER: Real-Time Crowd-Oriented Search and Computation Systems","IIS","INFO INTEGRATION & INFORMATICS","02/15/2012","03/18/2014","James Caverlee","TX","Texas Engineering Experiment Station","Continuing grant","Maria Zemankova","01/31/2017","$324,966.00","","caverlee@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7364","1045, 9251","$0.00","While long-lived communities have been one of the key organizing principles of Web-based systems, there is widespread evidence of highly-dynamic, ad-hoc crowd formation in emerging real-time socio-computational systems. These crowds are dynamically formed and potentially short-lived, often with only implicit signals of their formation and evolution. The goal of this research project is to develop the framework, algorithms, and systems for lightweight crowd-oriented search and computation so that stakeholders can distill high-quality information from bursty social systems and actively engage with the crowds generating this information. First, the project provides the foundation for crowd-oriented search through new algorithmic advances for distributed crowd indexing and in an investigation of the design principles impacting crowd-oriented search. Next, the project develops self-tuning methods for assessing crowd quality, even with huge demands on efficiency and in the presence of limited evidence of crowd quality. Finally, the project explores methods for ""closing the loop"" in crowd-oriented search, so that crowds may become part of in situ human-computational systems. <br/><br/>The education and outreach efforts of the project are tightly linked to the research goals through leadership workshops, enhancements to the curricula, direct research training, and engagement with emergency response experts and major companies. Distilling high-quality information from bursty social systems and actively engaging with the crowds generating this information will result in improved real-time decision-making, impacting a wide range of stakeholders from areas such as epidemiology, law enforcement, government, finance, politics, among many others. Further information can be found on the project web page: http://faculty.cse.tamu.edu/caverlee/csc/."
"1054960","CAREER: An Integrated Framework for Multimodal Music Search and Discovery","IIS","INFO INTEGRATION & INFORMATICS","02/01/2011","03/18/2014","Gert Lanckriet","CA","University of California-San Diego","Continuing grant","Maria Zemankova","01/31/2016","$440,096.00","","gert@ece.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","1045, 1187","$0.00","A revolution in music production and distribution has made millions of songs instantly available to virtually anyone, on the Internet. However, a listener looking for ""dark electronica with cello"" or ""music like U2's"", without knowing a relevant artist or song name, or a musicologist wanting to search through large amounts of unknown ethnic music, would face serious challenges. Novel music search and discovery technologies are required to help users find the desired content.<br/><br/>The non-text-based, multimodal character of Internet-wide information about music (audio clips, lyrics, web documents, images, band networks, etc.) poses a new and difficult challenge to existing database technology that depends on unimodal, text-based data-structures. This project addresses two fundamental research questions at the core of addressing this challenge: (1) The automated annotation of (non-text-based) audio content with descriptive keywords; and (2) the automated integration of the heterogeneous content of multimodal databases, to improve music search and discovery on the Internet or in a personal database. The resulting architecture leverages the automation and scalability of machine learning with the effectiveness of human computation, engaging music professionals or enthusiasts around the world.<br/><br/>The research addresses questions at the core of multimedia information retrieval in general, enabling the design of a new generation of expressive and flexible retrieval systems for multimodal databases, with applications to music discovery, video retrieval, indexing multimedia content on the home PC, etc.<br/><br/>The results of this project, including a software library and annotated music data sets, will be incorporated in ongoing education and outreach activities and disseminated via the project website (http://cosmal.ucsd.edu/~gert/CAREER.html) to enhance research and education in music information retrieval."
"0905250","RI: Medium: Collaborative Research: The Effect of Subglottal Resonances on Machine and Human Speaker Normalization","IIS","ROBUST INTELLIGENCE, PERCEPTION, ACTION & COGNITION","09/01/2009","03/18/2014","Mitchell Sommers","MO","Washington University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$520,791.00","Steven Lulich","msommers@artsci.wustl.edu","ONE BROOKINGS DRIVE, CAMPUS BOX","SAINT LOUIS","MO","631304899","3148895100","CSE","7495, 7252","7495, 7924, 9215, HPCC, 6890","$520,791.00","Last Modified Date: 05/02/09 Last Modified By: Tatiana D. Korelsky <br/><br/>Abstract <br/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br/><br/>Despite large acoustic differences in the speech of various talkers, humans are generally able to understand each other quickly and easily. The mechanisms by which humans map such variability onto a set of phonemes has been the subject of research for more than 50 years. This ""speaker normalization"" problem has generally been thought of in terms of normalizing the formant frequencies of a particular speaker with a reference set of formants. In this project, a novel approach to speaker normalization is explored, in which not formants but subglottal resonances <br/>(SGRs) are normalized. SGRs have previously been shown to define a set of frequency bands within which formants may vary, yet retaining the same phonemic vowel quality. Normalizing SGRs (and associated frequency bands) therefore reduces formant variability in an effective way. In this project, effects of SGR normalization on automatic speech recognition <br/>(ASR) performance are evaluated for both adult and child speakers of English and Spanish. In parallel, effects on human speech perception in multi-talker conditions are explored. Results are expected to improve ASR performance and shed light on human speech production and perception. The project will result in speech databases (including direct recordings of SGR acoustics) and ASR tools, which are critically useful for research in speech production, perception, speaker identification, and speech processing algorithms for cochlear implants and multi-lingual ASR. The collaboration in Engineering, Linguistics, Speech & Hearing, and Psychology facilitates a multidisciplinary learning environment. <br/>Publications, results, databases, and tools will be disseminated to the research community."
"1225934","NRI-Large: Collaborative Research: Soft Compliant Robotic Augmentation for Human-Robot Teams","IIS","National Robotics Initiative, ROBUST INTELLIGENCE","10/01/2012","07/11/2013","Nikolaus Correll","CO","University of Colorado at Boulder","Continuing grant","Satyandra Gupta","09/30/2017","$244,849.00","","ncorrell@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803090572","3034926221","CSE","8013, 7495","7925, 8086, 9251","$0.00","This proposal addresses the hardware, control and planning technologies required to achieve soft robotic systems, in order to offer inherent safety and adaptation to the human-machine systems of the future. The project is motivated by a broad range of aspects of human-robot interaction, including soft augmentation tools for safe compliant manipulation, soft exoskeletons for rehabilitation of neuromuscular disorders, or active clamping systems that can conform to arbitrary surfaces. The proposed research will address the algorithmic and device-level challenges that arise in the design of soft compliant robots capable of pose-invariant and shape-invariant grasping. A combination of algorithmic solutions to modeling, control, planning, and adaptation will lead to new soft compliant manipulators that do not need accurate geometric models for grasping. By designing soft compliant fingers and hands, new approaches to grasp planning and manipulation will be enabled. A novel composable actuation system and supporting planning and control algorithms with features inspired by natural muscle will be developed.<br/><br/>Broader Impacts: Soft robots are inherently low-cost. Affordable soft manipulators will enable in-home assistants for the elderly or incapacitated, but these robots must be able to manipulate the natural world as easily as people do. The next generation robot manipulators will also support new levels of factory automation, in which robots will work synergistically with humans with the ultimate goal of reducing the cost of manufacturing in the USA. The proposed soft devices will provide a new approach to assistive and rehabilitative usage of compliant robotic platforms. Their functional compliant properties will enable them to work side-by-side with human beings or as part of their bodies, to augment and improve human productivity and performance. This new wearable soft robotic technology will not only help workers perform tasks, but also improve the quality of life for many people. In addition, the PIs have a long tradition of integrating research and education by providing research training at all levels, from high-school teachers and students to undergraduate and graduate students, and postdocs. A range of activities to reach out to undergraduate students, high-school communities, women and minorities is planned."
"1302338","HCC: Medium: Combining Crowdsourcing and Computer Vision for Street-level Accessibility","IIS","Cyber-Human Systems","05/01/2013","05/16/2013","Jon Froehlich","MD","University of Maryland College Park","Standard Grant","Ephraim P. Glinert","04/30/2017","$1,199,034.00","David Jacobs","jonf@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","7367, 7924","$0.00","Despite comprehensive civil rights legislation for Americans with disabilities, many city streets, sidewalks, and businesses remain inaccessible. The problem is not just that street-level accessibility affects where and how people travel in cities but also that there are few, if any, mechanisms to determine accessible areas of a city a priori. Traditionally, sidewalk assessment has been conducted via in-person street audits, which are labor intensive and costly, or via citizen call-in reports, which are done on a reactive basis. And while efforts exist for visualizing the walk-ability, bike-ability, and availability of public transport in cities, there are no analogous efforts for accessibility. Thus, wheelchair users, for example, often avoid going to new areas of a city where they don't know about accessible routes. The PI plans to address this problem by means of a two-pronged approach in which he will first develop scalable data collection methods for acquiring sidewalk accessibility information using a combination of crowd-sourcing, computer vision, and online map imagery; he will then use the new data to develop and evaluate a novel set of navigation and map tools for accessibility. To these ends, the PI and his team will collect and analyze interview and survey data both from mobility impaired persons and from ADA streetscape design experts, and will seek to understand how people with mobility impairments can make use of interactive mapping information to enhance mobility. They will study methods for efficiently and effectively crowd-sourcing map labeling tasks, evaluating existing approaches empirically and designing novel, more effective approaches. They will develop new computer vision algorithms for the analysis of street scenes, which will be used to help scale the data collection by focusing human labeling efforts on locations that are most likely to contain significant problems. And they will design, implement and evaluate new accessible-aware map-based tools to aid people with mobility impairments in navigating their cities. As appropriate for each phase of the research, user evaluations will include both lab and field studies.<br/><br/>Broader Impacts: Roughly 30.6 million individuals in the United States have physical disabilities that affect their ambulatory activities, and nearly half of these individuals report using an assistive aid such as a wheelchair, cane, crutches, or walker. The outcomes from this research will have a significant impact on the ability of these Americans to travel independently, by transforming the ways in which accessibility information is collected and visualized for every sidewalk, street, and building faade in America. Project outcomes will include a publicly accessible web site where both the labeled data collected during this work and the new prototype tools developed will be made available for general use. Furthermore, the PI and Co-PI will advise and mentor both graduate and undergraduate students throughout the course of the project, including two PhDs and two MS students who will obtain a cross-disciplinary education in human-computer interaction and computer vision."
"1117699","III: Small: Collaborative Research: Making Databases Green - An Energy-Aware DBMS Approach","IIS","INFO INTEGRATION & INFORMATICS","07/01/2011","08/13/2012","Yicheng Tu","FL","University of South Florida","Continuing grant","Frank Olken","06/30/2015","$266,440.00","Bo Zeng","ytu@cse.usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139745465","CSE","7364","7923","$0.00","Maintaining a sustainable society via technological innovations has been a major challenge for computing system design. In this project, we focus on the energy efficiency of an important type of computer applications, the database management systems (DBMS), which often consume a large portion of the computing resources and energy in modern data centers. The goal of this project is to design and implement a DBMS that enables significant energy conservation with graceful degradation of query processing performance. The project achieves its goal using the following approaches: (1) Dynamically exploit the energy-performance tradeoffs in DBMS as well as low-power modes of hardware systems for improved energy efficiency with performance guarantees; (2) Formulate the energy-efficient DBMS design as a feedback control problem, and adopt appropriate formal control techniques to achieve the desired performance and energy efficiency with theoretical analysis and guarantees; (3) Apply advanced multi-stage optimization methods to solve complex energy-aware storage management problems; and (4) Coordinate various control and optimization loops in different layers of the DBMS for maximized energy savings and global system stability. The broader impacts of the project are at two levels. At the society level, the reduction of energy consumption and CO2 emission by implementing the proposed energy-aware DBMS can be substantial. The project can benefit a large number of industrial sectors, the operations of which depend heavily on database-supported software such as online retailing systems, financial management software, and social networking platforms, by significantly lowering their electricity cost. At the education level, the project trains Ph.D. students in an interdisciplinary environment and enhances several courses taught at the University of Florida and the University of Tennessee at Knoxville by providing a rich set of application examples, software tools, and project opportunities. Publications, technical reports, software and experimental data from this project can be found at www.cse.usf.edu/~ytu/EDBMS."
"1242451","EAGER: Cluster Detection in Graphs for Noisy, Incomplete Biological Data","IIS","INFO INTEGRATION & INFORMATICS","09/15/2012","09/12/2012","Susan Epstein","NY","CUNY Hunter College","Standard Grant","Sylvia J. Spengler","08/31/2014","$50,000.00","Lei Xie","susan.epstein@hunter.cuny.edu","695 Park Avenue","New York","NY","100655024","2127724020","CSE","7364","7364, 7916, 9102","$0.00","The integration of gene annotations and omics (e.g., genomics, proteomics, metabolomics) data can provide important insights into noisy and incomplete biological data. Such data is often also on a scale presents computational challenges to many traditional algorithms. This project exploits Foretell, a local search algorithm originally created to accelerate solvers on large constraint satisfaction problems. Here Foretell is used to detect complex relationships among genes in context-specific protein-protein interaction (PPI) networks, with guidance from human experts. This is a novel, and potentially transformative, approach to provide new insights into the molecular and cellular mechanisms of fundamental biological processes. This flexible, innovative project is ideal for noisy, incomplete genomic data. It uses repeated local search guided by empirical biological knowledge to explore large weighted graphs under human direction. It provides users with meaningful feedback to reformulate their search for complex relationships among genes in context-specific PPI networks, and to devise new weight schemes to find them. Expected outcomes include a knowledge base of recurring clusters in Saccharomyces cerevisiae and the weight schemes used to detect them, a more flexible algorithm that detects and tabulates cluster features and provides meaningful feedback to the user, and a tool whose output suggests additional biological experiments. This project addresses, both in its design and its implementation, important questions in the discovery and application of computational approaches to biological networks.<br/><br/>Knowledge derived from this project will be broadly applicable and well promulgated through publication and through a web site. The resultant knowledge base will support other researchers? detection of combinations of interacting genes and the interpretation of their results. While it advances discovery and understanding, this project will support interdisciplinary collaboration, disseminate its results broadly, and promote research by students in a predominantly female, minority-serving institution."
"0905289","HCC: Medium: Social and Moral Relationships With Personified Robots","IIS","Cyber-Human Systems","09/01/2009","03/14/2014","Peter Kahn","WA","University of Washington","Standard Grant","William Bainbridge","08/31/2014","$1,264,424.00","","pkahn@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","6890, 7367, 7924, 9215, HPCC","$1,264,424.00","This award is funded under the American Recovery and Reinvestment Act of 2009<br/>(Public Law 111-5). This project will investigate people's social and moral relationships with personified robots. These robots, in various ways and to varying degrees, embody aspects of people insofar as they have a persona, are adaptive and autonomous, and can talk, learn, use natural cues, and self organize. This project will complete five complementary investigations: (1) Research on whether adults believe that a humanoid robot has feelings, is intelligent, can be a friend, is autonomous, and has moral standing (i.e., can be the recipient of unfair actions and unwarranted psychological harm). (2) A study of the extent to which children, adolescents, and adults believe that a robot can be responsible for harm it causes humans. (3) A study of moral standing and accountability that examines whether children, adolescents, and adults consider a humanoid robot most like a human, child, animal, or object - or as a new technological genre. (4) Research on whether children, adolescents, and adults believe that a robot is an entity that engenders trust and can be trusted. (5) A design study of patterns for sociality in human-robot interaction that characterizes essential features of social interaction between humans and robots. <br/><br/>Taken together, this body of work would provide for the first time a systematic account of social and moral behavior and reasoning with a humanoid robot that cuts across childhood, adolescence, and adulthood. In terms of basic science, this project will test the hypothesis that people do not simply act ""as if "" personified robots are social (like ""characters"" in a play), but engage personified robots sincerely and meaningfully as social others, and in some ways even as moral others. At the same time, this project would determine the extent to which human-robot interaction is not simply the mapping of human-human interactions (or human-animal interactions) onto robots, but represents a new genre: technological yet animate, personified, responsive, and seemingly autonomous.<br/><br/>As personified robots become more prevalent and integrated into people's everyday social lives, they will pose children and adults with significant challenges, socially and morally. The specific challenges will depend on how the robots are designed, their context of use, and on how people actually interact with such robots. In future, robots may become caretaking assistants for the elderly, academic tutors for children, or medical assistants, day care assistants, or psychological counselors. Thus, it is important to understand at the outset how different age groups respond to robots and conceptualize their increasingly complex behavior. It is likely in the near future that the public will raise serious concerns about the introduction of personified robots into society. Concerns may be voiced, for example, that interacting with personified robots will reify a master-servant relationship (with the robot as servant), or undermine authenticity of real social relationships. Parents, in particular, may voice concerns about the impacts of personified robots on their children. The results of this proactive research and design project will provide guidance in responding most appropriately to such concerns and will establish principles for assuring that robots will be used only for human benefit."
"1116653","HCC: Small: Website Design, Content, and Ideological Communication","IIS","Cyber-Human Systems, EXP PROG TO STIM COMP RES","09/01/2011","08/29/2011","Shane Connelly","OK","University of Oklahoma Norman Campus","Standard Grant","William Bainbridge","08/31/2014","$499,979.00","Norah Dunbar, Matthew Jensen","sconnelly@ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7367, 9150","7367, 7923, 9150","$0.00","This interdisciplinary research seeks to understand how website design and content influence psychological processes and attitudinal and behavioral outcomes on violent and non-violent ideological websites. A content analysis study will be conducted to identify and compare the level and nature of website credibility, interactivity, and persuasion tactics for ideological websites (violent and non-violent) and for non-ideological websites. Relationships of these variables to website usefulness for ideology dissemination and psychological processes such as identity expression, and dehumanization will also be examined. Next, a series of experiments examining causal influences of key website characteristics (credibility, interactivity, and persuasion) on website users' knowledge, attitudes, and behavioral intentions will be conducted. These studies will compare the effects of these characteristics for ideological websites advocating violence versus non-violence. Relevant user characteristics (e.g., demographics, social identity, self-esteem, physiological arousal) will be captured for purposes of model building and testing for moderating influences. In these experiments, simulated websites will be developed to represent varying facets of credibility, interactivity, and persuasion. Human participants will be asked to navigate through these websites and respond to discussion threads, explore related links, fill out short questionnaires, and engage in other activities intended to assess key outcomes. Measures of knowledge, attitudes, and intentions will be assessed before and after website exposure for comparison. By leveraging an interdisciplinary approach to the growing number and presence of ideological groups online, this series of studies will lead to new theories and models for future research and dissemination of educational websites serving public interests. <br/><br/>New knowledge will be developed by examining the specific facets of credibility, interactivity, and persuasion, which have not previously been studied with respect to ideologically motivated attitudes and behavior. An important comparison of violent and non-violent ideological websites will also contribute uniquely to better understanding the perceptions of and responses to ideologies through human-centered computing. This collaborative effort will also develop and demonstrate methods for future integrated research, for team members and the broader research community. Although the investigation and findings will focus on ideological website design and communication, the framework developed will also be relevant to studying the impact of website design on outcomes in other areas such as online education. <br/><br/>The combination of theoretical and methodological backgrounds required to conduct the experiments will contribute to the research training of doctoral students and undergraduate research assistants in Psychology, Communication, and Management Information Systems. Findings from this research are likely to also have a number of practical implications for educating the general public about ideological websites and how they attempt to influence and persuade individuals who visit these sites. In addition, dissemination of the results through the professional channels of several sciences will achieve the broader impact of contributing to multiple academic fields."
"1349774","CAREER: Bayesian Nonparametric Learning for Large-Scale Structure Discovery","IIS","ROBUST INTELLIGENCE","03/15/2014","03/13/2014","Erik Sudderth","RI","Brown University","Continuing grant","Todd Leen","02/28/2019","$98,404.00","","sudderth@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","1045, 7495, 9150","$0.00","CAREER: Bayesian Nonparametric Learning for Large-Scale Structure Discovery<br/><br/>This CAREER project will advance the state-of-the-art for automated discovery of structure within data as diverse as images and video, natural language, audio sequences, and social and biological networks. Contemporary applications of statistical machine learning are dominated by parametric models. This approach constructs models of pre-determined size (with a finite-dimensional vector of parameters which) are tuned using training data. To be effective, the underlying structure of such models must be manually specified by experts with application-specific knowledge. This presumed structure imposes limits on what can possibly be learned even from very big datasets.<br/><br/>Bayesian nonparametric models instead define distributions on models of arbitrary size with infinite-dimensional spaces of functions, partitions, or other combinatorial structures. They lead to flexible, data-driven unsupervised learning algorithms, and models whose internal structure continually grows and adapts to new observations. Bayesian nonparametric models, while promising, are an incompletely-developed technology posing significant challenges to practice. This CAREER project will increase the practical feasibility and impact of Bayesian nonparametric approaches by pursuing three interrelated themes:<br/><br/>1) Nonparametric Model Design and Evaluation. New families of models for data with hierarchical, spatial, temporal, or relational structure are investigated. Quantitative validation of the statistical assumptions and biases inherent in these models will be emphasized, evaluating whether these align with the empirical statistics of significant application areas.<br/><br/>2) Reliable Structure Discovery. Statistical inference algorithms which move beyond the local moves of standard (and widely used) Monte Carlo and variational methods will be developed. Compelling examples indicate that local optima are a significant issue for contemporary methods, so a family of novel algorithms is proposed, which dynamically adjust model complexity as learning proceeds.<br/><br/>3) Scalable and Extensible Nonparametric Learning. Common patterns across a wide range of popular nonparametric models are identified, which suggest a corresponding family of scalable and parallelizable online learning algorithms. The ""memoized"" online variational inference algorithm avoids some practical instabilities and sensitivities of conventional methods, while allowing provably correct optimization of the nonparametric model structure and complexity.<br/><br/>An extensible ""BNPy: Bayesian Nonparametric Learning in Python"" software package is under development to allow easy application of the novel learning algorithms to a wide range of current and future BNP models. The education and outreach plan of this CAREER project leverages this software to create interdisciplinary undergraduate research teams exploring applications in the natural and social sciences, and a week-long summer school on Bayesian nonparametrics to be held twice at Brown University's Institute for Computational and Experimental Research in Mathematics (ICERM)."
"1350721","CAREER: Legged Locomotion Across Scales: Closing the Loop Between Task Planning and Motion Control","IIS","ROBUST INTELLIGENCE","03/15/2014","03/13/2014","Ioannis Poulakakis","DE","University of Delaware","Continuing grant","Satyandra Gupta","02/28/2019","$77,762.00","","poulakas@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7495","1045, 7495, 9150","$0.00","This award seeks to introduce tightly integrated locomotion control and motion planning strategies for agile, highly-mobile legged robots with radically different sizes and morphologies. To realize the potential of these machines in real-world applications, basic movements must be composed to synthesize more complex locomotion behaviors that achieve desirable high-level planning objectives. As dynamic legged robots are becoming increasingly more capable, the need for hierarchically consistent locomotion planning strategies that translate descending task-level commands to suitable low-level control actions that harness the platform's locomotion capabilities becomes pressing. To address this need, this effort pursues new directions (i) in dynamic legged locomotion, by offering a portable library of locomotion primitives; (ii) in robot control, by providing constructive feedback reduction strategies and stochastic data-driven methods that map complex legged robot platforms to behavior-encoding target models; and (iii) in hybrid systems, by introducing a framework for complexity reduction through multiple layers of information processing and control action. This research effort seeks to enable legged machines to perform real-world tasks reliably and efficiently. This way, it promotes many different applications, including industrial, agricultural, and emergency response applications that require highly mobile and versatile robots. This effort also includes substantial educational and community outreach components, aiming at attracting underrepresented groups to science, technology, engineering, and mathematics. In addition, by pairing high-school teachers with graduate students, this effort addresses the critical need for K-12 teachers to stay current and articulate their teaching with the demands of college courses."
"1350904","CAREER: Controlling Ecologically Destructive Processes with a Network of Intelligent Robotic Agents","IIS","ROBUST INTELLIGENCE","03/15/2014","03/13/2014","Mac Schwager","MA","Trustees of Boston University","Continuing grant","Satyandra Gupta","02/28/2019","$92,031.00","","macschwager@gmail.com","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7495","1045, 7495","$0.00","This project aims to control destructive environmental processes such as forest fires, oil spills, and agricultural pest infestations through the intelligent, coordinated intervention of a group of robots. This requires the development of fundamentally new control theoretic and algorithmic tools to drive the robots to take control actions to regulate the environmental process. The robots' control actions close a large-scale feedback loop around the robots and the environment, giving rise to complex dynamical phenomena. The project proposes control strategies for this coupled robot-environment system in three different timescale regimes: (i) the environment changes slowly compared to the robots' dynamics, (ii) the environment and robot dynamics are on the same timescale and immediate control effect is sought, and (iii) the environment and robot dynamics are on the same timescale and long-term control effect is sought. Three different optimization based techniques are proposed to generate decentralized control strategies for each regime. Stability, convergence, and optimality properties of the robot-environment system under these strategies are studied. Furthermore, experiments with a network of quadrotor aerial robots, both in the lab and outdoors, demonstrate the practicality of the control strategies. The project also incorporates a comprehensive education and outreach program using quadrotor robots as teaching tools to reach students from diverse backgrounds at all grade levels. Ultimately, the project seeks to alleviate the economic, social, and ecological damage caused by oil and other chemical spills, forest fires, pest infestations, and other ecologically destructive phenomena by laying the foundations of a new robotic technology."
"1350879","CAREER: Gait Transition Principles in Quadruped Robots","IIS","ROBUST INTELLIGENCE","06/01/2014","03/10/2014","Sang bae Kim","MA","Massachusetts Institute of Technology","Standard Grant","Satyandra Gupta","05/31/2019","$400,000.00","","sangbae@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","1045, 7495","$0.00","Quadrupedalism, pervasive in nature, is a promising locomotion mode for numerous future robotic applications. Utilizing its versatility can play a crucial role in managing unexpected and varying terrains in an efficient and stable manner. Understanding of why, how, and when to use a certain gait is central to successfully building stable, adaptable robots. Gait transition criteria in animals involve an intricate interplay among such biological characteristics as metabolic cost, bone stress, muscle physiology, and social stimuli. Obtaining general principles that are useful in design of robots by studying animals is very challenging. This project investigates the intrinsic nature of dynamic characteristics of quadrupedal gaits and the transitions among them by utilizing appropriate computational models. These models are selected to represent only important dynamic characteristics of quadrupedal gaits and filter out biological aspects that are not essential to the realization of robots. These models help to develop gait selection criteria from the energetics and stability analyses of each gait. The gait selection criteria constitute the basis of the development process of stable gait-transitioning controllers. This project aims to enhance our understanding of quadrupedal locomotion, contributing to future applications such as disaster response robots and new transportation systems. In addition, the project plans to integrate research results with educational activities. The new class on bio-inspired robot provides the opportunities for students to learn how to investigate scientific questions using computational methods and physical robots. The student training includes several outreach activities such as participation in science festivals and developing science exhibitions for K-12 education."
"1053398","CAREER Digital Privacy and Regulation","IIS","Cyber-Human Systems","02/01/2011","02/19/2014","Catherine Tucker","MA","Massachusetts Institute of Technology","Continuing grant","Ephraim P. Glinert","01/31/2017","$360,018.00","","cetucker@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","1045, 1187, 7367","$0.00","This project has three main goals: 1) to estimate how privacy regulation will affect the shape and direction of electronic commerce; 2) to empirically investigate how online consumers respond to being given control over how their personal data are used and how these responses are interconnected across consumers; and 3) to assess how best organizations can safeguard and protect consumer data and the legal risks that might entail, with particular application to the health sector.<br/><br/> This 5-year integrated program of research will build upon concepts from multiple fields, including computer science, economics, marketing and information systems, to measure and evaluate the current effects and the likely future effects of various ways of regulating firms' use of consumer data online. The research program combines computer science techniques designed to optimize the mining of online information with economic analysis and policy evaluation techniques. The research will advance and synergize literatures in each of these fields, and apply these advances to the important academic topic of measuring the likely effect of privacy regulation and other governmental attempts to safeguard digital data. The program will uniquely yield prescriptive recommendations regarding significant industry and public concerns, based on scientific measurements.<br/><br/> The activities are designed to have broader impact within the practitioner, policy and academic community. Once the research program is complete, practitioners, policymakers and academics will have new ways that they can measure the impacts of existing and proposed privacy regulations. This will lead to clearer guidance for policymakers seeking to improve the design of privacy laws, and better practices for firms trying to retain a viable business model while safeguarding consumers' privacy. The research program will enable websites to use consumer data in ways that improve consumers' experience of online advertising, rather than unintentionally creating situations where consumers feel that their privacy has been violated. It will help guide privacy regulation directed at protecting the most vulnerable types of digital consumer data, such as digitized patient records, from unintentional security risks.<br/><br/> The educational program will create a new mentoring program for undergraduate and graduate students, focusing especially on recruiting undergraduate and graduate women and under-represented minorities with an interest in the intersection between information systems and public policy. It also involves a specialized digital data and privacy course at MIT Sloan School of Management, introducing a generation of students to new complexities raised by protecting privacy when digitization automates the collection of potentially personal data. It is increasingly important for business students to come to grips with the privacy challenges and the business practices encountered when using the Internet, and such course development will assist in that process. A graduate student seminar will help more technically-minded students understand the nuances of applying policy evaluation techniques to IS policy issues. The data, results and educational exercises resulting from this proposal will be made available to the broader academic community, to further disseminate the planned research and teaching advances."
"0953662","CAREER: Dimensionality Reduction for Multi-Label Classification","IIS","INFO INTEGRATION & INFORMATICS","04/01/2010","03/10/2014","Jieping Ye","AZ","Arizona State University","Continuing grant","Maria Zemankova","03/31/2015","$401,528.00","","jieping.ye@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","1045","$0.00","Recent advances in high-throughput technologies have unleashed a torrent of data with a large number of dimensions. Examples include gene expression pattern images, microarray gene expression data, protein/gene sequences, and neuroimages. Dimensionality reduction, which extracts a small number of features by removing the irrelevant, redundant, and noisy information, is crucial for the analysis of these data. The goal of this project is to develop efficient and effective dimensionality reduction algorithms for multi-label classification. Multi-label dimensionality reduction poses a number of exciting research questions that will be studied in this project: How to fully exploit the class label correlation for effective dimensionality reduction? How to scale dimensionality reduction algorithms to large-scale multi-label problems? How to effectively combine dimensionality reduction with classification? How to derive sparse dimensionality reduction algorithms to enhance model interpretability? How to derive multi-label dimensionality reduction algorithms for multiple data sources?<br/><br/>To address these questions, a hypergraph spectral learning formulation will be developed for multi-label dimensionality reduction, in which a hypergraph is used to capture the class label correlation. A joint learning formulation will be developed, in which dimensionality reduction and multi-label classification are performed simultaneously. In addition, a multi-source dimensionality reduction framework is developed for learning from multiple heterogeneous data sources. <br/><br/>The success of this project will largely improve the state-of-the-art in dimensionality reduction for multi-label classification, and broaden this research area by opening up and addressing many new research themes. The algorithms and tools developed in this project will directly impact biological research, as they will be used to annotate FlyExpress images; FlyExpress is the only digital library of standardized fruit fly embryonic expression patterns. The educational component of this project includes developing a new curriculum that incorporates research into the classroom and provides students from under-represented groups with opportunities to participate research. Project results, including open source software and data sets will be disseminated via project Web site (http://www.public.asu.edu/~jye02/Project/CAREER)."
"1317947","NRI: Small: Collaborative Research: Active Sensing for Robotic Cameramen","IIS","ROBUST INTELLIGENCE","09/15/2013","09/12/2013","Kostas Daniilidis","PA","University of Pennsylvania","Standard Grant","Jie Yang","08/31/2015","$433,711.00","Sampath Kannan","kostas@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7495","7923, 8086","$0.00","With advances in camera technologies, and as cloud storage, network bandwidth and protocols become available, visual media are becoming ubiquitous. Video recording became de facto universal means of instruction for a wide range of applications such as physical exercise, technology, assembly, or cooking. This project addresses the scientific and technological challenges of video shooting in terms of coverage and optimal views planning while leaving high level aspects including creativity to the video editing and post-production stages. <br/><br/>Camera placement and novel view selection challenges are modeled as optimization problems that minimize the uncertainty in the location of actors and objects, maximize coverage and effective appearance resolution, and optimize object detection for the sake of semantic annotation of the scene. New probabilistic models capture long range correlations when the trajectories of actors are only partially observable. Quality of potential novel views is modeled in terms of resolution that is optimized by maximizing the coverage of a 3D orientation histogram while an active view selection process for object detection minimizes a dynamic programming objective function capturing the loss due to classification error as well as the resources spent for each view.<br/><br/>The project advances active sensing and perception and provides the technology for further automation on video capturing. Such technology has broader impact on the production of education videos for online courses as well as in telepresence applications. Research results are integrated into robotics and digital media programs addressing K-12 students."
"1351677","CAREER: Generalizations in Obstacle Avoidance Theory","IIS","ROBUST INTELLIGENCE","03/15/2014","03/11/2014","Animesh Chakravarthy","KS","Wichita State University","Continuing grant","Satyandra Gupta","02/28/2019","$75,100.00","","animesh.chakravarthy@wichita.edu","1845 Fairmount","Wichita","KS","672600007","3169783285","CSE","7495","1045, 7495, 9150","$0.00","This project develops a theoretical framework that enables an analytical characterization of guidance laws for obstacle avoidance, accompanied by an experimental validation of these laws. This has significant implications since the obstacle avoidance problem is an important component of the path planning problem, which appears in several diverse fields including robotics, autonomous air, ground and underwater vehicles, computer animation, molecular motion, autonomous wheelchairs, spacecraft avoiding space debris, robotic surgery, assistance aids for the blind, etc. The guidance laws designed are particularly applicable for real-time implementation of precise path planning in cluttered dynamic environments such as those containing robot manipulators, humanoid robots, vehicles flying in formation and other high-dimensional spaces wherein the agents have no a priori information about their environment. A robustness analysis of the designed guidance laws to various uncertainties such as sensor noise, data delays and data dropouts is performed, followed by an experimental validation wherein the guidance laws are coded on microcontroller platforms in a resource-efficient manner and implemented on small-scale robotic ground and air vehicles. The expected results include guidance laws suitable for collision avoidance of obstacles of various, possibly time-varying, shapes moving in high-dimensional stochastic environments, along with a postulation of the safety guarantees of these guidance laws. This project also performs multiple outreach activities and introduces new curriculum that promote the education and applications of robotics, and these activities are conducted in levels starting from K-12 all the way through undergraduate and graduate level engineering education."
"1419976","Student Travel Support for the 2014 SIAM International Conference on Data Mining","IIS","INFO INTEGRATION & INFORMATICS","04/01/2014","03/10/2014","Hui Xiong","NJ","Rutgers University Newark","Standard Grant","Christopher Clifton","03/31/2015","$27,744.00","","hxiong@rutgers.edu","Blumenthal Hall, Suite 206","Newark","NJ","071021896","9733531538","CSE","7364","7364, 7556","$0.00","This award provides travel support for approximately 24 graduate students to attend the 2014 SIAM Data Mining Conference (SDM 2014), and the associated Doctoral Student Forum, that is being organized by the Society for Industrial and Applied Mathematics (SIAM) in cooperation with the American Statistical Association. SDM 2014 is being held April 24-26 in Philadelphia, Pennsylvania. Twelve students will present at the Doctoral Forum consisting of a poster session for Ph.D. candidates in data mining or closely related areas who have made significant progress towards Ph.D. candidacy. The Ph.D. student forum participants will be able to present their work, interact with their peers from other universities as well as hundreds of leading researchers in data mining from around the world. In addition, they will attend the technical sessions, plenary talks, and tutorials and workshops of their choice at the conference. Each student will be assigned a senior researcher to serve as a mentor on a variety of career-related issues.<br/><br/>Participation in premier research conferences is an integral component of the training of Ph.D. students in data mining. The SDM 2014 Doctoral Student Forum is aimed at providing an opportunity for Ph.D. candidates to present their work and receive constructive feedback and mentoring from established researchers in data mining. Such feedback and mentoring is expected to improve the quality of the students thesis research. Similarly, student recipient of a travel award will be able to attend technical sessions, plenary talks, panels, tutorials and workshops. They will interact with peers who share similar interests from other universities, as well as hundreds of leading researchers in data mining from around the world. This experience will be extremely formative and fruitful towards the shaping of their future research endeavors.<br/><br/>Data mining is playing an increasingly important role in many emerging data-rich sciences and application domains, such as healthcare informatics, bioinformatics, computational biology, link analysis, counterterrorism and security. The SDM 2014 Doctoral Student forum will enrich the education and training of student researchers at early stages in their careers. Attendance in SDM 2014 will expose students to cutting-edge research and to relevant applications in a variety of domains. The travel awards will help broaden the participation of women and members of under-represented groups within the Data Mining research community."
"1351028","CAREER: Apprenticeship Learning for Robotic Manipulation of Deformable Objects","IIS","ROBUST INTELLIGENCE","03/15/2014","03/10/2014","Pieter Abbeel","CA","University of California-Berkeley","Standard Grant","Satyandra Gupta","02/28/2019","$500,000.00","","pabbeel@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","1045, 7495","$0.00","This project considers the problem of apprenticeship learning, in which a robot first gets access to demonstrations of a task and ought to learn from these demonstrations how to perform that task in new, yet similar, situations. This line of work has already shown significant promise, including in helicopter control where it enabled autonomous helicopter aerobatics at the level of the best human pilots. However, fundamental limitations remain, and robotic capabilities to manipulate deformable objects are currently still well below human level. The approach followed builds on, and extends, non-rigid registration algorithms, which can capture how scenes with deformable objects relate to each other. Such registration is extrapolated to morph a demonstrated manipulation trajectory into a good trajectory for a new scene. New machine learning algorithms are developed to enable choosing the optimal training demonstration and the optimal morphing objective while accounting for external constraints, such as avoiding collisions and satisfying joint limits. Infrastructure is being built for large-scale data collection of demonstrations and theoretical and empirical characterizations are developed for how much data is needed for a given task. Concrete challenge tasks considered are knot tying, cloth and fabric manipulation, surgical suturing, and small surgical procedures. Results will be incorporated into the PI's graduate robotics course and the source code will be shared with the robotics community."
"0952943","CAREER: Learning Models for Scalable Content-Based Image Retrieval","IIS","ROBUST INTELLIGENCE","04/01/2010","03/08/2014","Lorenzo Torresani","NH","Dartmouth College","Continuing grant","Jie Yang","03/31/2015","$494,964.00","","lorenzo@cs.dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551404","6036463007","CSE","7495","1045, 1187, 9150","$0.00","This project addresses the design of machine learning algorithms enabling content-based image retrieval in Web-scale collections of photos. This research formulates image retrieval as a binary classification problem: decide which database images are the ""same"" as the user-provided photo. Efficiency and scalability to large collections are achieved by constraining the classifiers to be models supported by traditional text-search engines, which perform real-time search in databases of several billion documents. In order to implement search based on high-level notions of similarity, the research team develops methods to automatically localize the most content-relevant regions in the input photo and to extract from them semantically powerful classifiers combining appearance cues with robust geometric constraints. The algorithms learn from user-provided labels indicating the presence but not the location of similar visual content, thus requiring a minimal amount of human supervision. This research investigates also how this advanced form of similar-image search can be used to organize personal photos, provide semantic annotations, and support content-based clustering of pictures. Furthermore, this work provides technical advances in a wide range of computer vision problems including object detection, visual saliency, and content-based clustering of photos. Moreover, the research team is collecting an unprecedentedly large image data set to evaluate the developed image retrieval system and to be available to the community. Research is naturally integrated with education and outreach by means of related courses and out-of-classroom activities aimed at attracting students to this field and at encouraging interdisciplinary collaborations."
"1431969","Travel support for the Organizational Communications and Information Systems Doctoral Consortium","IIS","Cyber-Human Systems","03/01/2014","03/06/2014","Mary Beth Watson-Manheim","IL","University of Illinois at Chicago","Standard Grant","William Bainbridge","02/28/2015","$24,829.00","","mbwm@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7367","7367, 7556","$0.00","The Organizational Communication and Information Systems (OCIS) doctoral consortium at the 2014 Academy of Management meeting in Philadelphia, Pennsylvania, will bring together approximately 30 dissertation-stage OCIS doctoral students for one and a half days of talks and interactions with distinguished OCIS researcher faculty. The Academy of Management is a well-established professional organization for scholars, social scientists, and management leaders, and OCIS is a division of the Academy. The OCIS division at the annual AOM meetings provides a leading international forum for the presentation and discussion of research and practical issues related to the use and impact of information and communication technologies in organizations.<br/><br/>The doctoral consortium provides highly-talented students with feedback on their work from other students and faculty members, allowing them to enhance their own research proposal. As well, because of the diversity of the communities involved, the consortium will allow students to make connections beyond their own disciplines. Both faculty and students are diverse on several dimensions, notably research topics, methodological approaches, and cultural background. As a result, participation will allow students to develop a better understanding of the different research communities, which will facilitate their participation in future inter-disciplinary research. This event has helped to launch the careers of many outstanding OCIS researchers, in the past. It provides feedback to students in order to develop higher quality and more relevant research in the field of organizational communication and information systems."
"1418913","WORKSHOP: Doctoral Research Consortium at ACM CHI 2014","IIS","Cyber-Human Systems","02/01/2014","02/07/2014","Katherine Isbister","NY","Polytechnic University of New York","Standard Grant","Ephraim P. Glinert","01/31/2015","$21,120.00","","kin205@nyu.edu","15 Metrotech Center","Brooklyn","NY","112013826","7182603360","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) of about 15 promising graduate students from the United States and abroad, along with 6 distinguished research faculty mentors. The event will take place in conjunction with the ACM 2014 Conference on Human Factors in Computing Systems (CHI 2014), which is sponsored by the Association for Computing Machinery's Special Interest Group on Human-Computer Interaction (SIGCHI) and will be held April 26-May 1 in Toronto, Canada. The annual CHI conference is the leading international forum for the presentation and discussion of human-computer interaction (HCI) research and practice, and is attended by approximately 3,400 HCI professionals from around the world. Research reports published in the CHI Conference Proceedings and the CHI Extended Abstracts are heavily refereed and widely cited; they are among the most scientifically respected research publications in the field of HCI. More information about the conference is available online at http://chi2014.acm.org.<br/><br/>The Doctoral Consortium is a research-focused meeting that has taken place annually at the CHI conference since 1986, and has helped to launch the careers of many outstanding HCI researchers. Goals of the workshop include building a cohort group of new researchers who will then have a network of colleagues spread out across the world, guiding the work of new researchers by having experts in the research field give them advice, and making it possible for promising new entrants to the field to attend their research conference. Student participants will present their work during the two full days of the Consortium on April 26-27. Each student will have a 45-minute time slot in which to make a formal presentation and receive feedback from the faculty panel, which is geared to helping students understand and articulate how their work is positioned relative to other human-computer interaction research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. The program for the two full days of the Consortium will also include substantial informal opportunities for discussion and additional feedback, with follow up activities planned during the technical program of the conference. Extended abstracts of the students' work will be published in the CHI 2014 Extended Abstracts, which is distributed to all conference registrants and included in the ACM Digital Library. SIGCHI's conference management committee will evaluate the event, and the results will be made available to the organizers of future consortia. The CHI doctoral consortia have been highly successful in providing a forum for the initial socialization into the field of young doctoral scholars; many of today's leading HCI researchers participated as students in earlier consortia.<br/><br/>Broader Impacts: The annual CHI doctoral consortia traditionally bring together the best of the next generation of HCI researchers, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Applications are encouraged from all doctoral students whose research is HCI-related, regardless of the fields in which they are earning their degrees. In accordance with CISE policy, NSF funds will be used solely to support participation by students enrolled in graduate programs in the United States, although there will also be a number of international participants in recognition of the fact that the HCI field embraces educational and cultural traditions that vary in different parts of the world. The organizers have undertaken to work to identify and include the broadest possible group of highly qualified participants; as a consequence, the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field. To further promote diversity no more than one student will be accepted from any given institution, except in the case where including a second student from the same school would allow a woman to be a participant."
"1419590","Workshop on Taskability","IIS","ROBUST INTELLIGENCE","03/01/2014","03/06/2014","John Laird","MI","University of Michigan Ann Arbor","Standard Grant","James Donlon","02/28/2015","$13,510.00","","laird@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7484, 7495, 7556","$0.00","This workshop concerns the ""taskability"" of cognitive agents, meaning the ability of an intelligent and adaptable system to accept high level, task-oriented instructions from a human and translate those goal-oriented directives into a suitably decomposed plan of sensing, reasoning, or action. The current state of the art in research for cognitive systems and agents in general allows human handlers to issue directions to agents either in terms of lower level action primitives that correspond to the agent's particular design, or constrained by a higher-order action language that is engineered to suffice as a shorthand for some sequence of the same kinds of agent-specific behaviors. <br/><br/>This workshop is addressing four key considerations for this emergent topic: 1) defining this new research area with sufficient clarity that research agendas can proceed productively; 2) identifying the science and technology issues that most be addressed to create systems that meet that definition of taskability; 3) decomposing that further into research and development needs that are the precursors to such research; and 4) exploring the formation of a research community on taskability. Taskability holds the potential to transform the way humans interact with intelligent systems. The ability to instruct a wide variety of agents to perform tasks that are not preprogrammed will have a profound effect on the broader AI enterprise, and eventually on the technologies that will enrich the daily lives of people."
"1117509","RI: Small: Exploiting Correlated Sparsity Pattern Change in Dynamic Vision Problems","IIS","ROBUST INTELLIGENCE","09/01/2011","08/22/2011","Namrata Vaswani","IA","Iowa State University","Standard Grant","Jie Yang","08/31/2014","$204,395.00","","namrata@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","7495","7923","$0.00","This project develops a new framework to solve a large class of dynamic vision problems by exploiting correlated sparsity pattern change in the appropriate domain. The focus is on high-dimensional visual tracking problems such as deformable contour tracking or target tracking in the presence of significant illumination changes. These are difficult because of the high dimensionality and because the observation models are highly nonlinear and/or non-Gaussian due to clutter, occlusions or low contrast. However, in most such problems, even though the state (e.g., contour deformation or illumination) is high-dimensional, at any given time, most change occurs in only a few principal directions. In a long sequence, this set of directions can gradually change over time. Most existing methods need a set of past state estimates to estimate this change on-the-fly while tracking noisy or nonlinear systems. The research team provides a completely new solution to this difficult problem by re-interpreting it as a problem of ""recursively reconstructing sparse state sequences with slow time-varying sparsity patterns"" and tapping into ideas from their ongoing recursive sparse recovery work.<br/><br/>The research of this project enriches the knowledge base of computer vision and can be applied to many different applications such as medical image analysis and video surveillance. The project provides research opportunities for graduate students and involves undergraduate students, including under-represented minorities, through summer, senior design projects and REU projects."
"1350550","CAREER: More than Words: Advancing Prosodic Analysis","IIS","ROBUST INTELLIGENCE","06/01/2014","03/04/2014","Andrew Rosenberg","NY","CUNY Queens College","Continuing grant","Tatiana D. Korelsky","05/31/2019","$98,156.00","","Andrew@cs.qc.cuny.edu","65 30 Kissena Blvd","Flushing","NY","113671575","7189975400","CSE","7495","1045, 7495","$0.00","Prosody is an essential component of human speech. Whereas the words are ""what is said"", prosody is ""how it is said"". A wealth of information is communicated via prosody including information about a speaker's intent and state (speaking-style and emotion). To advance the capabilities of machines to understand human speech, this CAREER project develops new representations of prosody and applies them to a variety of spoken language processing tasks: word recognition, speaking-style recognition, dialog-act classification and speaker identification. This project employs and advances semi-supervised and unsupervised representation learning techniques to characterize prosody. This project also investigates prosody across multiple languages. Speakers of multiple languages contribute speech and annotate some basic prosodic phenomena (phrasing and prominence). The overarching goal is to identify a compact and universal representation of prosody that will be employed effectively in spoken language processing tasks across languages. Scientific results, representations and tools for extraction will be made open-source as will the collected, annotated multi-lingual data.<br/><br/>Speech recognition is being integrated into our lives through mobile devices and spoken dialog systems. The next great hurdle in the ability to communicate with machines via speech is understanding prosody. Taking prosody into account will result in machines understanding humans better; conversely, automatically generating adequate prosody to convey intent will allow machines to sound more human. Both types of improvement are sorely needed as automated conversation agents and robots are starting to become a part of our everyday lives. Finally, this project implements an innovative and challenging education plan that is well-integrated with its research. It includes curricula modules on prosodic analysis and representation learning to be widely disseminated. Moreover, undergraduate students who provide and annotate speech samples for the project will get a hands-on introduction to computer science research, and will be compensated in part with tuition waivers for introductory courses in computer science."
"1149570","CAREER: Signal Models, Channel Capacity, and Information Rate for Noninvasive Brain Interfaces","IIS","Cyber-Human Systems","02/01/2012","02/27/2014","Deniz Erdogmus","MA","Northeastern University","Continuing grant","Ephraim P. Glinert","01/31/2017","$297,263.00","","erdogmus@ece.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","1045, 7367","$0.00","The PI's ultimate research goal is to empower people with severe speech and physical impairments so they can live their lives to the fullest extent independently and productively. To this end, he will in this project exploit and advance emerging brain computer interface (BCI) technology by rigorously developing macro-level dynamic models for the visual evoked potentials (VEP) in the brain measured by electroencephalography (EEG) in the context of BCI design. The models will enable a communication channel interpretation of the BCI and will allow analysis and design breakthroughs stemming from the application of information theory and digital communication concepts. Cortical dynamics and background processes will be modeled using a probabilistic dynamic framework at a spatiotemporal scale appropriate for BCI analysis and design. Model-based performance limits on bandwidth and calibration accuracy will then be determined, in order to develop better information coding techniques for optimal communication bandwidth (speed) utilization and better subject training and model calibration procedures for best accuracy return on investment of effort. Prototype real-time applications that operate at optimal or near-optimal performance levels utilizing the developed theoretical advancements for communication and control will be implemented, to enable access by and support independence for the target user groups. <br/><br/>Project outcomes will disrupt the trend of black-box BCI design by building dynamic system models for stimulus-to-EEG systems encountered in BCI applications, and treating them as stochastic communication channels in order to characterize signals accordingly and to employ information theoretic approaches to analysis and design. This novel theoretical framework will enable model-based quantitative characterization of BCI performance limits and will allow the design of optimal or near-optimal coding/decoding strategies as well as improved calibration procedures that will have immediate impact on increasing bandwidth and intent detection accuracy, as well as calibration duration reduction in BCI systems - primary barriers between laboratory prototypes and real-world-worthy BCI products.<br/><br/>Broader Impacts: If successful this project will advance BCI technology to the next level, thereby revolutionizing human computer interaction and empowering persons with physical disabilities by enabling seamless control of computers and devices. The project will afford, through collaboration with the Center for Subsurface Sensing and Imaging Systems (CenSSIS) at Northeastern University as well as colleagues across departments and institutions, opportunities to both undergraduate engineering and non-engineering majors for enhanced learning and collaboration skills by immersing them in interdisciplinary cutting-edge research and design projects with societal impact. The PI will engage high school students and teachers in the research through his institution's Center for STEM Education. And he will inform the broader public of ongoing technological advances in the BCI field and raise disability awareness through collaboration with the Cahners ComputerPlace at the Boston Museum of Science."
"1419433","CAREER: Toward Discovering the 3D Geometrical and Semantic Structure of Objects and Scenes","IIS","ROBUST INTELLIGENCE","10/01/2013","02/28/2014","Silvio Savarese","CA","Stanford University","Continuing grant","Jie Yang","12/31/2015","$150,135.00","","silvio@eecs.umich.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","1045","$0.00","This project develops a novel framework for jointly understanding the 3D spatial and semantic structure of complex scenes from images. The state-of-the-art computer vision methods deal with these two tasks separately. Methods for object recognition typically describe the scene as a list of class labels, but are unable to account for the 3D spatial structure. Methods for scene 3D modeling produce accurate metric reconstructions but are unable to infer the semantic content of its components. This project seeks to fill this gap and creates the foundations for a new framework for coherently describing objects, object components and their 3D spatial arrangement in the scene's physical space. The research of this project makes two main contributions. First, novel models for representing the intrinsic multi-view nature of object categories and for measuring critical object geometrical attributes are explored. Second, a new coherent probabilistic formulation that is capable to use these measurements for simultaneously estimating the most likely 3D configuration of scene elements and the critical semantic phenomena of the scene are investigated. This research has potential to play a transformative role in many strategic areas such as autonomous navigation, robotics, and 3D automatic modeling of urban environments. Moreover, it is crucial in designing technology for assisting people with reduced functional capabilities. The project integrates research and education by involving undergraduates or high school students in projects whose primary application goal is to develop technology for people with disabilities."
"1149001","EAGER: Distributed Imaging Through Networks of Robotically Actuated Cameras","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","01/01/2012","08/26/2011","George Legrady","CA","University of California-Santa Barbara","Standard Grant","Ephraim P. Glinert","12/31/2014","$124,644.00","","legrady@arts.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7367, 7453","7367, 7453, 7916","$0.00","This project enhances the research direction of the interdisciplinary arts-engineering Media Arts & Technology (MAT) doctoral program at UC Santa Barbara, through the introduction of a practice-based, study in visually applied robotics. The ultimate challenge in any arts, science and engineering collaboration is a convincing articulation as to why and how artistic contribution can be of benefit to the scientific and engineering research. We propose to develop a prototype multi-camera instrument consisting of three robotically actuated cameras for experiments in content recognition and image stabilization of real-time noisy images generated by the moving cameras which try to synchronize their visual content. Our project?s purpose is to develop new solutions in image synchronization through the study of images generated by machine behavior, bridging knowledge perspectives from visualization experts from the two fields of arts and engineering.<br/><br/>Through the iterative working process of experimental staging and evaluation of results, we plan to identify and formally define methodology similarities and differences by which artists and engineers arrive at solutions. We are therefore interested in closely examining problem-solving at the implicit and explicit levels. Our project?s principal objectives are to: a) To develop an instrument of an exploratory, experimental nature that will be used in multiple ways to stimulate advances in research dealing with the optical-mechanical robotic vision machine; the study of machine behavior, and the study of machine generated images. b) Advance the infrastructure for research and education through the creation of an imaging instrument that will bring together specialists from different disciplines to explore a common computational imaging problem and lead to further arts-engineering collaboration, and c) the intent is to position artistic vision as a contributing force to advancing research and thereby to push recognition of the artistic paradigm as of relevance to the research community. A part of this work will therefore be to identify opportunities that current scientific/engineering research have not explored but that have potential and resonances for both disciplines.<br/><br/>The project will have significant educational impact as imaging-computational-robotics is a curriculum and research direction that MAT has desired to integrate for years, and the project will formally set the stage for direct engagement with the controls mechanical engineering branch of the College of Engineering. Dissemination of results will occur in a broader spectrum then conventional research such as engineering conference papers and arts academic presentations. This proposal also includes the creation of a state-of-the-art installation based on the result of the experimental studies, to be circulated in the general public context of exhibitions in museums, where feedback can be further collected."
"1156435","III: Small: Collaborative Research: Making Databases Green - An Energy-Aware DBMS Approach","IIS","INFO INTEGRATION & INFORMATICS","06/30/2011","06/21/2012","Xiaorui Wang","OH","Ohio State University","Continuing grant","Frank Olken","06/30/2015","$229,875.00","","xwang@ece.osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7364","7923, 9150","$0.00","Maintaining a sustainable society via technological innovations has been a major challenge for computing system design. In this project, we focus on the energy efficiency of an important type of computer applications, the database management systems (DBMS), which often consume a large portion of the computing resources and energy in modern data centers. The goal of this project is to design and implement a DBMS that enables significant energy conservation with graceful degradation of query processing performance. The project achieves its goal using the following approaches: (1) Dynamically exploit the energy-performance tradeoffs in DBMS as well as low-power modes of hardware systems for improved energy efficiency with performance guarantees; (2) Formulate the energy-efficient DBMS design as a feedback control problem, and adopt appropriate formal control techniques to achieve the desired performance and energy efficiency with theoretical analysis and guarantees; (3) Apply advanced multi-stage optimization methods to solve complex energy-aware storage management problems; and (4) Coordinate various control and optimization loops in different layers of the DBMS for maximized energy savings and global system stability. The broader impacts of the project are at two levels. At the society level, the reduction of energy consumption and CO2 emission by implementing the proposed energy-aware DBMS can be substantial. The project can benefit a large number of industrial sectors, the operations of which depend heavily on database-supported software such as online retailing systems, financial management software, and social networking platforms, by significantly lowering their electricity cost. At the education level, the project trains Ph.D. students in an interdisciplinary environment and enhances several courses taught at the University of Florida and the University of Tennessee at Knoxville by providing a rich set of application examples, software tools, and project opportunities. Publications, technical reports, software and experimental data from this project can be found at www.cse.usf.edu/~ytu/EDBMS."
"1433485","EAGER: Discovery of Segmental Sub-Word Structure in Speech","IIS","ROBUST INTELLIGENCE","03/01/2014","03/04/2014","Karen Livescu","IL","Toyota Technological Institute at Chicago","Standard Grant","Tatiana D. Korelsky","02/28/2015","$99,911.00","","klivescu@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372902","7738340409","CSE","7495","7495, 7916","$0.00","This EArly Concept Grant for Exploratory Research (EAGER) investigates new machine learning techniques for discovering sub-word units in speech for use in automatic speech recognition (ASR). The representation of this EArly Concept Grant for Exploratory Research investigates new machine learning techniques for discovering sub-word units in speech for use in automatic speech recognition (ASR). The representation of words in terms of sub-word units is rarely learned from data, despite significant disagreement among linguists as to the sub-word unit inventory. This project represents exploratory work toward a larger goal of making all aspects of ASR learnable, using scientific insights while being discriminatively trained.<br/><br/>In contrast with prior work, speech segments are clustered into units using discriminatively learned segmental similarities, rather than via dynamic time warping or hidden Markov models. Rather than pre-supposing phoneme-like units, multiple heterogeneous unit types<br/>are learned. The project also leverages multi-modal (video, articulatory, and so on) data to improve unit discovery by sharing<br/>information across modalities. In this exploratory work, the learned units are used in a discriminative model that rescores initial outputs from a standard phone-based recognizer, and the experiments focus on small-/medium-vocabulary recognition.<br/><br/>This project explores new ways of discovering the basic units of speech. Beyond improvements to speech recognition, this project has<br/>the potential for broad impact on other research areas involving sequences with segmental sub-structure (such as text, video,<br/>biological data, and financial data) or involving clustering. The results may also include new representations for the study of speech<br/>in linguistics and speech science. From a societal perspective, in the long term making speech recognition more learnable will enable<br/>improved porting of the technology to under-served linguistic communities, which do not have the benefit of large data sets or other resources."
"0964324","HCC: Medium: Collaborative Research: Low Cost, Portable, Multi-User, Immersive Virtual Environment Systems for Education and Training in Worlds of Unlimited Size","IIS","Cyber-Human Systems","04/15/2010","04/10/2013","Eric Bachmann","OH","Miami University","Continuing grant","Ephraim P. Glinert","03/31/2015","$659,010.00","David Waller","Eric.Bachmann@miamiOh.edu","500 E High Street","Oxford","OH","450563653","5135292161","CSE","7367","7924, 9215, HPCC","$0.00","In recent years immersive real-time interactive 3D computer environments (virtual reality or VR) have become an invaluable tool for research and development, training, healthcare, commerce, communication, and education, as well as a medium for entertainment. Yet, in general, the use of current VR systems requires travel to specialized facilities in which a sophisticated infrastructure has been pre-installed at great expense. Furthermore, although fully immersive systems that allow teams of users to concurrently explore a simulated environment by walking, turning, and looking around in a natural manner are particularly useful because they provide increased realism through multisensory stimulation, current VR facilities often support only one user at a time who is constrained to explore the virtual world by means of an artificial interface or a movement metaphor that is arbitrary and awkward (e.g., treadmills or walking in place). For most people, the benefits of VR are thus relatively inaccessible and fall quite short of their promise. In this collaborative effort between Miami University and the Naval Postgraduate School, the PIs will conduct research whose goal is to develop an innovative immersive VR system that is completely portable, that will allow multiple users to be immersed simultaneously, and that can be used in any large indoor or outdoor area such as a gymnasium or parking lot. Users will be able to walk naturally for miles in a virtual world without ever becoming aware of the physical limits of the tracking space or the locations of other users. A system capable of immersing a single user will cost an order of magnitude less than current systems. To these ends the PIs will exploit two emerging techniques: redirected walking, an algorithm that imperceptibly steers users away from obstacles such as walls and which the PIs have previously shown can, given a physical area of sufficient size, enable users to navigate through a virtual world of unlimited size in a natural manner without encountering real-world boundaries and obstacles; and self contained inertial position tracking, which prior research has shown can be used to accurately monitor and track the position and orientation of the user's viewpoint in space without the need for pre-installed permanent infrastructure. In addition, the PIs will integrate into the new VR technology ultrasonic mapping and positioning, a technique commonly used in robotics to provide estimates of absolute position. <br/><br/>Broader Impacts: By creating VR systems that are portable and relatively inexpensive, this research will take significant steps toward making VR technology available to a much broader range of people than has heretofore been possible, providing first-hand exposure to cutting-edge concepts and models in science and technology to any population that educators or researchers chose. In particular, the work will enable students at any grade level to experience computer simulations and models by walking within them, instead of by reading about them or by viewing them as an outside observer. The synthesis of redirected walking and self-contained inertial position tracking will offer rich research potential in the computer and behavioral sciences. Implementing relative position tracking through inertial sensors and periodic position fixes instantiates a biologically plausible model of navigation and can parallel research on how humans and other animals find their way through environments."
"1150028","CAREER: Communicative Efficiency and Adaptiveness in the Ideal Speaker","IIS","ROBUST INTELLIGENCE, PERCEPTION, ACTION & COGNITION","01/01/2012","02/25/2014","T. Florian Jaeger","NY","University of Rochester","Continuing grant","Tatiana D. Korelsky","12/31/2016","$334,194.00","","fjaeger@bcs.rochester.edu","518 HYLAN, RIVER CAMPUSBOX 27014","ROCHESTER","NY","146270140","5852754031","CSE","7495, 7252","1045, 7495, 9251","$0.00","Human communication is typically robust even at high speeds. This suggests that both speakers and listeners efficiently deal with the uncertainty and noise inherent to perception, production, and the environment. This CAREER award investigates how the human brain accomplishes this. A mathematical model of efficient communication based on probability and information theory (the Ideal Speaker model) is tested against data from conversational speech. Specifically, the project investigates how the pronunciation of words in spontaneous speech depends on words' expected confusability in context, the cognitive load the speaker is under and the situational incentive for robust communication. The Ideal Speaker model also predicts that efficient communication with a particular interlocutor requires adaptation to that interlocutor, a prediction that the project tests in behavioral paradigms against task-oriented speech production. <br/><br/>The project contributes to our understanding of how humans produce language, why language has the properties it has, and to what extent the neural systems underlying language production can adjust to different communicative task demands. These insights can contribute to the development of better automatic speech recognition systems (this project is limited to the evaluation of such systems). In addition, novel paradigms to gather large amounts of language data are developed that will dramatically cut research costs. Finally, training in the emerging field of computational psycholinguistics is provided to a broad international audience via summer schools and workshops. This will contribute to a new generation of multidisciplinary scientists working across traditional boundaries between computer science, linguistics, and cognitive psychology."
"1225629","Extended Visit to Asian Research Labs for Selected Students Attending ACL 2012 Student Research Workshop","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","06/15/2012","06/13/2012","Yang Liu","TX","University of Texas at Dallas","Standard Grant","Tatiana D. Korelsky","05/31/2015","$44,000.00","","yangl@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7298, 7495","5921, 5927, 5942, 7556, 9200","$0.00","The project funds extended research visits of U.S-based graduate students to selected Asian research groups working in speech and language processing. These students are selected from those attending the annual meeting of Association for Computational Linguistics (ACL), which will be held in Jeju, Korea, July 8-14, 2012. The selected students will work on a research project with researchers in the hosting group they are visiting.<br/><br/>This project will provide opportunities for students to be exposed to different culture and new research paradigm in other countries, broaden their horizon and help generate new research ideas, and help make them more competitive in the global market and develop into the scientists that are needed globally in the future. The extended visit also helps build bridges between the Asian hosts and the student's home research group in the U.S. This will facilitate long term collaboration between U.S. and other countries, and advance science and technology in the whole world."
"1252648","CAREER: Self-adjusting Models as a New Direction in Machine Learning","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","02/25/2014","Murat Dundar","IN","Indiana University","Continuing grant","Sylvia J. Spengler","02/28/2018","$230,334.00","","dundar@cs.iupui.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7364","1045, 7364","$0.00","Machine learning algorithms are now routinely used to build predictive models from data in wide range of applications. However, current approaches to machine learning have an important limitation: They assume that the set of classes observed in a training data set is exhaustive and that new data samples originate from one of the existing classes represented in the training data set. This assumption is unrealistic in many real-world applications in which previously unobserved classes of interest emerge. <br/><br/>This study explores a new class of machine learning algorithms that produce self-adjusting models that can accommodate new classes observed in data in offline as well as online learning scenarios. The project aims to (i) use non-parametric models to dynamically incorporate the changing number of classes; (ii) develop new online and offline inference techniques to accommodate new classes as they emerge (iii) automatically associate newly discovered classes with higher-level groups of classes in an attempt to identify potentially interesting class formations, and (iv) develop partially-observed tree models containing observed and unobserved nodes, where observed nodes represent existing classes and unobserved nodes are introduced online to fill the gaps in the existing data hierarchy that become evident only with the arrival of new data.<br/><br/>The broader impacts of this work could extend to several real world applications: Bio-security and bio-surveillance, information retrieval, and remote sensing among others in settings where all of the classes are not known a priori. The educational plan includes outreach to K-12 students and enhanced research opportunities for undergraduate and graduate students in computer science as well as at the intersection of computational and life sciences. All the software, publications, and data sets resulting from the project will be freely disseminated to the larger research and educational community. Additional information about the project can be accessed through the project website at http://www.cs.iupui.edu/~dundar/career.html"
"1262010","HCC: Medium: A Toolkit to Evaluate the Effect of Multitouch Interaction on the Musculoskeletal System and Design Safe Multitouch Systems","IIS","Cyber-Human Systems","05/16/2012","04/11/2013","Devin Jindrich","CA","University Auxiliary and Research Services Corporation","Continuing grant","Ephraim P. Glinert","03/31/2015","$926,657.00","","devin.jindrich@asu.edu","435 East Carmel Street","San Marcos","CA","920784362","7607504700","CSE","7367","9215, HPCC, 7367, 7924","$0.00","Some have heralded multi-touch interaction as the technology to drive computing systems into the future. But as we move towards a world where interaction is based on human body movement that are not well documented or studied, we risk creating technology and systems that may lead to musculoskeletal disorders (MSDs). This is not a hypothetical but a real danger. In the past devices such as keyboards have led to MSDs, yet many new systems make no effort to avoid gestures that are known to lead to musculoskeletal disorders or to eliminate gestures that are symptomatic of a patient population. With multi-touch interfaces currently being considered for adoption by companies and academia, it is now more critical than ever that good design practices incorporating preventive approaches be implemented in the initial stages of product design and development. In this research, the PI and his interdisciplinary team that includes experts in human-computer interaction, kinesiology and ergonomics will evaluate the effect of multi-touch interaction on the musculoskeletal system and provide mechanisms for developing safe multi-touch systems that involve interactions designed to cause minimal musculoskeletal stress and risk. Project outcomes will include best practices and standards for interaction that are safe yet allow users to fully benefit from the new levels of immersion that multi-touch interaction affords. In particular, the PI will develop a toolkit that will allow multi-touch designers to input a gesture movement and evaluate its induced stress in a variety of situations and under different variables. In addition, the software will allow input of formal definitions of HCI tasks and some choices of gestures, and will suggest a set of suitable gestures for the task based on the given choices. To achieve these goals, the PI will explore new formal models of human-computer interaction that take multi-touch interaction into account at both the cognitive and psychomotor levels.<br/><br/>Broader Impacts: This research will provide multi-touch interaction researchers with valuable new models and tools that focus not on a particular application area but rather on the generic technique of multi-touch interaction and design. The new biomechanical models will also contribute to our fundamental understanding of the functioning of our hands. Project outcomes will be generalizable to other emerging types of input devices, such as the Nintendo Wii remote."
"1319674","Student Travel Support for the 2013 SIAM International Conference on Data Mining","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","05/15/2013","05/03/2013","Chandan Reddy","MI","Wayne State University","Standard Grant","Sylvia J. Spengler","04/30/2015","$28,000.00","","reddy@cs.wayne.edu","5057 Woodward","Detroit","MI","482023622","3135772424","CSE","1640, 7364","1640, 7364, 7556","$0.00","This award provides travel support for approximately 26 students to attend the 2013 SIAM Data Mining (SDM 2013) Conference (and the Doctoral Student Forum) that is being organized by the Society for Industrial and Applied Mathematics (SIAM) in cooperation with the American Statistical Association. SDM 2013 is being held in Austin, Texas, USA from May 2 to 4, 2013. The Doctoral Forum will consist of a poster session for Ph.D. candidates in data mining or closely related areas or Ph.D. students who have made significant progress towards Ph.D. candidacy. The Ph.D. student forum participants will be able to present their work, interact with their peers from other universities as well as hundreds of leading researchers in data mining from around the world. In addition, they will attend the technical sessions, plenary talks, and tutorials and workshops of their choice at the conference. Each student will be assigned a senior researcher to serve as a mentor on a variety of career-related issues.<br/><br/>Participation in premier research conferences in data mining is an integral component of the training of Ph.D. students in data mining. The SDM 2013 Doctorul Student Forum is aimed at providing an opportunity for Ph.D. candidates to present their work and receive constructive feedback and mentoring from established researchers in data mining. Such feedback and mentoring is expected to improve the quality of the students thesis research. Similarly, student recipient of a travel award will be able to attend technical sessions, plenary talks, panels, tutorials and workshops. They will interact with peers who share similar interests from other universities, as well as hundreds of leading researchers in data mining from around the world. This experience will be extremely formative and fruitful towards the shaping of their future research endeavors.<br/><br/>Data mining is playing an increasingly important role in many emerging data-rich sciences and application domains, such as healthcare informatics, bioinformatics, computational biology, link analysis, counterterrorism and security. The SDM 2013 Doctoral Student forum will enrich the education and training of student researchers at early stages in their careers. Attendance in SDM 2013 will expose students to cutting-edge research and to relevant applications in a variety of domains. The travel awards will help broaden the participation of women and members of under-represented groups within the Data Mining research community."
"1254206","CAREER: A Novel Framework for Knowledge Discovery from Time Series Data in Biology and Climate Science","IIS","INFO INTEGRATION & INFORMATICS","03/15/2013","02/21/2014","Yan Liu","CA","University of Southern California","Continuing grant","Sylvia J. Spengler","02/28/2018","$308,010.00","","yanliu.cs@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7364","1045, 7364","$0.00","Recent advances in sensors and high throughput data acquisition technologies have made it possible to collect massive amount of data, and especially time series data in a number of domains (e.g., climate sciences, biological sciences). While a wide range of techniques have been developed for clustering and mining such data, there has been limited progress on scalable algorithms for extracting causal relationships from time series data. This project aims to develop novel machine learning models based on Granger causality to uncover the complex dependence structures from high-dimensional time series. The resulting algorithms will be evaluated in the context of two real-world applications (climate change, computational biology).<br/><br/>The project aims to address three fundamental challenges of data analysis from time series data, including: (1) developing the theoretical foundations of causality analysis from time series data to quantify the gap between Granger causality and true causality, (2) developing a unified framework to incorporate different types of domain knowledge in data analysis, and (3) examining effective solutions to important but usually overlooked practical issues, including irregular nature of the time series and scalability. The resulting algorithms will be evaluated on two real applications, i.e., gene regulatory network discovery in immune systems and climate change attribution, by collaborating with researchers in biology and climate science.<br/><br/>The proposed research could impact multiple application domains where discovery of causal relationships from high dimensional time series data is of interest. The project is expected to advance the theoretical foundations of data analytic techniques for time-series data and provide a unified framework that can easily integrate domain knowledge. The results of this project can be expected to significantly advance the current state of the art in eliciting insights regarding causal relationships from time series data. In addition to the core research advances, this project contributes easy-to-use software based on workflows for teaching machine learning to students, researchers and practitioners with a broad range of backgrounds. Educational and outreach activities include new interdisciplinary courses, workshops, tutorials, and high-school visits. Software and data resulting from this work will be freely disseminated to the broader research and educational community. Additional information about the project can be found at: http://www-bcf.usc.edu/~liu32/uscTimeSeries.htm."
"1253950","CAREER: Robust Strategic Reasoning for Multi-Agent Systems","IIS","ROBUST INTELLIGENCE","02/15/2013","02/21/2014","Christopher Kiekintveld","TX","University of Texas at El Paso","Continuing grant","Todd Leen","01/31/2018","$197,167.00","","cdkiekintveld@utep.edu","ADMIN BLDG RM 209","ElPaso","TX","799680587","9157475680","CSE","7495","1045, 7495","$0.00","Many important decision problems in computational science involve multi-agent systems (MAS) in which multiple decision makers must choose strategies for action from a set of alternatives. (One example is selecting a security policy --- for example by police --- to protect critical infrastructure against attackers.) This CAREER award project develops methods for analyzing MAS to select strategies for an agent to follow that will lead to desirable outcomes. <br/><br/>The central tenant driving the project is that a good strategy should be robust in the sense that it will continue to perform well even when there is uncertainty about the outcomes or how other agents will choose their strategies. An important component of the project is a multi-purpose web platform supporting both research experiments and education on game-playing agents. The PI will design course modules that use this platform to involve undergraduates in designing game-playing agents, offering an exciting way to practice basic programming and develop critical thinking and data analysis skills. The agents designed by students also play an important role in the research; they will provide a diverse library of strategies to evaluate the robustness of reasoning methods for play against opponents with unanticipated behaviors. This platform, and the data sets generated with it will serve the broader research and education communities in computer science and MAS.<br/><br/>Research on robust methods for strategic reasoning has the potential to significantly improve decision making in many important real-world problems, including decision support tools for homeland security operations. The availability of robust methods will also enable new applications of computational game theory in domains where confidence in the strategies, despite uncertainty, is critical. This award also supports broadening participation by developing research capacity at UTEP, a minority-serving institution. <br/><br/>The project's primary technical contributions are in computational game theory. Typical game-theoretic solutions are not robust to the kinds of uncertainty that arise in real applications; these include payoff uncertainty, abstraction error, and opponent modeling error. Robustness requires techniques that encompass unanticipated situations, as well as those where it is possible to precisely characterize the uncertainty. The project extends the framework of meta-games to provide a methodology for evaluating robustness in the context of different kinds of uncertainty, including the three listed above. The PI uses meta-games to evaluate new concepts for robust strategic reasoning, including methods based on Bayesian games, interval-based approaches, and approaches drawn from behavioral game theory. The web-based platform developed in the project facilitates extensive experiments with game-playing agents. This will be used to collect a diverse pool of unanticipated agent strategies (including ones designed by undergraduate students), enabling a more comprehensive investigation of robustness to unanticipated opponent behaviors."
"1149783","CAREER: Visual Tracking with Online and Prior Learning","IIS","ROBUST INTELLIGENCE, OTHER GLOBAL LEARNING & TRNING","01/01/2012","02/20/2014","Ming-Hsuan Yang","CA","University of California - Merced","Continuing grant","Jie Yang","12/31/2016","$279,688.00","","mhyang@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2092284318","CSE","7495, 7731","1045, 5950, 5979, 7495","$0.00","This project develops efficient and effective algorithms to handle challenging problems in visual tracking such as drift, heavy occlusion, and failure recovery. The research team is developing an integrated framework in which object detection, tracking and recognition are addressed simultaneously. Within this framework, the prior knowledge is learned from a large set of images pertaining to object classes of interest. Such knowledge serves as long-term memory for the proposed appearance models which are then adapted to unseen new object instances. In addition, a top-down saliency model for each object class of interest is developed in order to handle heavy occlusion and failure recovery. The project has four major components: developing algorithms for learning visual prior and transferring knowledge for online appearance model, designing tracking algorithms that handle draft with the proposed appearance model, modeling top-down saliency maps to handle full occlusion and tracking failure, evaluating state-of-the-art algorithms with a large benchmark dataset. <br/><br/>This project provides a building block for robust object tracking, which can be applied to motion analysis, surveillance, and multi-object tracking. The developed top-down saliency map provides a flexible way to represent objects, which can be extended to object detection and segmentation. The proposed tracking library and benchmark data set provide a platform for evaluation of advances in object tracking. This research is integrated with education and outreach by courses and activities aimed at attracting students to this field and encouraging interdisciplinary collaborations."
"1149803","CAREER: A New Neat Framework for Statistical Machine Learning","IIS","ROBUST INTELLIGENCE","03/01/2012","02/20/2014","Pradeep Ravikumar","TX","University of Texas at Austin","Continuing grant","Todd Leen","02/28/2017","$274,094.00","","pradeepr@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","1045","$0.00","The pendulum in Artificial Intelligence (AI) research has periodically swung from so called ""neat"" or mathematically rigorous approaches, and ""scruffy"" or more adhoc approaches. In recent years, real-world data across varied fields of science and engineering are increasingly complex, and involve a large number of variables, which has resulted in a surge of scruffier methods. This proposal develops a general ""neat"" framework for such modern settings by leveraging state of the art developments in two of the most popular subfields of machine learning methods: graphical models and high-dimensional statistical methods. These developments have in common that a complex model parameter is expressed as a superposition of simple components, which is then leveraged for tractable inference and learning.<br/><br/>Our unified framework results not only in a unified picture of these developments but also provides newer methods to work with such high-dimensional data. The research thus impacts problems across science and engineering wherever statistical machine learning approaches are being used (such as genomics, natural language processing and image analysis, to name a few). The work on a unified framework for statistical machine learning problems is highly coupled with a push for imparting training to students on what we call ""comptastical"" thinking. This combines both computational and statistical thinking required for addressing the problems of limited computation and limited data inherent in modern statistical AI application domains. The proposal also develops an infrastructure for component-based courses with relationally organized lecture module components."
"1149851","CAREER: A novel framework for mining graph patterns in large biological and social networks","IIS","INFO INTEGRATION & INFORMATICS","03/01/2012","02/20/2014","Mohammad Hasan","IN","Indiana University","Continuing grant","Sylvia J. Spengler","02/28/2017","$385,991.00","","mahasan@iupui.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7364","1045","$0.00","Frequent subgraph mining is a core task in data mining which can be applied to various real-life problems related to graphs and networks. Presently, the research value of this task has been heightened by the increased availability of massive network data in the domains of life and social sciences. However, existing algorithms for subgraph mining suffer from various limitations; noteworthy among these are lack of scalability, lack of user interaction and the absence of a mechanism to mine dynamic graphs. This research aims to overcome the above limitations by accomplishing the following three related tasks: (1) use of Monte Carlo sampling mechanisms for designing scalable graph mining algorithms; (2) develop real-time interactive graph mining systems using subgraph sampling approaches; and (3) discover models for graph evolution that are based on sampling and driven by the principles of game theory and economics.<br/><br/>This research builds a novel paradigm for subgraph mining that is based on Monte Carlo sampling. This allows the development of algorithms that are scalable, by avoiding the need to enumerate all subgraph patterns. The resulting algorithms will be applied to subgraph mining problems in systems biology, e.g., predicting disease pathways by mining graphs from genomics and proteomics co-expression networks. A second outcome of this research is an interactive pattern mining framework using subgraph sampling where user feedback guides updates of the sampling distribution such that subsequent sampling prioritizes patterns that are considered ""interesting"" to the user. A third outcome is a subgraph sampling method that uses a game theoretic mechanism to design a subgraph evolution model for prediction tasks (such as link prediction) in dynamic networks. <br/><br/>Broader Impacts: Availability of tools for mining large graphs enables the opportunity to build network biomarkers, which are novel signatures for disease diagnosis and risk factor analysis. A sampling based interactive pattern system is instrumental to mine ""interesting"" associations between diseases and medicines from numerous hidden datasets that are currently unexplored in many hospitals and health clinics. Scalable graph mining algorithms are also likely to find use in search, e-commerce and social networks based industry. The educational goal of this research is to leverage the PI's industrial experience to develop a ""Large-scale data analysis"" course on methods needed to build data mining systems that work on industry-scale data.<br/><br/>Additional information about the project, including the findings, methods, open source implementations of algorithms, publications and data can be accessed through the project website at http://www.cs.iupui.edu/~alhasan/graph_mining."
"1149633","CAREER: Non-Parametric Image Parsing","IIS","ROBUST INTELLIGENCE","03/01/2012","02/20/2014","Robert Fergus","NY","New York University","Continuing grant","Jie Yang","02/28/2017","$288,997.00","","fergus@cs.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","1045","$0.00","This project develops new techniques for visually interpreting an image in a way that specifically leverages large image collections, now common on the web and elsewhere. The research team uses an approach whose performance directly scales with the size of the dataset, unlike many existing approaches to image understanding. The basic approach is to build a copy of a query image by assembling pieces of image from a large set of training images, in the manner of a jigsaw. Each region in the query is classified by copying labels from the matched regions. The larger the training set, the more jigsaw pieces there are to choose from, thus the more accurate the match.<br/><br/>The initial work of the project focuses on developing efficient methods for performing the matching that allow the incorporating of various desirable constraints. The approach is then extended to handle training data with incomplete labels -- important since few datasets have labels for every region. The research plan also includes building better embeddings for the regions which place semantically similar regions closer together than current representations do, and developing efficient binary matching schemes along with further work on the region embeddings. <br/><br/>Robust techniques for visual recognition have widespread applicability, in such areas as image search, robotics and surveillance. The project also involves extensive outreach activities, including high-school internships and the organization of a NY-area vision day for students and researchers"
"0953756","CAREER: New Directions in Computing Game-Theoretic Solutions: Commitment and Related Topics","IIS","ROBUST INTELLIGENCE, COMPUT GAME THEORY & ECON, ALGORITHMIC FOUNDATIONS","03/01/2010","02/19/2014","Vincent Conitzer","NC","Duke University","Continuing grant","James Donlon","02/28/2015","$500,002.00","","conitzer@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495, 7932, 7796","1045","$0.00","Game Theory occupies an important place in the foundations of multi-agent systems in artificial intelligence. Research under this award focuses on settings where one agent can commit to her (possibly randomized) strategy before the other agent moves. We consider how to compute optimal strategies to commit to in games with a combinatorial structure, extensive-form games, and repeated/stochastic games. Among other topics are connections to learning in games and mechanism/environment design, and the implications of commitment for the efficiency of computing game-theoretic solutions more generally.<br/><br/>The main objective of the research is to make scientific contributions to artificial intelligence, multi-agent systems, and computational game theory, but to also advance real-world applications. For example, other researchers have expanded on the PI's prior theoretical research (with his PhD advisor) to apply the commitment framework to security applications, such as the placement of checkpoints and canine units at Los Angeles International Airport and the scheduling of Federal Air Marshals. The research performed under this award aims to provide a solid scientific foundation for improving and expanding this and related applications. The award also helps to build connections between computer science and economics, the traditional home of Game Theory. This interdisciplinary link can help diversify the computer science community, intellectually and demographically. Research is tightly integrated with the PI's educational efforts, which include the development of courses in Computational Microeconomics and Game Theory and an approved Computational Economics minor."
"0953445","CAREER: Capturing Content and Linguistic Quality in Automatic Extractive and Abstractive Summarization","IIS","ROBUST INTELLIGENCE","02/01/2010","02/19/2014","Ani Nenkova","PA","University of Pennsylvania","Continuing grant","Tatiana D. Korelsky","01/31/2015","$549,933.00","","nenkova@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7495","1045, 1187, 9102","$0.00","This CAREER proposal deals with the development of novel systems for automatic summarization which incorporate both linguistic and content quality considerations in their operation. The main motivation for the work is that even the best current systems do not take the characteristics of the input into account during their operation, they cannot estimate how successful they perform content selection, and completely ignore issues of linguistic quality of the output.<br/><br/>Improvement of linguistic quality of summaries requires a combination and relative assessment of a wide range of text quality factors:<br/>discourse relations, topic/entity/word coherence, form of referring expressions, vocabulary. Tools for automatic extraction of such models from the input text, including automatic discourse analysis of explicit and implicit discourse relations, are developed as part of the project. The resulting models of linguistic quality will have broader impact on a whole range of text producing applications including questions answering, machine translation, automatic essay grading and computer-assisted writing tutoring.<br/><br/>Improvement of content quality requires taking into account characteristics of the input. In particular, we develop measures of input difficulty, which enable systems to automatically predict if they can produce a good quality summary for a given input and permit for change of summarization strategy when necessary. Specialized summarization strategies for input types where current system performance is known to be suboptimal are also elaborated.<br/><br/>Text quality and summarization are research topics with cross-disciplinary appeal. The PI will offer project-based courses at the undergraduate and graduate level which have the potential to attract young people to the field of computer science."
"1149837","CAREER: Mining structure and dynamics of groups of nodes in real-world networks","IIS","INFO INTEGRATION & INFORMATICS","01/15/2012","02/20/2014","Jurij Leskovec","CA","Stanford University","Continuing grant","Sylvia J. Spengler","12/31/2016","$339,045.00","","jure@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7364","1045","$0.00","Social, technological, information and biological systems can be studied as graphs, where nodes represent entities (i.e., people, websites) and edges represent interactions (friendships, communication). The project aims to analyze and discover explanatory and predictive models of networked systems, such as large groups of people and societies, or large biological and technological systems, in order to understand their structure and make predictions about their global dynamics.<br/><br/>The research studies the structure and dynamics of communities of nodes, with the goal to invent novel network community detection methods and build predictive models of behavior of groups of nodes. The proposed research has three main thrusts: (1) Structure and discovery of network communities, (2) Dynamics and ""health"" of network communities, and (3) Supervised community detection in networks with rich node and edge metadata. The research focuses on harnessing massive network datasets, as certain behaviors and patterns are observable only when the amount of data is large enough. The intellectual focus of the project is on increasing the expressivity of the models to also include rich node and edge metadata and explore the connections between the network structure and the attributes/features of nodes and edges.<br/><br/>The education plan provides for rich research experiences and helps students develop the interdisciplinary attitudes and skills needed for this work through courses that look at real-world network problems and data. An integral part of this proposal is public release of datasets and computational tools for analysis of large networks. Additional information about the project including publications, data sets, source code, and educational materials can be accessed through the project website at http://snap.stanford.edu."
"1144106","CAREER: Probabilistic Methods for Addressing Complexity and Constraints in Protein Systems","IIS","INFO INTEGRATION & INFORMATICS","03/01/2012","02/20/2014","Amarda Shehu","VA","George Mason University","Continuing grant","Sylvia J. Spengler","02/28/2017","$292,581.00","","ashehu@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7364","1045, 9251, 9102","$0.00","The proposed activity involves a research environment and educational curriculum dedicated to dealing efficiently with the complexity and constraints that protein molecules pose to computational studies. The emphasis is on elucidating the motions that proteins employ for biological function. This is a fundamental issue in the understanding of proteins and biology due to the central role of proteins in cellular processes.<br/><br/>The research addresses fundamental issues in protein modeling. Understanding proteins in silico involves searching a vast high-dimensional conformational space of inherently flexible systems with numerous inter-related degrees of freedom, complex geometry, physical constraints, and continuous motion. Three core research directions are identified. (1) Geometric constraints underlying protein motion are not trivial to identify or address. The proposed research exploits mechanistic analogies between proteins and robot kinematic linkages and investigates inverse kinematics techniques to efficiently formulate and address complex geometric constraints arising in diverse protein studies. (2) The funnel-like protein energy landscape exposes physics-based energetic constraints that are often demanding to address in silico. The proposed research pursues a multiscale treatment of energetic constraints in the context of probabilistic search, supporting coarse- and fine-grained levels of protein representational detail and converting between them with information gathered during exploration. (3) The conformational ensemble view of the protein state relevant for function necessitates search algorithms capable of exploring the high-dimensional conformational space and its rugged energy landscape. A novel probabilistic search framework is proposed that gathers information about the space it explores and employs this information to advance towards promising unexplored regions of the space. Taken together, these research directions allow addressing complexity in proteins by formulating and exploiting geometric and energetic constraints, thus narrowing the search space of interest to regions where the constraints are satisfied, and by employing a novel probabilistic framework with enhanced sampling capability able to feasibly search the relevant regions of the space.<br/><br/>The proposed activity promises to advance discovery and understanding both in the computer science and protein biophysics communities. Since most problems of practical interest are high-dimensional and often exhibit complex non-linear spaces, the proposed research cuts across and spans multiple areas in computer science, such as robot motion planning, optimization in complex non-linear spaces, and modeling and simulation of complex physics-based systems. In particular, the research will reveal effective probabilistic search strategies for continuous high-dimensional search spaces. Analogies with articulated mechanisms will offer insight on how to generate valid robot configurations in the presence of constraints. On the biophysical side, the research promises to advance protein modeling and understanding across diverse applications. The proposed activity involves interdisciplinary collaborations with computer scientists, biophysicists, and chemists. Findings and data will be disseminated broadly to enhance scientific understanding across diverse communities. Specific educational objectives focusing on curriculum design and outreach activities are formulated to employ the proposed research for broadening the participation of college and pre-college students, with a particular emphasis on underrepresented groups."
"1350339","CAREER: Combining Crowdsourcing and Computational Creativity to Enable Narrative Generation for Education, Training, and Healthcare","IIS","Cyber-Human Systems","02/15/2014","02/20/2014","Mark Riedl","GA","Georgia Tech Research Corporation","Continuing grant","Kevin Crowston","01/31/2019","$99,657.00","","riedl@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","1045, 7367","$0.00","The proposed project explores the problem of automated narrative generation, the creation of narratives by computer systems. The project introduces a transformative new approach to narrative generation that blends human and computational creativity with crowdsourcing. The system addresses fundamental limitations of computer reliance on pre-coded domain knowledge in order to generate a virtually unlimited variety of narratives and make it possible for non-experts and non-programmers to create interactive narratives. The research has four major components: (1) Develop artificial intelligence algorithms that emulate human ability to create narratives. (2) Design and implement novel models of human-computer creative collaboration. (3) Study fundamental questions pertaining to human narrative learning and cognition. (4) Explore the role of narrative generation in real-world domains: virtual agents that create rapport with humans and intelligent creativity augmentation tools for creating and sharing interactive experiences. The work will be piloted in two healthcare systems: a virtual agent that creates rapport and fosters longitudinal engagement with patients through autobiographical narratives; and intelligent tools that allow caregivers to create social skill scenarios for young adults with autism to practice. <br/><br/>Narratives are important because they are a fundamental means by which humans organize, understand, and explain the world. If computer systems could create effective narratives, they would be better able to interact with people. The research will result in novel algorithms, software, and a body of experimental knowledge that will enable the building of interactive narrative systems that are practical, scalable, usable by non-programmers, and can address societally important problems in education, training, and healthcare interventions. The proposed approach to creativity support will significantly lower the technical, artistic, and skill barriers to creating interactive narrative systems, opening avenues for educators, trainers, caregivers, and hobbyists to create and share interactive experiences.<br/><br/>The project includes an educational plan to develop a sustainable, annual summer hack-a-thon camp wherein high school students work alongside K-12 teachers to create interactive narratives that motivate and guide classroom inquiry based learning. The hack-a-thon aims to provide minority and low socioeconomic high school students with hands-on computing science experience and to produce a library of interactive inquiry-based learning software systems for K-12 teachers."
"1065270","RI: Medium: Collaborative Research: Learning Representations of Language for Domain Adaptation","IIS","ROBUST INTELLIGENCE","04/01/2011","02/20/2014","Douglas Downey","IL","Northwestern University","Continuing grant","Tatiana D. Korelsky","03/31/2015","$200,000.00","","ddowney@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495","7924, 7495","$0.00","Supervised Natural Language Processing (NLP) systems perform poorly on domains and vocabulary that differ from training texts. A growing body of empirical and theoretical work points to the features used by traditional NLP systems as the culprit for domain-dependence and for the inability to generalize to previously unseen words. <br/><br/>This project is the first to systematically investigate representation-learning as a technique for improving performance on domain adaptation. It explores latent-variable language models ? including Factorial Hidden Markov Models, dependency parsing models, and deep architectures ? as techniques for extracting novel features from text. The resulting representations yield similar features for distributionally-similar words, thereby allowing generalization to words not seen during training of a classifier. The project also explores novel procedures for training a language model, which incorporate Web-scale ngram statistics as substitutes for standard statistics used in unsupervised training.<br/><br/>Language users are extraordinarily inventive, and new domains of discourse appear constantly, such as in specialized areas of science and technology. By building on top of the representations produced by this project, NLP systems can improve in accuracy on new domains and on Web text, bringing applications like the Semantic Web closer to reality. For resource-poor languages and domains, the project can help reduce the cost of annotating texts by reducing the need for broad coverage in the training texts. By involving the diverse student bodies at Temple University and Philadelphia-area high schools, the project helps to broaden participation in computer science research by underrepresented groups."
"1149965","CAREER: Toward Automating Surgical Tasks","IIS","ROBUST INTELLIGENCE","03/01/2012","02/20/2014","Ron Alterovitz","NC","University of North Carolina at Chapel Hill","Continuing grant","Satyandra Gupta","02/28/2017","$266,694.00","","ron@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","1045","$0.00","This project, developing a new motion planning framework for medical robots that combines automatic planning algorithms, robot control, and human oversight to enable new and safer robotic procedures that are beyond current clinical capabilities, will increase the autonomy of surgical robotic systems. This framework will result in improved speed, accuracy, and precision of existing procedures and enable entirely new classes of procedures that require dexterity and control beyond the capability of a human operator. <br/><br/>The funding of this proposed work will introduce and evaluate a new motion planning framework that simultaneously addresses the challenges of deformations, uncertainty, and optimality that arise in medical applications. The research will combine ideas from multiple areas of computer science and engineering, including robotics, computer graphics, finite element methods, optimization theory, Markov decision processes, stochastic modeling, and learning from demonstrations. Expected scientific contributions include new motion planning algorithms that efficiently integrate physically-based simulation, motion planning under uncertainty, and sensor placement, as well as new approaches to integrate user input into feedback-based motion planning. In the long term, these contributions may lead to new avenues of research at the intersection of motion planning, anatomy and biomechanical modeling, learning from demonstrations, and medical robotics.<br/><br/>Broader Impacts: A motion planning framework for medical robots will improve patient care and the resulting increased autonomy will reduce surgical errors -- which currently contribute to 1 in 10 post-surgical deaths -- by enabling physicians to focus on high-level tasks rather than low-level motion control. The application of this framework to prostate interventions, lung biopsies, and neurosurgery could affect hundreds of thousands of people annually and have broad societal impact. The ability of computer science to improve healthcare may attract new students to computer science who might previously not have been interested in the field, particularly women and underrepresented groups. The PI will develop new outreach activities centered around an interactive game-like simulation of medical procedures that highlights the impact that computer science can have on medicine, create a new undergraduate course for pre-meds to teach future physicians crucial computer science concepts, and revamp the robotics curriculum to create excitement through labs and provide students with the skills necessary to pursue a career in America's growing healthcare and service robotics industries."
"1054199","CAREER: Eyes of the Foreseer - Integrative and In Situ Information Retrieval and Mining in Online Communities","IIS","INFO INTEGRATION & INFORMATICS","01/15/2011","02/19/2014","Qiaozhu Mei","MI","University of Michigan Ann Arbor","Continuing grant","Maria Zemankova","12/31/2015","$352,619.00","","qmei@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364","1045, 7364","$0.00","With the growth of online communities, the Web has evolved from networks of shared documents to networks of knowledge-sharing groups and individuals. A vast amount of heterogeneous yet interrelated information is being generated for which existing information analysis techniques are inadequate. Current tools often neglect the actual creators and consumers of information, and as a result, the findings are only useful to data analysts. <br/><br/>The user-centric Foreseer is the next generation of information analysis for online communities. It represents a new paradigm of study through the four ""C's"": content, context, crowd, and cloud. Information analysis of content is put into the context of the users' daily lives to benefit the communities (crowd) that generate information residing in the cloud. This project provides integrative and in situ analysis of information generated in online communities that is of the people, by the people, and for the people. Research of Foreseer consists of formal community models, efficient data analysis tools, advanced solutions of real applications, and novel information systems.<br/><br/>Making the results available to everyday Web users, not just data analysts, will result in improved dissemination of ideas, shared public opinions, and wise decision-making in online communities. Novel Web-based information systems will form prototypes that can be used in online social and health communities. The research will enhance the current information analysis and retrieval curricula and lead to a number of new classes in information science and health informatics. Research results will also be published on the project Web site (http://www-personal.umich.edu/~qmei/foreseer/)."
"1422020","ACL 2014 Student Research Workshop","IIS","ROBUST INTELLIGENCE","03/01/2014","02/19/2014","Jordan Boyd-Graber","MD","University of Maryland College Park","Standard Grant","Tatiana D. Korelsky","02/28/2015","$15,000.00","","jbg@umiacs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7556","$0.00","The Association for Computational Linguistics (ACL) is the primary international organization in the field of natural language processing, and its annual conference is the primary international conference in this research field. This project supports the travel, conference, and housing expenses of students selected to participate in the Association for Computational Linguistics (ACL) Student Research Workshop, held in conjunction with the ACL conference on June 23-25, 2014 in Baltimore. The workshop consists of two tracks: full paper presentations and poster presentations. All selected work has only student authors. The full paper sessions are composed of paper presentations followed by a discussion panel led by respected researchers in the field. The workshop is organized and run by students.<br/><br/>The Student Research Workshop provides a valuable opportunity for the next generation of researchers to enter the computational linguistics community. It allows the best students in the field to receive critical feedback on their work from external experts and to forge contacts with other students and senior researchers. The organizers also pair each participant with a senior researcher to provide specific feedback on the students' research. The students who select papers for the workshop and plan the sessions also gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference. The workshop contributes to the maintenance and development of a skilled and diverse computational linguistics and natural language processing research community."
"1053856","CAREER: Bayesian Models for Lexicalized Grammars","IIS","ROBUST INTELLIGENCE","02/01/2011","02/19/2014","Julia Hockenmaier","IL","University of Illinois at Urbana-Champaign","Continuing grant","Tatiana D. Korelsky","01/31/2016","$419,047.00","","juliahmr@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","1045, 1187, 7495","$0.00","Natural language processing (NLP) is a key technology for the digital age. At the core of most NLP systems is a parser, a program which identifies the grammatical structure of sentences. Parsing is an essential prerequisite for language understanding. But despite significant progress in recent decades, accurate wide-coverage parsing for any genre or language remains an unsolved problem. The broader impact of this CAREER project will be to advance the state of art in NLP technology through the development of more accurate statistical parsing models. <br/><br/>Since language is highly ambiguous, parsers require a statistical model which assigns the highest probability to the correct structure of each sentence. The accuracy of current parsers is limited by the amount of available training data on which their models can be trained, and by the amount of information the models take into account. This CAREER project aims to advance parsing by developing novel methods of indirect supervision to overcome the lack of labeled training data, as well as new kinds of models which incorporate information about the prior linguistic context in which sentences appear. It employs Bayesian techniques, which give robust estimates and allow rich parametrization, and applies them to lexicalized grammars, which provide a compact representation of the syntactic properties of a language.<br/>This CAREER project will also train graduate students in natural language processing and develop materials that can be used to teach middle and high school students about NLP and to inspire them to pursue an education in computer science."
"1256036","EAGER: Collaborative Research: Sequential Recommender Systems in Mobile and Pervasive Environments","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/30/2012","Alexander Tuzhilin","NY","New York University","Standard Grant","Maria Zemankova","08/31/2014","$74,734.00","","atuzhili@stern.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7364","7364, 7916","$0.00","Individuals on the move, e.g., tourists on a sightseeing trip in an unfamiliar city often find themselves overwhelmed by the challenges of coping with unfamiliar environments. This presents a need for tools and methods that will guide them by providing them useful recommendations while they are ""on the move."" Recent advances in mobile and sensor-based technologies have made it possible to collect and process location traces across many different mobile applications. Such data, when combined with other spatio-temporal, contextual, and user-specific information can, in principle, be used to generate useful recommendations for individuals on the move. <br/><br/>This exploratory research project formulates and explores a novel variant of recommender systems, namely, mobile sequential recommender systems for mobile users where each recommendation takes into account the trajectory and history of past recommendations, as one of selecting a sequence of locations to recommend under a set of spatio-temporal, contextual, and privacy constraints. Given the combinatorial nature of the problem (where the size of the search space grows is exponential in the relevant parameters) the project aims to explore heuristics. It will also develop appropriate measures for assessing the effectiveness of alternative solutions.<br/><br/>The project, if successful, would establish the feasibility of a line of investigation that could lead to the development of effective approaches to sequential recommendation problem with obvious benefits to mobile users. The project enriches research based advanced training opportunities for graduate and undergraduate students. All of the data, software, and publications resulting from the project will be made freely available to the broader research community."
"0845439","CAREER: New Technologies for Querying Pathway Databases","IIS","INFO INTEGRATION & INFORMATICS","02/15/2009","02/19/2013","Tamer Kahveci","FL","University of Florida","Continuing grant","Frank Olken","01/31/2015","$400,000.00","","tamer@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7364","1045, 1187, 7364, 9216, HPCC","$0.00","Unlike most bioinformatics data, such as DNA sequences and protein<br/>structures, pathways show the interactions of different bio-chemical<br/>entities. Thus, each entity or subpathway can have a function in its<br/>pathway that the pathway can not realize without it. Formulating these<br/>functions presents exciting computational challenges. <br/><br/>This proposal develops algorithms for efficient and accurate<br/>computational analysis of pathways. The first step in achieving this<br/>goal is to build a mathematical model for functions of pathways and<br/>subpathways. This proposal defines the function of a subpathway as its<br/>contribution to the steady state of the entire pathway. Computing this<br/>contribution is a difficult problem especially for gene regulatory<br/>pathways. Existing methods can compute this for metabolic pathways,<br/>but they do not scale to even medium sized gene regulatory<br/>pathways. This proposal develops efficient methods for computing<br/>function.<br/><br/>Finding the subpathway that has a desired function is a challenging<br/>problem. There is no clear way of searching for subpathways with<br/>desired functions using existing tools. This proposal develops<br/>efficient algorithms for searching subpathways with desired function.<br/>This proposal takes this one step further, and develops mathematically<br/>sound algorithms for comparing two pathways so that the entities that<br/>map are functionally, homologically and topologically similar. This<br/>proposal also explores feature and reference-based index structures<br/>for biological pathway databases.<br/><br/>Further information on the project can be found at the project web<br/>page:<br/> http://bioinformatics.cise.ufl.edu/"
"1065009","HCC: Medium: Collaborative Research: Generating Accurate, Understandable Sign Language Animations Based on Analysis of Human Signing","IIS","Cyber-Human Systems, IIS SPECIAL PROJECTS","07/01/2011","05/08/2013","Matt Huenerfauth","NY","CUNY Queens College","Continuing grant","Ephraim P. Glinert","06/30/2015","$359,005.00","","matt@cs.qc.cuny.edu","65 30 Kissena Blvd","Flushing","NY","113671575","7189975400","CSE","7367, 7484","7367, 7924, 9251","$0.00","American Sign Language (ASL) animations have the potential to make information accessible to many deaf adults in the United States who possess only limited English literacy. In this research, which involves collaboration across three institutions, the PIs' goal is to gain a better understanding of ASL linguistics through computational techniques while advancing the state of the art in the generation of ASL animations for accessibility applications for people who are deaf. To these ends, the PIs will develop linguistically based models of two aspects of ASL production: movements required for head gestures and facial expressions that carry essential grammatical information and frequently extend over domains larger than a single sign, and the timing and coordination of manual and non-manual elements of ASL signing. Preliminary work has shown that these issues significantly affect how well signers understand ASL animations, and that these aspects of current ASL animation technologies require improvement. How should the face of a human or animated character be articulated to perform, with accuracy, the linguistically meaningful facial expressions that are part of ASL grammar? How should the onsets, offsets, and transitions of these movements be produced? How should the facial expressions and hand movements be temporally coordinated so that the ASL production is as grammatically correct and understandable as possible? To answer open questions such as these, the PIs' novel approach will apply techniques from computer vision to linguistically annotated video data collected from human signers, in order to produce models for use in animation-production. The PIs will expand their existing annotated video ASL corpora through new data collection and annotation, and will analyze these data to study the use, timing, and synchronization of manual and non-manual components of ASL production. The annotated videos will be used to train high quality computer vision models for recognition of linguistically significant facial expressions and timing subtleties. Parameters of these computer vision models will be used to hypothesize computational models of ASL timing and facial movements, to be incorporated into ASL-animation generation software and evaluated by native signers. The models will be iteratively refined in cycles of user-based studies and incorporated into ASL animation technologies to more accurately mimic human signing. Project outcomes will include high quality models of the movement of virtual human characters for animations of ASL performance. The analysis of video corpora of ASL will produce new linguistic insights into the micro-facial expressions and the temporal coordination of the face and hands in ASL production, while advances in the analysis of ASL prosody will contribute to an understanding of the fundamental commonalities and modality-specific differences between signed and spoken languages that is essential to a full understanding of the human language faculty. The creation of new modeling approaches and recognition techniques will advance the field of computer vision, by benefiting the identification and tracking of the human face and body in video during the rapid and complex movements of ASL (and other forms of human movement).<br/><br/>Broader Impacts: This research will lead to significant improvements to technology for generating linguistically accurate ASL animations, which will make information, applications, websites, and services more accessible to the large number of deaf individuals with relatively low English literacy. Advances in computer vision techniques for recognizing ASL in videos of humans will have general applicability in human-computer interaction, recognition and animation of facial expressions, and computer vision. The corpora created in this project will enable students and researchers in both linguistics and computer science (including those without access to the requisite technological and human resources to carry out their own data collection from native signers and time-intensive linguistic annotations) to engage in research on ASL. The techniques to be developed will also enable partial automation of the time-consuming creation of annotated ASL video corpora. As in the PIs' earlier work, the proposed research will create opportunities for people who are deaf and members of other underrepresented groups to participate in scientific research."
"1359499","REU Site: Summer Undergraduate Program in Engineering Research at Berkeley-Information Technology for Sustainability (SUPERB-ITS)","CNS","RSCH EXPER FOR UNDERGRAD SITES, ROBUST INTELLIGENCE","02/15/2014","02/18/2014","David Culler","CA","University of California-Berkeley","Standard Grant","Anindya Banerjee","01/31/2017","$314,968.00","","culler@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","1139, 7495","9250","$0.00","This award renews a Research Experience for Undergraduates (REU) site at the University of California, Berkeley. The intellectual focus of the proposed research is information technology for sustainability through the efficient extraction, distribution and use of energy. The site will bring together a cohort of 8 undergraduate students per year who, together with faculty mentors, will participate in a range of projects based on the energy and sustainability theme. The site focuses on recruiting a sufficiently diverse pool of students, including women and underrepresented minorities.<br/><br/>The main intellectual merit of the proposal is the innovative projects designed to optimize energy consumption and thereby promote sustainability. Example projects are (a) optimal control of building systems; (b) energy efficient air traffic control; (c) energy efficient, power proportional data centers; and (d) energy management systems for smart building infrastructures. A separate strand of work will consider how to retain performance speedups in the presence of low energy devices since often performance and energy consumption are inversely related. Students will be mentored by both faculty and graduate students and will be exposed to all aspects of the research process. <br/><br/>The project's broader impacts are technological contributions to the significant national challenge of developing an optimized energy infrastructure for the 21st century. The projects are designed to find ways of reducing wasteful expenditure of energy and to manage energy systems in an efficient way. Thus the project can have a positive impact on the environment, which will lead to an improved quality of life. Moreover, the project trains a diverse pool of undergraduate students including women and underrepresented minorities, students of low socioeconomic status, as well as veterans of the US Armed Services, in acquiring basic research and problem solving skills. Because the proposed activities address critical national problems, students will be inspired to contribute to solutions to these problems by deepening their understanding which, in turn, will lead to their pursuing advanced degrees in science and engineering"
"1256016","EAGER: Collaborative Research: Sequential Recommender Systems in Mobile and Pervasive Environments","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/30/2012","Hui Xiong","NJ","Rutgers University Newark","Standard Grant","Maria Zemankova","08/31/2014","$74,907.00","","hxiong@rutgers.edu","Blumenthal Hall, Suite 206","Newark","NJ","071021896","9733531538","CSE","7364","7364, 7916","$0.00","Individuals on the move, e.g., tourists on a sightseeing trip in an unfamiliar city often find themselves overwhelmed by the challenges of coping with unfamiliar environments. This presents a need for tools and methods that will guide them by providing them useful recommendations while they are ""on the move."" Recent advances in mobile and sensor-based technologies have made it possible to collect and process location traces across many different mobile applications. Such data, when combined with other spatio-temporal, contextual, and user-specific information can, in principle, be used to generate useful recommendations for individuals on the move. <br/><br/>This exploratory research project formulates and explores a novel variant of recommender systems, namely, mobile sequential recommender systems for mobile users where each recommendation takes into account the trajectory and history of past recommendations, as one of selecting a sequence of locations to recommend under a set of spatio-temporal, contextual, and privacy constraints. Given the combinatorial nature of the problem (where the size of the search space grows is exponential in the relevant parameters) the project aims to explore heuristics. It will also develop appropriate measures for assessing the effectiveness of alternative solutions.<br/><br/>The project, if successful, would establish the feasibility of a line of investigation that could lead to the development of effective approaches to sequential recommendation problem with obvious benefits to mobile users. The project enriches research based advanced training opportunities for graduate and undergraduate students. All of the data, software, and publications resulting from the project will be made freely available to the broader research community."
"1338260","US-Based Students Support to Attend the IEEE International Conference on Mobile Data Management 2013 (IEEE MDM 2013)","IIS","INFO INTEGRATION & INFORMATICS","04/15/2013","04/10/2013","Ouri Wolfson","IL","University of Illinois at Chicago","Standard Grant","Sylvia J. Spengler","03/31/2015","$20,000.00","","wolfson@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364","7484, 7556","$0.00","This proposal seeks support in the form of travel awards for U.S.-based graduate and undergraduate students to participate in the 14th IEEE MDM 2013 Conference, which will be held in Milan, Italy, June 3-6, 2013. The MDM series of conferences, annually organized by the IEEE society since 1999, has established itself as a prestigious forum for the exchange of innovative and significant research results in mobile data management. The conference provides unique opportunities for researchers, engineers, practitioners, developers, and users to explore new ideas, techniques, and tools, and to exchange experiences in mobile data management. Attendees will participate interactions via lively presentations of accepted technical papers, posters and demos, and invited talks given by leading academics and industry professionals of related fields. The participation of US based graduate and promising undergraduate students will result in the intellectual simulation of young minds to pursue advanced research and development activities in this area that has huge technical and societal impact, and helps U.S. keep the leading position in this vital field. To ensure a broader impact in disseminating the results of the conference, and to garner interest among young researchers in the fields of mobile data management, this award is for travel grants enabling student travel to attend IEEE MDM 2013 and the workshops to be held in conjunction with the MDM 2013. The purpose is to encourage the attendance of students who otherwise would not have the opportunity to participate in such a conference.<br/><br/>The allocation of the grants will be based on need and impact of the applicant?s attendance in increasing the diversity of conference participation. Minority students, students from underrepresented institutions, and students in financial need will be given higher priority."
"0845916","CAREER: Categorical Shape Reconstruction","IIS","ROBUST INTELLIGENCE, GRAPHICS & VISUALIZATION","03/01/2009","04/08/2013","Li Zhang","WI","University of Wisconsin-Madison","Continuing grant","Jie Yang","02/28/2015","$500,001.00","","lizhang@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495, 7453","1045, 1187, 9215, HPCC","$0.00","Reconstructing 3D geometric models of objects from their 2D images has been a longstanding problem in computational vision. Traditional approaches to this problem require many images taken of the same objects under different viewpoints and/or illuminations; this requirement poses a significant limitation on the operating range of these methods. For example, in consumer photography, the majority of photos are not taken with such a purpose in mind. Even in research communities, collecting multi-view/illumination image data sets is a tedious task. <br/><br/>The PI and his team are investigating novel 3D reconstruction methods that operate on a collection of images for similar-but-not-identical objects in one category and recover a family of parameterized 3D models for the category. The underlying assumption made is that the shape distribution has only limited number degrees of freedom, many less than the image data that are available for the category. This approach exploits the abundance of images on the Internet that densely sample the appearance of similar objects in different categories, such as faces, vehicles, architectures, humans, and animals. The outcome of this research enables the creation of large-scale parameterized 3D model databases for these categories, without the need of placing all individual objects on a turntable in a controlled setting. Such databases have a wide range of impact, such as autonomous navigation, security surveillance, human computer interaction, biometrics, graphics, industry design, virtual environment, forensics, archeology, and entertainment. <br/><br/>The PI also seeks to integrate the core idea of this research project into his education plan. In particular, his primary education goal-both in course work and in mentoring graduate students - is to emphasize a data - driven approach to vision that is both foundational and practically important. The data and tools will be disseminated in a timely fashion. Updates will be available from http://www.cs.wisc.edu/~lizhang"
"1314365","HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","IIS","Cyber-Human Systems","08/01/2013","08/07/2013","Anita Sarma","NE","University of Nebraska-Lincoln","Standard Grant","Ephraim P. Glinert","07/31/2017","$857,156.00","Gregg Rothermel","asarma2@unl.edu","2200 Vine St, 151 Whittier","LINCOLN","NE","685830861","4024723171","CSE","7367","7367, 7925, 9150","$0.00","In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br/><br/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask ""why"" questions to understand the differences among variations of a system. For novices, an ""Idea Garden"" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br/><br/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students."
"1149599","CAREER: Information Misperceptions in the Internet Era","IIS","Cyber-Human Systems","03/01/2012","02/11/2014","R Garrett","OH","Ohio State University","Continuing grant","William Bainbridge","02/28/2017","$321,967.00","","garrett.258@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7367","1045, 7367","$0.00","Scholars have observed that online news and political talk have the potential to promote belief in false or misleading factual claims, frequently attributing this to distinctive characteristics of the Internet such as the absence of gatekeepers, the freedom to screen out disagreeable evidence, and personalization systems that shield news consumers from uncomfortable truths. However, these mechanisms are largely speculative, and do not align well with existing data. This project moves toward a theoretically grounded and empirically tested understanding of political misperceptions in the Internet era. <br/><br/>Hypotheses focus both on broad effects associated with use of online news media, and on the mechanisms through which these effects occur. Specifically, a series of media-effects hypotheses address the prevalence and consequences (1) of partisan bias in media exposure decisions, (2) of the use of social media as a source of political news, and (3) of automated (and often invisible) personalization technologies that shape what online news consumers see. A second more nuanced set of predictions concerns how these technologies could lead individuals to be more likely to accept as true inaccurate political information. These hypotheses link the attributes of the technologies in question with established theoretical work on processing fluency, affect, and biased assimilation. <br/><br/>To test the hypotheses, the study will pair multi-wave surveys of representative samples of Americans with a series of controlled experiments designed to evaluate the specific mechanisms theorized. A three-wave survey will be conducted in year one, and a two-wave survey in year five, corresponding with U.S. Presidential elections. Measuring respondents' use of various online political news sources and services in early waves, and assessing respondents' store of political knowledge and misperceptions in later waves will provide clear evidence concerning the consequences of using these Internet technologies. The first survey will also include an embedded experiment in order to test the influence of processing fluency in the field. A series of interrelated experiments will be conducted in the intervening years. Year two will focus on testing the influence of metacognitive experiences, such as processing fluency, on the acceptance of false information and factual corrections. In year three the emphasis will be on affect, testing the influence of emotional responses to political claims on individuals' assessments. Year four experiments will focus on biased assimilation as it informs credibility effects, and on the relative importance of institutional trust and individual judgment on participants' beliefs. <br/><br/>The datasets will be shared with students and other scholars, further enhancing the impact of the research endeavor. A new undergraduate course, intended to help students become more informed consumers of political information, will be based on the theoretical and empirical work coming out of this research. Public outreach, communicating key lessons concerning the sources and remedies of political misperceptions to journalists and the broader public, as well as publications in scientific venues, will raise awareness of effective strategies for assessing political information."
"1350438","CAREER: Scaling Up Mobile Accessibility Through Touchscreen Personalization","IIS","Cyber-Human Systems","02/15/2014","02/11/2014","Leah Findlater","MD","University of Maryland College Park","Continuing grant","Anthony Hornof","01/31/2019","$109,336.00","","leahkf@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","1045, 7367","$0.00","Touchscreen interfaces are becoming increasingly prevalent as the interface with which people interact with computers and yet, for people with motor impairments, many touchscreen commands are difficult or impossible to execute. With the increased deployment of touchscreen interfaces, it becomes critically important for hardware and software developers to ensure that such devices are accessible to a broad range of users. While these challenges can be partially offset by multimodal (speech) input, touch and gesture remain necessary for fully functional, efficient, and socially acceptable use of many touchscreen devices. This is a serious concern for the almost 20 million people in the U.S. who have motor impairments that affect their upper body, a number that will only rise with the unprecedented increase in America's senior population.<br/><br/>This project pursues a research program to advance a fundamental understanding of how decreased motor ability impacts touchscreen interaction and, in turn, how touchscreen interactions can be personalized to support each user's abilities. While substantial user-interface-development effort has focused on personalizing content, personalized-interaction interfaces, such as to alter the means of issuing the taps, swipes, and clicks that underlie the use of touchscreen devices, have received much less attention. The increased use of touchscreens presents a tremendous opportunity for software-based modifications because the entire interactive surface is software-controlled, an advantage that this researcher has already leveraged to adapt touchscreen keyboards to how motor abilities for people without disabilities change in some situations such as while walking. This project goes far beyond this preliminary work to provide great benefits to people with permanent motor impairments.<br/><br/>The project consists of two complementary major activities. The first major activity employs large-scale studies to reliably assess and predict the impact of motor abilities on touchscreen interaction. By developing new methods to leverage user-generated content (e.g., videos, tweets) and by employing large-scale online experimentation, the large-scale studies will provide a more in-depth and ecologically valid characterization of how motor ability impacts touchscreen use than has been previously possible. The second major activity of the project builds on findings from the first major activity to design and evaluate new approaches for personalizing touchscreen interaction. The second activity will contribute new techniques for personalizing mobile interactions, generate new algorithms and predictive models of touchscreen performance, and identify design guidelines for personalizing mobile interaction.<br/><br/>Broader Impacts: This work will transform mobile accessibility for people with motor impairments. Enabling mobile access can lead to greater empowerment and independence for people with disabilities. Many of the proposed techniques will also likely benefit users more broadly. This work also has implications for the accessible design of the next generation of mobile devices, including wearables and 3D-gesture interfaces. Many of the techniques should be applicable in a commercial context, which is important to insure that new commercial interfaces are accessible to all users. Education plans include two courses related to accessibility, one of which establishes a partnership with the DC Public Library on touchscreen training for people with disabilities."
"1350995","CAREER: Measuring and Reducing Cybersickness in Virtual Reality Physical Rehabilitation","IIS","Cyber-Human Systems","02/15/2014","02/11/2014","John Quarles","TX","University of Texas at San Antonio","Continuing grant","Anthony Hornof","01/31/2019","$195,126.00","","jpq@cs.utsa.edu","One UTSA Circle","San Antonio","TX","782499113","2104584340","CSE","7367","1045, 7367","$0.00","The effects of cybersickness (i.e., motion sickness caused by immersive simulation, such as virtual reality) on healthy users has been one of the fundamental research areas in virtual reality (VR) for many years, but its impact on persons with physical disabilities is still unknown, even though it could have a significant an impact on VR-based physical rehabilitation for this population. This project investigates cybersickness for persons with disabilities, specifically for persons with multiple sclerosis with a moderate level of mobility impairment and no cognitive impairment. The expected outcome of this research is to minimize the negative effects of cybersickness for people with disabilities, and to thereby significantly improve the effectiveness of VR-based physical rehabilitation and the quality of life for people with motor impairments.<br/><br/>The first objective of this project is to determine the best way to measure cybersickness in people with disabilities, and the second is to then figure out the main factors that contribute to cybersickness in persons with disabilities, specifically for people with proprioceptive and balance deficits (e.g., due to neurological, vestibular, balance issues). Based on preliminary data, the central hypothesis is that VR-induced cybersickness will be magnified for persons with disabilities as compared to persons without disabilities because of differences in balance and proprioception abilities. To test this hypothesis, the project will (a) determine how disability correlates with VR-induced cybersickness, (b) determine the most effective objective measures of VR-induced cybersickness for people with disabilities, (c) determine the main contributing aspects of VR design that affect cybersickness in people with disabilities and (d) create, disseminate, and maintain an open database of (anonymized) cybersickness data from people with disabilities.<br/><br/>Broader Impacts: The project will take a critical step towards the challenge of universal usability in VR and offer a deeper understanding of the effectiveness of VR as a medium for rehabilitation. The project will impact the way that people with disabilities are able to engage in VR-based rehabilitation and exercises, which could potentially have long term impact on the effectiveness and efficacy of the rehabilitation and ultimately the quality of life for these people. The project will actively engage graduate and undergraduate students in research, integrate results from research into a novel course on accessible user interfaces and universal usability, and collaborate with national advocacy societies for persons with disabilities to promote education and motivation for VR-based rehabilitation."
"1149970","CAREER: Designing Socially Adept Robots","IIS","Cyber-Human Systems","01/15/2012","02/10/2014","Bilge Mutlu","WI","University of Wisconsin-Madison","Continuing grant","Ephraim P. Glinert","12/31/2016","$296,712.00","","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7367","1045, 7367","$0.00","Robots hold the promise of delivering significant social contributions in such key domains as education, rehabilitation, and collaboration, but to achieve this promise they must be able to communicate effectively with people. The goal of this project is to design effective social behaviors for robots by modeling human verbal, vocal, and nonverbal behavior using computational tools, regenerating them in robots, and evaluating their effectiveness in human-robot studies in social scenarios such as storytelling, interview, conversation, instruction, and collaborative work. The research will follow an interdisciplinary approach, combining computational and social-scientific methods toward advancing the state of the art in robotic technology.<br/><br/>Intellectual Merit: The research will create a set of design specifications that robot designers can use to create robots that effectively communicate with people. These specifications will be openly disseminated to robot designers and researchers as modules for the open-source Robot Operating System (ROS). The project will also lead to new computational tools that will enable modeling human behavior and synthesizing effective behaviors for robots. In addition, this research will contribute to social science by providing a more detailed, computational understanding of human social behavior. <br/><br/>Broader Impacts: The research will enable robots to communicate more effectively with people in such critical domains as education, collaborative work, and health and wellbeing. The projects will also introduce computational tools into areas that have not yet substantially benefited from advancements in computer technology, such as the diagnosis and treatment of autism and traumatic brain injury. Through an integrated education and outreach program, this project will also contribute to interdisciplinary education, undergraduate and graduate curricula, K-12 and special education, public understanding of science and technology, and further inclusion of minorities and children with disabilities in scientific research and education."
"1338995","Symposium on Combinatorial Search - 2013","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","05/15/2013","05/15/2013","Richard Korf","CA","University of California-Los Angeles","Standard Grant","James Donlon","04/30/2015","$20,000.00","","korf@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","1640, 7495","7495, 7556","$0.00","This grant provides travel support for selected students attending the annual Symposium on Combinatorial Search (SoCS). Student participation in SoCS encourages young investigators in their research in combinatorial search. This symposium carries on a tradition of bringing together researchers and students around issues of pattern-database heuristics, inconsistent heuristics, real-time search, path-finding for physical robots and computer-game agents, parallel search, and search using external memory. These search techniques have a significant place in broader AI application in areas such as robotics, computer games, planning, and bioinformatics. In addition, SoCS 13 includes a special focus on graph search engineering."
"1344437","Student Travel Fellowships: 2013 Web Reasoning and Rule Systems Conference","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/26/2013","Krzysztof Janowicz","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","08/31/2014","$9,000.00","Alessandra Mileo, Marco Maratea, Michael Kifer, Pascal Hitzler","jano@geog.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7556","$0.00","Semantic technologies, Linked Open Data, and knowledge representation formalisms such as OWL are beginning to play increasingly important roles across a broad range of applications.Ontology modeling languages, e.g., RDF, OWL, and RIF, enable the inference of implicit knowledge from knowledge that is explicitly encoded in the knowledge base. Web Reasoning and allied fields focus on the design, analysis, and development of ontology languages, study of their theoretical properties, and the design and implementation of effective inference algorithms. There is an urgent need for advanced training graduate students to conduct research in this area and prepare for academic or industrial careers. Participation in premier research conferences in the area is an essential element of such training. <br/><br/>The Web Reasoning and Rule Systems conference series, established in 2007, attracts the leading researchers in the field of Web Reasoning, and offers a venue for presentation of the latest advances in the field. The co-location of the conference with the Reasoning Web Summer School makes it also an excellent venue for training graduate students. This project provides travel grants for U.S. based graduate students to attend the 2013 Web Reasoning and Rule Systems Conference scheduled to take place during July 27-29, in Mannheim, Germany. The conference is co-located with the 2013 Reasoning Web Summer School, and also with the 26th International Workshop on Description Logics. In addition to attending the invited and contributed talks at the conference, and the Summer School, the students will benefit from individualized mentoring by established researchers. <br/><br/>Broader impacts of the project include the training of a new generation of researchers and technologists in the emerging area of Web Reasoning which is currently seeing substantial industrial interest and uptake, and enhanced opportunties for broadening the participation of groups that are currently under-represented in Computer Science in general, and Semantic Technologies, Web Reasoning, and related areas in particular."
"1053868","CAREER: Pixel-Based Interpretation and Modification of Graphical User Interfaces","IIS","Cyber-Human Systems","03/01/2011","02/10/2014","James Fogarty","WA","University of Washington","Continuing grant","Ephraim P. Glinert","02/29/2016","$464,657.00","","jfogarty@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","1045, 7367, 9251, 1187","$0.00","Nearly every graphical user interface (GUI) is implemented using some form of GUI toolkit. While these toolkits have enabled many successes of the past forty years of research and practice in human-computer interaction (HCI), they have unfortunately also become stifling. The rigidity and fragmentation of current GUI toolkits makes it difficult or impossible to deploy new ideas in complex existing applications, so researchers are instead often limited to demonstrating and evaluating small toy applications. This is a major challenge for the field, as it limits both the progress and impact of HCI research. The PI's goal is to transcend the fragmentation of modern GUIs by building upon their single largest commonality, namely that all GUIs ultimately consist of pixels painted to a display. He argues that if it were possible to quickly and robustly interpret those pixels, without application source code and independent of its underlying toolkit implementation, we could use that understanding to modify any interface. The PI's prior work on the Prefab system has shown promising preliminary results, enabled by a strategy of reverse engineering widget appearance. In the current project the PI will develop methods for pixel-based interpretation of graphical user interfaces, including methods for identifying complex widgets, for extracting widget content, and for recovering widget relationships, and he will build upon these to model widgets state and to address occlusion of portions of interfaces. He will create methods for modifying graphical user interfaces, including semantic views on pixel-based interpretation, methods for manipulating underlying interfaces, methods for translation between presentations, visual programming methods, and end-user tools for interface customization. He will implement new tools for informing, deploying, and evaluating interaction research in the field, and he will partner with leading researchers to apply these tools to target-aware pointing and automatic interface generation. And he will validate his pixel-based methods in real-world datasets collected from broad deployments.<br/><br/>Broader Impacts: In this project the PI will pursue a vision of a transformative democratization of every aspect of interaction, in which instead of being limited to a single provided interface anybody can modify any interface of any application. For example, an HCI researcher might implement and evaluate a new interaction technique in several existing applications; a practitioner or hobbyist who sees the publication might add the technique to their favorite applications. Web communities might organize around causes, such as translating interfaces into new languages, improving the accessibility of existing applications, or updating interfaces to support gestures, speech access, or other interactions. End-users might browse libraries of extensions, vote on their favorites, and use visual programming tools to create their own. Project outcomes, including tools and dataset, will be openly disseminated. The PI will make special efforts to recruit students from under-represented groups, to integrate the research into existing and new courses, and to use a high school design competition as a channel for recruiting high school students for internships."
"1345006","EAGER: Sub-second human-robot synchronization","IIS","Cyber-Human Systems","07/01/2013","08/23/2013","Gil Weinberg","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","06/30/2015","$155,973.00","","gil.weinberg@coa.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7916","$0.00","The Principal Investigator (PI) will explore and test a number of hardware platforms and software algorithms whose goal is to facilitate sub-second human-robot synchronization. To this end the PI will utilize the medium of music, one of the most time-demanding media where accuracy in milliseconds is critical because asynchronous operations of more than 10 ms are noticeable by listeners. Specifically, the PI will develop up to three different kinds of robotic devices intended to allow a drummer, whose arm was recently amputated from the elbow down, to play and synchronize between his organic functioning arm and the newly developed robotic devices. In addition, he will develop and investigate the efficiency of novel anticipation algorithms designed to foresee human actions before they take place and trigger robotic actions with low-latency and in a timely manner. This research will advance our understanding in a variety of areas, including the biomechanics of limb operations, machine-learning techniques for the anticipation and prediction of human gestures, and highly accurate myoelectric robotic devices.<br/><br/>Broader Impacts: This project will ultimately benefit a large population of amputees whose quality of life could improve through the use of low-latency robotic limbs with sub-second synchronization. Facilitating such accurate sub-second human-robot synchronization could also improve efficiency and flow in other human-robot interaction scenarios where humans and robots must collaborate to achieve time-demanding common goals. The novel solenoid-based robotic device(s) created in this research should also benefit musicians in general (that is to say, who are not disabled), who will be able to explore novel drumming techniques and create novel musical results."
"0953107","CAREER: Brain-Tongue-Computer Interfacing","IIS","Cyber-Human Systems","03/01/2010","02/07/2014","Maysam Ghovanloo","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","02/28/2015","$548,298.00","","mghovan@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","1045, 1187, 9215, 9251, 7367, HPCC","$0.00","The PI's long-term research plans involve exploring new pathways to the human central nervous system (CNS) in order to expand our knowledge about this highly complex system and understand how it works, and developing innovative technologies and research tools that will enable direct or indirect communication with the CNS through such pathways. In particular, he is keen to utilize and evaluate new interfacing technologies in devices that will help individuals who suffer from chronic disabilities and neurological diseases, such as blindness, deafness, and paralysis to improve and extend their quality of life. With these general goals in mind, the PI will in this project focus on exploring the use of voluntary tongue motion as a substitute for some of the functions traditionally performed by the arms and hands in personal environmental control. This has not been possible in the past absent access to tongue motion without impeding the tongue's key roles in swallowing, respiration, and speech. The PI has previously developed and successfully tested a new wireless, unobtrusive, and wearable technology he calls the Tongue Drive System (TDS), to indicate tongue position in real time within certain user-defined locations in the oral space. Building upon the TDS prototype, he will explore whether the inherent characteristics of the tongue and its rich motor capabilities can be harnessed as an intermediary pathway to the human brain. In other words, he will seek to create a Brain-Tongue-Computer Interface (BTCI) by enhancing the functionality of the TDS hardware, signal processing algorithms, and GUI software to support a large number of choices that will be simultaneously available to users, in addition to the proportional control capability that is currently employed to facilitate navigation and computer access. The PI will conduct experiments to evaluate the performance, usability, and acceptability of the BCTI platform, and will employ it to achieve a fundamental understanding of human factors associated with voluntary tongue motions. Finally, the PI will combine his real time 3-D tongue tracking technology with multi-channel wireless neural recording to explore the relationship between unconstrained tongue movements and whole muscle/single motor unit activities in speech, respiration, and swallowing without any bodily restraints.<br/><br/>Broader Impacts: Individuals who are severely disabled as a result of various causes from spinal cord injuries to stroke, cerebral palsy, and ALS find it extremely difficult to carry out everyday tasks without continuous help. This research will ultimately transform the lives of many persons with severe disabilities, by helping them live active, self-supportive, and productive lives. Solutions such as the BTCI may also help reduce healthcare and assisted-living costs by relieving the burden on family members and dedicated caregivers. Utilization of the tongue's motion as an untapped human motor modality in command, control, and navigation tasks involves costs and benefits which are at present unknown; quantitative analysis of human performance in concurrently conducted sensory, motor, and cognitive tasks, both in the presence and absence of tongue motions, is likely to bring about new scientific discoveries in human system integration. The PI's 3-D tongue tracking technology will also impact speech/language therapy, as well as the treatment of communication and sleep disorders that involve tongue motion. The PI will explore use of the BTCI technology in educational settings for children with special needs through programs such as Tools for Life, and will also conduct outreach efforts to expose K-12 students to facts about the CNS, its associated impairments, and different ways to address those problems with engineering solutions."
"0845036","CAREER: Scalable Algorithms for Individual Decision Making in Multiagent Settings","IIS","ROBUST INTELLIGENCE","06/01/2009","04/12/2012","Prashant Doshi","GA","University of Georgia Research Foundation Inc","Standard Grant","Todd Leen","05/31/2015","$445,663.00","","pdoshi@cs.uga.edu","200 D.W. Brooks Drive","ATHENS","GA","306025016","7065425939","CSE","7495","1045, 1187, 9215, HPCC, 9251","$0.00","Research under this award is developing efficient and effective methods for strategic decision making by an individual artificial agent cohabiting with other agents in uncertain environments. For example, how should an autonomous unmanned aerial vehicle decide between closer surveillance of a possible fugitive or intercepting the target who may be aware of the monitoring? Toward this goal, the research is identifying the sources of computational complexity and understanding the conflicting interrelationship between computational efficiency and decision-making effectiveness. This problem of individual decision making in uncertain multiagent settings is formalized using a recognized framework that combines the decision-theoretic paradigm of partially observable Markov decision processes (POMDPs) with elements of Bayesian games and interactive epistemology. In this framework, called interactive POMDP (I-POMDP), the research utilizes innovative ways of minimally modeling contextual knowledge in multiagent settings, exploits novel decision-making heuristics and embedded structure in problems.<br/><br/>Integration of research and education is manifest in the development and delivery of a multi-disciplinary course on strategic decision making under uncertainty, which integrates and compares normative theories with real human decision-making behavior.<br/><br/>By combining aspects of decision and game theories, both of which seek to understand normative ways of decision making, with attention to real human decision-making behavior, this research is contributing to long-term research and development of artificial agents that can assist with rational, long-term decision making and planning in areas including emergency response, environmental sustainability, autonomous vehicles and many others."
"1141517","EAGER: GreenSC: Characterizing and Modeling Energy Use in Social Computing","IIS","Cyber-Human Systems","09/01/2011","08/17/2011","Thomas Finholt","MI","University of Michigan Ann Arbor","Standard Grant","William Bainbridge","08/31/2014","$299,982.00","Erik Hofer","finholt@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","7916, 7367","$0.00","Social networks link behavioral and social activities with a myriad of infrastructural networks that support relationships between individuals. These infrastructural networks include the Internet, telephone systems and transportation networks, all of which are in turn tied to power and fuel-supply networks, such as electricity grids. Social networks play a powerful shaping role on underlying infrastructural networks, placing great demands on their capacity and helping determine how they evolve through use. <br/><br/>An initial set of analyses suggests that there are significant opportunities for improving energy use by analyzing and optimizing the energy required to build and sustain social networks. This project seeks to quantify the energy requirements of social networks and identify strategies for optimizing their energy use by: assessing the ecology of technologies used in social networks through surveys and crowdsourced data; modeling and empirically measuring the power consumed in communication technologies; and developing a social sustainability composite indicator that will be integrated into a tool to help users make more sustainable choices. <br/><br/>Intellectual Merit This project will lead to an improved understanding of the behavior and dynamics of complex, socio-technical networks so that future networks can be better designed. The project seeks to build an understanding of how different communication technologies are used together in social networks and to use this model to address how energy use accumulates in technical networks that support relationships. Finally, the project seeks to link large-scale problems with the actions and behaviors of individuals, which is critical for promoting behavioral change. <br/><br/>Broader Impacts The questions answered in this project are critical to informed optimization and innovation of energy use in the context of social networks and social life. A better understanding of the energy cost of social networks and social computing technologies promises to have impact in climate change, information technology for development and operational efficiency. Additionally, the project?s findings will be distributed through a number of national programs for training and curriculum development."
"1345449","III: Travel Fellowships for Students from U.S. Universities to Attend ISWC 2013","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/26/2013","Krzysztof Janowicz","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","08/31/2014","$20,000.00","Pascal Hitzler","jano@geog.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7556","$0.00","Semantic technologies, are beginning to play increasingly important roles across a broad range of applications. There is an urgent need for advanced training graduate students to conduct research in this area and prepare for academic or industrial careers.<br/><br/>Participation in premier research conferences in the area is an essential element of such training. This project provides funds to subsidize the travel expenses of 10-15 students at U.S. universities to attend the 2013 International Semantic Web Conference (ISWC) which will be held October 21-25, 2013 in Sydney, Australia. <br/><br/>ISWC is a premier international conference which offers a venue for presentation of rigorously peer-reviewed research results in Semantic Web and allied areas. The conference includes two events specially targeted to graduate students: The ISWC doctoral consortium offers an opportunity for doctoral students to present their work and receive feedback and mentoring. The ISWC Career Mentoring lunch provides an informal setting for students to discuss all issues pertaining to research careers with senior researchers in the community, and to establish long-term mentoring ties. <br/><br/>Broader impacts of the project include: Enhanced opportunities for training and mentoring of US-based graduate students in Semantic Web and related areas, broadening the particiation of students from groups (women and minorities) that are currently under-represented in Computer Science in general, and Semantic Web in particular."
"1064495","CAREER: Computing for Advanced Identity Representation","IIS","Cyber-Human Systems","07/01/2010","02/07/2014","Douglas (Fox) Harrell","MA","Massachusetts Institute of Technology","Continuing grant","Ephraim P. Glinert","12/31/2014","$535,062.00","","kitsune@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","1045","$0.00","The Advanced Identity Representation (AIR) Project is a new transdisciplinary approach to the problem of designing identity technologies to enable imaginative self-representations and to counter social stigmas by implementing dynamic social identity models grounded in computing and cognitive science. The AIR Project seeks to: (1) Develop models of social computational identity (e.g., virtual characters, avatars, and social networking profiles) to enable user representations that dynamically change in response to context and use, and can minimize implicit stigma built into underlying infrastructure, (2) Implement an identity modeling toolkit for constructing empowering, cross-application self-representations (crucially, both back-end semantic data structures and graphical representations), (3) Use the AIR toolkit to build integrated social networking and narrative/game applications, and empirically assess the quality and nature of user representations constructed in contrast with the quality and nature of current systems.<br/><br/>The AIR Toolkit entails developing new components as follows: Front End/Graphics (for avatars/characters): (1) Support for implementing modular graphical user representations annotated with semantic identity metadata; (2) Functions for transforming modular graphical user-representations dynamically; Back End Semantics (for social networking profiles and simulating identity phenomena): (3) Support for implementation of Identity Semantic Structures (knowledge bases to represent aspects of identity meaning in the application); (4) Functions for generating, transforming, and performing inferences on Identity Semantic Structures; and (5) Customizable data fields for multimedia information profiles.<br/><br/>Broadening diversity of participation is intrinsic to the AIR Project, both in the educational components of this project, and in the technical research itself. Humans have the ability to creatively present themselves in dynamic, fluidly nuanced ways, seamlessly varying body language, discourse, fashion, and more, with astounding sensitivity to context. They also adapt their self-presentations in response to expected behaviors and appearances, as well as to social prejudices, biases, and stigmas. Already, everyday users represent themselves in digital media, yet enabling real world identity dynamics within computational structure is a challenging problem that this research will address. The AIR Project represents a human-centered ethos that extends to education in the classroom, curriculum, mentoring, and outreach. Pilot evaluation work will include participants from diverse demographics and institutions. Theories will be developed in the lab and then deployed in teaching. Technical results will provide a platform that will aid in mentoring new graduate students. Most importantly, the AIR Project serves society-at-large by developing technology to enable real-world empowerment and diversity."
"0953181","CAREER: Socially Guided Machine Learning","IIS","Cyber-Human Systems","01/01/2010","02/07/2014","Andrea Thomaz","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","12/31/2014","$551,063.00","","athomaz@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","1045, 1187, 9102, 9215, HPCC, 7218, 7367","$0.00","There is currently a surge of interest in service robotics, a desire to have robots leave the labs and factory floors to help solve issues facing society. But if robots are to play a useful role in domains ranging from eldercare to education, they will need the ability to interact with ordinary people and to acquire new relevant skills after they are deployed; we cannot pre-program these robots with every skill they might conceivably need. The PI's approach to solving this critical issue is Socially Guided Machine Learning (SG-ML). In this project she will explore ways in which machine learning agents can exploit principles of human social learning. An important question for SG-ML is ""What is the right level of human involvement?"" Previous efforts in machine learning systems that use human input have tended to hold this level constant (e.g., guidance oriented approaches that are completely dependent on human instruction in order to learn, and exploration oriented approaches with limited input from a human partner). The PI, taking her inspiration from human learning and from her prior work in robot learning, posits that a robot should be able to explore and learn on its own, while also taking full advantage of a human partner's guidance when available. The PI's goal in this work is to successfully incorporate self and social learning within a single SG-ML framework, enabling a robot learner to dynamically adjust to varying levels of human involvement in the learning process. To this end, the PI will seek to make progress toward four main objectives:<br/><br/>1) Motivations for learning: Typically machines learn because they are programmed to do so, unlike children and animals who learn because they are motivated to master their environment. A key component of this work is computational motivations that drive a robot to good learning opportunities.<br/><br/>2) Multiple learning strategies: As mentioned above, an SG-ML framework should have a repertoire of self and social learning mechanisms working together. A central issue of this research is how the robot should best arbitrate and manage the use of multiple strategies.<br/><br/>3) Transparency devices: Learning is a collaborative activity. The learner's behavior has to be understandable, and has to express a certain level of internal state to help the teacher guide the learning process. Transparency is a fundamental issue of this work, developing robot behaviors that successfully communicate the progress of the learning process.<br/><br/>4) Engagement mechanisms: In human social learning, teaching is a rewarding process for both the learner and the teacher. This is a positive feedback loop from which a machine learner could benefit. A primary component of this work is to develop mechanisms that make the teaching process rewarding.<br/><br/>Broader Impacts: The long-term promise of this research is robots in society able to adapt and learn from everyday people. The core principles developed in this work will one day enable robots to adapt and learn about the changing needs of people in their homes, or staff in a hospital. The lessons learned about social learning with robots will be relevant both to computational devices and to human-computer interaction in general. The PI will exploit the fact that social robot projects like this one generate particular interest in the community to conduct outreach programs in local area high schools, to raise awareness about the work of women in science, and to stimulate the American public's interest in science."
"1254021","CAREER: Choosing Wisely: Leveraging User-Generated Doctor Ratings","IIS","Cyber-Human Systems","02/01/2013","02/06/2014","Guodong Gao","MD","University of Maryland College Park","Continuing grant","William Bainbridge","01/31/2018","$163,219.00","","ggao@rhsmith.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","1045, 7367","$0.00","This research will advance our knowledge of user-generated doctor ratings on the Internet, thereby providing the basis for improving these systems and increasing their value for better consumer choices. In so doing, the research will achieve a more general advance in our understanding of online reputation systems. The study has three aims: (1) to examine the supply of online doctor ratings, including their prevalence, growth trends, and the factors that affect rating posting behavior; (2) to assess the informedness of online doctor ratings, especially whether these ratings truly reflect the quality of the doctor or whether they are biased and misleading, and (3) to understand the use and impacts of online doctor ratings.<br/><br/>Despite the growing popularity of online physician ratings, there is surprisingly little study of this emerging trend. What motivates patients to provide online ratings? To what degree do the ratings reflect a doctor's clinical quality? How do patients use these ratings, and how are their decisions affected as a result? In what situations should patients be cautious when using online doctor ratings? Can the user interface design and information display be improved to make the ratings more useful? The research represents the first systematic study of these fundamental questions.<br/><br/>Findings from this study will have a direct impact on the policy and practice of quality transparency in healthcare. They will be particularly beneficial for senior citizens, who require more medical services, but they also will be incorporated into new college curriculum. Furthermore, upon completion of the study, the methods and non-proprietary data will be made publicly available to further enhance the research and education infrastructure."
"1016029","RI: Small: Boosting, Optimality and Game Theory","IIS","ROBUST INTELLIGENCE","09/01/2010","07/01/2011","Robert Schapire","NJ","Princeton University","Continuing grant","Todd Leen","08/31/2014","$450,000.00","","schapire@cs.princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085400036","6092583090","CSE","7495","7923","$0.00","Boosting is a machine-learning method based on combining many<br/>carefully trained weak prediction rules into a single, highly accurate<br/>classifier. Boosting has both a rich theory and a record of empirical<br/>success, for instance, to face detection and spoken-dialogue systems.<br/><br/>The theory of boosting is broadly connected to other research fields,<br/>but has only been fully developed for the simplest learning problems.<br/>Nevertheless, in practice, boosting is commonly applied in settings<br/>where the theory lags well behind. We do not know if such practical<br/>methods are truly best possible; even for binary classification, it is<br/>not clear how to best exploit what is known about how boosting<br/>operates. New challenges will demand an even greater widening of the<br/>foundations of boosting.<br/><br/>The goal of this project is to develop broad theoretical insights and<br/>versatile algorithmic principles. The aim is to study<br/>game-theoretically how to design the most efficient and effective<br/>boosting algorithms possible.<br/><br/>Research on boosting is spread over many years. across multiple<br/>publications and disciplines. To organize this body of work, a<br/>significant activity of this project is the completion of a book on<br/>boosting which will provide a valuable resource for students and<br/>researchers of diverse backgrounds and interests.<br/><br/>Boosting has historically had a major impact on areas outside machine<br/>learning, such as statistics, computer vision, and speech and language<br/>processing. Thus, there is a strong potential for work at its<br/>foundations to have a broad impact on these other research and<br/>application areas as well."
"1253863","CAREER: Ubilytics: Harnessing Existing Device Ecosystems for Anywhere Sensemaking","IIS","Cyber-Human Systems","02/01/2013","02/06/2014","Niklas Elmqvist","IN","Purdue University","Continuing grant","William Bainbridge","01/31/2018","$149,934.00","","elm@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7367","1045, 7367","$0.00","This research project addresses the fundamental question of how we can use the existing ecosystem of networked devices in our surroundings to make sense of and exploit massive, heterogeneous, and multi-scale data anywhere and at any time. Assembling these devices into unified sensemaking environments would enable deep analysis in the field. Examples include managing heterogeneous data in scientific lab notebooks, scaffolding undergraduate classroom learning with examples, manuals, and videos, and supporting police investigation by linking facts, findings, and evidence. On a higher level, this concept would stimulate our digital economy by supporting fields such as design and creativity, command and control, and scientific discovery. However, despite this ready access to a myriad of handheld devices as well as those integrated in our physical environments, each individual device is currently designed to be the focus of attention, cannot easily be combined with other devices to improve productivity, and has limited computational and storage resources. This project introduces a comprehensive new approach called ubiquitous analytics (ubilytics) for harnessing these ever-present digital devices into unified environments for anywhere analysis and sensemaking of data.<br/><br/>Ubilytics draws on human-computer interaction, visual analytics, and ubiquitous computing as well as a synthesis of distributed, extended, and embodied cognition, based on three principles. First, universal interaction requires designing an interaction model that combines several devices into a holistic distributed interface, transparently bridges multiple devices, surfaces, and even physical objects, and unifies interaction with various data types. Second, flexible visual structures must be created in order to generate representations that adapt to varying device dimensions, resolution, viewing angle, and distance, support space and layout management in ego-centric and world-centric configurations, and can utilize both novel and appropriated displays for output. Third, efficient distributed architecture must be achieved through methods for discovering, merging, and synchronizing heterogeneous devices with support for a generic component model to facilitate reuse, offloading costly computation into the cloud, and meshing ubilytics environments for collaboration. <br/><br/>Sensemaking is often attributed to professional analysts finding meaning from observed data, but this research will take a comprehensive view of sensemaking for both casual and expert users, in both dedicated and mobile settings, and with both large-scale and small-scale datasets. This work will therefore benefit society by focusing on three example domains: (1) scientific discovery, (2) classroom learning, and (3) police investigation. It will also advance discovery and understanding by integrating the research in an undergraduate programming course used as a testbed for learning in ubilytics environments. Another goal is to broaden participation of underrepresented groups by engaging in a women in engineering program as well as by mentoring minority undergraduate students during summer research internships. Results, software, and documentation will be disseminated under Open Source and Creative Commons licenses."
"1404352","ComputEL: A workshop to explore the use of computational methods in the study of endangered language; Baltimore, MD - June 2014","BCS","LINGUISTICS, ROBUST INTELLIGENCE, DEL","02/15/2014","02/06/2014","Jeffrey Good","NY","SUNY at Buffalo","Standard Grant","Shobhana Chelliah","01/31/2015","$25,007.00","","jcgood@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","SBE","1311, 7495, 7719","1311, 7495, 7556, 7719, SMET","$0.00","Contemporary efforts to document the world's endangered languages are dependent on the widespread availability of modern recording technologies, in particular digital audio and video recording devices and software to annotate the recordings that such devices produce. However, despite well over a decade of dedicated funding programs aimed at the documentation of endangered languages, the technological landscape that supports the activities of those involved in this work remains fragmented, and the promises of new technology remain largely unfulfilled. Moreover, the efforts of computer scientists, on the whole, are mostly disconnected from the day-to-day work of documentary linguists, making it difficult for the knowledge of each group to inform the other.<br/><br/>The ComputEL workshop will address this state of affairs by bringing together field linguists and computer scientists to explore how computational techniques and tools can be created to better aid in the analysis of endangered languages. A particular focus will be on how to facilitate the process through which research results in this domain can be developed into software that is well-supported for use by those documenting endangered languages in the field.<br/><br/>The workshop will be co-located with the Association for Computational Linguistics Annual Meeting in Baltimore in June 2014. This will allow it to reach a wider audience than would otherwise be possible, while taking advantage of its East Coast location to involve participants from nearby areas. Its first day will consist of research presentations scheduled as a part of the ACL meeting. On the following day, participants will take part in discussions designed to lay out a near-term agenda for the improved application of computational methods to the study of endangered languages.<br/><br/>The papers from the workshop will be published in the Association for Computational Linguistics conference proceedings, and an additional report will be produced summarizing the conclusions of the closed meeting. Smaller speaker communities worldwide will benefit from the results which will support better documentation and preservation of endangered languages."
"1332109","III: Small: Nonparametric Structure Learning for Complex Scientific Datasets","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","03/14/2013","Han Liu","NJ","Princeton University","Continuing grant","Sylvia J. Spengler","07/31/2015","$407,185.00","","hanliu@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085400036","6092583090","CSE","7364","7923","$0.00","The project brings together an interdisciplinary team of researchers from Johns Hopkins University, Carnegie Mellon University, and the University of Chicago to develop methods, theory and algorithms for discovering hidden structure from complex scientific datasets, without making strong a priori assumptions. The outcomes include practical models and provably correct algorithms that can help scientists to conduct sophisticated data analysis. The application areas include genomics, cognitive neuroscience, climate science, astrophysics, and language processing.<br/><br/>The project has five aims: (i) Nonparametric structure learning in high dimensions: In a standard structure learning problem, observations of a random vector X are available and the goal is to estimate the structure of the distribution of X. When the dimension is large, nonparametric structure learning becomes challenging. The project develops new methods and establishes theoretical guarantees for this problem; (ii) Nonparametric conditional structure learning: In many applications, it is of interest to estimate the structure of a high-dimensional random vector X conditional on another random vector Z . Nonparametric methods for estimating the structure of X given Z are being developed, building on recent approaches to graph-valued and manifold-valued regression developed by the investigators; (iii) Regularization parameter selection: Most structure learning algorithms have at least one tuning parameter that controls the bias-variance tradeoff. Classical methods for selecting tuning parameters are not suitable for complex nonparametric structure learning problems. The project explores stability-based approaches for regularization selection; (iv) Parallel and online nonparametric learning: Handling large-scale data is a bottleneck of many nonparametric methods. The project develops parallel and online techniques to extend nonparametric learning algorithms to large scale problems; (v) Minimax theory for nonparametric structure learning problems: Minimax theory characterizes the performance limits for learning algorithms. Few theoretical results are known for complex, high-dimensional nonparametric structure learning. The project develops new minimax theory in this setting. The results of this project will be disseminated through publications in scientific journals and major conferences, and free dissemination of software that implements the nonparametric structure learning algorithms resulting from this research.<br/><br/>The broader impacts of the project include: Creation of powerful data analysis techniques and software to a wide range of scientists and engineers to analyze and understand more complex scientific data; Increased collaboration and interdisciplinary interactions between researchers at multiple institutions (Johns Hopkins University, Carnegie Mellon University, and the University of Chicago); and Broad dissemination of the results of this research in different scientific communities. Additional information about the project can be found at: http://www.cs.jhu.edu/~hanliu/nsf116730.html."
"1054587","CAREER: Looking Glass: Leveraging Mentor Interactions to Create Personalized Programming Help for Independent Learners","IIS","Cyber-Human Systems","02/01/2011","02/06/2014","Caitlin Kelleher","MO","Washington University","Continuing grant","William Bainbridge","01/31/2016","$462,223.00","","ckelleher@cse.wustl.edu","ONE BROOKINGS DRIVE, CAMPUS BOX","SAINT LOUIS","MO","631304899","3148895100","CSE","7367","1045, 1187, 7367, 9251","$0.00","This project will amplify the efforts of computer scientists who do outreach to middle school students by capturing mentor-mentee interactions and using this captured content to create a virtual mentoring system to support independent learners (children without access to computer science experts) within the Looking Glass programming environment. Looking Glass is a novice programming environment that presents programming as a means to the motivating end of creating 3D animated stories. In the system to be developed, mentors will do three things: First, a mentor watches the story-programs his or her mentee created and writes a code suggestion: new or revised functionality that will help to improve the mentees' programs. Next, the mentor edits a draft tutorial that Looking Glass has automatically generated from the mentor's code suggestion. Looking Glass then sends this edited tutorial to the mentee. Finally, the mentor writes rules that help Looking Glass identify contexts in which that code suggestion could be helpful. Looking Glass will use the mentor-contributed code suggestions, personalized tutorials, and rules to provide virtual mentoring for independent learners. Specifically, this project will explore three hypotheses: <br/><br/>Hypothesis One: The approach of capturing and evaluating mentor-created learning materials will enable the creation of a virtual mentoring system to support independent learners. <br/><br/>Hypothesis Two: Independent learners who are presented with in-context code suggestions that both further their stories and introduce new programming concepts will develop greater programming skills than those without access to these suggestions. <br/><br/>Hypothesis Three: Independent learners who are presented with personalized tutorials based on their experience level with each topic presented will perform better than independent learners who are presented with a single level of scaffolding. <br/><br/>The National Academy of Engineering lists personalized learning as one of the grand challenges for engineering in this century. This project will develop and evaluate the impact of two techniques for personalizing learning: program-specific code suggestions and personalized, multi-level tutorials. The majority of research into educational environments has focused on formal educational settings, but Looking Glass will advance research in how to effectively support independent learning in open-ended software environments. The enhancement to Looking Glass will provide an environment for exploring computer programming and learning support through virtual mentoring to middle school children without access to computer science learning opportunities. The project's educational plan uses biographies of computer scientists integrated into Looking Glass and a research blog to help middle school children develop an accurate image of computer science."
"1348542","CAREER: Advancing Social Computing with Tailored Motivators","IIS","Cyber-Human Systems","06/16/2013","02/05/2014","Gary Hsieh","WA","University of Washington","Continuing grant","Kevin Crowston","01/31/2018","$160,848.00","","garyhs@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","1045, 7367","$0.00","This project will enable the development of personally-tailored motivators for the use of social technologies, e.g., various incentives to encourage users to contribute knowledge, provide emotional support or curate information on an online system. The project includes (1) study of motivator-to-motivation matching using a series of controlled studies, (2) development of models to infer users' motivation profiles through analyzing how underlying motivations predict usages of social technologies, and (3) application and evaluation of tailored motivators to encourage user-participation in naturalistic settings. <br/><br/>The results of this research will advance scientific understanding of how a person's motivations influence his or her usage of social technologies. It will also deepen our understanding of human motivations more generally by elucidating the intricate relationship between the types of rewards and how they are moderated by different underlying motivations to affect behaviors. In addition, the research will also result in models for identifying users' motivation profiles, and a general design framework for researchers and designers to tailor motivators, bridging multiple disciplines.<br/><br/>The developed motivation profiles and design framework may be useful to tackle a variety of everyday challenges of motivation in social technologies to improve knowledge sharing, social support and information representation. Through collaborative projects, this research will also aid health behavior change efforts to encourage blood donation and combat infant obesity. Finally, through an integrated educational plan, this research program will also contribute to improving general classroom learning, the creation of a graduate course and high school summer camp, and the training of scholars in interdisciplinary research methods."
"1217659","RI: Small: Collaborative Research: Distributed Heterogeneous Ocean Robots for Detecting and Monitoring Oil Plumes","IIS","ROBUST INTELLIGENCE","09/01/2012","08/27/2012","Brian Bingham","HI","University of Hawaii","Standard Grant","Satyandra Gupta","08/31/2015","$199,336.00","","bsb@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","CSE","7495","7923, 9150","$0.00","This collaborative project addresses the need for ocean observational techniques which was highlighted by the recent Deepwater Horizon incident. The proposed project investigates heterogeneous ocean robots (including wave gliders, unmanned surface vessels, and autonomous underwater vehicles) to detect and monitor the propagation of oil plumes. Specific objectives include: 1) the development of a distributed multi-robot cooperative deployment algorithm using partial differential equation (PDE) based methods that match the oceanographic model of oil transport, 2) the development of authentic dynamic model of the new wave glider platform to incorporate in the cooperative control, and 3) assessing the potential advantages of innovative algorithms through simulations and experimental demonstration in a coastal experiment using a network of ocean robot platforms.<br/><br/>Broader Impacts: The proposed project will provide novel algorithmic and software support for collective sensing, and address a pressing real-world need for better sensing of underwater hydrocarbon plumes. The techniques developed in the proposal will have long-term impacts in underwater exploration such as oceanographic survey and energy production in deep water. The results may also potentially benefit other environmental monitoring tasks with underlying diffusion and advection processes, such as weather event tracking and climate prediction. The planned work will integrate research projects with education activities through robot-centric undergraduate and graduate education, robotics competition, short course and workshop development, and outreach to K-12 education. Partnering with the Stevens' Center for Innovation in Engineering and Science Education, the project will showcase the proposed research in the curriculum of the Stevens Build IT Underwater Robotics Scale-Up for STEM Learning and Workforce Development Project awarded by NSF."
"1253758","CAREER: Control and Sensing Strategies for Robotic Falcons to Prevent Airport Bird Strikes","IIS","ROBUST INTELLIGENCE","02/15/2013","02/25/2013","Soon-Jo Chung","IL","University of Illinois at Urbana-Champaign","Continuing grant","Satyandra Gupta","01/31/2018","$332,795.00","","sjchung@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7495","1045","$0.00","The intellectual merit of this proposal lies in the bio-inspired approaches to novel control strategies, vision-based sensing solutions, and strategies for cooperative pursuit and herding that will be gleaned from the literature and observations of the behavior of birds. This study will result in both fundamental scientific knowledge and a practical application revolving around the development of highly maneuverable unmanned aerial vehicles based on flapping-wing robots. The intelligence of birds manifests itself in the evasive talents of flocks of birds and this proposal attempts to recreate that intelligence through the challenge of applying a bird-like robot to the problem of preventing aircraft/bird collisions near airports. According to surveys by the International Bird Strike Committee, none of the existing systems to prevent bird strikes on airfields are adequate. The reasons include habituation by birds to these systems; movement of birds to other parts of the area, or scattering of them all over the airfield; and the tendency of birds to come back when a threat has gone. The only proven lasting way of removing birds is by using live birds of prey, but real birds are too difficult to control and train. An alternative is to study and extract the behaviors and dynamics of real birds in order to develop and deploy a robotic lookalike. The objective of this proposal, motivated by the problem of keeping airfields clear of disruptive avian flocks, is to develop control and sensing strategies for bird-like flapping robots that can be deployed in swarms to fend off ""antagonists."" This work will build upon the PI's previous work on the control of flapping-wing aircraft using limit-cycle-based central pattern generators (CPGs), and on the dynamics and control of flexible, articulated-wing aircraft.<br/><br/>Broader Impacts: Society as a whole stands to benefit immensely from robotic birds that can effectively prevent bird strikes, which cause airplane crashes and millions of dollars annually in damage. Furthermore, because of their high aerodynamic efficiency in forward flight, articulated-winged flapping aerial robots equipped with sensors could have tremendous value by being able to inspect hazardous areas. For the field of robotics, the proposed transformative research will make far-reaching contributions, advancing the state of the art in aerial robotics, cooperative control theory, and control of flexible robot structures. Additionally, this project's education and outreach activities will help introduce a new generation of young people, including those from underrepresented populations, to the excitement of science and engineering careers. Multiple avenues of educational outreach will be pursued, taking advantage of the powerful appeal of the topics of robotics and bio-inspired flight."
"1217447","RI: Small: Practical techniques for robotic manipulation of string and wire","IIS","ROBUST INTELLIGENCE","10/01/2012","09/06/2012","Devin Balkcom","NH","Dartmouth College","Standard Grant","Satyandra Gupta","09/30/2015","$482,112.00","","devin@cs.dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551404","6036463007","CSE","7495","7923, 9150","$0.00","This proposal presents a plan to attack the problem of manipulating flexible materials like string and wire using minimal sensing and actuation. Flexible materials are ubiquitous in manufacturung and surgery, and human examples demonstrate that complex manipulation of flexible materials is possible, from knot-tying to folding laundry or even origami. Robots are currently far less capable in these domains, leaving many boring, repetitive factory tasks inaccessible to robotic automation. Current simulation models of flexible objects are too computationally complex for standard approaches to manipulation planning to be effective. Furthermore, although the simulated dynamic behavior of a piece of string using existing models might be visually believable, the behavior is unlikely to match any particular piece of string in the real world and, therefore, is of limited use.<br/><br/>Knot tying has many applications ranging from manufacturing to surgery to agriculture and service robots. Manipulation of deformable objects is fundamental to many manufacturing and household applications. The proposed work has application to factory operations and seems to apply to potential future needs in manipulation of linear, flexible 1-D structures such as carbon nanotubes and proteins.<br/><br/>Broader Impacts: The development of reliable, inexpensive techniques for manipulation of flexible materials goes beyond the obvious potential impact on factory automation. Minimalism is particularly appropriate for problems involving manipulation at new scales. Fixtures for tying knots might be built at the microscale, allowing parallel manipulation of many very tiny threads or rods. Although we emphasize that the focus of the current work is on theoretical foundations and manipulation at the macro-scale, one can imagine using cleverly-designed geometries to manipulate carbon nano-tubes or proteins - things not possible with standard serial arm designs."
"1027289","Workshop on NLP and Linguistics: finding the common ground","IIS","LINGUISTICS, ROBUST INTELLIGENCE","10/01/2010","02/05/2014","Fei Xia","WA","University of Washington","Standard Grant","Tatiana D. Korelsky","09/30/2014","$16,996.00","","fxia@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","1311, 7495","1311, 7495","$0.00","Since early 1990s, with the advancement of machine learning methods and the availability of data resources such as treebanks and parallel corpora, data-driven approaches to Natural Language Processing (NLP) have made significant progress. The success of such data-driven approaches has cast doubt on the relevance of linguistics to NLP. Conversely, NLP techniques are rarely used to help linguistics studies. The goal of this NSF-sponsored workshop is to carefully examine the relationship between linguistics and NLP and determine how incorporating linguistic knowledge into NLP systems can advance the state of the art of NLP and how NLP can assist linguistic studies through automatic collection and analysis of linguistic data.<br/><br/> The workshop will bring together researchers from linguistics and NLP with diverse interests in and across both disciplines. The workshop is held in conjunction with ACL on July 16, 2010 in Sweden. This award provides financial support that allows the workshop to attract top researchers in the US to attend the workshop in Sweden, and the support is crucial especially for linguists who normally do not attend ACL.<br/><br/> This workshop is intended to begin collaboration between linguists and NLP researchers that will continue long after the workshop has finished. The ultimate goals of the workshop and follow-up events are to accelerate work in NLP by bringing in important knowledge and information from linguistics, and to open the eyes of NLP researchers to the challenges within the field of linguistics that could benefit from cutting-edge, state-of-the-art NLP.<br/>The cross pollination between the disciplines can only push both forward and in directions that otherwise would come much later or not at all."
"0812258","III-COR-Small: Efficient Matching for Large Real-World Schemas and Ontologies","IIS","INFO INTEGRATION & INFORMATICS, INFORMATION TECHNOLOGY RESEARC","09/01/2008","09/06/2013","Maria Cruz","IL","University of Illinois at Chicago","Continuing grant","Sylvia J. Spengler","08/31/2014","$504,995.00","","ifc@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364, 1640","7364, 9102, 9216, HPCC, 9251, 1640, 9215","$0.00","III-COR-Small: Efficient Matching for Large Real-World Schemas and <br/>Ontologies<br/><br/>PI: Maria Cruz<br/><br/>This project aims at bridging across heterogeneous data and will<br/>impact applications in multiple fields, including emergency<br/>management, biomedicine, digital government, and environment. In<br/>particular, this project extends the state of the art in schema and<br/>ontology matching, and therefore in data integration, by testing and<br/>evaluating methods and strategies that establish relationships among<br/>semantically related concepts in heterogeneous data sources.<br/><br/>The following research issues are addressed: (1) Design of methods and<br/>algorithms for schema and ontology matching that operate at different<br/>levels of granularity (e.g., concept, structure); (2) Development of a<br/>prototype of an integrated system that supports the visualization and<br/>manipulation of large schemas and ontologies in addition to the<br/>developed matching methods and algorithms; (3) Test and evaluation of<br/>the above methods and system prototype in terms of their<br/>effectiveness, including accuracy (precision, recall) and efficiency<br/>(execution time). From an educational viewpoint, this project impacts<br/>the design of courses and the research training of graduate and<br/>undergraduate students, and of a postdoc.<br/><br/>Further information about this project can be found at:<br/>http://www.cs.uic.edu/~ifc/grants/SchemaOntologyMatching/"
"1014762","Grassroots 2010 - Travel Support for the Intelligent Robots and Systems Conference in Taiwan","IIS","ROBUST INTELLIGENCE","05/15/2010","07/30/2013","Ron Lumia","NM","University of New Mexico","Standard Grant","Satyandra Gupta","10/31/2014","$49,639.00","","lumia@unm.edu","1700 Lomas Blvd. NE, Suite 2200","ALBUQUERQUE","NM","871310001","5052774186","CSE","7495","7484, 9150","$0.00","Proposed is travel support for US graduate students to participate in the IEEE Intelligent Robots and Systems (IROS) conference. IROS will be held in Taipei, Taiwan, October 2010. A unique aspect of this proposal is lab visits. Approximately 30 students will visit academic, government and/or industrial labs in Taiwan while in Taiwan for IROS. These students will be hosted by Taiwanese graduate students. The envisioned outcome is that the 30 students will reciprocate; they would host the Taiwanese students when future conferences are held in the US."
"0916027","III: Small: RIOT: Statistical Computing with Efficient, Transparent I/O","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","05/11/2010","Jun Yang","NC","Duke University","Standard Grant","Sylvia J. Spengler","08/31/2014","$516,000.00","","junyang@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7364","7364, 7923, 9216, HPCC, 9251","$0.00","Recent technological advances enable collection of massive amounts of<br/>data in science, commerce, and society. These datasets bring us<br/>closer than ever before to solving important problems such as decoding<br/>human genomes and coping with climate changes. Meanwhile, the<br/>exponential growth in data volume creates an urgent challenge. Many<br/>existing analysis tools assume datasets fit in memory; when applied to<br/>massive datasets, they become unacceptably slow because of excessive<br/>disk input/output (I/O) operations.<br/><br/>Across application domains, much of advanced data analysis is done<br/>with custom programming by statisticians. Progress has been hindered<br/>by the lack of easy-to-use statistical computing environments that<br/>support I/O-efficient processing of large datasets. There have been<br/>many approaches toward I/O-efficiency, but none has gained traction<br/>with statisticians because of issues ranging from efficiency to<br/>usability. Disk-based storage engines and I/O-efficient function<br/>libraries are only a partial solution, because many sources of<br/>I/O-inefficiency in programs remain at a higher, inter-operation<br/>level. Database systems seem to be a natural solution, with efficient<br/>I/O and a declarative language (SQL) enabling high-level<br/>optimizations. However, much work in integrating databases and<br/>statistical computing remains database-centric, forcing statisticians<br/>to learn unfamiliar languages and deal with their impedance mismatch<br/>with host languages.<br/><br/>To make a practical impact on statistical computing, this project<br/>postulates that a better approach is to make it transparent to users<br/>how I/O-efficiency is achieved. Transparency means no SQL, or any new<br/>language to learn. Transparency means that existing code should run<br/>without modification, and automatically gain I/O-efficiency. The<br/>project, nicknamed RIOT, aims at extending R---a widely popular<br/>open-source statistical computing environment---to transparently<br/>provide efficient I/O. Achieving transparency is challenging; RIOT<br/>does so with an end-to-end solution addressing issues on all fronts:<br/>I/O-efficient algorithms, pipelined execution, deferred evaluation,<br/>I/O-cost-driven expression optimization, smart storage and<br/>materialization, and seamless integration with an interpreted host<br/>language.<br/><br/>RIOT integrates research and education, and continues the tradition of<br/>involving undergraduates through REU and independent studies. As a<br/>database researcher, the PI is committed to learning and drawing from<br/>work from programming languages and high-performance computing.<br/>Findings from RIOT help create synergy and seed further collaboration<br/>with these communities. To ensure practical impact on statistical<br/>computing, RIOT has enlisted collaboration from statisticians and the<br/>R core development team on developing, evaluating, and disseminating<br/>RIOT.<br/><br/>Further information can be found at: <br/>http://www.cs.duke.edu/dbgroup/Main/RIOT"
"1253553","CAREER: Cooperative Motion Planning for Human-Operated Robots","IIS","ROBUST INTELLIGENCE, CAREER: FACULTY EARLY CAR DEV","10/01/2013","09/09/2013","Kris Hauser","IN","Indiana University","Continuing grant","Satyandra Gupta","09/30/2018","$283,620.00","","hauserk@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7495, 1045","1045, 7495","$0.00","This proposal outlines a research and educational plan to advance decision-making techniques for robots that cooperate with human operators. Because humans far exceed the abilities of state-of-the-art robots in vision, creativity, and adaptability, interest is rapidly growing in a human-centered approach to robotics: combining the strengths of humans with the superior precision and repeatability of robots. And yet, our available motion planning tools, while powerful at computing motions for complex autonomous tasks, are poorly suited for human-centered applications that demand responsive and natural motions. This proposal hypothesizes that a new cooperative motion planning paradigm will support major advances in intuitiveness and task performance of human-operated robots such as intelligent vehicles, tele-surgery systems, search and-rescue robots, and household robots. This hypothesis is echoed in an educational plan that aims to train engineers with cross-disciplinary strengths that bridge both the technical and social dimensions of robotics. Initial human subjects studies on novice operators with the PI's cooperative motion planning algorithms suggest that the technique leads to dramatic reductions in task completion time and collision rate in cluttered environments. The proposed work will conduct further investigations along this line of research to 1) identify characteristics of cooperative planners - such as optimality, responsiveness, and completeness - that yield effective human-operator systems, both in terms of objective performance metrics and subjective preferences, 2) to design planners that optimize cooperativity metrics under computational resource and communication constraints, and 3) to enhance the capabilities of such planners to assist operators in complex manipulation tasks.<br/><br/>The planners developed in this research and the rich datasets acquired via user studies will serve as resources to help human-robot interaction (HRI) researchers design safe and socially acceptable robot behaviors. Moreover, advances in cooperative motion planning may have long-term social and economic impact by enabling new applications of robotics in driver assist systems, space exploration, medicine, household robotics, manufacturing, and construction. Research is integrated with education in a range of activities that include CS curriculum development, development of a new graduate course on optimization and machine learning, and in new software libraries for robotics education. New modules on motion planning, behavior recognition, and HRI will be incorporated in AI and robotics courses. An REU is requested for each summer of the grant and will be recruited from a minority-serving institution in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). One or more IU undergraduates will be involved in research and mentored according to the Undergraduate Research Opportunities in Computing (UROC) program, with preference given to minority and women students."
"1208479","NRI-Small: Collaborative Research: Addressing Clutter and Uncertainty for Robotic Manipulation in Human Environments","IIS","ROBUST INTELLIGENCE","10/01/2012","09/20/2012","Kevin Lynch","IL","Northwestern University","Standard Grant","Satyandra Gupta","12/31/2014","$150,000.00","","kmlynch@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495","7923, 8086","$0.00","The long-term goal of this project is to develop personal robots that share a workspace with humans. To achieve the goal of personal robots in homes, the robots must adapt to the humans? living space, not vice-versa. Unfortunately, most human living spaces appear cluttered and unstructured to a robot. Much of this ""clutter"" is in fact structure, but structure for humans, not robots. The preliminary work proposed in this revised project addresses preliminary work in robot manipulation in the presence of clutter and uncertainty. The demonstrator task is a canonical example of human-robot coexistence: sharing a refrigerator. The robot must be able to extract specified items from a refrigerator that may also be accessed and altered by humans. We will develop the beginnings of a solution based on the following principles: such manipulation tasks can be solved by a hierarchical two-level planning strategy, consisting of a high-level metaplanner making use of low-level primitives; the low-level primitives should include push-grasping, sweeping, and other nonprehensile actions that take advantage of mechanics to manipulate cluttered environments when simple grasp-and-carry is impeded; and uncertainty in the state of the environment and its physical properties should be accounted for at both the metaplanner and primitive levels.<br/><br/>Broader Impacts: Although not all outreach goals can be completed within the revised scope, cluttered tasks are critically important for an aging population of about 35 million people (one in eight) in the United States. Furthermore, graduate students involved in this project will benefit from an ongoing collaboration with TU Munich, a world leader in robot control and personal robotics. TUM, CMU, and Northwestern have a history of graduate student exchange and have agreed to host exchange students under this project. Undergraduates will participate in the research as REU students or in other capacities. Several recent undergraduates working in the labs at CMU and Northwestern have gone on to PhD study in robotics, some with NSF graduate fellowships. Graduate students on this project will participate in internships at the Museum of Science and Industry during its upcoming Robot Revolution exhibit. They will interact with the public and help develop a robot manipulation demonstration for the exhibit main stage. These students will provide technical expertise to the exhibit while benefitting from a valuable outreach experience. Other planned outreach activities include lab tours and talks at local high schools. Both PIs serve as mentors in research programs for underrepresented undergraduate students. These students would have an opportunity to work on state-of-the-art manipulation hardware as part of this project."
"1218155","RI: Small: Collaborative Research: Distributed Heterogeneous Ocean Robots for Detecting and Monitoring Oil Plumes","IIS","ROBUST INTELLIGENCE","09/01/2012","08/27/2012","Yi Guo","NJ","Stevens Institute of Technology","Standard Grant","Satyandra Gupta","08/31/2015","$200,501.00","","yguo1@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7495","7923","$0.00","This collaborative project addresses the need for ocean observational techniques which was highlighted by the recent Deepwater Horizon incident. The proposed project investigates heterogeneous ocean robots (including wave gliders, unmanned surface vessels, and autonomous underwater vehicles) to detect and monitor the propagation of oil plumes. Specific objectives include: 1) the development of a distributed multi-robot cooperative deployment algorithm using partial differential equation (PDE) based methods that match the oceanographic model of oil transport, 2) the development of authentic dynamic model of the new wave glider platform to incorporate in the cooperative control, and 3) assessing the potential advantages of innovative algorithms through simulations and experimental demonstration in a coastal experiment using a network of ocean robot platforms.<br/><br/>Broader Impacts: The proposed project will provide novel algorithmic and software support for collective sensing, and address a pressing real-world need for better sensing of underwater hydrocarbon plumes. The techniques developed in the proposal will have long-term impacts in underwater exploration such as oceanographic survey and energy production in deep water. The results may also potentially benefit other environmental monitoring tasks with underlying diffusion and advection processes, such as weather event tracking and climate prediction. The planned work will integrate research projects with education activities through robot-centric undergraduate and graduate education, robotics competition, short course and workshop development, and outreach to K-12 education. Partnering with the Stevens' Center for Innovation in Engineering and Science Education, the project will showcase the proposed research in the curriculum of the Stevens Build IT Underwater Robotics Scale-Up for STEM Learning and Workforce Development Project awarded by NSF."
"1143712","EAGER: Cultural models in social robotics - Comparative studies with users in the US and Japan","IIS","ROBUST INTELLIGENCE, IIS SPECIAL PROJECTS, Cyber-Human Systems, COLLABORATIVE RESEARCH","08/01/2011","07/23/2011","Selma Sabanovic","IN","Indiana University","Standard Grant","Satyandra Gupta","08/31/2014","$49,957.00","","selmas@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7495, 7484, 7367, 7298","5921, 5978, 7916, 7495","$0.00","This project performs comparative research in the United States and Japan on cultural models of social behavior and technology that influence how users perceive, make sense of, and interact with social robots. Social robots are designed to engage and communicate with people using socially appropriate behaviors, cues, norms, and roles. We (1) develop a comparative framework to study how users of social robots understand, apply, and react to cultural models of sociality and technology, as expressed in the material and discursive framing of robots, in the US and Japan, and (2) establish the foundation for long-term research collaboration on cross-cultural studies of robotics between Dr. Selma Sabanovic at Indiana University Bloomington (IUB), Dr. Takanori Shibata at the National Institute for Advanced Industrial Science and Technology (AIST) in Tsukuba, and Dr. Kazuyoshi Wada at Tokyo Metropolitan University (TMU) in Japan.<br/><br/>The project produces guidelines for best practices for using social robots in the US and Japan; this is particularly timely for Paro, which is commercially available in both countries. We also strengthen existing and build new collaborations with individuals and institutions in Japan. The project impacts education through the exchange of students and month-long internships and provides educational experiences for a broader audience, including other students, users, and relevant stakeholders through open houses and presentations by participating institutions."
"1161909","RI: Medium: Collaborative Research: Hybrid Unmanned Aerial Vehicles that Interact with Surfaces","IIS","ROBUST INTELLIGENCE","10/01/2012","09/06/2012","Russell Tedrake","MA","Massachusetts Institute of Technology","Standard Grant","Satyandra Gupta","09/30/2015","$253,941.00","","russt@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7924","$0.00","In this project, the PIs propose just the first-year study of a program of research for ""Hybrid Aerial Vehicles"" that routinely execute dynamic maneuvers to land on, move along, and take off from sites such as walls, roofs, trees and power lines. These platforms combine the best attributes of unmanned aircraft and climbing robots. They can reach remote sites rapidly, flying directly to them. After landing, they can move along surfaces to strategic locations and provide stable inspection platforms while consuming little power for hours or days. If they cling tenaciously, they can also ride out weather that is too rough for flight. When conditions improve, or the mission changes, they can jump off and become airborne, flying to a new site..<br/><br/>Broader Impacts: Although this is only an initial investigation, the PIs suggest, in addition to the usual publication and web-based dissemination, the long-term impact of the larger project will be enhanced with workshops organized to bring together academic and industry experts in the emerging topic of perching aircraft. The proposal also includes a new course to be offered during MIT?s Independent Activities Period that will introduce undergraduates to interesting problems that arise at the intersection of aerodyamics, robotics and bio-inspired mechanisms. The course takes advantage of the low cost of small RC planes to provide hands-on testing and prototyping. Based on the experience gained in running the course, the same material will be adapted to a short course for high school students, organized in collaboration with the Stanford School of Education. Both laboratories have a strong track record of involving undergraduates and under-represented minorities in research and in outreach to local high schools. To help disseminate the educational material, all software and hardware will be open source."
"1065202","RI: Medium: Collaborative Research: Towards Perpetual Flight of a Gliding Unmanned Aerial Vehicle in the Jet Stream","IIS","ROBUST INTELLIGENCE","03/01/2011","04/08/2013","John Spletzer","PA","Lehigh University","Continuing grant","Satyandra Gupta","02/28/2015","$804,219.00","Joachim Grenestedt","josa@lehigh.edu","Alumni Building 27","Bethlehem","PA","180153005","6107583021","CSE","7495","7924, 9251","$0.00","The necessary science and technology are developed to demonstrate sustained dynamic soaring of an unmanned aerial vehicle. This has four primary components. First, the team develops novel, real-time solutions specific to the dynamic soaring motion planning problem to enable perpetual flight. Second, they develop compact representations for estimating wind field in real time. These measurements serve as input to the motion planner to optimize energy that is recovered from a given soaring cycle. Third, they develop a novel airframe whose design is tightly coupled with motion planning algorithm development. Finally, a significant technical evaluation is performed which culminates in a demonstration of sustained low-altitude dynamic soaring.<br/><br/>The realization of unmanned aerial vehicles capable of staying aloft is transformative for many fields, e.g., as a low altitude and cost alternative to conventional satellite systems. Such pseudo-satellites serve as a sensor network and provide surveillance data, weather monitoring, and act as relay nodes in telecommunications networks. They are put into place, recovered, and maintained without the significant expense and failure risk associated with a space launch. A dynamically soaring unmanned aerial vehicle is ideal for hurricane observation since the craft is designed with the required strength and the associated wind gradients provide sufficient aircraft endurance for the life of the storm. One major outreach effort is the Robotics and Aerospace Camp for a group of 20-30 eighth and ninth grade students; this is part of a year round academy to promote academic achievement and college placement for economically and academically challenged middle level and high school students."
"1018613","III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications","IIS","INFO INTEGRATION & INFORMATICS","09/15/2010","09/11/2013","Rada Mihalcea","TX","University of North Texas","Standard Grant","Sylvia J. Spengler","08/31/2014","$275,336.00","","mihalcea@umich.edu","1155 Union Circle #305250","DENTON","TX","762035017","9405653940","CSE","7364","7923","$0.00","This project is devoted to building a large multilingual semantic network<br/>through the application of novel techniques for semantic analysis<br/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br/>the project is that the structure of Wikipedia can be effectively used to<br/>create a highly structured graph of world knowledge in which nodes<br/>correspond to entities and concepts described in Wikipedia, while edges<br/>capture ontological relations such as hypernymy and meronymy. Special<br/>emphasis is given to exploiting the multilingual information available in<br/>Wikipedia in order to improve the performance of each semantic analysis<br/>tool. Significant research effort is therefore aimed at developing tools<br/>for word sense disambiguation, reference resolution and the extraction of<br/>ontological relations that use multilingual reinforcement and the<br/>consistent structure and focused content of Wikipedia to solve these tasks<br/>accurately. An additional research challenge is the effective integration<br/>of inherently noisy evidence from multiple Wikipedia articles in order to<br/>increase the reliability of the overall knowledge encoded in the global<br/>Wikipedia graph. Computing probabilistic confidence values for every piece<br/>of structural information added to the network is an important step in<br/>this integration, and it is also meant to provide increased utility for<br/>downstream applications. The proposed highly structured semantic network<br/>complements existing semantic resources and is expected to have a broad<br/>impact on a wide range of natural language processing applications in need<br/>of large scale world knowledge.<br/><br/>For further information, please see the project website:<br/>http://lit.csci.unt.edu/index.php/Mu.Se.Net"
"1018590","III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications","IIS","INFO INTEGRATION & INFORMATICS","09/15/2010","09/13/2010","Razvan Bunescu","OH","Ohio University","Standard Grant","Sylvia J. Spengler","08/31/2014","$224,540.00","","bunescu@ohio.edu","108 CUTLER HL","ATHENS","OH","457012979","7405932857","CSE","7364","7923","$0.00","This project is devoted to building a large multilingual semantic network<br/>through the application of novel techniques for semantic analysis<br/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br/>the project is that the structure of Wikipedia can be effectively used to<br/>create a highly structured graph of world knowledge in which nodes<br/>correspond to entities and concepts described in Wikipedia, while edges<br/>capture ontological relations such as hypernymy and meronymy. Special<br/>emphasis is given to exploiting the multilingual information available in<br/>Wikipedia in order to improve the performance of each semantic analysis<br/>tool. Significant research effort is therefore aimed at developing tools<br/>for word sense disambiguation, reference resolution and the extraction of<br/>ontological relations that use multilingual reinforcement and the<br/>consistent structure and focused content of Wikipedia to solve these tasks<br/>accurately. An additional research challenge is the effective integration<br/>of inherently noisy evidence from multiple Wikipedia articles in order to<br/>increase the reliability of the overall knowledge encoded in the global<br/>Wikipedia graph. Computing probabilistic confidence values for every piece<br/>of structural information added to the network is an important step in<br/>this integration, and it is also meant to provide increased utility for<br/>downstream applications. The proposed highly structured semantic network<br/>complements existing semantic resources and is expected to have a broad<br/>impact on a wide range of natural language processing applications in need<br/>of large scale world knowledge.<br/><br/>For further information, please see the project website:<br/>http://lit.csci.unt.edu/index.php/Mu.Se.Net"
"0913015","RI: Small: Swarms That 'Hear The Shape of a Drum'","IIS","ROBUST INTELLIGENCE","07/15/2009","05/05/2011","Herbert Tanner","DE","University of Delaware","Continuing grant","Satyandra Gupta","08/31/2014","$450,001.00","","btanner@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","7495","7495, 7923, 9150, 9215, HPCC","$0.00","This proposal identifies a pathway to distributed pattern recognition through parallelization of a particular contour identification algorithm and decentralized data collection using formations of robots. Such a system recognizes patterns in the data it collects autonomously. Anticipated applications range from homeland security, to emergency response, scientific exploration and environmental monitoring. <br/><br/>Traditional mobile sensor networks are based on an architecture in which some minimal signal processing is performed on the sensing nodes, while the bulk of information is directed to a network sink for processing and interpretation. The hypothesis here is that the same communication infrastructure that enables motion coordination in formation of robots can be exploited for distributed processing of sensor data and autonomous pattern recognition without human intervention. Thus, information is interpreted in a distributed fashion and without dependence on the capabilities of specialized individual nodes. This method brings forward a robust and autonomous system which can inherently tolerate node and network failures and exhibits collective intelligence in the form of group associative memory. <br/><br/>Technical challenges to be overcome are the development of decentralized and provably convergent cooperative motion control designs which can enable targeted data collection, and the scalable implementation of a pattern recognition algorithm based on Dirichle Laplacians along with its integration with spatially distributed Hopfield neural networks. The complete system will be demonstrated by an experimental test-bed with mobile robots capable of recognizing noisy, variable shapes on the laboratory floor. Outreach activities will include undergraduate research and summer programs for secondary school teachers."
"0910640","HCC: Large: Collaborative Research: Widescale Computer-Mediated Communication in Crisis Response: Roles, Trust & Accuracy in the Social Distribution of Information","IIS","Cyber-Human Systems","09/01/2009","08/20/2009","Gloria Mark","CA","University of California-Irvine","Standard Grant","Ephraim P. Glinert","08/31/2014","$479,270.00","","gmark@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7925, 9215, HPCC","$0.00","Information and communication technology (ICT) promises to help reduce impacts of large-scale disruptions from natural hazards, pandemics, and terrorist threat. This research focuses on a critical aspect of large-scale emergency response -- the needs and roles of members of the public. By viewing the citizenry as a powerful, self-organizing, and collectively intelligent force, ICT can play a transformational role in crisis situations. This view of a civil society augmented by ICT is based on socio-behavioral knowledge about how people behave in crisis, rather than on simplified and mythical portrayals. With a critical reframing of emergency response as a socially-distributed information system, the project aims to leverage the knowledge of members of the public through reuse of publicly available computer mediated communications (CMCs) (e.g., community, mapping, and social networking sites; blogs; Twitter). The project will study and integrate that heterogeneous information and -- with techniques of information extraction through natural language processing as well as trust and reputation modeling -- add meta-information to help users assess context, validity, source, credibility, and timeliness to make the best decisions for their highly localized, changing conditions. <br/><br/><br/>The results of this research addresses matters of policy, practice and technological innovation, responding directly to needs identified in national policy statements, including Grand Challenge #1 of the National Science and Technology Council's Subcommittee on Disaster Reduction, which calls for the provision of ""hazard and disaster information where and when it is needed"" (SDR, 2005). At-risk populations are disproportionately affected by crises; the results of this research could mitigate the impacts on these communities. The research is also inclusive of people across different cultures/ethnic groups within the U.S. and from different countries. The project broadens the future STEM workforce, since socio-technical and practical orientations to computational research attract women to study STEM disciplines. The research contributions include cyberinfrastructure-aware applications, techniques, and services built from empirical knowledge of the social structures that produce crisis data."
"1253146","CAREER: A Rigidity Theory for Multi-Robot Formations","IIS","ROBUST INTELLIGENCE, CAREER: FACULTY EARLY CAR DEV, IIS SPECIAL PROJECTS","10/01/2013","09/12/2013","Audrey St. John","MA","Mount Holyoke College","Standard Grant","Satyandra Gupta","09/30/2018","$411,531.00","","astjohn@mtholyoke.edu","50 College Street","South Hadley","MA","010756456","4135382000","CSE","7495, 1045, 7484","1045, 7484, 7495, 9229","$0.00","This proposal connects foundational research for multi-robot formations with the development of empowering experiences for women undergraduates in the classroom and beyond. The theoretical nature of the research is complemented by a firm grounding in hardware and computer vision fundamentals, integrated throughout a comprehensive education plan. The PI will develop an understanding of geometric formations of multi-robot systems, such as swarms in both 2- and 3-dimensions. Sensor and communication costs will be integral to modeling and algorithmic considerations, as minimizing power consumption is increasingly important for the design of lightweight and agile robot platforms. The PI will establish mathematical foundations and develop algorithms in three fundamental directions: (1) understanding a formation's structural properties, (2) producing optimal control architectures, and (3) predicting a formation?s internal motions. Developing a unifying theory from both theoretical and applied perspectives will produce a wealth of new directions, such as actuating a formation as if it were a single traditional robot.<br/><br/>The research contributions have the potential to significantly impact cutting-edge technology for the control and coordination of multi-robot systems. The PI is junior faculty at Mount Holyoke College, a liberal arts college for women, where a recent growth in enrollments has led to an average of 15 computer science majors a year (surpassing the peak of 2002). She will engage this vibrant community of budding computer scientists through her proposed education plan. Two courses will be developed, designed to simultaneously educate undergraduates through core computer science principles and expose them to exciting research problems challenging the field. Students will have additional opportunities for experiences outside the classroom through highly visible robotics and computer vision projects on campus, producing role models for generations to come. By working closely with the student-run CS Club, the PI will establish a supportive environment that fosters growing interest in technology from traditionally under-represented groups. She will also actively involve students in research by supervising two undergraduates each summer through a compelling research experience."
"1218534","RI: Small: Discovery and Reuse of Domain Knowledge in Large Motion Planning Systems","IIS","ROBUST INTELLIGENCE","09/01/2012","06/19/2013","Kris Hauser","IN","Indiana University","Continuing grant","Satyandra Gupta","08/31/2015","$381,168.00","","hauserk@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7495","7923","$0.00","This project, developing new techniques for enabling planners to automatically learn from experience, offers fast, high-quality solutions to very large motion planning problems that arise in robotics, CAD/CAM, animation of virtual characters, and surgical planning. These problems are challenging because they require searching high-dimensional state spaces with complex geometric constraints, nonlinear dynamics, often with contact and impact, and long time horizons. Prior approaches have sought to solve these problems efficiently by embedding a great deal of domain knowledge into planning, but have relied heavily on human expertise to develop and exploit this knowledge. This process is tedious, error-prone, and does not scale well to harder problems that do not possess an obvious structure. This project will investigate automated strategies for planning systems to automatically discover common solution structures from past experience and to reuse this knowledge in new problems, with the ultimate goal of demonstrating a system that automatically optimizes planning strategies for a novel domain with minimal training and hand tuning.<br/><br/>Broader Impacts: The ability to solve large planning problems efficiently has myriad benefits to many fields of knowledge. But on a human level, this grant will provide the opportunity to recruit an undergraduate or Master's student intern from a minority-serving institution each summer, in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). Broader dissemination of the work will be achieved by distributing a research and educational software library for task-and-motion planning (PyTAMP), and integrating software with the open-source ROS and OMPL libraries. Research will be integrated with education in robotics and AI courses at the undergraduate and graduate level, as well as in K-12 robotics outreach."
"1161679","RI: Medium: Collaborative Research: Hybrid Unmanned Aerial Vehicles that Interact with Surfaces","IIS","ROBUST INTELLIGENCE","10/01/2012","09/06/2012","Mark Cutkosky","CA","Stanford University","Standard Grant","Satyandra Gupta","09/30/2015","$220,102.00","","cutkosky@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7924","$0.00","In this project, the PIs propose just the first-year study of a program of research for ""Hybrid Aerial Vehicles"" that routinely execute dynamic maneuvers to land on, move along, and take off from sites such as walls, roofs, trees and power lines. These platforms combine the best attributes of unmanned aircraft and climbing robots. They can reach remote sites rapidly, flying directly to them. After landing, they can move along surfaces to strategic locations and provide stable inspection platforms while consuming little power for hours or days. If they cling tenaciously, they can also ride out weather that is too rough for flight. When conditions improve, or the mission changes, they can jump off and become airborne, flying to a new site.<br/><br/>Broader Impacts: Although this is only an initial investigation, the PIs suggest, in addition to the usual publication and web-based dissemination, the long-term impact of the larger project will be enhanced with workshops organized to bring together academic and industry experts in the emerging topic of perching aircraft. The proposal also includes a new course to be offered during MIT?s Independent Activities Period that will introduce undergraduates to interesting problems that arise at the intersection of aerodyamics, robotics and bio-inspired mechanisms. The course takes advantage of the low cost of small RC planes to provide hands-on testing and prototyping. Based on the experience gained in running the course, the same material will be adapted to a short course for high school students, organized in collaboration with the Stanford School of Education. Both laboratories have a strong track record of involving undergraduates and under-represented minorities in research and in outreach to local high schools. To help disseminate the educational material, all software and hardware will be open source."
"1305093","IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2012-2013) Student Travel Awards","IIS","ROBUST INTELLIGENCE","02/01/2013","01/16/2013","Dylan Shell","TX","Texas Engineering Experiment Station","Standard Grant","Satyandra Gupta","01/31/2015","$10,000.00","","dshell@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495","7495, 7556","$0.00","The annual IEEE International Symposium on Safety Security and Rescue Robotics (SSRR),<br/>sponsored by the IEEE Robotics and Automation Society, International Rescue System Institute,<br/>and the Center for Robot-Assisted Search and Rescue, has a tradition of attracting cutting-edge<br/>papers in the theory and practice of robots for rapid and secure inspection of critical<br/>infrastructure, disaster response and recovery, disaster mitigation and recovery, detection of<br/>chemical, biological and radiological risks, and operations in these dangerous sites.<br/><br/>In the past it has served as a forum gathering international researchers together for the<br/>exchange of ideas on technical problems and their solutions in these domains. The 10th<br/>anniversary SSRR 2012 will be hosted this year at Texas A&M, College Station, Texas, while the<br/>11th will be hosted in Linkoping, Sweden. This proposal requests travel funds from NSF to assist<br/>students to participate in SSRR 2012 & 2013 to participate in field trials with actual responders.<br/>This represents both the intellectgual merit and the broader impacts."
"1054331","CAREER: Lifesaving Robotic Tentacles","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","07/01/2011","02/01/2011","Robert Webster","TN","Vanderbilt University","Standard Grant","Satyandra Gupta","06/30/2016","$400,000.00","","robert.webster@vanderbilt.edu","Office of Sponsored Programs","NASHVILLE","TN","372407830","6158756070","CSE","7495, 9150","1045, 1187, 7495, 9150","$0.00","Within medical robotics, this research advances telerobotics, and continuum robot architectures, models, sensing, and control, as well as medical science by enabling new diagnostic procedures. Scientific understanding of continuum robots is entering an exciting era where early assumptions implying constant curvature are giving way to more descriptive models of how actuators and external loads combine to produce variable curvatures. Infusing theory from mechanics into robotics science provides a bright path forward. Outside its own field, this also enhances human understanding of biology ? mechanics-based models provide insight on how elephant trunks, octopus tentacles, and other biological continuum structures perform so elegantly.<br/><br/>These systems are minimally invasive and are used to combat the most deadly form of cancer (lung), surgically access one of the most difficult to reach locations (the skull base), and increase the impact of one of the most underutilized curative treatments available (cochlear implantation). Within and beyond these first three applications, these less invasive, more accurate, information-guided continuum robots improve public health by reducing patient recovery times, infection rates, and treatment costs, and enabling entirely new surgical approaches to diseases that are untreatable (and in many cases terminal) today. The proposed curriculum infuses research results into the classroom, and involves undergraduates, high school girls, and high school teachers which enhances the research while promoting learning. The tactile haptic device increases the accessibility of engineering to the blind. The testbeds enhance the research infrastructure of the PI?s lab, and the haptic devices enhance the educational infrastructure in universities, in high schools, and in schools for the blind."
"1017926","III: Small: AegisDB: Integrated Real-Time Geo-Stream Processing and Monitoring System: A Data-Type-Based Approach","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","09/21/2011","Yan Huang","TX","University of North Texas","Standard Grant","Sylvia J. Spengler","08/31/2014","$465,807.00","","huangyan@unt.edu","1155 Union Circle #305250","DENTON","TX","762035017","9405653940","CSE","7364","7923, 9251","$0.00","This project contributes to the exciting field of geo-stream processing. <br/>Specifically, an integrated real-time geo-stream processing and monitoring <br/>system called AegisDB will be built and the research environment and results <br/>will be leveraged to stimulate learning at the K-12, undergraduate, and <br/>graduate levels. <br/><br/>The AegisDB system includes a Geo-Stream Algebra which uses a data-type-<br/>based approach as opposed to a traditional tuple-based approach for <br/>representing and querying geo-streams. The STREAM data types of the <br/>algebra unify static data, traditional streams, geo-streams from fixed <br/>locations, and geo-streams that move. The proposed Aggregate Algebra <br/>generalizes the operator GROUP BY to generalized aggregations (GAs) <br/>and bridges the fundamental gap between point observations from sensors <br/>and spatio-temporally continuous phenomena. Several novel <br/>spatial-centric operator optimization techniques are proposed, <br/>which include a velocity-based filtering that utilizes the physical <br/>limitations of most moving objects and a spatial-coverage-based query <br/>combination that combines geo-stream queries based on <br/>their intended spatial coverage.<br/><br/>The proposed AegisDB system will transform the ways to define and monitor <br/>more sophisticated spatio-temporal events for alerting purposes. The result is <br/>the significantly improved realtime access to important spatio-temporal events <br/>related to our lives by professionals and the general public. The system will <br/>be critical for important domains including transportation, environmental <br/>science, hazard monitoring, and emergency responses. <br/><br/>This project has strong education and outreach components. Environmental <br/>models for K-12 teachers and students using real-time environmental datasets <br/>will be designed. An informal session on how to collect, store, and distribute <br/>environmental data will be presented through the Family Fun Science <br/>Saturday events of the Elm Fork Education Center of UNT. A course module <br/>on geo-stream processing will be developed. Women and minorities will be <br/>recruited into the research project. Undergraduate students looking for <br/>research opportunities will be mentored. <br/><br/>For further information concerning this project see the project web page: <br/>URL: http://www.cse.unt.edu/~huangyan/AegisDB/"
"0916852","III: Small:Using Data Mining and Recommender Systems to Facilitate Large-Scale Requirements Processes","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","06/13/2013","Jane Huang","IL","DePaul University","Standard Grant","Sylvia J. Spengler","09/30/2014","$507,563.00","Bamshad Mobasher","jhuang@cs.depaul.edu","1 East Jackson Boulevard","Chicago","IL","606042287","3123418000","CSE","7364","7364, 7923, 9216, HPCC, 9251, 9102","$0.00","Problems related to requirements definitions account for numerous project failures and translate into significant amounts of wasted funds. In many cases, these problems originate from inadequacies in the human-intensive task of eliciting stakeholders' needs, and the subsequent problems of transforming them into a set of clearly articulated and prioritized requirements. These problems are particularly evident in very large projects such as the FBI Virtual Case File or NASA's Space Station, in which knowledge is dispersed across thousands of different stakeholders. On one hand, it is desirable to include as many people as possible in the elicitation and prioritization process, but on the other hand this can quickly lead to a rather chaotic overload of information and opinions. The work proposed under this grant will develop a new framework that utilizes data mining and recommender systems techniques to process and analyze high volumes of unstructured data in order to facilitate large-scale and broadly inclusive requirements processes. The proposal is based on the observation that the requirements elicitation process of many large-scaled industrial and governmental projects is inherently data-driven, and could therefore benefit from computer-supported tools based on data mining and user modeling techniques. <br/><br/>INTELLECTUAL MERIT <br/>The proposed research will lead to a robust requirements elicitation framework and an associated library of tools which can be used to augment the functionality of wikis, forums, and specialized management tools used in the requirements domain. Specifically, this research will enhance requirements clustering techniques by incorporating prior knowledge and user-derived constraints. A contextualized recommender system will be designed to facilitate appropriate placement of stakeholders into requirements discussion forums generated in the clustering phase. <br/><br/>BROADER IMPACT <br/>The proposed work has potential for broad impact across organizations that develop stakeholder-intensive systems. Technology transfer can be expected due to collaborations with organizations such as Siemens and Google planned as an integral part of this research. Educational materials will be developed specifically for requirements engineering and recommender systems courses, and will be broadly disseminated. <br/><br/>Key Words: Recommender systems; Data mining; Clustering; Requirements engineering; Requirements elicitation."
"0916614","III:Small: Commugrate -- A Community-based Data Integration System","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","11/15/2011","Mourad Ouzzani","IN","Purdue University","Standard Grant","Sylvia J. Spengler","08/31/2014","$498,373.00","Ahmed Elmagarmid, Mourad Ouzzani","mourad@cs.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7364, 7923, 9216, HPCC","$0.00","The goal of this project is to build Commugrate, a community-driven <br/>data integration system that capitalizes on the information gained<br/>from the interactions of communities of humans with data sources.<br/><br/>Commugrate tackles key challenges raised by the increase in the<br/>number of information sources used in science, engineering, and<br/>industry, as well as the need for large-scale data integration<br/>solutions to enable effective access to these sources. These challenges<br/>include schema matching and mapping, record-linkage, and data repair.<br/><br/>More specifically, Commugrate (i) utilizes both direct and indirect<br/>contributions from different types of human communities with a focus on<br/>the latter contributions, (ii) solves key data integration issues using <br/>new evidences like usage and behavior data which have not been previously <br/>used, (iii) adopts a new technique for schema matching, which defines <br/>a new class of its own, namely usage-based schema matching, <br/>(iv) introduces the first of its genre technique for record linkage based <br/>on entities' behavior, and (v) provides an adaptive feedback system to <br/>improve the quality of the data by making the best use of users feedback. <br/><br/>Commugrate has a broad impact across multiple segments of society as data <br/>integration is by far the most important and in the same time vexing issue <br/>in many areas in sciences, engineering, and industry. Furthermore, <br/>leveraging users' interactions with data sources, especially indirect <br/>interaction, may provide several benefits and help solve many intractable <br/>data integration tasks which cannot be done without human intervention. <br/><br/>PhD students will pursue research in this project. Publications, technical <br/>reports, software and experimental data from this research will be <br/>disseminated via the project web site at <br/>http://www.purdue.edu/cybercenter/commugrate."
"0916720","RI: Small: AquaSWARM: Small Wireless Autonomous Robots for Monitoring of Aquatic Environments","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2009","08/14/2013","Xiaobo Tan","MI","Michigan State University","Standard Grant","Satyandra Gupta","08/31/2014","$433,999.00","Elena Litchman","xbtan@msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7495, 8013","7923, 9215, HPCC, 9251, 7495, 8086","$0.00","The goal of the AquaSWARM project is to design and develop small, energy-efficient, autonomous underwater robots as sensor-rich platforms for dynamic, long-duration monitoring of aquatic environments. A novel concept of gliding robotic fish is investigated, which merges the energy-efficient design of underwater glider with the high maneuverability of robotic fish. Gliding motion, enabled by pitch and buoyancy control, is exploited to realize dive/ascent and large-distance horizontal travel. Soft actuation materials-based flexible tail fins are used to achieve maneuvers with high hydrodynamic efficiency. The research is focused on understanding gliding design for small robotic fish, and addressing the energy efficiency issue from a systems perspective. Schools of such autonomous robots are deployed in lakes at the Michigan State University Kellogg Biological Station to detect harmful algal blooms (HABs) and validate models for HAB dynamics. <br/><br/>The project is expected to result in cost-effective, underwater robots that can perform uninterrupted, long-duration (several months), long-travel (hundreds of miles) operation in aquatic environments. This will provide a novel, viable, versatile, cyber-physical infrastructure for aquatic environmental monitoring, with applications ranging from understanding the impact of global warming, to environmental protection, drinking water reservoir safety, and seaport security. The project also offers an interdisciplinary training environment for graduate and undergraduate students, and provides outreach opportunities to inspire pre-college students and train highly qualified teachers. Robotic fish-based HAB detection will also be used as a tool to engage communities at local lakes and stimulate their interest in novel technology and environmental issues."
"0916749","HCC: Small: Perceiving and Enacting Actions in Simulated Environments: The Role of Perceptual Motor Features and Individual Differences","IIS","Cyber-Human Systems","09/01/2009","07/07/2009","Shulan Lu","TX","Texas A&M University-Commerce","Standard Grant","Ephraim P. Glinert","08/31/2014","$500,000.00","Tracy Henley, Derek Harter","lu.shulan@gmail.com","Office of Research & Sponsored P","Commerce","TX","754293011","9038865964","CSE","7367","7367, 7923, 9215, HPCC","$0.00","The long-term practical objective of this research project is to develop simulated training environments that mesh with the constraints of perceiving and enacting actions in the real world. Simulated environments differ from real environments in a number of aspects. In particular, there are significant differences in perceptual and motor features between these environments. Advances in embodied cognitive science have consistently demonstrated how the body, and the environment which it inhabits, are tightly coupled with the mind, and together they form a complex system for perception and action. The central questions being investigated in this research involve identifying the conditions that promote perceiving and enacting actions in simulated training environments, and include questions such as: (a) whether high fidelity simulation environments and perceptual motor cues signaling risk are necessary ingredients to enhance training effectiveness; (b) whether performance pressure is a necessary component in training paradigms; (c) the extent to which bodily interactivity with the training environment is necessary; and (d) the extent to which individual differences in perception and action contribute to training effectiveness of simulated environments. This research project also begins to investigate whether encoding events in language that selectively focus on particular conceptual components can be used as an effective mechanism to guide visual attention. Simulation environments will be modeled after real world events, and will vary the degree of user control and level of immersion. Research participants will have their eye movements recorded, mark off when a meaningful event ends and another begins, perform perceptual mental simulation tasks by identifying the correct bodily movements, or manipulate user controlled simulation environments. <br/><br/>This research project investigates how people spontaneously engage in riskier behaviors due to differences between simulated environments and the real world, whether putting people under some pressure is critical for successful training in simulated environments, and what type of physical interactivity with simulated environments is essential for optimal performance. This research also investigates whether differences in cognitive abilities and personality types have effects on performance in simulated environments. This project uses multiple methods in an attempt to understand along which dimensions training in simulated environments can effectively transfer to real world practice. This research pushes forward the frontiers of perceiving and enacting actions in psychology, computer science, robotics, and human computer interactions. The results will form an empirical basis promoting the development of improved methods for training in simulated worlds. Improved designs of simulated worlds for training and modeling are increasingly important in many areas of our society including: impacts in education, military, law enforcement and emergency response organization training; smart environments for the better treatment of disabled or special needs populations; and entertainment industries and the arts."
"1247813","BIGDATA: Mid-Scale: DA: ESCE: Collaborative Research: Scalable Statistical Computing for Emerging Omics Data Streams","IIS","Big Data Science &Engineering, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","08/01/2013","01/24/2014","Martin Morgan","WA","Fred Hutchinson Cancer Research Center","Standard Grant","Sylvia J. Spengler","07/31/2015","$1,200,000.00","","mtmorgan@fhcrc.org","1100 FAIRVIEW AVE N J6-300","SEATTLE","WA","981094433","2066674868","CSE","8083, 1640, 7364","7433, 7924, 8083, 1640","$0.00","Bioinformatic data sets are large and complicated. Marshalling and managing necessary resources (e.g., hardware; computer and programmer time) requires significant skill. Effective analysis and comprehension involves sophisticated statistical understanding. Domains of application and available data types change rapidly, requiring flexible and familiar programming environments. Collaborations involve diverse research groups of heterogeneous size and expertise. This project develops and disseminates new and efficient approaches to solving present and emerging problems in statistical analysis and interpretation of very large data. The project combines the strengths of two very widely used and complementary bioinformatics projects, Bioconductor and Galaxy.<br/><br/>The project has three components. The first, providing scalable access, develops R programming paradigms appropriate for scalable analysis. R/Bioconductor software will be developed for efficient reduction of large data to statistical descriptions by iterating data through transformation kernels. Bioconductor will be deployed for use in an accessible cloud-based environment, and will be integrated into the Galaxy deployment scheme. The second component is to provide statistical methods for big genomic data bydeveloping high performance statistical methodologies for analysis of large bioinformatics data. This applies the initial technical achievements to specific requirements of statistical analysis in genomics. Domains of application include: quality assessment and normalization of very large raw data; data reduction and uncertainty measure calculation for downstream interrogation; and discovery, reporting and auditing of novel biological findings. Developments require novel computational approaches that avoid all-data-in-memory computational models (prevalent in current algorithm implementations), and that re-express monolithic algorithms as concurrently executable independent components. This emphasizes extensible and composable elements to yield a richer toolkit for statistical genomics. The aim leverages R?s strength as a language for rapid development of statistical methodologies, and emphasizes areas of proven strength in the Bioconductor project. The third component addresses decision making. This aspect provides integration of R / Bioconductor work flows into Galaxy. We will deploy key results from Aim 2 as Galaxy work flows. New real-time feedback for streaming analytics will be introduced to Galaxy, and leveraged by Bioconductor.<br/><br/>The project includes very significant capacity building. The Bioconductor project successfully solicits, tests, and disseminates over 600 R packages for the statistical analysis and comprehension of high-throughput genomic data. All packages include extensive documentation, including vignettes describing intent, function, and interoperability. Packages reflect contributions from a broad scientific community, and enable national and international graduate, post-graduate, and commercial research activities in statistical, bioinformatic, and computational domains. This project furthers the capacity building impact of Bioconductor by addressing memory and performance limitations to statistical analysis of large and complicated bioinformatic data. Galaxy enables broad access to computational resources for data intensive biomedical research. This project enhances the capacity building impacts of Galaxy by providing scalable processing of big bioinformatic data, and enabling exploratory analysis by a broad bioinformatic community. The coupling of Bioconductor and Galaxy provides significant synergy, facilitating rapid translation of statistical and bioinformatic research developed in R to broad use through Galaxy."
"0747356","CAREER: Scalable Image Search and Recognition: Learning to Efficiently Leverage Incomplete Information","IIS","ROBUST INTELLIGENCE","06/01/2008","03/30/2011","Kristen Grauman","TX","University of Texas at Austin","Continuing grant","Jie Yang","05/31/2015","$509,050.00","","grauman@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","1045, 1187, 7495, 9216, HPCC, 9102, 9215","$0.00","Abstract<br/><br/>Title: Scalable Image Search and Recognition: Learning to Efficiently Leverage Incomplete Information<br/>PI: Kristen Grauman<br/>Institution: The University of Texas at Austin<br/><br/><br/>As it becomes increasingly feasible to capture, transmit, and store image and video content on a large scale, the need for machine vision algorithms capable of interpreting it is undeniable. The opportunities appear vast, but progress towards large-scale visual recognition hinges on the development of computationally efficient methods that can effectively leverage minimal supervision. The proposed research considers how informative but incomplete cues can contribute to the learning process, with the goal of enabling large volumes of visual data to be efficiently organized and queried, and a greater number of visual categories to be recognized.<br/><br/>This project intends to advance the scale of the recognition problem by using fragments of supervision, even when they are inexact or dynamic. The PI and her team will develop methods to allow very large image databases to be searched according to distance functions inferred from sparse similarity constraints. They will consider visual category learning scenarios where the system itself actively requests only the most useful information, and integrates ambiguous cues from external modalities such as text. As knowledge about an image collection evolves over time, so must the associated search structure. The PI will investigate ways to adapt image indexing techniques according to dynamic constraints. The proposed technical plan calls for a combination of ideas from vision, learning, and algorithms. Scalable recognition and image search will affect the extent to which visual data can be accessed and mined, making this work relevant to other scientific disciplines where images capture vital information but currently lack proper tools for large-scale analysis. The project also entails complementary educational and outreach activities aimed at engaging students in research, furthering communication across related areas, and encouraging young students to consider studying computer science or engineering.<br/><br/>Updates will be available from: http://www.cs.utexas.edu/grauman/"
"0644418","CAREER: Designing Systems for Molecular Query-Retrieval and Molecular Informatics","IIS","INFO INTEGRATION & INFORMATICS","02/01/2007","01/22/2014","Rahul Singh","CA","San Francisco State University","Continuing grant","Sylvia J. Spengler","01/31/2015","$501,053.00","","rahul@sfsu.edu","1600 Holloway Ave","San Francisco","CA","941321722","4154053943","CSE","7364","1045, 1187, 7364, 9216, HPCC","$0.00","The ability to manage and efficaciously reason with molecular structural information has enormous impact both for bio-chemical research as well as for the discovery of new and more efficacious therapeutics. The advent of technologies like NMR, Crystallography, and Combinatorial Chemistry, allow us today to generate unprecedented amounts of information at the molecular structural level. However, the capacity to generate molecular structural data far exceeds our ability to effectively manage, query, and assimilate it at the state-of-the-art.<br/><br/>From a computer science perspective, molecules are complex, multidimensional entities which present critical challenges for effective and efficient design of representation, retrieval, modeling, and interaction techniques. In this context, this research focuses on three challenges: (1) Designing techniques for representation and similarity-based matching of molecules, (2) Development of indexing strategies for molecular query-retrieval, and (3) Designing knowledge environments for discovery of therapeutics. The specific research innovations include design of standard coordinate systems to represent highly complex molecular surfaces, developing efficient information matching and retrieval techniques for comparing molecules, and design of integrated information management of molecular structures and biological properties including the development of user-data interaction techniques and algorithms for context supportive access to meta-knowledge. <br/><br/>Broader Impact: Techniques and systems developed as part of this research will be made publicly available and allow fundamental advancements in management, exploration, analysis, and reasoning with molecular information. This has the potential to introduce ground breaking advancements in areas like drug/therapeutics discovery and thus is critical to the society at large. Furthermore, this research will establish ""Molecular Query-Retrieval and Molecular Informatics"" as an integral part of computer science research in information management, retrieval, analysis, and assimilation. This will allow computer scientists to participate and advance a critical and new interdisciplinary area. Finally, the education and outreach component will (a) develop models to enhance research experience and productivity of students, (b) providing exposure to computer science at the grassroots-level through novel interactions with students and teachers at K-12 levels, and (c) broaden participation by mentoring women and minority students."
"1350671","CAREER: Problem Solving in Dynamic, Distributed Environments","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","01/15/2014","01/23/2014","Roger Mailler","OK","University of Tulsa","Standard Grant","James Donlon","12/31/2018","$450,793.00","","roger-mailler@utulsa.edu","800 S. Tucker Drive","Tulsa","OK","741049700","9186312192","CSE","7495, 9150","1045, 7495, 9150","$0.00","Computers are increasingly used to monitor and manage many aspects of our daily lives. These systems are often required to work together to solve complex problems that are rapidly changing. Current approaches to addressing these situations develop tailored distributed protocols that are verified through empirical testing. This project increases the practical applicability of distributed problem solving techniques by developing a theoretical model of these problems based on thermodynamic theory. Using this model, a protocol's performance can, for the first time ever, be predicted under previously untested conditions.<br/><br/>This theoretical model is validated through extensive empirical evaluation and this project develops a new protocol that alters its problem solving strategy to maximize the trade-off between deliberate and reactive decision making based on environmental dynamics. This protocol is applied to address a pressing practical problem: allocating telescopes for tracking objects in Low Earth Orbit (LEO). With nearly all of our manned space missions and satellites in LEO, effectively monitoring space debris has broad implications to society at large and scientific progress along numerous directions.<br/><br/>This transformative research combines cross-disciplinary ideas from artificial intelligence, distributed systems, and statistical physics. The educational initiatives in this project directly address the recruitment and retention of students, especially focusing on women and minorities, into Computer Science by generating excitement through the Heartland Gaming Expo and by utilizing a new peer outreach program, called Engineering Ambassadors."
"1025569","Public engagement in networked virtual organizations and its effects on discovery and innovation","ACI","Cyber-Human Systems, VIRTUAL ORGANIZATIONS","09/01/2010","08/06/2010","Christopher Kelty","CA","University of California-Los Angeles","Standard Grant","Kevin Crowston","08/31/2014","$378,182.00","Aaron Panofsky","ckelty@ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7367, 7642","7969, 7642","$0.00","This research project asks: How does public engagement in collaborative science and engineering projects affect the process of discovery and innovation? Combining approaches and tools from sociology, information studies, anthropology and public policy, we will provide both concrete models and detailed case studies that analyze the effects of organizations' involvement with members of the organized public on the nature of new networked virtual organizations with respect to three domains of variation: structure, outcomes and governance. The models, concepts and modes of analysis will be constructed to be understandable across disciplines, as well as in the scientific and engineering domains under study.<br/><br/>To build these models and concepts, we will analyze existing cases in the scholarly and popular literature and create in-depth studies of exemplary cases showing how they work and the struggles they face. Our results will have implications for how we measure, report and reward innovation; how we design policy and distribute resources that encourage public participation; and how we build infrastructures that integrate the work of professional scientists with that of other individuals who have a stake in science and engineering."
"1350360","CAREER: Authorship Analysis in Cross-Domain Settings","IIS","ROBUST INTELLIGENCE","01/15/2014","01/17/2014","Thamar Solorio","AL","University of Alabama at Birmingham","Continuing grant","Tatiana D. Korelsky","12/31/2018","$85,664.00","","solorio@cis.uab.edu","AB 1170","Birmingham","AL","352940111","2059345266","CSE","7495","1045, 7495, 9150","$0.00","Authorship Analysis (AA) is the task of extracting characteristics from written documents that can help to determine authorship of a document, generate a profile of the author, or identify cases of plagiarism. AA can be used for historical purposes, to settle disputes over the original creators of a given document, and to build a prosecution case against an online abuser.<br/><br/>Most previous work in AA assumes the availability of samples with known authorship that closely match the domain of the documents of interest. A strong assumption like this one limits the applications of AA approaches. This program addresses this key outstanding challenge by designing robust frameworks for scenarios with different cross-domain degrees: cross-topic, cross-genre and cross-modality (text vs. transcribed speech). The project leverages the large amounts of free text available representing each cross-domain setting to learn general lexical and syntactic distributional correspondences. These correspondences are used to map the out-of-domain texts to a representation that is closer to the target domain. <br/><br/>Direct contributions of this research include new approaches to extract and embed cross-domain prior knowledge into AA models in the form of distributional trajectories; and a solid understanding of the influence of topic, genre, and modality in the feature engineering process for AA that will also be helpful in other text processing tasks. This research will make direct contributions to the field of forensic linguistics, which is of major relevance for national security.<br/><br/>The PI will design an advanced seminar in computational approaches for forensic linguistics and will expand her ongoing educational and outreach activities for underrepresented groups in the STEM disciplines. The PI will integrate opportunities for international visits to key research labs for the graduate students involved in the program that will enrich their training and provide great networking opportunities."
"0964196","SHF: Medium:Performance Analysis and Optimization for Logic Rule Engines","CCF","Programing Languages&Compilers, Software Engineering, INFO INTEGRATION & INFORMATICS, SOFTWARE & HARDWARE FOUNDATION","06/01/2010","06/15/2012","Michael Kifer","NY","SUNY at Stony Brook","Continuing grant","Sol J. Greenspan","05/31/2015","$831,991.00","David Warren, Yanhong Liu","kifer@cs.stonybrook.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7943, 7944, 7364, 7798","9218, 7943, 9251, HPCC, 7924","$0.00","Rule systems are increasingly used in areas ranging from Program Analysis,<br/>Semantic Web, Security Frameworks, Sensor Networks, Cognitive Radio, and<br/>Disruption-tolerant Networking, each with its own demands for efficiency<br/>and scalability. Advances in these areas will lead to a new generation of<br/>robust and secure applications that control devices on which human safety<br/>and even lives depend, supply with critical information, and help people<br/>make informed decisions by pulling together distributed Web-centric<br/>resources, analyzing them, and automating complex information-bound tasks.<br/>However, existing implementations of rule systems are not sufficiently<br/>scalable and have been shown to vary widely in performance. To make the<br/>above vision of next generation robust applications a reality, one must<br/>understand the performance characteristics of rule systems and develop<br/>scalable optimization and analysis techniques for them. Although advances<br/>have been made in improving performance of rule systems, the problem<br/>remained extremely challenging and poorly understood both theoretically and<br/>implementation-wise.<br/><br/>This project will develop a comprehensive framework for rigorous<br/>understanding and optimization of rule systems. The approach is based on<br/>precise cost calculations and global program transformations, and it<br/>combines and extends techniques from database query optimization, compiler<br/>optimization, and recursive query processing. It includes: (1) techniques<br/>for generating logically equivalent but more efficient programs; (2) cost<br/>models and analysis for generating parameterized cost formulas for the<br/>running time and space usage of rule programs; (3) techniques for<br/>estimating parameters of the cost formulas; (4) heuristics for searching<br/>the exponentially large space of logically equivalent rule programs to find<br/>the ones with the best predicted time, space, and tradeoffs; and (5)<br/>implementation of the strategy as an optimizer for the widely used,<br/>open-source XSB Logic Programming System. The method and implementation<br/>will be evaluated using applications in Program Analysis and Semantic Web."
"1346605","FrameNet Workshop: Developing New NLP Applications","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","08/01/2013","08/08/2013","Collin Baker","CA","International Computer Science Institute","Standard Grant","Tatiana D. Korelsky","01/31/2015","$30,000.00","","collinb@icsi.berkeley.edu","1947 CENTER ST STE 600","BERKELEY","CA","947044115","5106662900","CSE","7364, 7495","7495, 7556","$0.00","In recent years, computer systems designed to understand ordinary language have improved rapidly. These advances depend in part on improving the language resources that help systems recognize different senses of individual words and how the parts of a sentence fit together. <br/><br/>People understand words largely by relating them to common situations; in 'She tossed the letter across the table to Jerry', one recognizes that the main idea comes from 'toss', and understands the different roles that 'she', 'the letter', 'across the table', and 'to Jerry' play. For the past fifteen years, the FrameNet team at the International Computer Science Institute has been defining situations, called semantic frames, and labeling examples with semantic roles on the constituents of illustrative sentences. The FrameNet knowledge database contains over 1,100 semantic frames, ranging from getting a job to curing a disease, and almost 200,000 labeled sentences. Other researchers have created software to automatically label sentences in open text based on FrameNet data; these automatic semantic role labeling (ASRL) systems facilitate the automatic recognition of events and their participants in documents ranging from news stories and military reports.<br/><br/>This award funds a one-week workshop, September 9-13, 2013, introducing FrameNet to a wider range of industry and academic participants. Speakers include the FrameNet team as well as developers and users of ASRL systems. Topics covered range from implications of FrameNet for protecting privacy to using frames in understanding metaphor. Software developers have a hands-on coding session using the new FrameNet library for NLTK; other participants perform hands-on frame definition and annotation."
"1318759","RI: Small: Collaborative Research: Learning Causal Structure from Complex Time Series Data","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","09/01/2013","08/26/2013","Sergey Plis","NM","The MIND Research Network","Standard Grant","Kenneth C. Whang","08/31/2016","$280,559.00","","splis@mrn.org","1101 Yale Blvd. NE","Albuquerque","NM","871064188","5052725028","CSE","7495, 9150","7495, 7923, 9150","$0.00","In many important domains, one must learn the causal structure of a dynamical system in order to design appropriate interventions, policies, and experiments. This project develops a well founded theory and practical algorithms for such learning when scientists cannot measure the system quickly enough and/or omit causally important variables. Moreover, the theory and algorithms will focus on the most challenging case, when scientists do not know how much information is missing because of lack of either speed or breadth. For example, fMRI measurements in cognitive neuroscience experiments occur roughly every two seconds, but communication between neural regions happens much more quickly (though exactly how much more quickly is unknown). In addition, neuroscientists are almost certainly unable to record all causally significant variables, such as other bodily states. Similarly, many climatological studies omit important variables (e.g., land use) and yield only monthly (or slower) measurements, even though the underlying phenomena presumably proceed on a faster timescale.<br/><br/>This project will first focus on the challenge of learning from an undersampled time series (with unknown undersample rate), which will require (a) extending the formal framework of causal graphical models to represent such possibilities; (b) providing a set of theorems characterizing how causal structures change under undersampling; (c) developing algorithms that infer constraints on the ""true"" timescale causal structure from the causal structure learned from the undersampled data; (d) implementing these algorithms in a pre-existing, open-source causal learning environment; (e) testing these algorithms in silico through extensive simulations; and (f) applying them to real world datasets, including large-scale neuroimaging data. This last step is particularly important as it will enable real-world validation of the theory and algorithms developed earlier. In parallel, the project will address the same six challenges for situations in which data are correctly sampled, but causally significant variables are missing. Finally, these two pieces will be merged into an integrated framework and algorithms for situations in which both challenges arise simultaneously. The resulting set of theorems, algorithms, and applications will both extend the current theory of causal modeling and causal structure learning, and also address the practical needs of researchers engaged in causal learning from complex, real-world time series data."
"1319966","RI: Small: Any-Angle Search","IIS","ROBUST INTELLIGENCE","08/01/2013","01/15/2014","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","07/31/2016","$452,979.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7495","7495, 7923, 9251","$0.00","In this project, the PI studies any-angle search methods. Any-angle search methods are variants of the heuristic search method A* that interleave the search with path optimizations by propagating information only along grid edges (to achieve small runtimes) but without constraining the paths to grid edges (to find short ""any-angle"" paths, namely paths whose headings can change by any angle). The objective of this project is to broaden any-angle search from a few isolated search methods to a well-understood framework and to extend its applicability. To this end, the PI is developing new any-angle search methods and analyzing their properties, which is complicated by the fact that even base properties often do not transfer from A* to them. The team will also evaluate all new and existing any-angle search methods against each other and against alternative search methods, for example, to understand how they trade off among runtime, path length and memory consumption.<br/><br/>Any-angle search is a recent search paradigm that promises to result in a new class of powerful path-planning methods for mobile robots, including underwater and aerial vehicles. The project includes dissemination activities to raise awareness of any-angle search in artificial intelligence and robotics (such as via tutorials, open-source code and web applets) and offers research opportunities to both graduate and undergraduate students."
"1217466","III: Small: Transforming Feature Selection to Harness the Power of Social Media","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","05/02/2013","Huan Liu","AZ","Arizona State University","Standard Grant","Sylvia J. Spengler","08/31/2015","$426,387.00","","hliu@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7364","7923, 7364, 9251","$0.00","The growth of social media data in size and variety accelerates rapidly as more people use social media such as Facebook, Twitter, LinkedIn, among others. It is a massive ""treasure trove"" interesting to researchers and practitioners of different disciplines, and a great source for data mining. However, attribute-value data in classic data mining differs from social media data besides both are large-scale. Social media data are noisy, incomplete, comprised of multiple sources, and form multi-modal and and multi-attributed networks. Furthermore, such data are not independent and identically distributed (i.i.d.). These unique properties present new challenges for mining social media data. <br/><br/>This project investigates a novel approaches to feature selection in linked data in general and social media data in particular. Specifically, it seeks to exploit link information in supervised as well as unsupervised feature selection for social media data. Because social media data are drawn from multiple noisy, partial, or redundant sources, the proposed approach to feature selection seeks to select relevant sources and use them together to guide linked feature selection in multi-modal, multi-attributed social media.<br/><br/>The project lies at the confluence of feature selection, social media analysis, and data mining. The project offers an opportunity to engage students who are adept users of social media in developing computational tools that can harness the power of social media. Some broader impacts of this research include integration of social media analytics into undergraduate and graduate courses as well as student research projects; enhanced research-based training opportunities for students from under-represented groups; and powerful social media analytics tools for understanding collective behavior in social media, employing social media for crisis response and disaster relief, and studying social and political movements. The results of the project (including publications, software, etc.) will be made available through the project web site: http://www.public.asu.edu/~huanliu/projects/NSF12"
"1218712","III: Small: Pattern Learning in a Minimax Framework","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/10/2012","Qiang (Shawn) Cheng","IL","Southern Illinois University at Carbondale","Standard Grant","Sylvia J. Spengler","08/31/2015","$254,661.00","","qcheng@cs.siu.edu","Ofc. of Sponsored Projects Admin","Carbondale","IL","629014308","6184534540","CSE","7364","7923, 7364","$0.00","Machine learning currently offers one of the most cost-effective approaches to building predictive models from data. However, practical applications of machine learning have to cope with sparsity, noise, and uncertainty of data present. Against this background, this project aims to: 1) Introduce a minimax framework for pattern learning to unify various regularization models, and characterize a variety of data uncertainty (e.g. incomplete data, local nonrigid displacements, lighting variations) and the corresponding regularizations regarding their intrinsic properties (e.g. sparsity, locality, robustness); 2) Establish new feature subset selection methods and quantify group effects as well as confidence levels/intervals of selecting/discarding features; 3) Construct new methods of sparse grouping representation for resilience to labeling errors by exploiting effective regularizations and their properties. The project aims to explicitly model various classes of data uncertainty (distortions) within a minimax framework, to optimize pattern learning process based on the worst distortion(s) in a given class, and to exploit regularization properties (e.g. sparsity, robustness).<br/><br/>Anticipated results of the project include: (1) New models and methods for accounting for various classes of distortions and for finding optimal solutions under the worst distortion(s) over a given class; (2) New methods for selecting features with confidence analysis and for learning predictive models resilient to labeling errors; (3) Rigorous evaluation of the resulting methods on real-world data sets.<br/><br/>The new machine learning algorithms resulting from this research find applications in many areas that rely on predictive modeling from large data sets(e.g. medical analysis, earthquake modeling). All of the software tools developed in this project will be made available to the scientific community, educators and students. The project offers enhanced research-based training opportunities for graduate and undergraduate students, as well as outreach to K-12 students, and efforts aimed at broadening the participation of under-represented groups in Computer Science research and education."
"1219071","III: Small: Inferring first movers in large-scale socio-technical networks","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/27/2012","Vijay Subramanian","IL","Northwestern University","Standard Grant","Sylvia J. Spengler","08/31/2015","$500,000.00","Randall Berry","v-subramanian@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7364","7923","$0.00","This project is studying statistical inference from datasets tracking the diffusion of new ideas or behaviors through a population. Game theoretic models for the diffusion are utilized in which members of the population decide to adopt a technology by maximizing a pay-off that depends on an underlying network structure. Example questions include the identification of ""first movers"" and the most likely series of actions that result in a given observed state of the network. Algorithms are being developed for characterizing the maximum likelihood estimate of first movers for an evolutionary game theoretic framework with smoothed best response dynamics. Additionally algorithms to identify influential nodes and the network graph along with the associate payoff functions are being studied. The associated modeling and analysis build upon foundations in probability and statistics, Markov processes, statistical mechanics, optimization and game theory.<br/><br/>Understanding diffusions in social networks is broadly applicable across society including areas such as marketing, economics and social sciences; efforts are being made to disseminate the results of this work to such fields as well as to incorporate ideas into undergraduate and graduate courses in EECS."
"1218393","III: Small: Dynamic Social Network Mining: Feature Extraction, Modeling and Anomaly Detection","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/27/2012","Aidong Zhang","NY","SUNY at Buffalo","Standard Grant","Sylvia J. Spengler","08/31/2015","$500,000.00","","azhang@buffalo.edu","402 Crofts Hall","Buffalo","NY","142600000","7166452634","CSE","7364","7923","$0.00","This project develops a general framework for anomaly detection in dynamic social networks that evolve in both links and nodes. The framework includes first capturing the information of timestamps of dynamic networks by transferring them into carefully selected graph kernel feature spaces. A dynamic modeling method is then designed to learn the dynamism on the target dynamic social network. Anomaly detection methods are finally developed to mine abnormal nodes in the dynamic network. The main innovation of the approaches is to represent dynamic networks by bags of attributes, including graph kernel features to epitome details in each timestamp, learned latent variables for dynamism of networks and user specified features to turn the direction of attributes representation towards aimed tasks. Based on this representation, the project designs innovative methods based on latent support vector machine and transfer learning to detect abnormal nodes. <br/><br/>This research provides a clear understanding of evolution patterns, including both normality and abnormality in dynamic social networks. The approaches developed in this project help identify various abnormalities in our life, including detecting spammers in websites, monitoring potential dangerous activities in crime networks, identifying malicious source of infection in disease networks, and many others. The successful modeling of such network dynamics can provide scientific basis for appearance and disappearance of human relationships, improve the prospects for uncovering potentially undiscovered evolution patterns in social networking process and help develop qualitative and quantitative algorithms for more applications."
"1249316","EAGER: Preliminary Study of Hashing Algorithms for Large-Scale Learning","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/18/2012","Ping Li","NY","Cornell University","Standard Grant","Sylvia J. Spengler","08/31/2014","$100,000.00","","pingli@stat.rutgers.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7364","7364, 7916","$0.00","Many emerging applications of data mining call for techniques that can deal with data instances with millions, if not billions of dimensions. Hence, there is a need for effective approaches to dealing with extremely high dimensional data sets. <br/><br/>This project focuses on a class of novel theoretically well-founded hashing algorithms that allow high dimensional data to be encoded in a form that can be efficiently processed by standard machine learning algorithms. Specifically, it explores: One-permutation hashing, to dramatically reduce the computational and energy cost of hashing; Sparsity-preserving hashing, to take advantage of data sparsity for efficient data storage and improved generalization; Application of the new hashing techniques with standard algorithms for learning ""linear"" separators in high dimensional spaces. The success of this EAGER project could lay the foundations of a longer-term research agenda by the PI and other investigators focused on developing effective methods for building predictive models from extremely high dimensional data using ""standard"" machine learning algorithms. <br/><br/>Broader Impacts: Effective approaches to building predictive models from extremely high dimensional data can impact many areas of science that rely on machine learning as the primary methodology for knowledge acquisition from data. The PI's education and outreach efforts aim to broaden the participation of women and underrepresented groups. The publications, software, and datasets resulting from the project will be freely disseminated to the larger scientific community."
"1218036","III: Small: Mining Local Correlations in Extremely High-Dimensional Data: Models, Algorithms, and Applications","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/07/2012","Xiang Zhang","OH","Case Western Reserve University","Standard Grant","Sylvia J. Spengler","08/31/2015","$471,187.00","Xiaofeng Zhu","xiang.zhang@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7364","7923, 7364","$0.00","This project develops the computational and statistical principles of mining local latent correlations in extremely high-dimensional data. Recent advances in experimental technologies have rendered it possible to collect data of extremely high dimensionality. Examples include gene expression, genetic variation, and protein and DNA sequence data. A key problem in analyzing such data is finding latent local correlations among features. Such local correlations only exist in feature subspaces and may involve more than two features. The large number of features and the noisy characteristics of the data make modeling, identifying, and assessing the statistical significance of such local correlations a challenging research problem. <br/><br/>The project aims to develop tools that enable users to mine and explore local correlations efficiently and effectively. It seeks to develop (1) effective models to capture the local correlations among features; (2) scalable algorithms to identify local correlations from extremely high-dimensional data; (3) robust methods to assess the statistical significance of the identified correlations. The proposed methods combine the advantages of dimension reduction, intrinsic dimensionality estimation, information theoretic approach, and hypothesis testing for modeling and identifying significant local correlations. <br/><br/>The resuling tools will assist scientists in many disciplines including biologists in their study of gene function and medical doctors in their understanding of disease progression and searching for new and effective treatments. The research results will be published in peer reviewed data mining and bioinformatics journals and conferences and integrated into the educational and outreach programs at CWRU. The project Web site (http://engr.case.edu/zhang_xiang) will be used for dissemination of research results including publications, data, and software."
"1319378","III: Small: TwitterHealth: Learning Fine-Grained Models of Health Influences and Interactions From Social Media","IIS","INFO INTEGRATION & INFORMATICS, Smart and Connected Health","09/01/2013","08/26/2013","Henry Kautz","NY","University of Rochester","Standard Grant","Sylvia J. Spengler","08/31/2016","$481,939.00","","kautz@cs.rochester.edu","518 HYLAN, RIVER CAMPUSBOX 27014","ROCHESTER","NY","146270140","5852754031","CSE","7364, 8018","7923, 8018, 7364","$0.00","Current techniques for answering questions about the influence of behaviorial and environmental factors on public health are based on surveys, which are costly and subject to response bias, or simulations, which rely on possibly incorrect or simplistic assumptions. The TwitterHealth project is developing techniques to extract reliable public health information from social media. In essence, the online population becauses a vast organic sensor network. Statistical natural language processing techniques are employed to classify tweets (or other social media postings) as self-reports of disease or particular behaviors of interest. GPS information included in postings made from cell phones allow a variety of behavioral information to be inferred about each user, such as the venues visited and the other individuals from the data set who are encountered.<br/><br/>Major technical challenges for using social media in this manner are the highly noisy nature of the information channel, scaling to a large number of different health conditions, and the need to discover causal influences as well as correlations between behavioral and environmental factors and health. The challenge of noise is approached by learning dynamic relational models of health states, which generalize classical epidemiological models but support individual as well as aggregate predictions. The scaling challenge is dealt with by knowledge transfer techniques, which reduce data and computational requirements by transfering information between models for different health conditions. Specific knowledge transfer techniques are cascaded training of a target classifier starting with a given classifier for a related but different disease, and the use of ensembles of general and specific classifiers. The challenge of inferring casuality is addressed by temporal-lag methods, which identify changes in behaviorial or environmental conditions that consistently precede changes in health. For example, the inference that a venue is a cause (vector) of disease spread is accomplished by tracing backward in time the GPS trails of users who post social media reports of illness. TwitterHealth employs two approaches for validating its results: first, comparing the aggregate predictions of the model against CDC statistics; second, comparing individuals' behavior in reporting or not reporting disease symptoms in status updates against the behavior predicted by the models. The project also includes planning for clinic based evaluations, in which subjects identified by their social media postings would provide swabs that would be tested for disease agents.<br/><br/>The TwitterHealth approach to collecting and analyzing health information has the potential to improve public health, by making detailed data about health, behavior, social structure, and geographic influences available in real time and at almost no cost. While it will not completely replace traditional methods of gathering health information, it provides an important complementary information channel, which emphases speed, reach, and scale. The project includes outreach expert medical professionals in order to plan future clinical validation. The outreach interaction provides a forum for exchange of computer science and medical expertise between researchers and students in the two fields. Information about the project is available online at http://www.cs.rochester.edu/u/kautz/twitterhealth."
"1302564","III: Medium: Collaborative Research: Robust Large-Scale Electronic Medical Record Data Mining Framework to Conduct Risk Stratification for Personalized Intervention","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/13/2013","Jing Cao","TX","Southern Methodist University","Standard Grant","Sylvia J. Spengler","08/31/2017","$196,717.00","","jcao@smu.edu","6425 BOAZ","DALLAS","TX","752056312","2146922000","CSE","7364","7924, 7364","$0.00","The increasingly large amounts of Electronic Medical Record (EMR) data offer unprecedented opportunities for EMR data mining to enhance health care experiences for personalized intervention, improve different diseases risk stratifications, and facilitate understanding about disease and appropriate treatment. To solve the key and challenging problems in mining such large-scale heterogeneous EMRs, the investigators aim to develop: (i) new computational tools to automate the EMRs processing, including new techniques for filling in missing values using a new robust rank-k matrix completion method; (ii) annotation of unstructured free-text EMRs using multi-label multi-instance learning; (iii) a new sparse multi-view learning model to integrate heterogeneous EMRs to predict the readmission risk of Heart Failure (HF) patients and to support personalized intervention; (iv) novel methods for identifying the longitudinal patterns using high-order multi-task learning; (v) a nonparametric Bayesian model for predicting the event time outcomes of the HF patients readmission. <br/><br/>The sparse multi-view feature learning and robust multi-task longitudinal pattern finding algorithms have a broad range of applications beyond EMR data mining. Free dissemination of source implementations of the algorithms enable other researchers to further develop and apply the resulting techniques. In particular, the methods and tools are expected to impact other EMR and public health research. This project offers enhanced opportunities for research-based advanced training of students (including members of minorities and under-served populations) and integration of research results into curricula at the University of Texas at Arlington, the University of Texas Southwestern Medical Center at Dallas, and Southern Methodist University. For further information see the web site at: http://ranger.uta.edu/~heng/NSF-III-1302675.html"
"1302675","III: Medium: Collaborative Research: Robust Large-Scale Electronic Medical Record Data Mining Framework to Conduct Risk Stratification for Personalized Intervention","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/13/2013","Heng Huang","TX","University of Texas at Arlington","Standard Grant","Sylvia J. Spengler","08/31/2017","$461,098.00","","heng@uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7364","7924, 7364","$0.00","The increasingly large amounts of Electronic Medical Record (EMR) data offer unprecedented opportunities for EMR data mining to enhance health care experiences for personalized intervention, improve different diseases risk stratifications, and facilitate understanding about disease and appropriate treatment. To solve the key and challenging problems in mining such large-scale heterogeneous EMRs, the investigators aim to develop: (i) new computational tools to automate the EMRs processing, including new techniques for filling in missing values using a new robust rank-k matrix completion method; (ii) annotation of unstructured free-text EMRs using multi-label multi-instance learning; (iii) a new sparse multi-view learning model to integrate heterogeneous EMRs to predict the readmission risk of Heart Failure (HF) patients and to support personalized intervention; (iv) novel methods for identifying the longitudinal patterns using high-order multi-task learning; (v) a nonparametric Bayesian model for predicting the event time outcomes of the HF patients readmission. <br/><br/>The sparse multi-view feature learning and robust multi-task longitudinal pattern finding algorithms have a broad range of applications beyond EMR data mining. Free dissemination of source implementations of the algorithms enable other researchers to further develop and apply the resulting techniques. In particular, the methods and tools are expected to impact other EMR and public health research. This project offers enhanced opportunities for research-based advanced training of students (including members of minorities and under-served populations) and integration of research results into curricula at the University of Texas at Arlington, the University of Texas Southwestern Medical Center at Dallas, and Southern Methodist University. For further information see the web site at: http://ranger.uta.edu/~heng/NSF-III-1302675.html"
"1319280","III: Small: Fast and Efficient Algorithms for Matrix Decompositions and Applications to Human Genetics","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/08/2013","Petros Drineas","NY","Rensselaer Polytechnic Institute","Standard Grant","Sylvia J. Spengler","08/31/2016","$329,455.00","","drinep@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7364","7364, 7923","$0.00","Linear algebraic algorithms, and in particular matrix decompositions, have proven extremely successful in the analysis of datasets in the form of matrices. Tools such as the Singular Value Decomposition (SVD) and the related Principal Components Analysis (PCA) have had a profound impact in diverse areas, ranging from web search engines to the physical sciences. Over the last decade, the introduction of randomization provided a new paradigm for the design and analysis of such algorithms. On the other hand, human genetics researchers are now finding out how truly different we are from one another. Large datasets describing the common patterns of human genetic variation may be easily thought of as matrices, with the rows representing individuals and the columns representing loci in the genome that correspond to common polymorphisms. The broader impact of such datasets can not be overemphasized: they are expected to be a key resource for researchers to use to find genes affecting health, disease, and responses to drugs and environmental factors, as well as understanding the evolutionary and biological history of our species.<br/><br/>The main objective of this proposal is to bridge the gap between state-of-the-art algorithms for data analysis developed in the theoretical computer science and applied mathematics communities and the application of such algorithms to the analysis of the increasingly larger volume of datasets in the human genetics community. The particular focus of our proposal is, from an algorithmic perspective, the design and analysis of (supervised and unsupervised) randomized algorithms for the so-called CX matrix factorization, and, from a population genetics perspective, the selection of ancestry informative and disorder associated markers, as well as ancestry and affection status prediction. This work will have immediate impact in the analysis of population genetics data. The results will be disseminated to a broad community of applied mathematicians, theoretical computer scientists, and population geneticists"
"1350330","CAREER: Geometric Shape Deformation with Applications in Medicine","IIS","Cyber-Human Systems","01/01/2014","01/15/2014","Ladislav Kavan","PA","University of Pennsylvania","Continuing grant","Ephraim P. Glinert","12/31/2018","$104,183.00","","ladislav@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7367","1045, 7367, 7453","$0.00","In spite of significant recent advances 3D computer graphics are still humbled when confronted with medical-grade requirements, so medical illustrators often continue to rely on 2D hand drawing. A fundamental challenge is that detailed geometric models and advanced nonlinear materials increase computational complexity, making them difficult to apply in real-time interactive applications. In this research, the PI will investigate an alternative approach based on geometric shape deformations rather than the processes which created them. He argues that intuitive shape deformation can be facilitated by guarantees of basic geometric properties such as smoothness and injectivity (no self-intersection). The key is to design algorithms that can do this quickly while providing the user with a small yet expressive set of adjustable controls to ensure an efficient interactive experience; the task of shape deformation techniques is to extrapolate this parsimonious, human manageable set of input controls into a full-scale 3D deformation field in a natural and predictable way. The PI's hypothesis is that this requirement can be formally expressed in terms of basic geometric properties. To this end, the PI will explore both direct (closed-form) and variational methods, because while direct methods excel in speed variational methods offer stronger guarantees and advanced geometric properties. In terms of direct methods, the PI will develop new ways to quickly blend certain groups of 3D transformations (e.g., with the help of new geometric algebraic structures). Transformation blending will be complemented by advanced influence weights that allow the user to explicitly control the resulting sparseness. In terms of variational methods, the PI will study deformation energies satisfying traditional properties such as rotation invariance but augmented with higher-order continuity and injectivity; here, the main challenge will be to find efficient numerical solutions for the underlying optimization problems. The PI believes it will prove possible to mitigate the inherent computational complexity of variational methods by suitably combining them with direct methods so as to cast some of the variational problems as convex optimizations, thereby opening the door to highly efficient convex solvers.<br/><br/>Broader Impacts: Shape deformation is relevant to architecture, computer aided design (CAD), and many areas of science and engineering, as well as to the entertainment industry. But this project has primarily been motivated by medical applications, inspired by requests from the PI's collaborators at The Children's Hospital of Philadelphia. Given the right tools, the classical field of hand drawn medical illustration will evolve into 3D animated medical atlases, setting new standards in medical education. Shape deformation techniques could ultimately contribute to clinical praxis, by facilitating diagnosis and pre-operative planning when treating conditions such as pathological skull deformities (craniosynostosis). And shape modeling tools in expert hands could help lower the radiation dose required in CT scanning, by applying new reconstruction methods that combine user input with template models and accurate surface scans (obtained with radiation-free methods such as laser scanning). The PI also will organize seminars and courses that bring together medical and engineering students, including members of underrepresented groups, thereby promoting interdisciplinary collaboration in both research and education."
"1218325","III: Small: Collaborative Research: Finding and Exploiting Hierarchical Structure in Time Series Using Statistical Language Processing Methods","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/23/2013","Jessica Lin","VA","George Mason University","Continuing grant","Sylvia J. Spengler","08/31/2015","$250,000.00","","jessica@cs.gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7364","7923, 7364","$0.00","Applications as diverse as manufacturing, medicine, earth science, finance, and entomology generate massive amounts of temporal or spatio-temporal data. More specifically, information about moving objects, events, and atmospheric measurements that are geo-referenced may be derived from high-resolution satellites, sensors, ground and aerial imagery, GPS, and RFID. Such data present challenges to current approaches for mining time series data. For example, shape-based similarity measures used for classification and clustering consistently fail to produce satisfactory results for long sequences, or trajectories modeling objects that move in 2D or 3D space which may often exhibit similar motion patterns but differ in locations and orientations. In addition, algorithms for finding frequent patterns and anomalies assume known, fixed pattern lengths. This project aims to address the limitations of current approaches to time series data analysis by adapting statistical language processing algorithms and approaches. Specifically, fast algorithms for learning context-free grammars can expose hierarchical structure in time series and thus enable efficient discovery of variable length patterns and facilitate human understanding of time series structure. Also, using the hierarchy to populate a ""bag of patterns"" can result in significantly more effective similarity measures for long time series, much like the familiar bag of words representation used with documents is effective for a variety of similarity-based language processing tasks on massive corpora.<br/><br/>Given the ubiquitous nature of time series data, advances in algorithms that can help uncover the structure of such data are likely to impact a broad range of applications. All of the results of this research, including publications, algorithms and software, would be made freely available to the broader research and educational community. The project offers enhanced research-based training opportunities for graduate and undergraduate students. The project leverages existing programs at George Mason University and the University of Maryland at Baltimore County to to increase the participation of women members of other groups that are under-represented in Computer Science."
"1143717","III: EAGER - Expressive Scalable Querying over Integrated Linked Open Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","03/29/2012","Amit Sheth","OH","Wright State University","Standard Grant","Sylvia J. Spengler","08/31/2014","$141,828.00","Pascal Hitzler","amit.sheth@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7364","7364, 7916, 9251","$0.00","Linked Open Data (LOD) is rapidly developing into an open data movement to connect a large variety of data across the World Wide Web using standards adopted by the World Wide Web Consortium (W3C). Driven by researchers, government agencies and companies, the resulting Web of Data has grown to over 25 billion RDF triples and is showing exponential growth. However, simply putting collections of data on the Web will be of very limited value. The key to unlocking the value for developing more powerful search, browsing, exploration and analysis is to richly interlink or semantically integrate components of LOD. Given the size, growth rate, heterogeneity and growing areas of coverage, manual semantic integration or interlinking is not practical. Furthermore, current techniques focus on 'same-as' relationship, which is much abused due to limited expressivity. This calls for ways to represent and identify richer and more explicit relationships between different entities that reflect the richness of relations that exist in the real world.<br/><br/>This project develops exploratory techniques to richly interlink components of LOD and then addresses the challenge of querying the LOD cloud, i.e., of obtaining answers to questions which require accessing, retrieving and combining information from different parts of the LOD cloud. Techniques for overcoming semantic heterogeneity include: semantic enrichment through Wikipedia bootstrapping; semantic integration through abstraction by means of upper-level ontologies; and, massively parallel methods for tractable ontology reasoning. Specifically, this research will: (1) identify richer, broader, and more relevant relationships between LOD datasets at instance and schema level (these relationships will promote better knowledge discovery, querying, and mapping of ontologies); (2) realize LOD query federation through an upper level ontology; and, (3) enable access to implicit knowledge through ontology reasoning. The project involves significant risk as it treads new paths in a new terrain, primarily due to the lack of descriptive information (schema) about the data provided by highly autonomous data sources, the significant syntactic and semantic heterogeneity among data originating from independent data sources, and the significantly larger scale, as well as unforeseeable obstacles associated with a rapidly changing and expanding environment. <br/><br/>This project aims to advance the state of the art in semantic integration of large amounts of heterogeneous and autonomously developed or managed data. It seeks to fundamentally transform the landscape of LOD usage because successful LOD querying is a key enabler for a variety of applications. The results of this project could set the stage for the development, and the far reaching adoption, of Semantic Web. The project is integrated with education and research-based advanced training of graduate and undergraduate students. Additional information about the project can be found at: http://knoesis.org/research/semweb/projects/ESQuILO."
"1148012","III: EAGER: Discovering Spontaneous Social Events","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","08/08/2011","Charles Dyer","WI","University of Wisconsin-Madison","Standard Grant","Sylvia J. Spengler","08/31/2014","$151,868.00","Xiaojin Zhu","dyer@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7364","7916, 7364","$0.00","Real-world social events provide a convenient and intuitive way to organize social media content for individuals. Current approaches to event detection from social media: assume that the events to be monitored (and their social media signatures) are known a priori; focus largely on text data and fail to take advantage of other forms of media e.g., images. <br/><br/>Against this background, this project explores a novel approach to discovering spontaneous, a priori unspecified, social events through joint Bayesian non parametric modeling of multi-modal data (including text and images) and using the events thus discovered to foster new social links. The resulting tools for event discovery will be tested in an application involving discovery of wild animal disease outbreaks from twitter text messages and images posted by individuals. <br/><br/>The project brings together an interdisciplinary team of researchers with expertise in image analysis, text mining, and machine learning to advance the state of the art in detection of spontaneous, a priori unspecified events (as they emerge) from social media data. It is expected to yield new scalable nonparametric Bayesian approaches to joint modeling of image and text data, and more generally multi-modal social media data. The resulting tools could potentially transform the way in which people use social media data by empowering them to discover and participate in real world events even as they emerge."
"1116439","III: Small: RUI: Practical Inference on Real-World Networks of Data","IIS","INFO INTEGRATION & INFORMATICS","10/01/2011","09/23/2011","Luke McDowell","MD","United States Naval Academy","Interagency Agreement","Sylvia J. Spengler","10/31/2014","$106,649.00","","lmcdowel@usna.edu","589 McNair Rd","Annapolis","MD","214025030","4102932504","CSE","7364","7364, 7923, 9229","$0.00",""
"1115871","III: Small: Scalable RDF Query Processing Using a Cloud Infrastructure","IIS","INFO INTEGRATION & INFORMATICS","07/01/2011","06/17/2013","Praveen Rao","MO","University of Missouri-Kansas City","Continuing grant","Sylvia J. Spengler","06/30/2015","$335,760.00","","raopr@umkc.edu","5100 Rockhill Road","Kansas City","MO","641102499","8162355839","CSE","7364","7923, 9251, 7364","$0.00","Resource Description Framework (RDF) has, in recent years, become an increasingly important data and knowledge representation formalism for a broad range of applications, including the World Wide Web. With rapidly growth in the size of RDF datasets, there is growing need for scalable and efficient technologies for storing, indexing, and querying RDF datasets that are trillions of triples in size. This project, led by Dr. Praveen Rao of University of Missouri-Kansas City, aims to address this need by developing: (1) A novel approach to storing, indexing, and querying of RDF data that treats graphs as first-class citizens to reduce the cost and number of joins required for graph pattern matching using RDF signatures, RDF signature indexes and line graphs; (2) A new approach for parallel SPARQL query processing on cloud platforms using data distribution schemes based on RDF signatures, location index for quickly finding RDF graphs of interest across computing nodes, and a gossip-driven query execution model and (3) A new approach for selectivity estimation of RDF graph patterns for query optimization based on new gossip algorithms for cardinality estimation of RDF graph patterns and a divide-andconquer method for effective load balancing and improved accuracy. <br/><br/><br/>The broader impacts of this project include new courses covering topics in RDF data management and cloud computing, a scalable RDF reasoning tool over cancer data for oncologists, new cloud services for very large RDF data stores, increased opportunities for research-based advanced training of undergraduate and graduate students, including women. The results of this research, including publications, software, and data sets will be freely shared with the broader community. Additional information about the can be accessed through the project website at http://vortex.sce.umkc.edu/ric.html."
"1320527","III: Small: Statistical Learning Algorithms for Micro-Event Time Series Data","IIS","INFO INTEGRATION & INFORMATICS","10/01/2013","08/21/2013","Padhraic Smyth","CA","University of California-Irvine","Continuing grant","Sylvia J. Spengler","09/30/2016","$349,411.00","","smyth@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7364","7364, 7923","$0.00","This project is focused on the development of new data analysis tools for analyzing personal data archives, namely, the streams of digital data that are routinely recorded reflecting different aspects of individuals' daily lives. Examples of such data include keystrokes, email histories, text messages, social media interactions, microblogs, as well as records of physical activity, diet, and sleep. As sensors become more accurate and cheaper and as data storage becomes effectively zero cost, there is increasing demand for data analysis tools that allow individuals to analyze and gain insight into their own personal data. This research project is developing new statistical machine learning algorithms for analyzing these types of data. The project has a particular focus on the development of models and algorithms to handle personal archives in the form of event time-series data, consisting of logs of time-stamped events involving interactions with other individuals as well as textual and other metadata. Testbed data sets being used to support this research include publicly-available archives of email histories, software development discussions, Twitter microblogs, Wikipedia editing interactions, and physical proximity data. In terms of broader societal impact, the data analysis tools being developed by this project have the potential to significantly transform how individuals analyze their personal data to better understand and monitor their physical and mental health."
"1217869","III: Small: Aspects of Integrating Heterogeneous and Inconsistent Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","06/19/2013","Phokion Kolaitis","CA","University of California-Santa Cruz","Continuing grant","Sylvia J. Spengler","08/31/2014","$481,000.00","Balder Ten Cate","kolaitis@cse.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7364","7923","$0.00","Integrating heterogeneous data is a major challenge that manifests itself across a wide spectrum, from government and business to science and health care. A critical task underlying this challenge is deriving the relationship between different database schemas. During the past decade, schema mappings have emerged as the right tool for this task. Schema mappings are high-level, declarative specifications of the relationships between two database schemas that provide the appropriate level of abstraction and, at the same time, can be compiled into executable code.<br/><br/>The first main aim of this project is to develop a framework and tools for designing schema mappings. This framework is based on the systematic use of data examples. The project investigates fundamental algorithmic tasks in using data examples as a device to illustrate and understand the behavior of already derived schema mappings, and also as inputs to a schema-mapping design system that will derive a suitable schema mapping based on the given data examples. The second main aim is to investigate the uses of schema mappings in integrating and exchanging inconsistent data that arise when bringing together data from heterogeneous sources. Since the current framework of data exchange does not handle inconsistencies well, this project re-examines data exchange and extends it to gracefully handle inconsistencies.<br/><br/>This project will advance the state of the art in designing schema mappings and managing inconsistent databases. Furthermore, it will contribute to the development of human resources in science and engineering through the teaching and research training of graduate students."
"1218749","III: Small: Collaborative Research: Efficient, Nonparametric and Local-Minimum-Free Latent Variable Models: With Application to Large-Scale Computer Vision and Genomics","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","08/07/2013","Le Song","GA","Georgia Tech Research Corporation","Continuing grant","Sylvia J. Spengler","09/30/2015","$299,979.00","Alexander Gray","lsong@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7364","7923","$0.00","Many modern applications ranging from computer vision to biology require modeling and inferring high-dimensional continuous variables based on distributions with multimodality, skewness, and rich latent structures. Most existing models in this regime rely heavily on parametric assumptions where the components of the model are typically assumed to be discrete or multivariate Gaussian, or the relations between variables are linear, which may be very different from the actual data generating processes. Furthermore, existing algorithms for discovering the latent dependency structures and learning the latent parameters largely are restricted to local search heuristics such as expectation maximization. Conclusions inferred under these restricted assumptions and suboptimal solutions can be misleading, if the underlying assumptions are violated or if the suboptimal solutions differ greatly from the globally optimal ones. This project aims to develop a novel framework which can (i) discover and take advantage of latent structures in the data, while (ii) allowing parts to handle near-arbitrary distributions, and (iii) allowing the models to scale to modern massive datasets in a local-minimum-free fashion. <br/><br/>The key innovation in the project is a novel nonparametric latent variable modeling framework based on kernel embedding of distributions. The basic idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances, projections, linear transformations and spectral analysis. Conceptually, the framework represents components from latent variable models, such as marginal distributions over a single variable, joint distributions over variable pairs, triplets and more variables, as infinite dimensional vectors, matrices, tensors and high-order tensors respectively. Probabilistic relations between these components, i.e., conditional distributions, Sum Rule, Product Rule etc. become linear transformations and relations between these feature space components.<br/><br/>The framework supports modeling data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. It supports the application of a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning and latent feature extraction. The framework applies not only to general continuous variables, but also to variables that take values on strings, graphs, groups, compact manifolds, and other domains on which kernels may be defined.<br/><br/>Besides advancing the state of the art in machine learning,the new non-parametric methods resulting from the project find applications in image data and understanding and gene expression data analysis. It also contributes to research-based training of graduate and undergraduate students at Georgia Tech and CMU."
"1320586","III: Small: Is Imprecise Supervision Useful? Leveraging Ambiguous, Incomplete or Conflicting Data Annotations","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/21/2013","Jinbo Bi","CT","University of Connecticut","Continuing grant","Sylvia J. Spengler","08/31/2016","$221,542.00","","jinbo@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","CSE","7364","7923, 7364","$0.00","Supervised machine learning approaches to building predictive models from data traditionally rely on labeled samples. However, in many real-world applications, samples are either unlabeled or labeled imprecisely labeled, i.e., labels are often ambiguous, conflicting, or incomplete. This presents the problem of learning predictive models under imprecise supervision.<br/><br/>This project aims to develop effective algorithms to address three different scenarios that lead to imprecise supervision (1) multiple labelers with varying expertise are employed to annotate samples; (2) annotated labels are associated with a set of samples instead of an individual sample; (3) annotations are derived by modeling multiple expert assessments. The project introduces a general bi-convex programming, minimax optimization, and multi-objective optimization based framework for learning predictive models from imprecisely labeled data. The resulting algorithms will be evaluated on a number of real-world applications. <br/><br/>Broader Impacts: The results of this research are likely to impact a range of biomedical applications, including medical image labeling, longitudinal behavioral studies, genomics, and drug safety. The project offers enhanced opportunities for curriculum development and research-based advanced training of grauduate amd undergraduate students in machine learning and its applications. Dissemination of open source software implementation of algorithms resulting from the project also contribute to the project's broader impact. Additional information about the project can be found at: http://www.labhealthinfo.uconn.edu/home/MachineLearning.jsp"
"1302497","III: Medium: Collaborative Research: Robust Large-Scale Electronic Medical Record Data Mining Framework to Conduct Risk Stratification for Personalized Intervention","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/13/2013","Song Zhang","TX","University of Texas Southwestern Medical Center at Dallas","Standard Grant","Sylvia J. Spengler","08/31/2017","$234,715.00","","Song.Zhang@UTSouthwestern.edu","5323 HARRY HINES BLVD.","DALLAS","TX","753909105","2146484494","CSE","7364","7924, 7364","$0.00","The increasingly large amounts of Electronic Medical Record (EMR) data offer unprecedented opportunities for EMR data mining to enhance health care experiences for personalized intervention, improve different diseases risk stratifications, and facilitate understanding about disease and appropriate treatment. To solve the key and challenging problems in mining such large-scale heterogeneous EMRs, the investigators aim to develop: (i) new computational tools to automate the EMRs processing, including new techniques for filling in missing values using a new robust rank-k matrix completion method; (ii) annotation of unstructured free-text EMRs using multi-label multi-instance learning; (iii) a new sparse multi-view learning model to integrate heterogeneous EMRs to predict the readmission risk of Heart Failure (HF) patients and to support personalized intervention; (iv) novel methods for identifying the longitudinal patterns using high-order multi-task learning; (v) a nonparametric Bayesian model for predicting the event time outcomes of the HF patients readmission. <br/><br/>The sparse multi-view feature learning and robust multi-task longitudinal pattern finding algorithms have a broad range of applications beyond EMR data mining. Free dissemination of source implementations of the algorithms enable other researchers to further develop and apply the resulting techniques. In particular, the methods and tools are expected to impact other EMR and public health research. This project offers enhanced opportunities for research-based advanced training of students (including members of minorities and under-served populations) and integration of research results into curricula at the University of Texas at Arlington, the University of Texas Southwestern Medical Center at Dallas, and Southern Methodist University. For further information see the web site at: http://ranger.uta.edu/~heng/NSF-III-1302675.html"
"0963285","Collaborative Research: Measuring Collective Intelligence","IIS","Cyber-Human Systems","01/01/2010","01/11/2010","Thomas Malone","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","12/31/2014","$538,213.00","","malone@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","9215, HPCC, 7924","$0.00","The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research. But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence. One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College. The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems. For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups. Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups. Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups. A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems. This research will provide powerful new tools for managing and designing such systems. Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors. Imagine that this test could predict the team's future performance on a wide range of important tasks. And imagine that the test could also help suggest changes to the team that would improve its flexibility. Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks. From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently. This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts: With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it. With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems. The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
"0845921","CAREER: Mathematical Sketching: Pen-based Tools for Conceptual Understanding in Mathematics and Physics","IIS","Cyber-Human Systems","05/01/2009","05/07/2013","Joseph LaViola","FL","University of Central Florida","Continuing grant","Ephraim P. Glinert","04/30/2015","$539,776.00","","jjl@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7367","1045, 1187, 7367, 9215, 9251, HPCC","$0.00","Pen-based computing has the potential to make a significant improvement in the education of our students in STEM disciplines so as to produce a more skilled technical workforce able to compete in the new global economy. Mathematical sketching, a pen-based interaction paradigm that is providing a new approach to STEM education, is the process of making and exploring dynamic illustrations by associating handwritten mathematics with free-form diagrams. The proposed research will develop new mathematical sketching tools to improve student learning in STEM. High level semantic recognition techniques for understanding mathematical sketches (the combination of handwritten problem description, mathematical expressions, and drawings) will be explored to ensure proper interactive feedback, facilitation of correct cognitive models, and the generation of the most appropriate dynamic visualizations for a given problem. In addition, these techniques will, in part, be used to develop strategies in inferential statics and dynamics, the process of finding appropriate animations when users do not directly specify motion equations in the problem solving process. Given the reliance on recognition-based interaction in mathematical sketching, usability studies will examine how users are affected by recognition feedback and accuracy levels. These studies will provide useful guidelines for ensuring that the mathematical sketching interface is usable by both teacher and student. Two educational studies will also explore how mathematical sketching affects teaching and learning. This work will advance the state-of-the-art in pen-based UIs through the development of techniques and exploration of user interface design issues for enriching mathematical sketching. <br/><br/>Broader Impact: This proposal links research in pen-based UIs with STEM education, a critical application area. Thus, the work has the potential to reach thousands of students each year. The PI has the opportunity to work on this research in conjunction with the University of Central Florida?s EXCEL Program, an NSF STEP-funded project that helps students succeed in math and science during the first two years of college, where the mathematical sketching paradigm is directly applicable. The PI will give demonstrations and lectures through the Florida High Tech Corridor Council techCAMP program to bring mathematical sketching to teachers and students in African American and Hispanic high schools. The proposed research will be integrated into a graduate-level course on pen-based UIs, thus enhancing the education of tomorrow?s pen-based UI designers and researchers. Finally, undergraduate courses will be taught on human computer interaction (HCI) and design of interactive systems that, together with the graduate course, will be an educational foundation for HCI at UCF."
"1313606","III: Medium: Collaborative Research: Toward Robust and Scalable Discovering of Significant Associations in Massive Genetic Data","IIS","INFO INTEGRATION & INFORMATICS","09/19/2012","07/15/2013","Wei Wang","CA","University of California-Los Angeles","Continuing grant","Sylvia J. Spengler","09/30/2016","$499,590.00","","weiwang@cs.unc.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7924, 9102","$0.00","A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high-throughput genetic data are still in their infancy. The objective of this project is to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, the team will develop a multi-layer indexing structure for robust and scalable multiple testing correction, a general phylogenetic tree based framework to account for local population structure, and an ensemble learning approach for studying joint effect of multiple genetic factors.<br/><br/>The research provides a computational framework for large scale genotype-phenotype association study. The outcome includes novel methods for addressing sample relatedness, capturing confounding factors, and controlling multiple testing errors which are widely applicable for many common data mining tasks including frequent pattern mining, multitask learning, and ensemble learning among others. Collectively, the theoretic framework and algorithms will provide the research community much better tools to dissect complex relationships between genotypes and phenotypes, and gain deeper understanding of the roles of environmental stimuli.<br/><br/>The proposed research directly involves applications in large scale genome-wide association study. Additional applications exist for biologists in their study of gene-gene interactions, metabolic pathways and protein-protein interaction networks. Beyond the applications proposed here, the algorithms can find wide applications in other areas of biology as well as other scientific disciplines. The methods will be evaluated thoroughly by both simulation and real data collected from yeast, mouse, and human. Early versions of the applications will be made available to the biological community through a web-based server to evaluate efficacy of the methods and to apply them to a broader set of problems.<br/><br/>The research findings and methods will be integrated into graduate and undergraduate instruction. The team already offer classes in computational biology and data-mining where the proposed tools will aid students in comprehending abstract concepts and data relations. They will also continue their commitment to supporting multidisciplinary educational experiences, and service to the research community, as well and proving research opportunities for undergraduate students."
"1217552","HCC: Small: Collaborative Research: Cognitive Approaches to Distributed Software Requirements Engineering","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","William Robinson","GA","Georgia State University Research Foundation, Inc.","Standard Grant","William Bainbridge","08/31/2015","$326,606.00","","wrobinson@gsu.edu","G76Dahlberg Hall 30 Courtland St","ATLANTA","GA","303033999","4044133500","CSE","7367","7367, 7923","$0.00","This research seeks to uncover explanations and principles about how requirements for information systems evolve and how they are managed across project contexts. It will enumerate project design workflows and practices to determine how different forms of artifact and process distribution affect requirements engineering goals and project success. Currently there are no rigorous, theory-based approaches to understanding and explaining large-scale distribution of requirements, though there is evidence of its success. Requirements engineering approaches address spatial and social distribution, and to a lesser extent, structural and temporal distribution. Most importantly, the combination of these issues, in total, has not been considered. Consequently, we cannot say which configuration of practices is best suited to achieve specified development goals, such as reduced time to market, or increased software quality and customer satisfaction. New theoretical models and empirical research are needed to understand the effects of distribution on evolving requirements.<br/><br/>The project will (1) conduct field studies and ethnography, (2) analyze work procedures via grounded theory and comparative methods, (3) construct tools for data analysis, model building, and model analysis, and (4) analyze models via simulations and goal analyses. It will apply a distributed requirements framework consisting of four forms of distribution (social, spatial, structural, and temporal) and four requirements tasks (discovery, specification, negotiation, monitoring) in conjunction with the theory of distributed cognition to analyze requirements knowledge evolution in software projects. Additionally, it will design new tools that help acquire, model, and analyze distributed requirements workflows. <br/><br/>The research aims to develop critical insights on emerging realities in large-scale design projects, which represent one of the drivers for economic growth and new forms of industrial organization. Yet, many software organizations are constrained by methodological and tool factors that do not recognize the increased challenges for requirements engineering. This research highlights the ways in which designers learn to manage the diversity of inputs and constraints, and seeks to understand processes that enhance software-based open innovation in the future."
"1218705","HCC: Small: Multitasking as a Collaborative System: Examining the Millennial Generation","IIS","Cyber-Human Systems","09/01/2012","01/29/2013","Gloria Mark","CA","University of California-Irvine","Standard Grant","Kevin Crowston","08/31/2015","$500,000.00","Stephanie Reich, Mark Warschauer","gmark@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7923","$0.00","This research investigates how Millennials, having grown up with the Internet, can become effective future information workers. Studies are suggesting that multitasking with digital media is associated with errors, stress and degraded performance. This study provides two main research contributions. First, to date no one has conducted an in situ investigation of multitasking among the Millennial generation. Second, whereas most investigations have approached multitasking as an individual activity, this research will instead take a new perspective on multitasking as a collaborative social system. This study will examine whether connectivity leads to information overload and distraction, how online media experience affects learning, communication, and behavior offline, as well as the relationship between degree of connectivity and work performance. This study will use a mixed-methods approach involving ethnographic techniques, sensors, and diaries to collect detailed activity. The results can contribute to an understanding of how young adults use digital media, it can inform the design of requirements for future technologies, and it can be used for the design of media literacy programs in K-12 schools. <br/><br/>Broader impacts: The results will contribute towards plans and policies that schools and organizations can enact to help young people manage their work and use of digital devices more effectively. A media literacy curriculum developed from this research can serve as a model for K-12 schools. While there has been much concern given to preventing worker ""burnout"" and lowering stress among information workers, this study can provide concrete results of how digital technologies contribute to distraction and stress, especially among the Millennial generation. The study will elicit requirements for technology design that could help people better manage multitasking, increase situational awareness and reduce errors. Results of this study will help young people improve their effectiveness in using digital media, which could improve future work life, productivity and satisfaction. Finally, the project will provide educational impact through the participation of undergraduate and graduate in the research and through the development of a new doctoral seminar."
"1247198","EAGER: Prototype Tool for Visualizing Online Polarization","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","Jason Thatcher","SC","Clemson University","Standard Grant","William Bainbridge","08/31/2014","$262,654.00","Vetria Byrd, Simon Appleford, Orville Burton","jthatch@clemson.edu","300 BRACKETT HALL","CLEMSON","SC","296340001","8646562424","CSE","7367","7367, 7916, 9150","$0.00","This study will use the 2012 election cycle as a testbed for examining and developing techniques to analyze the implications of the social web for national elections. The social web - broadly defined as the array of technologies that allow individuals to post their thoughts, pictures, and comments in a public forum - has profoundly changed the way in which political candidates, elected officials, and government agencies engage with potential supporters. As an ever-growing number of people join the plethora of available social networks (including Facebook, Twitter, Pinterest, Tumblr, Flickr, and Instagram), politicians across the world sought to develop increasingly sophisticated social web strategies that maximize their ability to engage directly with the public. At the same time, the social web has facilitated the ability of individuals to share ideas, form communities, and coordinate their actions and responses to political campaigns across time and space. Yet the sheer volume of data produced daily through this online civil discourse is overwhelming for researchers and, until recently, has defied our ability to collect, analyze, and comprehend in its entirety. <br/><br/>This research will develop a prototype visualization tool that will allow researchers to explore the online discourse surrounding elections. This tool will capture social media posts related to selected races in the 2012 Congressional election, both incumbent districts and open seats. Monitoring and analyzing the conversations relative to these races, this study will seek to determine any correlation between social media strategies employed by political candidates in the United States and any increase in polarization in the online discourse. To analyze this discourse, the research will explore the extent that those participating in an online discourse move towards a group polarization with more extreme policies and platforms. Group Polarization is a subset of research on Choice Shifts, which reflect instances where individuals alter their opinions based on commonality, unique information surfacing, or other outside influences. Experimental research suggests that group polarization occurs because the individual has had interaction with a group of like-minded peers. The theory suggests that, after discussion among the group, the individuals will come to a consensus opinion together. Thus, when competing groups form and engage in discourse separately, we are more likely to witness increasingly polarizing opinions between the two groups. This study is relevant for computer scientists, who need to develop strategies for managing, archiving, and providing access to large and dynamic datasets, and is particularly important for social scientists because this online social discourse reflects the moods, values, and attitudes of citizens towards participating in offline civil society. Moreover, scholars need to study how the new social media affect the democratic process of elections. <br/><br/>This study will provide an opportunity to explore strategies for collecting, aggregating, visualizing, and storing data culled from the social web. It will develop a prototype visualization tool that can be connected via APIs to visualize polarization as manifested through the social web and that will be made available to other researchers interested in studying conversations, sentiment, and the social web. Moreover, this tool will act as a first step in developing a deeper understanding of how to visually map sentiment, political action, and civic discourse over time and space. Additionally, the data collected through this project will provide the basis for future research that will enable a more detailed analysis of the data collected during the election and congressional session."
"1212940","HCC: Large: Collaborative Research: DNA Machine Builder: Creative molecular-machine design through mass-scale crowdsourcing","IIS","Cyber-Human Systems","09/01/2012","08/28/2012","Zoran Popovic","WA","University of Washington","Standard Grant","William Bainbridge","08/31/2015","$1,909,246.00","Seth Cooper, Georg Seelig","zoran@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7925","$0.00","This project will develop and evaluate methods by which large numbers of humans, together with computers, can advance the field of synthetic biology by assembling a corpus of creative designs of molecular machines built from DNA segments as well as other molecular structures. Specifically, it will develop a massively-distributed DNA machine construction game that will enable human worldwide collective creativity to be applied to problems ranging from the design of novel self-organizing materials to smart therapeutics that can sense and respond to their environment. The innovative approach is to cast problems of constructing molecular nano-machines with specific functions as a collaborative machine design game governed by the rules of DNA strand interactions. <br/><br/>This approach points to a new paradigm for future science, in which a large group of people together with computers work on difficult creative problems, finding solutions that could not be found by computers alone, or by people alone, or without the massive participation of users. If successful, this approach could change science profoundly, with wide-ranging impact on many disciplines including nanotechnology, biochemistry, medicine, and even social and economic behavior analysis. Although the project specifically focuses on games that use DNA strands as principal building blocks of nano-machines, the potential set of applications is large, and encompasses three of the most significant problems facing humanity today. <br/><br/>The primary goal of the computer game is to develop and focus collective creativity towards a design space of machines governed by DNA molecular mechanisms. It is currently not known whether this form of sophisticated scientific design creativity can be developed rapidly with non-experts. It is also unknown whether this developed creativity can exceed the current capabilities of the scientific community. This project aims to answer a number of fundamental questions: How does one develop computer games to maximize targeted human design creativity? What are the guiding principles of successful molecular design games? How do we generalize game-development principles to the widest possible range of synthetic biology problems? How can we develop a collective creative design process that outperforms any individual creativity? How do we learn from the way people play the game, and distill their strategies towards stronger automated approaches? <br/><br/>The successful outcomes of this project can have a wide ranging impact on health and medicine. One such problem is the design of diagnostic devices and imaging technologies. The game players will work to develop DNA sensors and circuits that can autonomously analyze and interpret the information encoded in a set of molecular disease markers. This approach will enable new devices for multi-analyte testing in low resource settings and will lead to novel medical imaging technologies. Another challenge is design of novel targeted therapeutics, in this case novel RNA-based therapeutics that can autonomously sense and analyze their environment and activate a therapeutic response only where required. A third problem is design of novel materials. This project will develop DNA nanostructures with the potential for the massively parallel self-assembly materials with desired electronic, optical, or chemical properties. These materials will find applications in areas from artificial photosynthesis to biofuels production. <br/><br/>This effort will have positive broader impacts for informal science education. The game will reach out to people of all demographic profiles in hope of educating everyone about key molecular research challenges, empowering them to solve important scientific problems, and engaging them in research and science in general. Hopefully, the best scores in these games turn into seminal discoveries with deep impact on people's lives. Also, undergraduates will be involved directly in game development, and a course centered around prototyping of molecular games will be offered. Furthermore, the research team will work with education scientists to develop a new curriculum about DNA and how nature uses molecular mechanisms to achieve function. The curriculum will be anchored around the DNA Machine game and will be piloted in US high schools."
"1218570","HCC: Small: Non-Visual Skimming: Improving the Usability of Web Access for Blind People","IIS","Cyber-Human Systems","10/01/2012","09/11/2012","Yevgen Borodin","NY","SUNY at Stony Brook","Standard Grant","Ephraim P. Glinert","09/30/2015","$500,000.00","I. Ramakrishnan","borodin@cs.sunysb.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7367","7367, 7923","$0.00","In our information driven Web-based society, we are all gradually falling victims to information overload. But while sighted people can develop ways to quickly skim Web content in order to get the gist of the information and find what they need, blind users are stymied because they must rely on screen reader software with limited functionality to narrate content using computer-generated speech through a serial audio interface, which does not allow these users to find out what content is important before they listen to it. So, they either listen to all content or listen to the first part of each sentence or paragraph before skipping to the next. The PI's goal in this project is to address this problem by developing novel interfaces and algorithmic techniques for non-visual skimming that will empower people with visual impairments to access information on the Web significantly faster than is currently possible with state-of-the-art screen readers.<br/><br/>When skimming, sighted people quickly look through content and pick out keywords and relevant phrases. The PI's approach is to emulate this process and enable a computer-assisted skimming experience for screen-reader users. To this end, he will iteratively and concurrently pursue two research directions: designing interfaces for non-visual skimming, and developing algorithms to enable these interfaces. Through a process of participatory design interfaces will be derived for skimming with standard shortcut-driven screen-readers, touch-based devices, and simulated haptic surfaces, while algorithms for generating summaries will be created to support skimming of various types of Web content at different levels of granularity and speed. Controlled and in-situ real-world experiments will be conducted to evaluate the utility of the resulting interfaces and algorithms. Project outcomes will include an open-source skimming tool and reusable datasets of Web pages with annotations and summaries.<br/><br/>Broader Impacts: Technology to facilitate non-visual skimming will transform information access for visually impaired users while also contributing to the fields of natural language processing, machine learning, and Web information retrieval. Additionally, this research will help us better understand how a combination of touch and haptic interfaces can improve website navigation and skimming. Although not explored in this research, project outcomes will likely prove useful to people with other disabilities such as cognitive and motor impairments, and they may ultimately also be helpful to sighted people."
"1247690","EAGER: Augmenting Human Creativity Through Human-Robot Interaction","IIS","Cyber-Human Systems","09/01/2012","08/27/2012","Peter Kahn","WA","University of Washington","Standard Grant","William Bainbridge","08/31/2014","$250,000.00","","pkahn@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7916, 7367","$0.00","Few would disagree about the importance of creativity in human lives. Science depends on the creative mind. So does the economic viability of nations today. The goal of this grant is to open up a new frontier in human-robot interaction whereby it becomes possible to augment human creativity through human-robot interaction. This possibility could emerge by embedding sophisticated search functions and AI software in a social robot, which then engages in dialog with the user, decides on key terms for a search, filters the results (based on unique and long-standing histories of the user), and decides which results to bring forward at specific junctions in the human-robot dialog. <br/><br/>Intellectual Merit: There are four overarching goals: (1) To conceptualize the creativity domain and to generate creativity methods in human-robot interaction. (2) To develop human-robot interaction patterns that set up (a) people's prior social relationships with a social robot such that people are open to creating with the robot, and (b) the interactions with the robot for the creative process itself. (3) Piloting research toward fostering creativity in interaction with ATR's humanoid robot, Robovie. And (4) conducting a formal research study to test new forms of creativity with ATR's humanoid robot, Robovie.<br/><br/>Broader Impacts: This research will (1) lead to the mentoring of undergraduate and graduate students; (2) broaden the participation of females in HCI; and (3) promote the transfer of expert knowledge from a leading Japanese laboratory to the United States. More broadly, (4) this new vision for HRI could be transformative insofar as over the next 3-10 years this form of human-robot interaction could provide an entirely new way that people generate new knowledge, and thereby help promote exponential growth in the sciences, as well as in some of the humanities."
"1258305","EAGER: Toward Automatic Generation of Challenge-Driven Interactive Narratives","IIS","Cyber-Human Systems","12/01/2012","11/07/2012","Michael Mateas","CA","University of California-Santa Cruz","Standard Grant","William Bainbridge","11/30/2014","$151,044.00","Arnav Jhala, Noah Wardrip-Fruin","michaelm@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7367","7367, 7916","$0.00","This project will conduct the first exploration of a computational system that co-generates intertwined narrative and gameplay progressions. The system will utilize a novel representation called ludo-narrative units (LNUs), representing combinations of narrative, gameplay challenges, and choices. Utilizing audience experience models taking into account phenomena such as player agency, narrative comprehension, and gameplay learning objectives, the system will reason about progressions of narrative choices, narrative exposition, and gameplay challenges, and can dynamically reshape content to match designated goals and audience context. To accomplish this, the project will build an artificial intelligence director to construct interactive scenarios for audiences during their engagement with a game-based narrative.<br/><br/>The dynamic construction of scenarios from a pool of authored LNUs would already comprise more flexibility than currently appears in state-of-the-art scenario driven games and other popular interactive narratives, since LNUs can be selected in multiple orders in response to audience activity. But the envisioned system will provide further flexibility and customization through modification of LNU content using story generation technology. Specifically, it will use a story-planning system based on imaginative recall to dynamically provide this content. Further, global narrative and gameplay structure will be provided by using a constraint-solving algorithm to create full experiences satisfying the various system goals, written using answer set programming techniques. This enables the crucial flexibility that allows the system to reason over an arbitrary number of domains without locking it into pre-planned interfaces and infrastructure.<br/><br/>A high-level impact of this research will be contributing to a deeper understanding of these scenarios, as it defines them with the level of rigor required for generation. At a more technical level, the research will produce the first system that generates mixed interactive narrative and gameplay guided by shared experience goals. One of the high-level motivations for pursuing this work is that it has potentially profound impact for education, allowing next-generation educational software to benefit from the motivating power of scenarios and to be generated specifically for the learning profile, goals, and progress of particular learners. It is also potentially the case that experiences generated in this manner, and based on these models, could more effectively reach audiences that have grown up with games as a primary media form."
"1219241","HCC: Small: Individualized Inverse-Blurring and Aberration Compensated Displays for Personalized Vision Correction with Applications for Mobile Devices","IIS","Cyber-Human Systems","08/15/2012","08/07/2012","Brian Barsky","CA","University of California-Berkeley","Standard Grant","Ephraim P. Glinert","07/31/2015","$499,996.00","","barsky@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367","7367, 7923","$0.00","This research is concerned with the refractive elements of the eye and the errors or artifacts produced in the process of focusing light onto the retina. As the popularity of mobile hand-held devices continues to grow, a limiting factor that may emerge as an increasing impediment to their adoption among sizeable segments of the population is the prevalence of vision problems. Effective use of these devices is predicated upon reasonable visual performance by a user who must interact with a small area. This is particularly problematic for the population of older users, who face increasing incidence of vision ailments as they age. But even for younger people, there is evidence that the prevalence of myopia is increasing, especially in Asian populations. Furthermore, some visual impairments involve higher order optical aberrations (sometimes referred to as ""irregular astigmatism""), which are impossible to correct with spectacle lenses.<br/><br/>In prior work, the PI developed Vision-Realistic Rendering (VRR) to simulate an individual's vision system from measuring his or her optical system. Given these same optical measurements for that individual, the PI's goal in the current project is to achieve vision correction algorithmically and digitally rather than optically; that is, given a user with refractive error corrected by spectacles or with high order optical aberrations, compute an individualized ""inverse blur"" transformation to be applied to a sharp image such that when the resulting transformed image is then viewed by this individual, the inverse blur is canceled by the optical aberrations of his or her vision and this blurred version of the image appears in sharp focus to this individual.<br/><br/>The problem with the inverse blurring process is that it tends to produce an image whose dynamic range is much larger than that of the original image (due to a weak frequency response in the blurring kernel, and division by weak response creates large values). There are usually many negative pixels and a bright spot in the pre-deconvolved image. Computation of the pre-deconvolved image involves using inverse-filtering or a spatial domain solver. However, the situation is fundamentally different from that of performing the image de-blurring as a post-process; since the blurring convolution is the final step, there is a loss of frequency information that cannot be recovered by adding prior knowledge. The PI's approach in this project is to address the large dynamic range of the pre-deconvolved image by using a high dynamic range display system, and the loss of frequency information by the concept of a multi-layered display that does not lose any frequency content even after the blurring.<br/><br/>Broader Impacts: Eyeglasses cannot correct higher order optical aberrations that arise in the vision system of many patients who have certain types of corneal pathologies or who experience side effects of corneal refractive surgeries (such as LASIK and PRK). If successful, this research will significantly impact vision correction technology by laying the foundations for a variety of new display algorithms and devices which transcend this limitation and provide vision correction for patients whose vision problems are related to either low or higher order optical aberrations. <br/><br/>The PI makes a concerted effort to involve undergraduate students and minorities in his research. He offers independent study for students at all levels, includes undergraduate students in research group meetings, and offers freshman and sophomore seminars on related topics. He works closely with the Black Graduate Engineering and Science Students and Latino Association of Graduate Students in Engineering and Science, and supervises students in the Summer Undergraduate Program in Engineering Research at Berkeley which brings underrepresented minorities from around the country to do research at Berkeley during the summer."
"1217212","III: HCC: Small: Effects of Automated Information Selection and Presentation in Online Information Systems","IIS","INFO INTEGRATION & INFORMATICS, Cyber-Human Systems","09/01/2012","05/13/2013","Emilee Rader","MI","Michigan State University","Standard Grant","Maria Zemankova","08/31/2015","$502,093.00","","emilee@msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7364, 7367","7364, 7367, 7923, 9251","$0.00","Socio-technical systems provide access to ever-increasing quantities of information online. To help people cope with information overload, these systems implement ""algorithmic curation"": automated selection of what content should be displayed to users, what should be hidden, and how it should be presented. Virtually every Internet user who reads online news, visits social media sites, or uses a search engine has encountered algorithmic curation at some point, probably without even realizing it. In a socio-technical system, user contributions, social relationships and behavior, and features of the technology are interdependent, and determine what the system is used for, how it is used, and how it evolves over time. The goal of this research project is to investigate the relationship between social behavior and algorithmic curation, in order to better predict the effects of this pervasive practice on what we read, contribute, and communicate about online.<br/><br/>This project uses a multi-method approach to identify ways in which social and technical mechanisms influence individual users' information production and consumption, and thereby shape system-level properties of the user population and the corpus of contributions. Lab experiments investigate how social processes, such as obeying social norms and altering communications for an intended audience, are affected by different types of algorithmic curation. Field studies augment the lab experiments, using technology interventions to demonstrate how these changes play out for people in the real world over time, and as algorithms change. At the system level, agent-based models connect individual-level processes with system-level effects of algorithmic curation, and large-scale data collection looks for signs of those effects on real systems.<br/><br/>This project advances the current understanding of forces that shape information access and use in an increasingly connected and automated environment. Results will be used to provide guidance to system designers who create and manipulate algorithms, in the form of design patterns that will support a systematic, generalizable way of planning for effects of algorithmic curation at different scales. The project Web site (http://bitlab.cas.msu.edu/curation) provides information. Undergraduate and graduate students involved in the project will become better problem solvers, and work effectively on collaborative interdisciplinary projects."
"1111446","HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","IIS","Cyber-Human Systems","09/01/2011","03/15/2012","Adriaan van der Hoek","CA","University of California-Irvine","Standard Grant","Kevin Crowston","08/31/2014","$491,542.00","David Redmiles","andre@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7925, 9251","$0.00","In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br/><br/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br/><br/>Broader Impacts: As society enters the era of ""ultra large scale"" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities."
"1153229","EAGER: Presence and Navigation in Virtual Reality Rehabilitation Games for Mobility Impaired Persons","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2011","04/16/2012","John Quarles","TX","University of Texas at San Antonio","Standard Grant","Ephraim P. Glinert","08/31/2014","$248,676.00","","jpq@cs.utsa.edu","One UTSA Circle","San Antonio","TX","782499113","2104584340","CSE","7367, 7953","7367, 7916, 9251","$0.00","The term presence refers to a user's level of involvement in, or feeling of actually being part of, an immersive virtual environment (VE), or virtual reality (VR) as it is commonly called. Although researchers have been empirically studying presence for over 15 years, they have typically only focused on persons without disabilities. So whether the findings from these studies hold true for persons with mobility impairments is unknown. Based in part on his personal experiences, the PI hypothesizes that in fact many of these prior results may not be relevant to persons with mobility impairments deriving, for example, from stroke, Multiple Sclerosis, or Parkinson's disease. Many of these individuals have sensory deficits (e.g., numbness in the legs and feet), and use assistive devices (e.g., canes, walkers, or wheelchairs), which impact the way they navigate through a virtual space. This, in turn, could affect their experience of presence.<br/><br/>VR games are intended to enable users to perform rehabilitation exercises (e.g., to practice walking in good form) as part of an immersive game. They aim to engage the user's senses with graphics, audio, and 3D user interfaces, and when properly designed have been shown to enhance motivation, which is a key factor in successful rehabilitation. However these games are not yet in widespread use for physical rehabilitation, most likely due to the many unanswered basic questions about how persons with mobility impairments navigate within a VE and how this affects their experience of presence. In this exploratory research the PI seeks to gain a better understanding of such issues, as well as their potential impact upon the user's motivation for rehabilitation. To these ends the PI will conduct a series of empirical studies in collaboration with the Neurology Institute of San Antonio (NISA). As preliminary work, he is currently studying how alternative navigation methods such as real walking, virtual walking, and flying impact presence for people who walk with canes.<br/><br/>Although the preliminary study is still underway, initial results suggest that people who walk with canes experience lower presence than persons without mobility impairments. The PI plans to focus next on a number of fundamental aspects of VR that may affect navigation and presence, especially avatars (virtual representation of the body as well as of assistive devices such as a virtual cane) and field of view (the typical human field of view in the real world is about 120 degrees but it is much lower in a typical VE, which may complicate navigation for some mobility impaired persons). Through these studies, the PI will develop a new presence questionnaire that is tailored to mobility impaired persons and which can be integrated into existing presence questionnaires. The outcomes of this research will be potentially transformative, in that the findings will challenge and potentially disrupt accepted theories and perspectives of presence in the fields of VR and rehabilitation games.<br/><br/>Broader Impacts: This exploratory research will lay the foundations for a better understanding of presence in VR for the mobility impaired that may enable more effective immersive experiences for this underrepresented population, thereby resulting to higher motivation and more effective VR games for rehabilitation. This, in turn, could ultimately improve rehabilitation adherence, thereby leading to an improved quality of life for mobility impaired persons. Moreover, The University of Texas at San Antonio (UTSA) is a minority serving institution. The PI has initiated a UTSA Game Development Club, which he plans to expand as a gateway for minority student involvement in VR games research."
"1110649","Collaborative Research: Cyber-Collective Movements: Novel Socio-Computational Approaches in Studying the Blogosphere","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2011","08/30/2011","Merlyna Lim","AZ","Arizona State University","Standard Grant","William Bainbridge","08/31/2014","$339,853.00","","Merlyna.Lim@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367, 7953","7367, 7953","$0.00","Using the global female Muslim blogosphere, this research aims to understand the complexity of cyber-collective action and factors contributing to its success or failure. Despite the exponential growth of Internet users in Muslim countries, there is a lack of empirical study of socio-political uses of the technology for expressing opinions and mobilizing individuals in these countries. The female Muslim blogosphere was selected as a test-bed for two reasons: First, while research shows that three of four females online are active social media users, very little research attempts to understand social, cultural and political roles of female bloggers and collectivity among female social groups. Second, the domain epitomizes an important contrast deserving attention, between socio-political systems where women are frequently denied freedom of expression and active political uses of social media by female Internet users. Female Muslim bloggers find the blogosphere as a digital recourse to exercise their freedom of speech if compared to their physical and repressively controlled spaces.<br/><br/>This longitudinal study will develop the theoretical underpinnings and experimental tools to examine the factors that govern the success and failure of cyber-collective movements more generally. It will develop novel algorithms modeling cyber-collective movements by utilizing existing social theories on collective action and computational social network analysis and basing the analysis upon three central tenets of individual, community, and transnational perspectives. Essential questions to be addressed in this study are: What transforms individual sentiments into collective sentiments? What are the dynamics of various socio-cultural dimensions in the evolution of opinion leaders? What social or organizational factors help transcend the nation-state barriers? Several independent validation strategies will be investigated, including monitoring the manifestation of cyber-collective movements as physical social movements, human evaluation, and crowdsourcing initiatives to bridge the gap between qualitative and quantitative evaluation measures.<br/><br/>The lessons learned from this research will create greater synergies between social science and computational science. Data collected from this research will be made publicly available due to its efficacy for various interdisciplinary research endeavors, especially in human-computer interaction, game theory, political communication, social network analysis and mining, and social computing, among others. Members of underrepresented groups, especially female bloggers will play an essential role in the project, lending insights into the idiosyncrasies of their socio-technical behavior advancing our understanding of the female demographics, thus making a significant impact on society at large. Educational impacts include the creation of much-needed interdisciplinary courses and training undergraduate, graduate and doctoral students by involving them at all stages of the research."
"1111288","HCC: Large: Collaborative Research: Information Technology, Remote Socialization, and the Development of Occupational Identity","IIS","Cyber-Human Systems","08/01/2011","08/10/2011","Bonnie Nardi","CA","University of California-Irvine","Standard Grant","William Bainbridge","07/31/2015","$503,883.00","","nardi@uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7925","$0.00","This project will explore how remote socialization enabled by information and communication technologies (ICTs) is transforming four occupations: graphic design, automotive engineering, banking, and Internet entrepreneurship. Following a comparative, field-based research design, this research will examine the effects of both organizational environments and socialization tactics on ICT use and consider issues of technology use, socialization, and the changing nature of work. In today's workplaces, it is increasingly common to encounter arrangements in which occupational members are geographically distributed from one another. This new reality calls into question existing theories of socialization and learning practices that highlight the importance of collocated interaction and in situ knowledge transfer. By focusing on how individuals use ICTs to learn what it means to be an occupational member, this research will contribute to a new breed of theory on socialization that indicates the processes, practices, and strategies individuals can use to become effective members of an occupation even though they work remotely from others. By drawing on recent theorizing, which suggests that ICTs may provide particular affordances for interaction that non-mediated (e.g. face-to-face) contexts do not, it will explore the possibility that remote socialization may, in fact, help occupations to transform themselves. One aim is to build theory about the mechanisms by which technology leads to occupational transformation. <br/><br/>Occupational skill is critical to economic success, social progress, and individual well-being. However, many occupations seem to be failing to adapt quickly to changes in science, technology, and policy. The failure of occupations to change and refashion themselves to meet new social and technological pressures portends job loss from reduced skill for American citizens, and potentially increased outsourcing to other countries. This study will provide insight into how technology-enabled remote socialization may be able to contribute to faster occupational transformation. Although, for many years, ICT-mediated communication has been seen to be impoverished when compared to face-to-face communication, but now that it has developed considerably, ICT-mediated communication may provide more opportunities for workers to break free from the inertia of established occupations and develop new work practices and strategies that move the occupation forward. Additionally, it is imperative that new occupational members learn how to effectively acquire the knowledge and skills they need to perform their jobs well when they work remotely from others. This study will provide insight into effective practices of remote socialization and occupational learning such that individuals who are attempting to learn new work practices and knowledge will be successful in their efforts."
"1409897","WORKSHOP: Doctoral Consortium at the PETRA 2014 Conference","IIS","Cyber-Human Systems","12/15/2013","12/18/2013","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Ephraim P. Glinert","11/30/2014","$25,415.00","Gian Luca Mariottini","makedon@cse.uta.edu","1 UNIVERSITY OF TEXAS AT","Arlington","TX","760199000","8172722105","CSE","7367","7367, 7556","$0.00","This is funding to support a doctoral consortium (workshop) of approximately 13 promising graduate students from U.S. institutions of higher learning along with distinguished research faculty, to be held in conjunction with the Seventh International Conference on Pervasive Technologies Related to Assistive Environments (PETRA 2014), which will take place May 27-30 on the island of Rhodes, Greece. The PETRA mission is to promote interdisciplinary research on ways to use pervasive ambient intelligent environments to improve the quality of life and enhance human performance with greater capabilities; it is the only annual conference that brings together theoreticians and practitioners from a wide variety of disciplines to focus on the application of pervasive technologies to assistive environments. Innovations to be presented at PETRA 2014 include smart tools for human sensing, devices to empower persons with disabilities, algorithms for data fusion, new computer aided rehabilitation methods, therapy game environments that can be personalized, gesture recognition tools, medication management, remote secure communications and data sharing, and remote health monitoring, among others. The PETRA proceedings are published by the ACM digital library, and the authors of the best papers are invited to submit to special journal issues after the end of the conference. More information about the conference may be found online at http://www.petrae.org. <br/><br/>The goals of the day-long Doctoral Consortium are to increase the exposure and visibility of the participants' work within the community, to help establish a sense of community among this next generation of researchers, and to help foster their research efforts by providing substantive feedback and guidance in a supportive and interactive environment from a group of senior researchers. Student participants will be drawn from diverse communities including computer science, engineering, psychology, social science, neuroscience, human-computer interaction, cognitive science and communication. They will make formal 20-minute presentations of their work and will receive feedback from a faculty panel; the feedback is geared to helping students understand and articulate how their work is positioned relative to other research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. The workshop faculty members will bring a wide spectrum of expertise, and provide student mentoring and coordination. Doctoral Consortium attendees will be asked to create and maintain a ""digital workbook"" where along with their work they include feedback on papers they attended and observations that they gathered (e.g., through meetings and discussions with conference speakers and other participants) that will apply to and impact their work. Short papers on the participants' work will be published in the conference proceedings, and a summary report on the event will be posted on the conference website. <br/><br/>Broader Impacts: The PETRA 2014 Doctoral Consortium will bring together some of the best students, researchers and practitioners in relevant fields, and will thereby afford the younger participants a unique opportunity to gain wider exposure for their innovative ideas while also receiving reinforcement for the importance and value of conducting research with societal impact. The workshop will allow the junior participants to create a social network both among themselves and with senior colleagues. The organizing committee will make a concerted effort to attract participants who are women, members of under-represented minorities, and persons with disabilities. To further assure diversity, NSF funds will be used to support no more than 2 student participants from any one institution. And this year, for the first time, NSF funds will also be used to support attendance at the conference of 2 select undergraduate students, in the hope of exciting them about possible career choices in science."
"1413869","WORKSHOP: iConference 2014 Doctoral Research Colloquium","IIS","Cyber-Human Systems","12/15/2013","12/18/2013","Karen Fisher","WA","University of Washington","Standard Grant","Ephraim P. Glinert","11/30/2014","$29,778.00","","fisher@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7484, 7556","$0.00","This is funding to support travel for a diverse group of U.S. PhD students and distinguished faculty mentors to participate in a doctoral colloquium (workshop) on research on information science that will be co-located with the 2014 iConference to be held March 4-7 in Berlin, Germany, and jointly hosted by the Berlin School of Library and Information Science at Humboldt-Universitat zu Berlin and the Royal School of Library and Information Science at the University of Copenhagen. The iConferences, the annual meetings of the iSchool community (cf. http://ischools.org/ for more information) are a leading forum that brings together faculty, students, research staff, and industry practitoners with a common interest in supporting and augmenting human engagement with information and technology. Open to broad participation, the iConferences have been successful in building a sense of community around the information field, bringing together people who otherwise might rarely interact with one another, and helping them share findings and exchange views relating to their interdisciplinary research. More information about the 2014 iConference may be found online at http://ischools.org/theiconference/call-for-participation/. <br/><br/>The 2014 iConference Doctoral Colloquium, which will take place on March 7, 2014 (the final day of the iConference), will be a day long research-focused meeting of approximately 35 selected PhD candidates studying all aspects of information science (IS) together with 12 distinguished mentors (NSF funds will be used to support 16 student participants from U.S. institutions). The primary objective of the Doctoral Colloquium is to help train the next generation of information science researchers. To this end, it will provide the student participants with an environment in which they can share and discuss their goals, methods and results at an early stage of their research. By participating in the doctoral colloquium, students will gain feedback on their work both from the mentors and from other students, which should allow them to enhance their research. Students will also develop a better understanding of the different research communities engaged in the study of information science, and learn how to position their work within the IS community. In addition, the colloquium will provide students with opportunities to make new professional connections beyond their own disciplines. <br/><br/>Broader Impacts: The iConference doctoral colloquia traditionally bring together the best of the next generation of researchers in information science and related areas, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Participation is encouraged from a broad range of relevant disciplines and approaches, thereby broadening attendees' perspectives on their topics of study and promoting advancement of the field. No more than one student will be accepted from any given institution, and priority will be given to students who have not previously attended an iConference Doctoral Colloquium. The organizers will proactively work to include women and minority representation among the student participants to the extent possible. As a consequence of these steps, the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field."
"1417007","WORKSHOP: ISMAR 2013 Doctoral Consortium","IIS","Cyber-Human Systems","12/15/2013","12/12/2013","Si Jung Kim","FL","University of Central Florida","Standard Grant","Ephraim P. Glinert","11/30/2014","$4,933.00","","sjkim@ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7367","7367, 7556","$0.00","This is funding to support participation by 2 graduate students from U.S. institutions in a Doctoral Consortium (workshop) that was held in conjunction with the 2013 International Symposium on Mixed and Augmented Reality (ISMAR 2013), which took place October 1-4 in Adelaide, Australia, and which was organized by the IEEE Computer Society with academic sponsorship from the Association for Computing Machinery (ACM). For over a decade, ISMAR (and its forerunner events IWAR/ISAR and ISMR) has been the premier international conference on research into the science, technology, applications and uses of Mixed Reality (MR) and Augmented Reality (AR). The proliferation of powerful mobile hardware has opened up new avenues of research into MR and AR while enabling corporate and consumer applications on a wide scale. Across this spectrum fascinating new types of user interfaces, technologies, and concepts are beginning to emerge. The field is highly interdisciplinary in nature, bringing together technologists, educators, humanists, artists and social scientists, among others. ISMAR is one of the largest meetings devoted to the advancement of mixed reality, augmented reality, virtual reality, and human-computer interaction with the physical world, and encourages six different submission types: Papers and Posters, Workshops, Panels, Tutorials, Demonstrations and Contests. Because of the diverse fields relevant to mixed and augmented reality, ISMAR content is organized in two tracks: The Science & Technology (S&T) program and The Arts, Media and Humanities (AMH) program. The top papers are often extended, reviewed, and submitted for publication in the prestigious IEEE Transactions on Visualization and Computer Graphics. More information about the conference may be found at http://ismar.vgtc.org/. <br/><br/>This was the second Doctoral Consortium held in conjunction with an ISMAR symposium. A total of 7 graduate students participated in the workshop, along with senior members of the community (faculty and industry researchers) who served as mentors. The goal was to provide the students with an opportunity at a critical time in their careers to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers within the ISMAR community. To these ends participants were asked to prepare both a technical presentation and a poster describing their work. A pre-event social dinner allowed the attendees (students, mentors and organizers) to get to know each other. The following day all attendees met for an informal breakfast at 8:00 AM, after which each student participant had 50 minutes devoted to his/her research, beginning with a presentation for approximately 30 minutes followed by about 20 minutes reserved for an extensive discussion with the other graduate student participants and the senior researchers. The discussion was facilitated by the Doctoral Consortium co-chairs and mentors, with the goal of addressing the strengths and weaknesses of the research, challenges and issues, implications of the results, potential suggestions for additional approaches or follow-on work, and career guidance related to the student's work and area. The posters were on display during the ISMAR conference poster sessions (in which the students were expected to take part), and were marked as being part of the Doctoral Consortium. All results from the Doctoral Consortium, including the procedures followed, were archived in the ISMAR 2013 DC binder as a reference for next year's conference.<br/><br/>Broader Impacts: The organizers took steps proactively to achieve a diversity of research topics, disciplinary backgrounds, methodological approaches, and home institutions among the students, to ensure that they met people outside their own specific area. For example, a maximum of one graduate student per institution was selected. Factors such as gender and ethnicity were also taken into account, with an emphasis on including underrepresented groups. Due in part to the remote location of this year's conference, in the end most of the student participants were from foreign universities; funding for the international students was secured from other sources, with NSF funds being requested only to support the 2 students from U.S. institutions of higher learning."
"1355298","EAGER: Virtual Personality Assessment Laboratory","IIS","Cyber-Human Systems","09/15/2013","09/10/2013","Alessandro Canossa","MA","Northeastern University","Standard Grant","William Bainbridge","08/31/2014","$247,572.00","Carey Colvin, Magy Seif El-Nasr","a.canossa@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7367","7916","$0.00","The goal of this project is to develop the principles to design a virtual personality assessment laboratory. This requires development of a preliminary taxonomy of mechanics, grounded on personality research, that allows researchers to use behavioral patterns of individuals in computer-generated virtual environments, to assess their real-world personality. Such virtual personality detection mechanisms can then be used by other researchers to adapt the laboratory further, which would be one ultimate goal: the design of more personalized and adaptive applications that may improve impact on large societal problems. The research activity will lead to a new methodology with the potential to transform current practices across disciplines, from social psychology to human-centered computing.<br/><br/>The virtual personality assessment laboratory will be developed as a set of modular challenges and situations that make use of the mechanics individuated in the taxonomy. These situations are constructed to elicit personality preferences. The design is driven by personality theory and validated by a wide range of personality measures such as the Need For Cognition, the California Q-Sort, the Reiss Motivation Profiler and the Five Factor Model. The system will be validated through two iterations to ensure that scenarios are assimilated and that they conform to the intention of the designers. A final summative evaluation will be administered utilizing data on the behavior of research subjects inside the environment, as well as various personality measures such as scores from personality questionnaires, informant interviews, and behavior coding. Correlation analysis will be used to investigate relationships between choices emerging from the context of action in the virtual environment and personality scores. <br/><br/>This research impacts directly a number of disciplines from psychology of personality to adaptive technologies and personalization. The research affects our understanding of personality within virtual environments, which are becoming a major part of our lives. It also has the potential of developing customizable learning environments. Understanding individual differences through the analysis of consumption and behavior of digital entertainments allows for a deeper level of adaptation and personalization of persuasive technologies aimed at fostering education, health or training, potentially increasing participation from all segments of society."
"1352992","EAGER: The LIT ROOM - A Networked Suite of Architectural-Robotic Artifacts Embedded in the Library for Advancing Literacy in Children","IIS","Cyber-Human Systems","09/15/2013","09/04/2013","Keith Green","SC","Clemson University","Standard Grant","Ephraim P. Glinert","08/31/2015","$199,995.00","Susan Fullerton, Ian Walker","kegreen@clemson.edu","300 BRACKETT HALL","CLEMSON","SC","296340001","8646562424","CSE","7367","7367, 7916, 9150","$0.00","In an effort to cultivate literacy skills in the United States the nation's public libraries have embraced digital technologies, mostly in the form of public-access computers loaded with software, supported by library staff. But interacting with a ""keyboard-mouse-screen"" may not offer the immediacy of interacting with the printed page, and both forms of interaction are far removed from the physical, tangible and social world in which young children thrive. The PI argues that literacy can be cultivated in a space that is at once physical and digital and evocative of the book being read. To this end, in this project the PI will explore the LIT ROOM, a literacy support tool at room-scale that consists of a novel suite of user-friendly, networked, ""architectural-robotic"" artifacts embedded in the everyday physical space of the library. This physical-digital environment is transformed by words read by its young visitors, so that the everyday space of the library ""merges"" with the imaginary space of the book; the book becomes the room, the room becomes the book. And should the LIT ROOM's intelligent reconfigurations not match the imagined spaces of young readers, they can ""fine-tune"" the room through tangible interfaces. The work will proceed in two phases. First, the PI will ask children to decide what makes for a compelling LIT ROOM. He will present to children, ages 4-8, low-fidelity ""architectural-robotic"" artifacts within a library space to help capture how children define and employ this digital-physical suite to ""create the book."" Then, he will iteratively develop and evaluate the suite as a fully-working environment that embodies what was learned from the child-centered participatory design process. The test bed implementation will be situated in the Richland County Public Library of Columbia, South Carolina, the largest public library in a state that ranks among the lowest in the State Technology and Science Index and the highest in numbers of people who are both illiterate and living below the poverty line. To tackle this challenge, the interdisciplinary team includes two investigators with complementary expertise in continuum and architectural robotics, and literacy education.<br/><br/>Broader Impacts: Because the prototype implementation will be located in a real-world public space it will have exposure to a large audience. Project outcomes will also advance the start-of-the-art of robotic systems for a real-world environment and application, using a mix of sensing/actuating and deformable continuum surfaces. The findings will further advance knowledge and understanding in literacy by studying and providing experimental data on the efficacy of tangible environmental technologies in promoting literacy in children."
"1355986","WORKSHOP: Doctoral Consortium for ASSETS 2013","IIS","Cyber-Human Systems","11/01/2013","11/07/2013","Gregory Abowd","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","10/31/2014","$22,582.00","","abowd@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7556","$0.00","This is funding to support a doctoral consortium (workshop) of approximately 10 promising graduate students from the United States and abroad (no more than 2 expected to be from outside the country), along with 5 distinguished research faculty. The event will take place on Sunday, October 20, immediately preceding and in conjunction with the 15th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2013), to be held Monday-Wednesday, October 21-23, in Bellevue, WA. The ASSETS conferences are the premier forum for presenting innovative research on the design and use of both mainstream and specialized assistive technologies. This includes the use of technology by and in support of: individuals with hearing, sight and other sensory impairments; individuals with motor impairments; individuals with memory, learning and cognitive impairments; individuals with multiple impairments; older adults; and professionals who work with these populations. Researchers and developers from around the world in both academia and industry will meet to exchange ideas and present their latest work. More information about the conference may be found at http://www.sigaccess.org/assets13. <br/><br/>A key component of building this community is through its youth. The ASSETS 2013 doctoral consortium will provide an opportunity for graduate students from diverse backgrounds (computing, engineering, psychology, architecture, etc.) to come together and explore their research interests in an interdisciplinary workshop, under the guidance of the PI and a panel of other distinguished experts in the field, so that they can appreciate the broader spectrum of research and development approaches to assistive technologies and universal usability, and also experience the community in which they can pursue their endeavors. Student participants will make formal presentations of their work during the consortium, and will receive constructive feedback from the faculty panel. The feedback is designed to help students understand and articulate how their work is positioned relative to related research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Thus, the consortium will help shape ongoing and future research projects aimed at assistive technologies and universal access, will promote scholarship and networking among new researchers in this emerging interdisciplinary area, and will also expose these promising young researchers to a larger community. In an effort to further integrate doctoral consortium participants into the conference itself, a (poster) session has been set aside in the technical program to allow all doctoral consortium participants to present their research to the full conference. In addition, one student from the doctoral consortium will be selected to deliver the closing plenary presentation. An evaluation of the consortium will be conducted and the results made available to the organizers of future such events. <br/><br/>Broader Impacts: The doctoral consortium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality/cultural and scientific discipline, the students' horizons are broadened to the future benefit of the field. The organizers will take special steps to promote participation from institutions with relatively large numbers of students from under-represented groups; to further increase diversity, participation will be limited to at most one male and one female student from the same institution."
"1350323","CAREER: Large-scale Appearance Modeling","IIS","Cyber-Human Systems","01/15/2014","01/10/2014","Pieter Peers","VA","College of William and Mary","Continuing grant","Ephraim P. Glinert","12/31/2018","$85,832.00","","ppeers@cs.wm.edu","Office of Sponsored Programs","Williamsburg","VA","231878795","7572213966","CSE","7367","1045, 7367, 7453","$0.00","The visual appearance of the world around us is the result of complex light interactions between different surfaces and material properties that comprise a scene. Despite staggering advances in data-driven appearance modeling, the creation of accurate models of large environments remains an open problem. The reliance of most current appearance modeling methods on active lighting to probe different slices of a scene's appearance precludes their use in environments where there is limited or no control over the incident ambient lighting. Furthermore, to facilitate calibration, many appearance modeling techniques estimate the appearance of a scene from a fixed vantage point, excluding scenes too large to fit in a single view with sufficient detail. In this research, the PI will investigate two novel appearance modeling paradigms designed expressly for large-scale environments under uncontrolled ambient lighting: appearance-from-motion and appearance-by-similarity. The former exploits relations between observations from different viewpoints to infer the full reflectance behavior, while the latter seeks to identify the best match from a library of pre-existing appearance instances to a possibly under-constrained set of observations. To support these two paradigms, a novel appearance model will be developed that builds upon our intuitions regarding scene appearance. The work will focus on two common types of input: community photo-collections and targeted video sequences.<br/><br/>Broader Impacts: This research will pave the way towards practical techniques for in-situ appearance modeling of large-scale environments, while stimulating new research in computer vision and in data-driven appearance modeling in computer graphics by answering fundamental questions as to whether we can model appearance from motion and/or by exploiting similarity. The project will have far-reaching impact not only on computer science but also on diverse fields ranging from metropolitan planning to cultural heritage to entertainment. The ability to model existing environments will be beneficial to various security and safety training programs (for example, virtual fire drill simulations of existing buildings and sites could help train and prepare firefighters and first responders). The emerging field of virtual reality therapy will also benefit from this research, by making it easier to create digital models of large-scale environments (so that, for example, patients who have suffered a stroke can practice motor rehabilitation skills in virtual reproductions of environments they encounter in their daily lives, while autistic children can train to improve their social interactions in virtual reproductions of places such as classrooms which they encounter in their daily lives)."
"1320690","HCC: Small: FIDO - Facilitating Interaction for Dogs with Occupations: Wearable computing for two-way communication with assistance dogs","IIS","Cyber-Human Systems","09/15/2013","09/04/2013","Melody Moore","GA","Georgia Tech Research Corporation","Continuing grant","Ephraim P. Glinert","08/31/2015","$244,325.00","","melody@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923","$0.00","Assistance dogs have improved the lives of thousands of people with disabilities. Guide dogs, service dogs, and hearing dogs can provide independence and significantly enhance quality of life. However, communication between human and canine partners is currently limited. Handlers give commands, and dogs respond with behaviors, which can sometimes have ambiguous meanings to the handlers. For example, a guide dog stops while walking with his handler, but the dog has no definitive way to tell the handler there is a new barrier on a familiar path. A hearing dog alerts his handler, but can't easily report that the fire alarm has sounded and they need to evacuate. A service dog may need to receive a ""lie down"" command silently in a dark, crowded theater, or from a distance, which would preclude verbal or hand signals. The PI's goal in this research is to explore fundamental aspects of wearable technologies to support two-way communication between assistance dogs and their handlers. To this end, the PI will investigate on-body interfaces for dogs in the form of electronic textiles and computers integrated into assistance dog clothing, such as vests and harnesses. Studies will assess the abilities of dogs to interact with affordances worn on their bodies, and determine what stimuli dogs can sense and comprehend from wearable technology. The work will be divided into three thrusts: Dog-to-handler communication (to determine to what extent dogs can activate affordances on their harnesses, vests, coats, or collars, such as ""touch points"" which can be activated by a dog's nose touch, and ""pull points"" which can be activated by tugging); Handler-to-dog communication (to investigate the sensory capabilities of dogs to respond to simple stimuli incorporated into a dog vest or harness, such as small vibrating motors); Handler feedback and control (the team will implement a head-mounted visual and/or auditory display to allow handlers to receive input from their dogs, as well as control interfaces that can be integrated into a harness handle, leash, or a piece of clothing worn by the handler). Design and testing of the on-body interfaces for the dogs will be carried out using an iterative approach, and the final designs will be validated with three assistance-trained dogs in laboratory and real-world environments. The PI will also stress-test the designs with dogs at speed on an obstacle course.<br/><br/>Broader Impacts: Project outcomes will extend the state of the art in wearable interfaces to animals, and will contribute pioneering work to the nascent fields of Animal Computer Interfaces and Inter-species Interaction, as well as discovering more about the physical and cognitive abilities of dogs. Adapting usability analysis and design techniques from the human realm to apply to animals will expand the body of knowledge in Interactive Computing. In addition to the direct impact of improving the quality of life for people with disabilities, the technologies developed in this project could have application to other working dog teams (e.g., in military or police canine units, and in search and rescue), and they may ultimately allow all pet owners to better communicate with and train their dogs."
"1002748","MAJOR: Assistive Artificial Intelligence to Support Creative Filmmaking in Computer Animation","IIS","Cyber-Human Systems, CreativeIT","09/01/2010","08/31/2010","Mark Riedl","GA","Georgia Tech Research Corporation","Standard Grant","William Bainbridge","08/31/2014","$695,485.00","Michael Nitsche","riedl@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367, 7788","7788","$0.00","This project will explore approaches to artificial intelligence that can support creative digital filmmaking, an extremely rich new form of expression and communication. The most accessible variant of digital filmmaking is ""machinima"" - cinematic movies created by manipulating avatars in 3D computer game worlds. Due to the allure of cheap, quick, and easy movie making, and the accessibility of high-fidelity graphics through video games technologies, machinima has grown into a mainstream form of creative expression and sharing. However, machinima has a high threshold of entry. This is due only partly to technical tools, which are cheap and easily acquired; digital filmmaking also has a high threshold of skill requirements. In general, creativity is collaborative, with creators often seeking feedback and critique from others. Intelligent systems can also participate in the feedback loop of creative practice by suggesting, autonomously creating, and critiquing digital media.<br/><br/>The goal of this research is to reduce the technological and skill barriers to complex, but rich forms of digital expression such as filmmaking, thereby increasing the creative productivity of amateur creators. Its approach is to develop digital media production tools that are instilled with computational models of creative practice and intuitive interfaces informed by empirical studies. The anticipated result is a greater understanding of creative processes involving feedback and critique, models of cognitive and emotive processes in human recipients of creative artifacts, and understanding about the tradeoffs of interface modalities involving intelligent participatory systems. The project is organized around two major, interrelated thrusts: (1) develop cognitive and computational models of feedback and critique as a means toward intelligent systems that participate in creative endeavors; (2) study how the creative abilities of amateur and expert digital filmmakers are affected by production interfaces along dimensions of (a) degree of constraint in cinematic control and (b) modes of intelligent participatory support.<br/><br/>It is anticipated that the resultant models and implementations will serve as next-generation creativity support tools to be adopted by the amateur digital filmmaking and machinima communities. By achieving its research goals, this project will demonstrate a technique for lowing the threshold of entry to a form of digital media creation. Lowering the threshold of machinima production, in particular, will open the practice to populations of users historically underrepresented in computing such as women, who are attracted to storytelling but often discouraged by highly technical ""hacker"" skills. As an expressive form, digital filmmaking is a powerful medium for communication, can be used as a draw to computing, and can be integrated into a wide repertoire of activities including entertainment and education. Resultant models and implementations may also impact the growing practice of previsualization in the movie and television industries. The approach will result in a model for incorporating intelligent creative assistance into other forms of expressive digital media."
"1017952","HCC: Small: Designing Effective Gaze Mechanisms for Cross-Modal Embodied Agents","IIS","Cyber-Human Systems, IIS SPECIAL PROJECTS","09/01/2010","09/30/2011","Bilge Mutlu","WI","University of Wisconsin-Madison","Continuing grant","William Bainbridge","08/31/2014","$499,050.00","Michael Gleicher","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7367, 7484","7923","$0.00","The goal of this project is to design and build gaze mechanisms for embodied agents that can achieve high-level social and communicative goals that people achieve using such mechanisms and that can be applied across a wide range of agent presentations and task domains.<br/><br/>Embodied agents promise significant social, cognitive, and organizational benefits through applications in education, training, rehabilitation, and collaborative work. However, in order to be effective across a wide range of applications, agents must be able to use the nonverbal social cues that humans employ in their communication and to employ these cues in whatever modality the agent is presented in - whether it be a social robot, a life-sized virtual human, or an animated avatar on a portable display. Gaze cues are particularly important social signals. Although they are subtle, they can serve as powerful mechanisms for achieving high-level social and communicative goals, such as improving a listener?s comprehension, controlling the flow of a conversation, and indicating interest in or appraisal of objects. This project investigates how such mechanisms might be designed and built for embodied agents and how similar social and communicative goals could be achieved using different agent representations across different task domains.<br/><br/>This investigation will involve (1) performing formal observational studies to better understand how people use gaze, (2) developing computational models that synthesize gaze behaviors that can be controlled precisely and retargeted to a range of agent platforms, and (3) evaluating in experimental studies the effectiveness of using gaze cues across a range of agent presentations and task contexts. Success in this project will create new knowledge on human gaze behaviors, connecting the high-level findings in the social science literature to more detailed, low-level cues and mechanisms. It will also produce a set of techniques that are based on this understanding for synthesizing controllable and flexible gaze movements that agents can use in order to achieve social and communicative goals. Finally, it will validate the effectiveness of the use of gaze cues by agents across a variety of agent presentations and task contexts.<br/><br/>A trans-disciplinary approach will combine rigorous, formal observational studies to build detailed models of human communicative mechanisms with practical efforts to build usable computational models that meet the needs of creating agents that work in real-world tasks. The focus on human models insures that the computational models are well founded, while the focus on developing practical algorithms guides the human studies towards creating understanding that will be most informative for agent design. The project plan involves connecting the disparate communities that work on developing social agents and training students to do the trans-disciplinary work required to create effective embodied agents. The project will also enable K-12 outreach efforts to use robots and connections to social science to engage students and increase participation by under-represented groups."
"1047567","Workshop on Collective Intelligence","IIS","Cyber-Human Systems","09/01/2010","08/13/2013","Thomas Malone","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","08/31/2014","$49,950.00","","malone@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7556","$0.00","The rise of Web 2.0 and large-scale distributed contributor systems is generating opportunities for a new interdisciplinary field on the topic of collective intelligence. Like cognitive science did beginning in the 1970's, this new field may help share perspectives and results from a variety of different fields. In the case of collective intelligence, potentially relevant disciplines include computer science, organization theory, social psychology, economics, and others. This workshop will frame a research agenda covering important aspects of collective intelligence such as: how to define and measure collective intelligence, how to motivate participants to form part of an intelligent collective, what is the effect of different patterns of connection among the participants (i.e., network science), what problems are well-suited to be attacked by a collective intelligence approach, and what are common design patterns among successful systems.<br/><br/>The workshop on collective intelligence will facilitate broader impacts in: (a) coalescing a community of people from different disciplines and perspectives, (b) initiating consensus on how to define collective intelligence as a field and the topics that should be central within it, (c) establish a preliminary research agenda for the field, and (d) catalyze publications about the prospects for this field in one or more high quality journals."
"1053235","CAREER: Material Computing for Everyone: Democratizing Creative Computing via Unexpected Materials and Cultures","IIS","Cyber-Human Systems","04/01/2011","03/23/2011","Leah Buechley","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","03/31/2016","$499,997.00","","leah@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","1045, 1187, 7367","$0.00","The PI's goal in this project is to answer the question: Can we engage new groups of people in engineering by situating technology in new material and cultural contexts? To this end, she will spark and study diverse engineering communities by developing tools that enable people to work creatively with computation in new material and cultural contexts. The PI's prior work provides strong support for her hypothesis that tools that include unorthodox combinations of materials can be uniquely appealing to diverse audiences. Materials like textiles, paper, and paint have powerful cultural associations that can balance the negative stereotypes often associated with technology. In this research the PI will explore these ideas by integrating new and traditional materials, bringing together computation, electronics, textiles and paper. Tools that open up new creative areas for mass experimentation and collaboration are tremendously important both for the future of computing and the future of society at large. Equally important are tools that bridge the digital and physical worlds, and tools and activities that diversify computing. This project is situated at a powerful intersection. The PI will design and test toolkits and curricula that blend computing with paper and fabric, and thus enable diverse groups of people to build hybrid digital-physical systems. And she will conduct longitudinal studies of the real-world creative communities that develop around these tools. This work will contribute to the study of creativity support tools, ubiquitous computing, educational technology, and creative communities.<br/><br/>Broader Impacts: The PI expects project outcomes to broaden participation in computing, by providing new communities (including groups of women, economically disadvantaged urban youth, and senior citizens) with compelling incentives to engage in computer science and other STEM disciplines. The tools developed in this work will expand the culture of computing by providing examples of technology that looks and feels very different from the technology we're accustomed to. The PI will make her tools available both to educators and the general public in order to ensure that the research has long-term, real-world impact."
"1002901","Major: Creative Secondary STEM Learning Through Collaborative Game Building (PedGames)","IIS","SPECIAL PROJECTS - CISE, Cyber-Human Systems, CreativeIT","09/01/2010","05/08/2013","Jihie Kim","CA","University of Southern California","Standard Grant","Janet L. Kolodner","08/31/2014","$666,000.00","Erin Shaw, James Baker","jihie@isi.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","1714, 7367, 7788","7367, 7788, 9251","$0.00","Educators at all levels have begun to exploit children's attraction to games. However, until recently, especially at the K12 level, it has been assumed that learners were consumers of games and not their producers. The goal of the Pedagogical Game project is to develop and evaluate a secondary school curriculum for learning standards-based content via collaborative game-making. The proposed work will test the hypothesis that creating computer games (game-making) can engage students in learning standards-based content and significantly impact achievement and retention and that collaborative game design can be a powerful tool for encouraging open negotiation and argumentation, a core element in promoting creativity. The interdisciplinary and project-based approach to learning will encourage art/theater and math/science students to work together in a collaborative setting and promote differentiation of learning tasks and student-centered learning. Research being undertaken includes (a) developing collaborative game making curriculum where standard based math content is effectively integrated; (b) identifying scaffolding opportunities, such as promoting student collaboration and reflection through online discussions and wiki-based journaling; (c) developing instructional assessment tools based on discourse analysis and course topic ontology that will monitor student progress over time according to the game making project goals.<br/><br/>The proposed work will strengthen and evaluate a fledgling game-building curriculum that was created to address the educational needs of at-risk high school students in underperforming schools in the Los Angeles Unified School District (LAUSD). The program has a large potential to positively impact the education and lives of our at-risk student population. The intellectual merit of the project includes a game-making curriculum with embedded standards and new ways to promote and evaluate collaboration in a game-making context. The results of the project will have broad societal impact by enhancing the ability of students from traditionally under-represented groups to participate in STEM fields of study while learning 21st century career skills. The project will also contribute to the knowledge base through careful empirical evaluation of the benefits of creative new instructional strategies (game-making, project-based learning) that support learning styles and strategies preferred by students who have had difficulty excelling in mathematics learning. With the support of LAUD teachers and staff, we are poised to develop and integrate the program into the curriculum and scale its adoption. Its success has the potential to transform learning strategies for at risk students."
"1018486","HCC: Small: Cyber-Enabled Analysis and Control of Building Evacuation","IIS","Cyber-Human Systems","09/15/2010","12/02/2013","Alla Safonova","PA","University of Pennsylvania","Standard Grant","William Bainbridge","08/31/2014","$500,000.00","Ali Malkawi, Maxim Likhachev","alla@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7367","7923","$0.00","This project will: (1) Build an experimental setup for conducting evacuation experiments inside 3D virtual online communities. (2) Analyze the realism of the experimental setup and research the ways to improve it. (3) Investigate the use of intelligent signs for controlling peoples' behavior in emergency situations. One of the major aspects in the design of buildings, stadiums and city blocks is their suitability for evacuation. Peoples' lives depend on how quickly these constructions can be evacuated in the emergency situations such as fires, earthquakes, terrorist attacks and collapsing structures. As a result of the 9/11 terrorist attacks however, it became apparent that current approaches to building design in regard to emergency evacuation for various building typologies such as high-rises, airports and stadiums need to be re-examined. In particular, the designs must be carefully evaluated against evacuation procedures. This raised a major concern about the lack of tools that would allow robust predictions of realistic human movements and interaction in the designed environments. It is clearly impractical to establish live experiments with thousands of people evacuating every possible building design for every possible emergency condition. <br/><br/>The research will not only evaluate virtual-world information technology as a tool for building design to facilitate evacuation, but it will also develop new information technology that could be incorporated in real-world buildings. For example, intelligent exit signs could automatically direct people during emergencies based on the known information about the construction, the type and location of emergency, and the current distribution of people. Building an experimental setup for conducting evacuation experiments within 3D virtual online communities requires answering such unorthodox questions as how to attract research subjects to the experiments, how to motivate the participants to evacuate buildings when emergency occurs, and what setup should be made to evaluate the efficiency of evacuation as truthfully as possible. The analysis and improvement of the realism of the setup requires research in realistic simulation of natural effects such as fire, real-time realistic human motion synthesis for hundreds of characters and developing effective means of measuring the immersiveness of participants. Finally, the design of control strategies for intelligent signs requires the research of real-time decision-theoretic planning under uncertainty algorithms suitable for the control of massive multi-agent systems. <br/><br/>The safety of buildings is of critical importance to any society. Natural hazards, terrorist attacks and fire accidents cause losses of thousands of lives every year. By designing buildings that are easier to evacuate, engineers can save a significant fraction of these lives. Yet, there is a lack of tools that would allow engineers to conduct high-fidelity evaluations of building designs in terms of evacuation efficiency. This research is directed towards providing engineers with access to conducting such large-scale high-fidelity experiments at drastically lower expense than previously possible. Progress in this direction will also have positive educational impacts. The project will play a significant part in the classes offered in an undergraduate Digital Media Design program, which has about 50% female students."
"1065275","HCC: Medium: New Technology Supports for Learning in Embodied Science Inquiry Contexts","IIS","Cyber-Human Systems","05/01/2011","09/26/2013","Thomas Moher","IL","University of Illinois at Chicago","Continuing grant","Kevin Crowston","04/30/2015","$1,197,551.00","James Slotta","moher@uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7367","7367, 7924","$0.00","This project centers on the design of technologies than can help teachers and students to effectively enact the kinds of complex, challenging instructional designs that characterize modern science pedagogy. While considerable effort has gone into the development of technologies to support learners who are seated at computers, this project will address the largely unexplored domain of embodied, whole-class science inquiry activities that are largely unmediated by traditional one-to-one technologies. The project focuses on ""embedded phenomena"" instructional units in which elementary school students conduct investigations of persistent, room-sized simulated phenomena over multi-week periods. Through a series of iterative design studies, the project will build and evaluate technology-based supports for teachers and students addressing three critical goals: (a) improving students' abilities to conduct accurate and reliable scientific investigations, (b) ensuring the regular and meaningful participation of all classroom students in collaborative investigations, and (c) helping students to effectively integrate, manipulate, and represent the results of their collective scientific work. The new technologies developed in the project will serve as foundational building blocks for a flexible, sustainable learning technology infrastructure supporting ambitious STEM instruction.<br/><br/>Broader impacts: The project will help students and teachers, particularly in the elementary and middle school grades, to overcome barriers to engaging in innovative but complex pedagogical forms that have the potential to transform science education. It will promote high-fidelity enactment of science practices, help to ensure that opportunities for participation are distributed throughout classes of students, and inform the design of new pedagogical approaches. The tangible products of the project-including new technologies, new instructional units, and evaluations of their effectiveness in supporting STEM learning-will be made broadly available to teachers, learning researchers, and technology developers."
"1065513","HCC: Medium: Removing Barriers to the Practical Use of Non-Invasive Brain-Computer Interfaces","IIS","Cyber-Human Systems","08/01/2011","09/26/2013","Charles Anderson","CO","Colorado State University","Continuing grant","Ephraim P. Glinert","07/31/2016","$1,100,027.00","Patricia Davies, William Gavin","anderson@cs.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","CSE","7367","7367, 7924","$0.00","Brain-computer interfaces (BCIs) are hardware and software systems that allow users to interact with computer applications by changing their mental activity, which causes variations in weak electrical voltages produced by the brain. BCIs measure these voltages in one of two ways: invasive methods use electrodes implanted in the brain, while noninvasive methods use electrodes resting on the scalp that are part of a cap worn by the user. A long-term goal of BCI research is a new mode of communication for subjects with diseases and injuries resulting in the loss of voluntary muscle control, such as amyotrophic lateral sclerosis (ALS), multiple sclerosis, high-level spinal cord injuries or severe cerebral palsy. If all voluntary muscle control is lost, a locked-in syndrome results in which a person is unable to communicate with the outside world. BCIs can provide a new way for users to communicate with their caregivers and to control devices such as televisions, wheelchairs, speech synthesizers and computers. While BCI technology holds great promise, most BCI systems remain in research labs. The goal of this project is to remove barriers to practical, noninvasive, BCI technology that exist in current approaches, and to field test the resulting BCI systems in the homes of users who suffer from motor impairments. Limitations of current BCI systems that will be addressed include the difficulty of applying an electrode cap, signal artifacts due to other assistive technology in the user's environment, and long computer and user training times required to calibrate current EEG classification algorithms.<br/><br/>A key barrier to practical BCI systems is the lack of methods for reliable, fast classification of EEG signals. In this project, this limitation will be addressed by conducting experiments in three areas. One set of experiments will investigate the quality of EEG signals recorded in subjects' homes and the performance of BCI applications in real-time in the homes. The second set of experiments will involve new algorithms for EEG artifact removal and signal classification that are tailored for EEG recorded in subjects' homes and for real-time use. For the second set of experiments, new user interfaces will be studied and compared to currently available interfaces. For the third set of experiments, several different user interface designs for BCI applications will be developed and studied. The effectiveness of visual and auditory feedback provided to the user in real-time will be investigated.<br/><br/> This interdisciplinary project involves a team of investigators and students from diverse backgrounds. Faculty and students in computer science will design and implement algorithms and the BCI user interface. Faculty and students in occupational therapy will guide the field testing of BCI systems and will guide the evaluation of these experiments. Progress will be evaluated in a number of ways, including experiments comparing EEG signal representations and classifiers by accuracy, reliability, and training time, and field tests of BCI systems. Ultimately, the project's success will be measured by new or improved means of individuals interacting with computers in their homes for purposes of communication with others and control of assistive devices like wheelchairs.<br/><br/>Broader Impacts: This project will develop a new technology for sensing and analyzing electroencephalogram signals (EEG) from human subjects. The resulting technology will help advance brain imaging and its application. The long term goal of this research is a new brain-computer interface based on EEG signals with which persons can use a computer to communicate with others in their vicinity or remotely over the net, to surf the net, and to control environmental entertainment, and assistive devices. The new technology will be simple enough for any person with minimal training to use. The project will also play a strong role in the education of future researchers and health professionals in this interdisciplinary field by involving graduate and undergraduate students from multiple departments as research assistants, by teaching a new course in BCI for students from a variety of backgrounds, and by providing fieldwork experiences."
"0953285","CAREER: Using Social Media to Manage Knowledge","IIS","Cyber-Human Systems","01/01/2010","01/08/2014","Gerald Kane","MA","Boston College","Continuing grant","William Bainbridge","12/31/2014","$501,005.00","","gerald.kane@bc.edu","140 Commonwealth Avenue","Chestnut Hill","MA","024673800","6175528000","CSE","7367","1045, 1187, 9215, HPCC","$0.00","This research studies how people use social media tools (e.g. blogs, wikis, electronic social networks) to work together more effectively to advance individual, group, organization, and community objectives. Despite high-profile success stories, we actually know very little about how best to use social media to enable effective collaboration among individuals or within organizations. The mere adoption of these tools by individuals or organizations is unlikely to have the desired effect unless people know how to use these tools to enable more effective collaborative processes. This research will employ qualitative content analysis to provide a rich picture of social media collaboration, conduct quantitative analysis on large-scale datasets to identify macro-level trends, and develop computer simulations to predict how social media might affect organizations in ways not yet observed. The educational activities of this proposal will focus on how to employ social media in the classroom to improve educational processes. I plan to introduce five different social media enabled innovations -crowdsourcing exams, wiki-based peer review, in-class blogosphere, video podcasting lectures, and in-class electronic social networks - and empirically test the effects of these innovations on classroom outcomes.<br/><br/>The broader impact of this research is to better understand how social media tools can be used to improve processes in a wide range of organizations and settings. These tools have been shown to have important economic, political, societal, and educational impacts. Regardless of whether particular social media tools endure in coming years, the technological features and collaborative capabilities they represent will continue to persist and evolve."
"1207592","US-German Collaboration: Unravel CNS regeneration - From Fact Extraction to Experiment Design","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","12/01/2012","09/06/2012","Lawrence Hunter","CO","University of Colorado at Denver","Standard Grant","Kenneth C. Whang","11/30/2017","$487,862.00","","Larry.Hunter@ucdenver.edu","MS F428, AMC Bldg 500","Aurora","CO","800450508","3037240090","CSE","1640, 7364, 7495","7327","$0.00","This research is motivated by the problem of spinal cord injuries, with the goal of producing data that can lead to pharmacological or other interventions to make recovery possible. It is hypothesized that major changes after a spinal cord injury occur on the protein level, and that a model of protein changes and interactions between proteins will make it possible to elucidate previously unnoticed relationships between the participating proteins and protein pathways. To do this, a computational neuroscience approach is a necessary addition to laboratory experiments. This analysis requires a considerable amount of background knowledge; to acquire this knowledge, natural language processing (text mining) is necessary; specifically, new techniques for natural language processing need to be developed in the neuroscience domain.<br/><br/>The research plan involves a series of proteomics experiments to be carried out on rats with induced spinal cord injuries and the interpretation of these results using a computational systems biology approach. The quality of knowledge-based computational analysis depends critically on the breadth of formally represented knowledge in the program. A major challenge is that much of the requisite knowledge is ""buried"" in scientific publications, rather than being available in computable form in databases. Therefore, novel text mining techniques will be developed, tailored for the neuroscience domain, to extract such knowledge from scientific publications and convert it into a computable form. A generic computational analytical tool, known as Hanalyzer, is already available but needs to be adapted to the specific problem; the challenge is to develop the natural language processing technology. A neuroscience-specific aspect of this challenge is that there is a high diversity in the surface forms of words that are used to refer to spinal cord regeneration, making machine-learning-based approaches susceptible to data sparsity and rule-based approaches vulnerable to an intractable number of keywords that must be accounted for. A distributional approach will be used to approach this challenge, with novel techniques that make use of semantic role labeling, recognition of ontological concepts, and dependency parsing to learn the surface forms that correspond to abstract or implicit concepts like spinal cord regeneration.<br/><br/>This project is a collaboration involving investigators in Denver, Colorado and in Duesseldorf, Germany. A companion project is being funded by the German Ministry of Education and Research (BMBF)."
"0915914","III: Small: SPAL3D -- Design and Implementation of a Type System for Three-Dimensional Spatial Data in Databases","IIS","INFO INTEGRATION & INFORMATICS","09/15/2009","08/01/2011","Markus Schneider","FL","University of Florida","Continuing grant","Maria Zemankova","08/31/2014","$354,292.00","","mschneid@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7364","7364, 7923, 9216, HPCC","$0.00","The research objective is the design and implementation of a new formal data model and type system called Spatial Algebra 3D (SPAL3D) for three-dimensional (3D) spatial data in database systems and geographical information systems. While these systems so far focus on two-dimensional spatial entities only, despite many potential geoscience applications, three-dimensional (3D) data modeling and data management have so far been rather neglected. This research and education project explores the fundamental properties and the structure of complex 3D spatial data from a data management and database perspective, identifies their most important operations and predicates, and supports their treatment in data modeling, representation, storing, manipulation, and querying. SPAL3D is extensible, makes it possible to add new types and operations, and can be plugged into different DBMS. The solution approach is based on three three fundamental pillars: (i) an abstract data model<br/>(SPAL3D-A) for the rigorous, mathematical definition of a comprehensive type system (algebra) for 3D spatial data including volumes, surfaces, and 3D lines, (ii) a discrete data model (SPAL3D-D) for the design of effective geometric data structures for the 3D spatial data types of SPAL3D-A and on efficient geometric algorithms on these data structures for the 3D operations and predicates of SPAL3D-A, and (iii) the implementation and database integration (SPAL3D-I) of the data structures and algorithms of SPAL3D-D as abstract data types into several extensible DBMS data models and query languages.<br/><br/>The results of this research are expected to have broad impact on applications in areas where the third dimension of spatial data plays an important role. Examples are geographical information systems, meteorology, hurricane research, environmental monitoring, pollution control, soil science, water supply and distribution, fishery monitoring and simulating, geology, soil engineering and mining, earthquake modeling and simulation, to name only a few. The educational component of this project includes specialized classes that focus on important aspects of this project, the creation and use of new GIS educational materials, and the involvement of students in interdisciplinary research. The project Website<br/>(http://www.cise.ufl.edu/~mschneid/Research/FundedResearchProjects/NSF-IIS-0915914/spal3d)<br/>is used for the dissemination of research results, educational material, publications, generated data sets, produced software, and other information of interest."
"1348109","CAREER: A Multiagent Teacher/Student Framework for Sequential Decision Making Tasks","IIS","ROBUST INTELLIGENCE","01/02/2013","01/14/2014","Matthew Taylor","WA","Washington State University","Standard Grant","James Donlon","08/31/2017","$411,162.00","","taylorm@eecs.wsu.edu","NEILL HALL, ROOM 423","PULLMAN","WA","991643140","5093359661","CSE","7495","1045, 7495, 9251","$0.00","Physical (robotic) agents and virtual (software) agents are becoming increasingly common in industry, education, and domestic environments. Although recent research advances have enabled agents to learn how to complete tasks without human intervention, little is known about how best to have humans teach agents or agents teach other agents or even how agents might teach humans. Considering the full matrix of agent/human learning, in which either an agent or a human can play the role of teacher or student, would increase the potential benefits of leveraging human and agent expertise and knowledge. <br/><br/>This project aims to study agent/human learning in the context of sequential decision-making problems, a class of central importance for real-world agent systems. This project aims to develop a novel teacher/student framework that integrates autonomous learning with teaching by another agent or a human. The project plans to develop and evaluate a set of core algorithms to allow: (1) agents to teach agents, thus enabling robust knowledge sharing among agents; (2) humans to teach agents, thus allowing humans to share or transfer common sense or domain-specific knowledge with agents; and (3) agents to teach humans, thus helping humans better understand how to perform or recast sequential decision-making tasks already understood or performed by autonomous agents. In all cases, the goal is to develop methods that significantly improve learning performance relative to learning without guidance from a teacher. Issues to be explored include mismatch between teacher/student abilities, learning from multiple teachers, and shared knowledge representation between teacher/student. The PI plans to focus on several scenarios, each with different sets of assumptions about the knowledge or skill of the student or teacher and the kind of interaction possible between them (e.g., whether the teacher can tell the student what action to take). The techniques developed in the project will be evaluated in a variety of tests domains and will involve simulations as well as actual robots.<br/><br/>The teacher/student framework will enable agents to teach other agents and humans, as well as integrate autonomous learning with agent and human teaching. Understanding how to best teach agents is of key importance in developing deployable agent systems. The platform- and domain-independent approach incorporates ideas from multiagent systems, machine learning, human-computer interaction, and human-robot interaction communities, and has the potential to impact each of these areas. This work takes a step towards transitioning agents from specialized systems usable only by experts into useful tools and teammates for people without programming expertise. <br/><br/>This project has a strong educational component. The PI teaches at an undergraduate college and undergraduate students will play a crucial role throughout the project. Furthermore, the research produced by this project will be incorporated into five of the PI's courses, providing exciting new material to attract and retain computer science majors. The PI will also continue outreach to secondary school students as well as to underrepresented groups via Lafayette College's S-STEM and Higher Achievement programs."
"1212280","ACL 2012 Student Research Workshop","IIS","ROBUST INTELLIGENCE","02/15/2012","02/08/2012","Yang Liu","TX","University of Texas at Dallas","Standard Grant","Tatiana D. Korelsky","01/31/2015","$19,500.00","","yangl@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7495, 7556","$0.00","The Association for Computational Linguistics (ACL) is the primary international organization in the field of natural language processing and computational linguistics. The ACL's annual conference is the major international conference in this field. This project is to subsidize travel, conference and housing expenses of students selected to participate in the ACL Student Research Workshop, which will take place during the main ACL conference on July 8-14, 2012 in Jeju Island, Korea. The Student Research Workshop accepts papers in two categories: thesis/research proposal and general research papers. The thesis/research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student. The workshop is organized and run by students.<br/><br/>The Student Research Workshop provides a valuable opportunity for the next generation of natural language processing researchers to enter the research community. It allows the students in the field to take an important step towards becoming professional computational linguists by receiving critical feedback on their work from experts outside of their dissertation committee, and by making contacts with other students and senior researchers in their field. The students who are involved in running and reviewing for the student workshop also gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference. The ACL Student Research Workshop contributes to the maintenance and development of a skilled and diverse computational linguistics and natural language processing community."
"1218209","HCC: Small: Collaborative Research: Real-Time Captioning by Groups of Non-Experts for Deaf and Hard of Hearing Students","IIS","Cyber-Human Systems","08/01/2012","07/16/2013","Jeffrey Bigham","NY","University of Rochester","Continuing grant","Ephraim P. Glinert","07/31/2015","$419,243.00","Daniel Gildea","jbigham@cmu.edu","518 HYLAN, RIVER CAMPUSBOX 27014","ROCHESTER","NY","146270140","5852754031","CSE","7367","7367, 7923","$0.00","Many deaf and hard of hearing students use real-time captioning to participate in education. Generally, real-time captions are provided by skilled professional captionists (stenographers) who use specialized keyboards or software to keep up with natural speaking rates of up to 225 words per minute. But professional captionists are expensive and must be arranged in advance in blocks of at least an hour. Automatic speech recognition (ASR) is improving, but still experiences high error rates in real classrooms. In this collaborative effort involving the University of Rochester and Rochester Institute of Technology, the PIs will address these issues by blending human- and machine-powered captioning to produce captions on demand, in real time, for low cost. The PIs' approach is for multiple non-experts and ASR to collectively caption speech in under 5 seconds, with the help of interfaces which encourage quick, incomplete captioning of live audio. Because non-experts cannot keep up with natural speaking rates, new algorithms will merge incomplete captions in real time. (While the sequence alignment problem can be solved exactly with dynamic programming, existing approaches are too slow, are not robust to input error, and do not incorporate natural language semantics.) Systematically varying audio saliency will encourage complete coverage of speech. Non-expert captions will train ASR engines in real time, so that ASR may improve during a lecture. (Traditional approaches for ASR training assume that training occurs offline.) The quikCaption mobile application will embody these ideas and will be iteratively designed with deaf and hard of hearing students at the National Technical Institute of the Deaf (NTID) via design sessions, lab studies and in-class deployments. Non-expert captionists can be drawn from broad sources: volunteers willing to donate their time, classmates with relevant domain knowledge, or always-available paid workers. They may be local (in the classroom) or remote. Captionists may have experience from prior quikCaption sessions, or novice crowd workers recruited on demand from existing marketplaces (e.g., Mechanical Turk). A flexible worker pool will allow real-time captions to be available on demand at low cost and for only as long as needed.<br/><br/>Broader Impacts: This research will dramatically improve education for deaf and hard of hearing students by enabling access to serendipitous opportunities, such as conversations after class or last-minute guest lectures for which no interpreter or captionist was arranged. Real-time captioning will also be useful in other settings such as school programs, artistic performances, and political events. Older hard of hearing adults usually prefer captioning, and represent a sizable and growing population; hearing people may benefit because captioning is a first step in automatic translation of aural speech. The algorithms developed as part of this project for real-time merging of incomplete natural language will likely be adaptable for other applications such as collaborative translation or communication over noisy mediums."
"1257141","EAGER: Large Scale Optical Music Recognition on the International Music Core Library Project","IIS","Cyber-Human Systems","10/01/2012","06/17/2013","Christopher Raphael","IN","Indiana University","Standard Grant","Ephraim P. Glinert","09/30/2014","$98,551.00","David Crandall","craphael@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7367","7367, 7916, 9251","$0.00","Vast quantities of character-encoded text form the foundation for the Information Retrieval revolution of recent decades. In contrast, very little symbolically-represented music exists, preventing music from fully participating in the Information Age. The International Music Score Library Project (IMSLP) is a large and rapidly growing open library of public domain machine-printed classical music scores, actively used by many musicians, music scholars, and researchers around the world. The PI's objective in this exploratory project is to begin creating the algorithms needed for automatic optical music recognition (OMR) to convert scanned musical scores into symbolic representations. This is the first step in the PI's long-term goal of building a system to transform the library's score images into symbolic representations, bringing the IMSLP community together in a Wikipedia-like collaboration to mine this invaluable resource. The result will be a comprehensive and open music library of symbolic scores allowing unprecedented access while forming the basis of many new music applications as well as commercial potential.<br/><br/>While there have been many efforts at OMR over the last fifty years, the current state of the art is far below what the IMSLP challenge requires. Existing systems require such laborious error correction that it is not clear if they actually improve on manual data entry. OMR is much harder than its optical character recognition (OCR) counterpart due to the fundamentally two-dimensional layout of music, which makes it difficult to cast the problem in terms of familiar recognition paradigms. Thus the primary focus of the current work lies in creating and implementing an appropriate recognition paradigm suitable for the two-dimensional structure of music notation, building in knowledge of notation conventions and allowing for automatic adaptation. To this end, the PI will explore strategies that merge recognition with segmentation, express the desire for non-overlapping musical symbols in a principled way, and model the interpretation problem which understands the often ambiguous meaning of the recognized symbols.<br/><br/>Broader Impacts: A large open music library of symbolic scores, as well as offering widespread and easy access to one of our culture's richest traditions, will be transformative for musicians, music researchers, and music lovers. Libraries will be able to distribute music scores electronically and globally, allowing for adaptive display, ongoing scholarly annotation, and registration of scores with video and audio. The prevalence of symbolic music scores will open up a world of possibilities to music-science researchers, including systems for music information retrieval, expressive performance, automatic musical accompaniment, transcription and arranging, performance assistance, and many others. Finally, the library will enable important commercial applications. For example, many expect that devices such as the iPad will form the sheet music ""delivery systems"" of the future; the benefits of basing such digital music readers on symbolically represented music are compelling, including automatic page turning and content-based annotation."
"1211047","SoCS: Towards Micro-Volunteerism: From Citizen Sensor to Citizen Participant","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","09/15/2012","07/12/2013","Eric Paulos","CA","University of California-Berkeley","Continuing grant","William Bainbridge","08/31/2015","$750,000.00","","paulos@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367, 7953","7953","$0.00","This project will design new models of social participation and volunteerism through mobile device platforms, with a focus on citizen science. Micro-volunteerism is a newly emerging design territory for volunteering on the order of seconds or minutes. This research will develop a flexible new framework for citizen science based mobile tools to study this novel and largely unexplored social model of citizen participation and volunteerism. Through a series of research studies and design interventions, it will explore challenges and opportunities for leveraging this crowd sourced just-in-time volunteering social participation framework. <br/><br/>These efforts contribute toward a series of open research themes in the field of citizen science such as: a subscription based model for campaigns, flexible sensor and data collection techniques that adapt to context, diverse sensing strategies, models for participatory sensing and participatory analysis, and citizen data debate mechanisms. Also studied will be the effect of novel contribution models, badges and rewards, narrative and storytelling, and other methods for improving participation, contribution, motivation, and usage. The research is designed to allow citizens to easily develop and deploy citizen science based mobile collaborative campaigns, often leveraging low-cost sensing and ubiquitous technologies to facilitate real, positive environmental change. <br/><br/>The everyday world can become a living laboratory where citizens play a new and active role in facilitating scientific research aimed at exposing the dynamic interactions between people and the natural ecosystems and improving overall human health and well being. This research departs from typical sampling and collection techniques, and hypothesizes that while traditional scientific methods and models play a vital role in understanding the complex dynamics of our world, everyday non-expert citizens with sensor equipped mobile phones have the potential to expand the model of how scientific research is conducted. This approach also stands counter to traditional ""smart computing"" strategies, and instead develops a vocabulary of technologies and experiences to promote human curiosity that serves to scaffold individuals and communities towards a new understanding of our world. Citizen science is also positioned to synergize a new cooperative and collaborative approach to problem solving across a variety of expert practitioners such as computer scientists, engineers, social scientists, atmospheric chemists, environmental health organizations, urban planners, local and national governments. Successful citizen science projects can achieve positive societal change and produce a more participatory and transparent democracy with improved public understanding of our environment and urban ecology."
"1217685","HCC: Small: Values of Information Technology for Progress: Three Case Studies","IIS","Cyber-Human Systems","09/01/2012","08/31/2012","Phoebe Sengers","NY","Cornell University","Standard Grant","William Bainbridge","08/31/2015","$497,401.00","","sengers@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923","$0.00","This project will develop methods for using historical understanding of technology to assess potential consequences of sociotechnical change and to inspire new design practices. Information technology (IT) builds on a longer history of technology tied to significant cultural shifts, commonly conceptualized as technological innovations driving societal progress. This research critically analyzes the idea of sociotechnical progress by asking: How is it conceptualized? What practices, values, and stakeholders become marginalized in the pursuit of progress, what are its consequences, and how can currently marginalized factors inspire new forms of design? It uses these questions to evaluate roles that IT has played in progress, and to envision and design for new roles it could play.<br/><br/>This project answers these questions through three case studies that look at societies on the global margin which have seized on technological progress as a means for bettering their circumstances. The case studies look at (1) a past attempt to rapidly transform from a subsistence, fishing-based to an industrialized economy in rural Newfoundland; (2) the consequences of a similar transformation in present Iceland, where pervasive adoption of information technology has transformed the small-boat fishing industry; and (3) debates over possible futures arising from the sudden and pervasive adoption of mobile phone technology in Jamaica. These novel case studies provide a new lens through which to understand the values embodied in information technology, its cultural impact, and their implications for practices in the field of human-computer interaction.<br/><br/>Methodologically, this work builds on design ethnography to demonstrate how historical methods can enrich the ability of work in human-computer interaction to address the broader cultural impacts of technology. By analyzing how the consequences of modernization compare with hopes invested in technology as a tool for progress, the project will provide evidence to support a more rigorous debate about the impact of information technologies. By using this analysis to generate new design insights, the project supports design practices that may improve the implications of technology, especially as productivity tools and means for advancing economic development."
"1247971","INSPIRE: The Hunting of the Spark: A Systematic Study of Natural Creativity in Human Networks","BCS","SOCIAL PSYCHOLOGY, INFORMATION TECHNOLOGY RESEARC, PERCEPTION, ACTION & COGNITION, Cyber-Human Systems, INSPIRE","09/15/2012","07/17/2012","Ali Minai","OH","University of Cincinnati Main Campus","Standard Grant","Betty H. Tuller","08/31/2015","$999,762.00","","ali.minai@uc.edu","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","SBE","1332, 1640, 7252, 7367, 8078","8653","$0.00","This INSPIRE award is partially funded by the Perception, Action, and Cognition Program and the Social Psychology Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral and Economic Sciences, and the Human-Centered Computing Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering. <br/><br/>The notion of collective wisdom - that many interacting individuals can produce better ideas, insights, solutions and decisions than a single individual can produce - is a foundational principle for many institutions of modern societies, including elections, parliaments, governing boards, free markets and the free press. Until recently, such collective wisdom could only be harnessed through massive unstructured mechanisms such as elections and markets, or through highly structured and interactive but smaller-scale mechanisms such as legislatures, committees, boards and panels. With the advent of the Internet, the World-Wide Web and social network technology, the paradigm has changed. It is now possible for large numbers of diverse, geographically distant individuals to interact in structured ways and at almost no cost. This has opened up vast possibilities for innovation and creativity, but these possibilities are still largely unrealized. A major reason for this is the lack of a systematic scientific understanding of collective innovation in human networks. The current project addresses this through a combination of methods from several disciplines, bringing together a unique group of researchers with expertise in social psychology, cognitive science, computer science, engineering and network theory.<br/><br/>The fundamental principle underlying the research is that an understanding of natural human innovation requires a coordinated combination of laboratory and field studies and that neither is sufficient on its own. Field studies of innovative human networks (communities of research scholars and engineers) will be used to identify natural patterns of innovation through data mining and intelligent analysis methods. Laboratory experiments will then verify and validate these patterns under controlled conditions. Thus, through a combination of large-scale fieldwork and careful experiments, the investigators will develop better metrics for measuring innovation and discover ways to help groups and individuals be more innovative. Most importantly, this project will clarify how the connectivity of individuals in a network acts to boost or suppress innovation, leading to recommendations for making human networks from corporations to social networks more innovative.<br/><br/>Recent studies suggest that the rate of innovation must increase exponentially to sustain a growing and urbanizing global society. While the proposed research will focus on specific areas, the methods it generates will inform organizations and governments broadly in developing policies conducive to innovation. In today's fast-moving, highly competitive world, such policies are likely to be a major determinant of scientific, technological and geopolitical leadership."
"1219261","HCC: Small: Telecollaboration in Physical Spaces","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","Matthew Turk","CA","University of California-Santa Barbara","Standard Grant","Kevin Crowston","08/31/2015","$499,970.00","Tobias Hollerer","mturk@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7367","7367, 7923","$0.00","The goal of this project is to develop and evaluate novel methods for telecollaboration - remote collaboration that effectively integrates video and voice communication, computer vision based tracking, and augmented reality display in order to enable participants to more fully leverage the local physical environment in their remote interactions. In this telecollaboration paradigm, remote and local users will interact with the physical environment using models derived from live imagery from a camera that the local user holds or wears, rather than merely passively viewing the video stream. A key aspect of the approach is that it does not require preparation of the environment or model information, so it can be viewed as an ""anywhere, anytime"" mobile communication technology.<br/><br/>Intellectual merit: The proposed research builds on promising preliminary work on telecollaboration showing the effectiveness of world-stabilized ""telepointers"" - markers controlled by the remote user that stick to the real-world referents in a dynamic environment. The project will advance the state of the art in remote collaboration by providing new capabilities to integrate real and virtual, verbal and spatial, local and remote. The proposed developments are needed in order to make the physical space a more fundamental part of telecollaboration, and significant user studies will be conducted to acquire a better understanding of the opportunities and limitations of physically-grounded remote interaction. <br/><br/>Broader impacts: Better, more compelling tools for telecollaboration can have a tremendous impact in terms of productivity and environmental consequences, as improved remote interaction reduces the need for physical collocation and thus travel. The educational impacts of the project include the training and mentoring of graduate students and a new seminar course. The research team will disseminate research results and collected data widely and use the developed technologies to provide outreach opportunities for select groups to participate in lab open houses."
"1217627","HCC: Small: Understanding, Sensing, and Accommodating Situational Impairments in Mobile Computing","IIS","Cyber-Human Systems","09/01/2012","08/06/2013","Jacob Wobbrock","WA","University of Washington","Continuing grant","Ephraim P. Glinert","08/31/2015","$499,722.00","Shwetak Patel","wobbrock@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7923","$0.00","A ""computer user"" can no longer be thought of only as a person sitting at a desk in a consistent and comfortable working environment. Today's typical computer user is now holding a mobile device smaller than his or her hand, is outdoors, under the sun or in the rain, and perhaps even in motion, such as walking or riding. However, mobile devices have no deep awareness of the environments in which they are being used, or how those environments will affect their users' abilities to act. Addressing this challenge is the central idea of this project. The approach is to better understand, through scientific means, and better accommodate, through clever sensing and design, the ""situational impairments"" that affect the new-typical computer user for our age, the mobile user. Although situational impairments have been noted in the past, few research efforts have looked at how to sense impairing effects and what to do about them. Innovations in sensors, inference, and user interfaces have the potential to improve mobile interaction in the presence of situational impairments, showing that accessibility is ""for everyone.""<br/><br/>The intellectual merits of this work include: (a) scientific studies of some situationally-impairing factors on human performance; (b) the invention and evaluation of ten projects designed to address and reduce the negative effects of certain situational impairments; (c) the development of clever reusable sensing techniques to enable the creation of those projects and advance the capabilities of mobile devices; and (d) the study of the ""crossover potential"" of projects to people with physical or health-induced impairments and disabilities.<br/><br/>The broader impacts of this work include: (a) pushing the capabilities of mobile devices and sensing technologies to become more useful and usable, especially in varied contexts, which may have relevance to mobile field workers; (b) concretely demonstrating that accessibility research benefits everyone, and that all people incur impairments of one form or another in their lives; (c) contributing to public health and safety by reducing the dangers situational impairments cause, particularly to and from people driving automobiles, and (d) creating a graduate course, an undergraduate workshop, and a grades 6-12 science unit on ability-based design for mobile computing."
"1248077","INSPIRE: Computer Learning of Dynamical Systems to Investigate Cognitive and Motivational Effects of Social Media Use on Political Participation","SES","SOCIAL PSYCHOLOGY, POLITICAL SCIENCE, INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS, INSPIRE","09/15/2012","09/25/2012","John Jost","NY","New York University","Standard Grant","Brian D. Humes","08/31/2015","$999,997.00","Richard Bonneau, Jonathan Nagler, Joshua Tucker","john.jost@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","SBE","1332, 1371, 1640, 7367, 7953, 8078","0000, 8653, OTHR","$0.00","This INSPIRE award is partially funded by Human-Centered Computing Program and by Social-Computational Systems Program both in the Division of Information and Intelligent Systems in the Directorate for Computer & Information Science & Engineering, and by the Social Psychology Program in the Division of Behavioral and Cognitive Sciences and the Political Science Program in the Division of Social and Economic Sciences in the Directorate for Social, Behavioral and Economic Sciences.<br/><br/>With regards to intellectual merit, the goal of this project is to forge an interdisciplinary collaboration that examines the impact of social media on political behavior. First, from social psychology and political science, fundamental hypotheses will be developed about how, why and when social media affects citizens' cognition and motivation with respect to political participation. Second, these questions will be expressed as testable hypotheses derived from behavioral models. And third, drawing from biology and computer science, the project adapts sophisticated computational methods of approximate inference and machine learning (adapting methods developed for the analysis of Systems Biology data) to evaluate the behavioral models using extremely large social media and social network datasets. <br/><br/>The scientific opportunities afforded by the use of social media are readily apparent when we consider the richness and precision of data on participation in elections, protests, riots, and other spontaneous political events. This project will construct a comprehensive data set of incoming and outgoing social media messages messages using systematically structure formats that are ideally suited to machine learning methods, and this information will be integrated with information on social network connectivity and a vast array of metadata on individuals and their social contacts. By developing new methods to harvest and combine these data sources effectively, it will be possible to transform the scientific study of social and political attitudes and behavior. Every time individuals use social media, they leave behind a digital footprint of what was communicated, when it was communicated, and, to whom it was communicated. Typically, such precise estimates of these variables are available only to laboratory investigators working in artificial settings. No previous study has successfully used fine-grained social influence data such as these to predict consequential behavioral outcomes, such as attendance at a given protest or rally. The structure of the data means that we will have panel data on respondents, many of potentially long duration. In addition, the investigators will conduct a panel survey, which is essential for drawing causal inferences about the cognitive and motivational processes whereby social media use facilitates political participation.<br/><br/>With regards to broader impacts, this research will enhance interdisciplinary training for graduate and undergraduate students. These include students in psychology, political science, computer science, and biology and also includes students from groups that are underrepresented in these sciences. In addition, opportunities will be provided for high school students to become involved in the research process. The research program will foster broad dissemination of scientific understanding by leveraging past experience of the principal investigators with disseminating large code-bases, data-bases, and data-sets to share work with other scientists (pre-publication). Finally, the researchers are committed to making their research available to the general public and have extensive experience doing so."
"1211266","SoCS: Collaborative Research: Data-Driven, Computational Models for Discovery and Analysis of Framing","IIS","Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS","10/01/2012","08/06/2013","Amber Boydstun","CA","University of California-Davis","Standard Grant","William Bainbridge","09/30/2015","$199,782.00","","aboydstun@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7367, 7953","7367, 7953, 9251","$0.00","This project studies framing, a central concept in political communication that refers to portraying an issue from one perspective with corresponding de-emphasis of competing perspectives. Framing is known to significantly influence public attitudes toward policy issues and policy outcomes. As social media allow greater citizen engagement in political discourse, scientific study of the political world requires reliable analysis of how issues are framed, not only by traditional media and elites but by citizens participating in public discourse. Yet conventional content analysis for frame discovery and classification is complex and labor-intensive. Additionally, existing methods are ill-equipped to capture those many instances when one frame evolves into another frame over time. <br/><br/>This project therefore develops new computational modeling methods, grounded in data-driven computational linguistics, aimed at improving the scientific understanding of how issues are framed by political elites, the media, and the public. This collaboration between political scientists and computer scientists has four goals: (a) developing novel methods for semi-automated frame discovery, whereby computational models guided by political scientists? expert knowledge speed up and augment their analytical process; (b) developing novel algorithms based on natural language processing for automatic frame analysis, producing measurably accurate results comparable with reliable human coders; (c) establishing the validity of these processes on well-understood cases; and (d) applying these methods to several current policy issues, using data across years and across traditional and social media streams. The resulting evolutionary framing data will help unpack the mechanisms of framing and help predict trends in public opinion and policy."
"1218283","HCC: Small: Determining the Effects of Latency in Virtual Reality Physical Rehabilitation","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","John Quarles","TX","University of Texas at San Antonio","Standard Grant","Ephraim P. Glinert","08/31/2015","$472,840.00","","jpq@cs.utsa.edu","One UTSA Circle","San Antonio","TX","782499113","2104584340","CSE","7367","7367, 7923","$0.00","Although the effect of latency (i.e., how quickly a system can respond to user input) on users has been one of the fundamental research areas in virtual reality (VR) for many years, latency's effect on persons with physical disabilities is still unknown. The PI's objective in this project is to acquire a better understanding of how latency of visual feedback in VR can impact interaction performance, perception, and subjective experience for users with reaction time and reflex deficits (e.g., due to neurological, vestibular, balance issues), and to investigate how this ultimately impacts the effectiveness of VR-based rehabilitation. The PI's central hypothesis, based on preliminary data, is that latency will be less perceivable but will have a more significant impact on interaction performance for persons with disabilities as compared to healthy persons. To test this hypothesis, the PI will focus on the main set of applications typically used in VR rehabilitation: games, exercise, and accessibility. He will explore, for members of the target community, latency's impact in VR rehabilitation games, on the effectiveness of visual feedback during rehabilitation exercises in virtual environments (VE), and on accessibility in a VE. Through a series of empirical studies, the PI will determine latency thresholds in VR with respect to interaction performance, physiological response, perception, and subjective impressions. <br/><br/>Broader Impacts: Project outcomes will afford a deeper understanding of the effectiveness of VR as a medium for rehabilitation. If the PI's hypothesis is confirmed, the potentially negative implications for the efficacy of VR-based rehabilitation may disrupt accepted theories and revolutionize design guidelines for this type of rehabilitation. Alternatively, this research may inspire other researchers to develop approaches to combat latency in VR specifically for disabled persons, which will also produce further vertical advancement in the field. More generally, this research will provide a critical step towards the grand challenge of universal usability in VR."
"1243170","INSPIRE: Tools, Models, and Innovation Platforms for Research on Social Media","IIS","POLITICAL SCIENCE, INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, SOCIAL-COMPUTATIONAL SYSTEMS, INSPIRE","10/01/2012","09/04/2012","Robert Mason","WA","University of Washington","Standard Grant","William Bainbridge","09/30/2015","$997,118.00","","rmmason@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","1371, 1640, 7367, 7953, 8078","8653","$0.00","This INSPIRE award is partially funded by the Human-Centered Computing Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering, the Political Science Program in the Division of Social and Economic Sciences in the Directorate for Social, Behavioral and Economic Sciences, and the multi-directorate Social-Computational Systems Program.<br/><br/>This project seeks 1) to develop an open-source toolkit of affordable methods and approaches that enables researchers in the information and social sciences to describe, analyze, and visualize how information flows within and between social media platforms and across geographic locations; and 2) to apply these methods and tools to create and analyze a dataset of tweets, posts, related messages and sites. The initial focus is on Twitter data associated with the social movement that began as ""Occupy Wall Street"" but broadens to include other venues and even other topics. This research will both develop tools for social media research and demonstrate how these tools improve our capabilities for research in this social media space. <br/><br/>Social media platforms are transforming how we work, live together, and govern ourselves. The many modalities offered by social media platforms such as Twitter, YouTube, and Facebook create a complex infrastructure, resulting in a dynamic ecosystem of information flows within and across platforms and among individuals and groups. The resulting socio-technical system enables both rapid and emergent organizational and relational transformations, but its scope and dynamic structure present conceptual and practical challenges for researchers studying the mechanisms of the transformations. The combination of volume, scope, complexity, and ephemeral nature of message flows require an interdisciplinary approach to developing research methods and tools for curating, processing, storing, and analyzing that go beyond the typical relational database management approaches.<br/><br/>The intellectual merit of the research is two-fold. First, the research will combine knowledge of social science, political science, communications, geography, information science, and emerging computing techniques to create a scalable and affordable approach to the selective collection and analysis of data from the huge flows of tweets, ""likes,"" and links associated with the Occupy movement. The approach will be documented and made available as an open source toolkit for other social media researchers, thus enabling a wider scope of inquiry. Second, the research will contribute to knowledge about grass-roots movements, using the Occupy movement as a currently active example that can serve as a test case, by examining the relationships of tweets, geography, and the possible linkages to other groups. The emerging information ecosystem of networks and linkages enabled by social media supplement traditional media such as newspapers and television, and messages may ""go viral,"" crossing community and geographic boundaries with unprecedented speed and quickly reaching remote and previously unconnected audiences. This work will provide new insights into the mechanisms by which these viral events occur and will help us understand the impact viral events can have on public participation in political discourse. <br/><br/>The broader impact of the research is both immediate and cumulative. The toolkit for data curation, analysis, and visualization has the potential for transforming the research questions social and information scientists can investigate using large datasets resulting from social media. These tools can enable us to envision different frameworks within which to understand how new social media communities form and engage in the broader public discourse. In this way, the research can transform how we think about and study the role of grass roots endeavors in community formation and change. The techniques developed through this research will lower the technical barriers and costs encountered by other researchers and observers who conduct their own research on such datasets. The research engages a new generation of researchers at both the doctoral and undergraduate levels. Graduate students working on the project will be developing the approach and methods and will be gaining experience in managing undergraduate students who work on the team. The experience of working on a truly transformative effort can inspire them and give them confidence to try risky and emergent efforts in the future, and they can be leaders in what may become an interdisciplinary area of study of large social media datasets."
"0845351","CAREER: Leveraging Online Behavior to Support Knowledge and Memory","IIS","Cyber-Human Systems","02/01/2009","09/10/2012","Daniel Cosley","NY","Cornell University","Continuing grant","William Bainbridge","01/31/2015","$563,880.00","","drc44@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","1045, 1187, 7367, 9215, 9251, HPCC","$0.00","This research will examine two related issues: (1) how to motivate people to contribute more to communities such as open source software and Wikipedia that produce public goods, and (2) how to strengthen people's self-concepts and relationships with others by using content they create online to support reminiscence. This work deeply intertwines computing and social science, using insight about people's motivation, goals, and behavior to drive models, algorithms, and interfaces that leverage people's online activity to create value for individuals and society. The online nature of this activity allows it to be aggregated into large data sets for modeling (e.g., social network analysis) and mining (e.g., collaborative filtering); a major theme of the research is to effectively wring more value out of the activities people already do.<br/><br/>Understanding why people act online will lead to process models that explain important features of the data people generate through their actions as well as new algorithms for exploiting that data. For example, the research will model how critical events and roles people adopt affect people's contributions over time in Wikipedia. Such models models will drive algorithms that expose people to other people, groups, tools, policies, and group norms in contexts the models suggest will increase people's motivation to contribute.<br/><br/>Understanding users' goals will also lead to new applications for data and more effective interfaces for presenting it. The research will study how and why people reminisce through a series of lightweight prototypes that cue memories, as well as through analysis of online behavior in social media. This work will lead to algorithms that capture memory-laden content from activity in social media and interfaces that effectively use that content to support reminiscence. Preliminary work suggests that spontaneous, mobile delivery of appropriately chosen reminders promises to increase the value people derive from the content they create.<br/><br/>More broadly, the process of designing these models, algorithms, and interfaces will lead to insights about using social science theory in design that can be captured and shared with practitioners, new methodologies for analyzing complex social data, and the production of useful behavioral datasets that will benefit other researchers. Increasing participation in public goods like Wikipedia will improve the individual experience of members and the social goods they create. Tools developed in the domain of reminiscing have the potential to improve many people's lives, especially as the population ages. The education plan provides for richer research experiences through conference attendance and summer exchange programs with other labs. It also helps students develop the interdisciplinary attitudes and skills needed for this work through courses that look at real systems and the data they provide from both technological and social perspectives."
"1247365","Workshop on Cognitive Science: the Computational Paradigm","BCS","PERCEPTION, ACTION & COGNITION, Cyber-Human Systems, ROBUST INTELLIGENCE","10/01/2012","09/17/2012","Peter Erdi","MI","Kalamazoo College","Standard Grant","Anne Cleary","09/30/2014","$20,000.00","","perdi@kzoo.edu","1200 Academy Street","Kalamazoo","MI","490063291","2693377162","SBE","7252, 7367, 7495","7252, 7367, 7495, 7556","$0.00","This award will provide support for a satellite workshop to the International Joint Conference on Neural Networks (IJCNN), to be held in Dallas, TX on August 4-9, 2013. The goal of the workshop is to explore subfields in cognitive science that hold the most promise for increasing our understanding of neural networks and computational intelligence.<br/><br/>The IJCNN explores the theoretical and computational understanding of the brain in order to develop new and more effective forms of machine intelligence. Cognitive science is the interdisciplinary, scientific study of the mind and mental processes. The workshop is intended to foster more effective integration between the two communities. The workshop will provide a venue in which neural network researchers and students can learn more about the state of the art in cognitive science and its interface with computational intelligence. The broader impacts of the workshop include fostering new collaborations between neural network researchers and those working in other areas of cognitive science. In addition, it provides for reduced registration for women and other scientists underrepresented in the field."
"1247861","EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","IIS","Cyber-Human Systems","09/01/2012","08/25/2012","Marshall Poole","IL","University of Illinois at Urbana-Champaign","Standard Grant","William Bainbridge","08/31/2014","$52,304.00","","mspoole@uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7367","7916","$0.00","This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess. <br/><br/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams. <br/><br/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs."
"1212673","VOSS: Collaborative Proposal: CyberGRID Networks - Cyber-enabled Global Research Infrastructure for Design Networks","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","11/01/2011","01/10/2012","John Taylor","VA","Virginia Polytechnic Institute and State University","Standard Grant","William Bainbridge","09/30/2014","$105,369.00","","jet@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","1640, 7367","7642, 9215, 9251, HPCC","$0.00","This research entails: (1) CyberGRID Net - developing a research data collection and analysis tool integrated into an existing global virtual engineering team working environment, and (2) CyberGRID Networks - utilizing that tool to develop fundamental insights into how globally distributed engineering teams enact complex design work together and with affordances in the virtual environment. The CyberGRID Net will be a research tool that augments an existing virtual environment developed by the investigators for global design work. It will extend current pedagogical tool functionality with the following research-oriented features: (1) the existing TeamWall model-sharing display will detect and track locations of object referencing actions (e.g., pointing to a feature in a design) and functionality will be added for participants to self-indicate when phenomena of research interest occur, (2) virtual environment recordings will be time-stamped when researcher-specified interactions take place, (3) avatar-avatar and avatar-object interactions will be detected along with metadata about the interaction, and (4) functionality will be added for collaborative discussion, data analysis and annotation across a global virtual research team.<br/><br/>In a series of experiments, the CyberGRID Net research infrastructure will be used to engage critical organizational research questions: How are Building Information Models (BIM) in the virtual environment used as a boundary objects to resolve conflicts in the knowledge system of global virtual engineering teams? How do conflicts emerge in avatar-avatar interactions? How are conflicting obligations resolved in virtual teams by emergent virtual team leaders? How are boundary objects used in a cross-cultural context? How do leadership styles and community of practice formation vary when team members come from different countries representing different cultures and standards of practice? These questions will be explored in three separate experiments employing a multi-method approach which includes ethnographic observation, social and interaction network analyses, and user reflection. They will involve international activities and will include graduate engineering students in the U.S., India and Finland, as well as industrial participants utilizing the CyberGRID in an industrial test case.<br/><br/>This research will utilize computational thinking to develop a new research tool to transform the way global virtual teams are researched, and to link avatar-object interactions into network analyses to transform approaches to modeling knowledge systems in global virtual teams. The CyberGRID Net tool will be used in experiments to expand knowledge system dynamics theory as well as theories of virtual team network formation and leadership. This research may lead to fundamental transformations in design pedagogy which, in turn, can provide new exciting engineering career paths. The research may also improve strategies of engineering firms and policymakers concerned about the leadership role of U.S. engineers in the global workforce."
"1249137","EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","IIS","Cyber-Human Systems","09/01/2012","06/06/2013","Noshir Contractor","IL","Northwestern University","Standard Grant","William Bainbridge","08/31/2014","$136,337.00","","nosh@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7916, 9251","$0.00","This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess.<br/><br/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams.<br/><br/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs."
"1217345","HCC: Small: Collaborative Research: Cognitive Approaches to Distributed Software Requirements Engineering","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","Kalle Lyytinen","OH","Case Western Reserve University","Standard Grant","William Bainbridge","08/31/2015","$173,298.00","","kalle@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7367","7367, 7923","$0.00","This research seeks to uncover explanations and principles about how requirements for information systems evolve and how they are managed across project contexts. It will enumerate project design workflows and practices to determine how different forms of artifact and process distribution affect requirements engineering goals and project success. Currently there are no rigorous, theory-based approaches to understanding and explaining large-scale distribution of requirements, though there is evidence of its success. Requirements engineering approaches address spatial and social distribution, and to a lesser extent, structural and temporal distribution. Most importantly, the combination of these issues, in total, has not been considered. Consequently, we cannot say which configuration of practices is best suited to achieve specified development goals, such as reduced time to market, or increased software quality and customer satisfaction. New theoretical models and empirical research are needed to understand the effects of distribution on evolving requirements. <br/><br/>The project will (1) conduct field studies and ethnography, (2) analyze work procedures via grounded theory and comparative methods, (3) construct tools for data analysis, model building, and model analysis, and (4) analyze models via simulations and goal analyses. It will apply a distributed requirements framework consisting of four forms of distribution (social, spatial, structural, and temporal) and four requirements tasks (discovery, specification, negotiation, monitoring) in conjunction with the theory of distributed cognition to analyze requirements knowledge evolution in software projects. Additionally, it will design new tools that help acquire, model, and analyze distributed requirements workflows. <br/><br/>The research aims to develop critical insights on emerging realities in large-scale design projects, which represent one of the drivers for economic growth and new forms of industrial organization. Yet, many software organizations are constrained by methodological and tool factors that do not recognize the increased challenges for requirements engineering. This research highlights the ways in which designers learn to manage the diversity of inputs and constraints, and seeks to understand processes that enhance software-based open innovation in the future."
"0846063","CAREER: Mobile and Ubiquitous Computing Technologies for Young Children with Chronic Health Conditions","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","02/15/2009","11/22/2013","Gillian Hayes","CA","University of California-Irvine","Continuing grant","William Bainbridge","01/31/2015","$560,898.00","","gillianrh@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","1640, 7367","1045, 1187, 1640, 7367, 9102, 9215, 9251, CL10, HPCC, 7218","$0.00","An emergent area of impact and significance is the application of mobile and ubiquitous computing technologies to chronic healthcare. The long-lasting nature of chronic medical conditions makes record-keeping and long-term analysis of diagnostic and evaluative measures extremely important and challenging. Capture and access technologies, i.e., ubiquitous computing technologies that enable recording and access to recorded data, are particularly promising for monitoring the effectiveness of interventions for chronic conditions. Health and behavioral data can be captured, analyzed, and mined over time, providing valuable evidence for tracking the progress of interventions. This research will examine the role that novel mobile and ubiquitous computing technologies can play in record-keeping for chronic care of young children. <br/><br/>Specifically, this research addresses three major challenges. First, technological interventions must be developed that support better record keeping and associated visualization and hypothesis testing to allow caregivers to understand the impacts of their pharmaceutical and behavioral interventions. Second, these interventions must be understood in the short-term to support testing of clinical efficacy and also over the lifetime of these patients whose chronic conditions can span several decades. Third, the focus of these technologies must be not only on capturing and allowing access to appropriate data but also in accomplishing these goals while easing the extensive burden on families."
"1218664","HCC: Small: Collaborative Research: RUI: Mobile Gesture Interaction for Kids: Sensing, Recognition, and Error Recovery","IIS","Cyber-Human Systems","09/01/2012","08/30/2012","Quincy Brown","MD","Bowie State University","Standard Grant","Ephraim P. Glinert","08/31/2015","$263,788.00","Lisa Anthony","qbrown@bowiestate.edu","14000 Jericho Park Road","Bowie","MD","207159465","3018604399","CSE","7367","7367, 7923, 9229","$0.00","Though many children use mobile applications to support their learning and entertainment, the devices and underlying interactions were not designed specifically for children. The goal of this project is to make touch and gesture interactions more accessible and user-friendly to young users. This research will yield new understanding about the appropriate and successful ways to sense, recognize, and recover from errors in touch-based interactions with children. The approach involves studying children interacting with mobile applications that gather data on their touch and gesture interactions, as well as conducting design sessions with children to elicit their preferences for mobile device interactions and error feedback and recovery strategies. This approach will result in design guidelines for those creating applications and tools for young users. The proposed research contributes towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. <br/><br/>Broader impacts: The broader impacts of this project lie in contributions towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. This work also will develop and validate an approach for investigating such interaction issues and designing improvements for them that can be used in future work with other populations such as older individuals or those with varying physical abilities. The grant will support two female young investigators, and will fund research experiences to benefit computer science students attending Bowie State University, a minority serving institution."
"1213127","HCC: Large: Collaborative Research: DNA Machine Builder: Creative molecular-machine design through mass-scale crowdsourcing","IIS","Cyber-Human Systems","09/01/2012","08/28/2012","Erik Winfree","CA","California Institute of Technology","Standard Grant","William Bainbridge","08/31/2015","$457,717.00","Lulu Qian","winfree@caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","CSE","7367","7367, 7925","$0.00","This project will develop and evaluate methods by which large numbers of humans, together with computers, can advance the field of synthetic biology by assembling a corpus of creative designs of molecular machines built from DNA segments as well as other molecular structures. Specifically, it will develop a massively-distributed DNA machine construction game that will enable human worldwide collective creativity to be applied to problems ranging from the design of novel self-organizing materials to smart therapeutics that can sense and respond to their environment. The innovative approach is to cast problems of constructing molecular nano-machines with specific functions as a collaborative machine design game governed by the rules of DNA strand interactions. <br/><br/>This approach points to a new paradigm for future science, in which a large group of people together with computers work on difficult creative problems, finding solutions that could not be found by computers alone, or by people alone, or without the massive participation of users. If successful, this approach could change science profoundly, with wide-ranging impact on many disciplines including nanotechnology, biochemistry, medicine, and even social and economic behavior analysis. Although the project specifically focuses on games that use DNA strands as principal building blocks of nano-machines, the potential set of applications is large, and encompasses three of the most significant problems facing humanity today. <br/><br/>The primary goal of the computer game is to develop and focus collective creativity towards a design space of machines governed by DNA molecular mechanisms. It is currently not known whether this form of sophisticated scientific design creativity can be developed rapidly with non-experts. It is also unknown whether this developed creativity can exceed the current capabilities of the scientific community. This project aims to answer a number of fundamental questions: How does one develop computer games to maximize targeted human design creativity? What are the guiding principles of successful molecular design games? How do we generalize game-development principles to the widest possible range of synthetic biology problems? How can we develop a collective creative design process that outperforms any individual creativity? How do we learn from the way people play the game, and distill their strategies towards stronger automated approaches? <br/><br/>The successful outcomes of this project can have a wide ranging impact on health and medicine. One such problem is the design of diagnostic devices and imaging technologies. The game players will work to develop DNA sensors and circuits that can autonomously analyze and interpret the information encoded in a set of molecular disease markers. This approach will enable new devices for multi-analyte testing in low resource settings and will lead to novel medical imaging technologies. Another challenge is design of novel targeted therapeutics, in this case novel RNA-based therapeutics that can autonomously sense and analyze their environment and activate a therapeutic response only where required. A third problem is design of novel materials. This project will develop DNA nanostructures with the potential for the massively parallel self-assembly materials with desired electronic, optical, or chemical properties. These materials will find applications in areas from artificial photosynthesis to biofuels production. <br/><br/>This effort will have positive broader impacts for informal science education. The game will reach out to people of all demographic profiles in hope of educating everyone about key molecular research challenges, empowering them to solve important scientific problems, and engaging them in research and science in general. Hopefully, the best scores in these games turn into seminal discoveries with deep impact on people's lives. Also, undergraduates will be involved directly in game development, and a course centered around prototyping of molecular games will be offered. Furthermore, the research team will work with education scientists to develop a new curriculum about DNA and how nature uses molecular mechanisms to achieve function. The curriculum will be anchored around the DNA Machine game and will be piloted in US high schools."
"1219197","HCC: Small: Patient-Provider Handoff: Collaboration Challenges and Technology Design","IIS","Cyber-Human Systems","09/01/2012","08/29/2012","Yunan Chen","CA","University of California-Irvine","Standard Grant","William Bainbridge","08/31/2015","$499,786.00","","yunanc@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7923","$0.00","This work aims to obtain an empirical understanding of the collaborative behaviors in patient-provider handoffs and to explore opportunities for designing technologies that support and enhance these practices. Handoffs, also called handovers, occur when workers exchange information necessary for their tasks, and when responsibility for an operation shifts from one person to another. Handoffs are often considered as the most error-prone activities in collaborative work, especially for time-critical tasks under continuous operation, such as in software design, 24/7 services areas, and healthcare practices. In healthcare, this project's area of study, repeated handoffs occur between patients and their health providers, with information being transferred from patients or caregivers to healthcare professionals, and conversely from professionals back to patients. The challenges involved in patient-provider collaboration make it a uniquely situated area to study.<br/><br/>This research uses ethnographic methods to investigate patient-provider handoffs in three different patient care settings: an emergency department, an inpatient ward, and an outpatient clinic. It aims to study the entire spectrum of activities related to handoffs, including pre-visit, medical visit, and post-visit information work performed by patients and clinicians. In addition, based on the empirical insights obtained through the ethnographic study, an information media prototype will be used to solicit feedback and further insights on designing information systems to mediate patient-provider collaboration.<br/><br/>The research will provide both empirical and conceptual insights into understanding the mechanisms, challenges and behavioral patterns of team collaboration involving consumers and professionals. The findings will benefit the design and the adoption of information systems for health practices, and will reduce information and communication errors in the handoff process. In the long run, this study will also positively impact larger populations of patients through the wide dissemination of the findings and through improving the design of the future information media for patient-provider handoffs."
"1111237","HCC: Large: Collaborative Research: Information Technology, Remote Socialization, and the Development of Occupational Identity","IIS","Cyber-Human Systems","08/01/2011","08/10/2011","Diane Bailey","TX","University of Texas at Austin","Standard Grant","William Bainbridge","07/31/2015","$453,374.00","","diane.bailey@ischool.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7367","7367, 7925","$0.00","This project will explore how remote socialization enabled by information and communication technologies (ICTs) is transforming four occupations: graphic design, automotive engineering, banking, and Internet entrepreneurship. Following a comparative, field-based research design, this research will examine the effects of both organizational environments and socialization tactics on ICT use and consider issues of technology use, socialization, and the changing nature of work. In today's workplaces, it is increasingly common to encounter arrangements in which occupational members are geographically distributed from one another. This new reality calls into question existing theories of socialization and learning practices that highlight the importance of collocated interaction and in situ knowledge transfer. By focusing on how individuals use ICTs to learn what it means to be an occupational member, this research will contribute to a new breed of theory on socialization that indicates the processes, practices, and strategies individuals can use to become effective members of an occupation even though they work remotely from others. By drawing on recent theorizing, which suggests that ICTs may provide particular affordances for interaction that non-mediated (e.g. face-to-face) contexts do not, it will explore the possibility that remote socialization may, in fact, help occupations to transform themselves. One aim is to build theory about the mechanisms by which technology leads to occupational transformation. <br/><br/>Occupational skill is critical to economic success, social progress, and individual well-being. However, many occupations seem to be failing to adapt quickly to changes in science, technology, and policy. The failure of occupations to change and refashion themselves to meet new social and technological pressures portends job loss from reduced skill for American citizens, and potentially increased outsourcing to other countries. This study will provide insight into how technology-enabled remote socialization may be able to contribute to faster occupational transformation. Although, for many years, ICT-mediated communication has been seen to be impoverished when compared to face-to-face communication, but now that it has developed considerably, ICT-mediated communication may provide more opportunities for workers to break free from the inertia of established occupations and develop new work practices and strategies that move the occupation forward. Additionally, it is imperative that new occupational members learn how to effectively acquire the knowledge and skills they need to perform their jobs well when they work remotely from others. This study will provide insight into effective practices of remote socialization and occupational learning such that individuals who are attempting to learn new work practices and knowledge will be successful in their efforts."
"0808678","HCC-Large: Using the Internet without using the Eyes: Models of Online Transactions for Non-Visual Interaction","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","09/01/2008","07/15/2011","I. Ramakrishnan","NY","SUNY at Stony Brook","Standard Grant","Ephraim P. Glinert","08/31/2014","$1,623,540.00","Yevgen Borodin, Amanda Stent, Susan Brennan","ram@cs.sunysb.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","1640, 7367","1640, 7367, 7925, 9215, 9251, HPCC","$0.00","The Internet has become the primary medium for accessing information and for conducting many types of online transactions, including shopping, paying bills, making travel plans, applying for college or employment, and participating in civic activities. The primary mode of interaction over the Internet is via graphical browsers designed for visual navigation. This seriously limits the access of people with impaired vision or blindness, a population that is large and growing ever larger. Existing assistive technology for non-visual Internet access typically forces users with visual impairments into an inefficient, sequential mode of information access. To do better, two kinds of models are needed. First, we need to build computational models to represent the structure of web pages and online transactions, and to present them effectively using non-visual modalities. Second, we need to better understand how users' mental models for online transactions are built and utilized; we then need to align the computational models with the users' mental models, so as to combine their strengths and significantly improve the efficiency of non-visual interactions. In previous work, the PI developed the HearSay non-visual web browser, which permits users to perform basic non-visual web browsing and search, contextual browsing, and online form-filling. However, HearSay does not take full advantage of the interaction context or the unique perceptual and processing strengths of people with visual impairments. In the current project, the PI seeks to combine basic computational and psychological research designed to produce accessibility technology embodying the synergy of computational modeling and users' mental models. In terms of computational research, the PI will: (i) automatically track the interaction context of user browsing actions; (ii) automatically build models for transactions that users perform online; and (iii) develop ways in which users can interact with transaction models through non-visual modalities efficiently and effectively. In terms of psychological research, user studies will be conducted to examine (i) how people build mental models for online transactions, and (ii) how they use modality-specific cues and their own short-term memory to utilize these mental models. The PI will incorporate the findings from these user studies into the computational models for online transaction processing, so as to align them with the users' mental models.<br/><br/>Broader Impacts: The ultimate goal of the PI's research is to empower people with visual impairments to lead completely independent lives with the help of the Internet. To this end, the PI has planned an extensive dissemination campaign involving workshops, collaborations with institutions that serve people who have visual impairments, and online dissemination of HearSay prototypes and HearSay component technologies. HearSay will also provide a means, in principle, for anyone who wishes to have non-visual Internet access (e.g., listening to Internet content while driving)."
"1150157","CAREER: Haptic Interaction for Robotic Caregivers","IIS","Cyber-Human Systems","03/01/2012","01/17/2012","Charles Kemp","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","02/28/2017","$499,996.00","","charlie.kemp@bme.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","1045, 7367","$0.00","Making contact with a person's body is critical to many of the most important caregiving tasks for people with physical disabilities. During these tasks, the forces applied by the robot to the body of the human client (care recipient) are of central importance. Yet robots are currently ignorant of what forces are appropriate for common tasks, and what forces are appropriate when making contact with different locations on the client's body. In this project, the PI's goal is to endow assistive robots with the ability to use appropriate forces when haptically interacting with people. To this end, he will capture and statistically model the forces applied when a person performs assistive tasks for him or herself, or provides care to another person. He will enable robots to intelligently regulate the forces they apply when performing assistive tasks, so that the applied forces are comparable to those used during human-human interactions. And he will enable clients to effectively control the forces applied by a robot during assistive tasks. Throughout the research, the PI will conduct experiments to test relevant hypotheses: That the type of task and the pose of the tool relative to the client's body are highly predictive of the force applied by a human caregiver; That when performing tasks on a mannequin, the robot will successfully emulate the forces observed during human-human interaction; That when the robot applies force to the client's body, the client will prefer that the robot use knowledge of the task and the pose of the tool to interpret user commands rather than a constant mapping. Because a person's ability to perform activities of daily living (ADLs) is highly predictive of his or her ability to live independently, the work will focus on four representative ADL tasks that require contact with the client's head: feeding a person yogurt, wiping a person's face, brushing a person's hair, and shaving a person with an electric razor. Project outcomes will include a system that enables a PR2 robot from Willow Garage to assist people with severe physical disabilities with these four tasks; the PR2 will be modified to have force-torque sensors at its wrists, specialized tools, and a Kinect 3D sensor on its head.<br/><br/>Broader Impacts: This research will begin to endow robots with a crucial form of ""common sense"" while quantitatively analyzing and synthesizing haptic interaction in the context of humans' most basic needs. It will also lead to a better understanding of human-robot interaction when the robot initiates contact with the user, and will contribute to data-driven methods for intelligent control. The PI will publish extensively and will release open source code, so that the work can catalyze progress towards robots that could empower millions of people to live more independently with a higher quality of life. The PI will directly involve people with disabilities in the research, and will actively engage the broader community by participating in events such as the RESNA conferences and the Atlanta Abilities Expo. In addition, he will incorporate research results in his biomechanics class and graduate course on haptics, and will then adapt the material to teach people around the world about these topics and robotics using the methods and tools of Khan Academy (http://www.khanacademy.org/)."
"1149601","CAREER: Improving the Development Process for Context-Aware Systems with Integrated Capture and Playback","IIS","Cyber-Human Systems","07/01/2012","01/13/2012","Mark Newman","MI","University of Michigan Ann Arbor","Standard Grant","Kevin Crowston","06/30/2017","$454,838.00","","mwnewman@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7367","1045, 7367","$0.00","Cheap sensors, high-speed wireless networks, and mobile device technologies are opening up new possibilities for human-computer interaction and are enabling important applications in areas such as health care, collaborative work, and sustainable resource use. Yet we still lack appropriate tools and methods for the design and development of applications that take advantage of these capabilities, hampering our ability to realize the technology's potential. When working with ""context-aware"" systems -- i.e., systems that sense and respond to the situations in which they are used, such as the user's current location, concurrent activities, or social setting -- it can be especially challenging to evaluate early-stage prototypes due to the difficulty of re-creating the anticipated context of use during development time. As a result, designers are forced to invest excessive effort into building robust, deployable prototypes early in the development process, resulting in premature commitment to inadequately explored design choices and an inability to apply best practices for user-centered design. <br/><br/>The goal of this CAREER project is to improve user-centered software development practices for context-aware applications by providing support for the systematic capture and reuse of contextual data throughout the development process. While previous efforts to support context-aware development have sought to make it easier to take prototypes into the field for testing, this approach seeks to ""bring the field into the lab"" by providing continuously available representations of an application's anticipated context of use. Such representations can be used for exploring and validating design alternatives with as little effort as possible. <br/><br/>The PI's RePlay system provides baseline support for the capture and playback of sensor traces representing an application's context, and will be extended through this research to include support for the capture and use of large sensor trace datasets; rapid, parallel prototyping of both interactive and infrastructure components of context-aware systems; and the ability to re-create complex contextual conditions during controlled user tests to an extent not currently possible. <br/><br/>Broader impacts: The PI's educational mission is to prepare rising HCI professionals for the constantly changing world of technology they will face throughout their career. As part of this project, he will develop teachable methods for integrating data capture, context representation, and novel forms of user testing into software design and development practice. These methods will be incorporated into existing design and evaluation courses at the graduate and undergraduate levels. Broader impacts will be obtained by sharing course materials, along with the tools described above, with educators and practitioners via the web. The PI also plans to present tutorials and workshops on the use of capture and playback tools during design at meetings and conferences hosted by professional design organizations."
"0845469","CAREER: Enabling Independent Access to Digital Graphical Content for People with Visual Impairment","IIS","Cyber-Human Systems","03/01/2009","04/08/2013","Baoxin Li","AZ","Arizona State University","Continuing grant","Ephraim P. Glinert","02/28/2015","$451,768.00","","Baoxin.Li@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","1045, 1187, 7367, 9215, 9251, HPCC","$0.00","While sighted people readily enjoy the added value of the graphical content (digital images, maps, diagrams, etc.) that has become prevalent in the information age, visually impaired users can with the help of screen-reader software such as JAWS and Window-Eyes independently access only digital textual data, because such software cannot handle graphical information. Typical procedures for manually producing tactile graphics by sighted professionals are generally time consuming and labor intensive, hence coverage is extremely limited; furthermore, there is no online and independent availability if the production has to be done by third-party professionals. The PI's ultimate goal is to afford users with visual impairments independent real-time access to diverse types of graphical information, while taking into account often-overlooked issues such as privacy. In this project, however, he will address one specific and challenging subproblem of practical significance: how to make digital graphical content more independently accessible to students in the science, technology, engineering, and mathematics (STEM) fields. In addition to line-drawing graphics of a primarily binary nature, a specific type of continuous-tone image, human portraits, will also be considered, both due to the special value that facial images have in our social and emotional life, and also to demonstrate the potential of the PI's approach for handling more complex visual content. The research activities planned to these ends include a focused study of the peculiarities of haptic perception in tactile exploration of graphics, development of visual processing techniques for automated visual-to-tactile conversion, a usability study to determine intuitive and efficient presentation and interface schemes for the target end-users, prototype development and evaluation. Encouraging preliminary results have been obtained by the PI, demonstrating the feasibility and potential of the planned research and of the proposed methodologies. This research will advance our knowledge in the domains of visual-tactile cognition, image understanding, human-computer interaction in general and assistive technologies for people with visual impairments in particular. The PI?s institution provides an excellent and unique environment for performing this work.<br/><br/>Broader Impacts: This research will contribute to the research fields of visual-tactile cognition, automatic understanding of visual data for visual-to-tactile conversion, and development of assistive devices for the visually impaired. It will have significant impact on society, by ultimately enabling independent access to a wide range of visual content by people who are blind. More immediately, the project will help overcome the current barriers to the STEM fields that confront individuals with visual impairments."
"0845529","CAREER: Generative Models for Character Animation and Gesture in the New Age of Art and Electronic Interaction","IIS","Cyber-Human Systems","09/01/2009","06/22/2009","Michael Neff","CA","University of California-Davis","Standard Grant","Ephraim P. Glinert","08/31/2014","$581,276.00","","neff@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7367","1045, 6890, 7367, 9215, HPCC","$581,276.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br/><br/>The motivating problem of this research is to determine how to build computational models of expressive human movement for use in character animation applications. Satisfactory solutions to this problem must allow a high degree of control so that character movement can be customized for any context. This work will unify traditionally separate knowledge-driven and data-driven approaches to character animation, building on the control inherent in knowledge-driven techniques and the realism of motion capture data. A feature-based approach will be used to develop generative models. In this approach, a key-feature set will be determined in consultation with movement professionals, and professional performers working in a motion capture studio will provide data sampling the range of these features. Computational models of each feature will be developed from this data using a combination of procedural and learning techniques. The end goal is style-definition, in which explicit aspects of movement style can be represented computationally. This will support both movement analysis and movement generation through a software framework that allows each of these features to be combined and expressed. Key applications include models for conversational agents and a range of animation tools.<br/><br/>This work benefits society through the development of new computational models of expressive movement and by providing deeper insights into the nature of human motion. Computational models of movement that offer meaningful, fine-grained control are essential for a range of applications, including virtual worlds like Second Life, conversational agents, remote collaboration systems, training environments, games and other interactive, character based media. These models will be developed by combining two main trends in computer animation research, one that builds models based on explicit representations of existing knowledge and one that mines movement data to create models. The research will integrate computer scientists, digital artists and movement professionals, bringing a broad set of insights to technology development and providing cross-fertilization between these normally disparate groups. Research results will be published broadly and lead to new computational tools that can be used in a range of applications."
"1139148","Collaborative Research: Socially Assistive Robots","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, ROBUST INTELLIGENCE","04/01/2012","07/10/2013","Maja Mataric","CA","University of Southern California","Continuing grant","Ephraim P. Glinert","03/31/2017","$1,358,000.00","Fei Sha, Gisele Ragusa, Donna Spruijt-Metz","mataric@usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","1640, 7367, 7495","1640, 7367, 7723, 9251","$0.00","Socially Assistive Robots<br/>Lead PI/Institution: Brian Scassellati, Yale University<br/>This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits. The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians. For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone. In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population. This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does. <br/>To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year. <br/>This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.<br/>For more information visit www.yale.edu/SAR"
"0846034","CAREER: Program Comprehension in Internet-Scale Code Search for Open Source Reuse in Opportunistic Software Development","IIS","Cyber-Human Systems","10/01/2009","09/06/2012","Susan Sim","CA","University of California-Irvine","Continuing grant","William Bainbridge","09/30/2014","$285,331.00","","ses@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","1045, 1187, 7367, 9215, HPCC","$0.00","This project will study software developers engaged in the process of searching the Internet for source code that can be adapted to their goals, and it will design tools to support decision-making in this kind of work. It has become commonplace to search the Internet for source code in the course of a software development project. Locating the right component for as-is reuse or a reference example at the right time can have significant impact on the how the project progresses. There are a number of critical decision points in the search process, when the matches returned are eliminated or selected. These judgments require a form of program comprehension, though one that not been studied previously. Current research in program comprehension has been concerned with how software developers form mental models of how a single body of source code works in order to perform a maintenance task. Program comprehension in the context of Internet-scale code search involves discerning the characteristics of a candidate piece of code without becoming entangled in the internals.<br/><br/>Internet-scale code search is exploratory, iterative, and open-ended, so both relevance and suitability judgments are made throughout the process. Relevance judgments are made by software developers while identifying promising candidates among the available matches. These decisions are rapid, taking only a few seconds, and use relatively little information. Suitability judgments are made when determining whether a promising candidate is appropriate for the software project. These decisions are slower and typically involve a careful cost-benefit analysis. In this project, both types of judgments will be studied with the aim of creating better tools for Internet-scale code search. By understanding how developers decide between options, the cues that they use to comprehend the match, and the kinds of errors that they make, it is possible to present matches so they can find the desired source code more quickly and accurately. The research will have three components: laboratory experiments to study relevance and suitability judgments in a controlled setting; field studies to examine the search process in context; and refinements to an existing research platform, the Sourcerer code search engine. The evaluation criterion for this project is whether the new knowledge, techniques, and prototypes have reduced errors in relevance and suitability judgments during Internet-scale code search for opportunistic software development.<br/><br/>The expected outcomes of the research are: an understanding of the program comprehension that occurs in the context of Internet-scale code search; a model of the search and comprehension process; a characterization of the cues that are used in relevance and suitability judgments; and prototype search tools that support this process. These results could have far-reaching impact, because opportunistic software development and open source reuse have become widely adopted strategies. These practices allow software developers to leverage a global supply chain for software components and knowledge that they can use to implement new product and service ideas to keep up with societal, economic, and corporate demands. Accurate and rapid relevance and suitability judgments are essential for the successful application of these strategies. The educational components of this project will prepare students for the very different world of software development that is currently coming into being."
"1116057","HCC: Small: Collaborative Research: Cloud Primer: Leveraging Common Sense Computing to Learn Parent-Child Interaction Models for Early Childhood Literacy","IIS","Cyber-Human Systems","09/01/2011","07/20/2012","Cynthia Breazeal","MA","Massachusetts Institute of Technology","Continuing grant","Ephraim P. Glinert","08/31/2014","$301,121.00","","cynthiab@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7923, 7367","$0.00","Providing young children with opportunities to develop early literacy skills is important to their success in school, their success in learning to read, and their success in life. This project focuses on the creation of a new interactive reading primer technology on tablet computers that will foster early literacy skills and shared parent-child reading through the use of a targeted discussion-topic suggestion system aimed at the adult participant. The Cloud Primer will crowdsource the interactions and discussions of parent-child dyads across a community of readers. It will then leverage this information in combination with a common sense knowledge base to develop computational models of the interactions. These models will then be used to provide context-sensitive discussion topic suggestions to parents during the shared reading activity with young children. The work will be evaluated in week-long at-home studies.<br/><br/>Intellectual merit: The project will make fundamental theoretical contributions to models of human-human and human-computer interaction, and their use in fostering engagement and learning. The effort will also produce new insights into how common sense reasoning can be integrated with large-scale data collection to develop interactive technologies that deal gracefully with inconsistencies and noise to provide diverse and semantically meaningful responses in unconstrained, real-world environments.<br/><br/>Broader impacts: Research shows that one in three children in the United States enter kindergarten unprepared, and the majority of children who start behind typically stay behind. The Cloud Primer will counteract this trend by leveraging a community of readers to define a set of common discussion topics, actively exposing parents to these topics, and, through a simple touch interface, providing children of pre-reading age a mechanism for engaging adults in discussion. The new context and common sense aware interactive reading primer will be a fundamental advance over current digital reading technologies, which neither effectively achieve educational goals when used alone, nor support joint reading and adult engagement. The project will further contribute to education through undergraduate research, graduate thesis research, graduate course development, and outreach programs to women and under-represented minorities. To promote research in this area, the project will make all parent-child interaction data captured and annotated in the process of this research freely available to the research community, together with the Cloud Primer software. Furthermore, the computational methods developed through the course of this research will have applications in interactive domains beyond early literacy, such as foreign language learning."
"1144327","EAGER: Collaborative Research: Developing a Culturally Compelling Social Network Approach to HIV/AIDS Prevention for African American College Students","IIS","Cyber-Human Systems","09/01/2011","11/18/2013","Fay Payton","NC","North Carolina State University","Standard Grant","William Bainbridge","08/31/2014","$284,360.00","James Kiwanuka-Tondo, Kathy Gore","fay_payton@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","7367, 7916, 9251","$0.00","The proposed research will advance scientific knowledge about health information dissemination and the design of appropriate social media tools for the African American female college student community. The goal of this project is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the HIV/AIDS epidemic in these communities. The project will achieve this goal the following aims: 1) Describe the ways in which African American female college students construct their cultural/racial identities; 2) Identify the relationship between these identities and the use of smart health information technology and social networking systems by the target user group. <br/><br/>The research project will provide empirical evidence on the design and implementation of HIV/AIDS preventive education, as well as the culturally-specific challenges related to the use of Information Computer Technology (ICT) for HIV/AIDS preventive education. It will contribute to understanding how social networks targeting African American female college students for HIV/AIDS prevention are received by the target community and how to improve the design of such tools for optimal effectiveness. This research will have very far-reaching implications for science and health education within and beyond the target research study community. These intellectual contributions will be of interest to scholars in communication and information studies, software engineering, pervasive mobile devices, and smart health information systems and trustworthy computing. <br/><br/>The project will engage college students in the Delta Sigma Theta Sorority as both users and participatory designers of social media tools intended to disseminate HIV information. The National Delta Sigma Theta Sorority, an organization with national and international programs for outreach and networking African American women in institutes of higher education, will offer a mechanism to reach additional college students beyond the physical locale of North Carolina State University - thereby providing a network penetration to other North Carolina chapters and beyond for future direction and interdisciplinary, inter-institutional collaborations. More specifically, this research is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the epidemic in these communities using innovative smart health information technologies."
"1117281","HCC: Small: An Analytical Framework for Provenance-Rich Social Knowledge Collection","IIS","Cyber-Human Systems","09/01/2011","09/01/2011","Yolanda Gil","CA","University of Southern California","Standard Grant","William Bainbridge","08/31/2014","$490,000.00","","gil@isi.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7367, 7923","$0.00","This project will investigate a new generation of provenance-rich social knowledge collection systems that will greatly improve the ability of people to create online communities of interest and share information. The research will transform the state of the art in social content collection in several important ways. First, social knowledge collection systems will be augmented to support contributors to structure factual content, so that information can be aggregated to answer reasonably interesting albeit simple factual queries. We will build on a semantic wiki framework to allow users to create structured factual content as object-property-value triples. It will not assume pre-defined ontologies, but rather develop algorithms that analyze current content and suggest opportunities for structuring contributions so they can be aggregated to answer simple queries. Second, they will include detailed provenance records that reflect how the content was created, allowing contributors to enter alternative viewpoints and enabling consumers to make quality and trust judgments. The research will include developing algorithms that derive trust metrics from the provenance records, and to allow users to define views on the content based on provenance criteria. It will create novel approaches to propagate trust across content topics and categories and complement existing algorithms that propagate trust in social networks. Third, the systems will proactively guide contributors to invest effort where it is most needed, developing novel algorithms to detect knowledge gaps, and by allowing users to define queries that will be used to drive further contributions.<br/><br/>This work has the potential for a broader impact in many areas where social content collection is already widely used, not only in scientific communities but also for societal issues, such as citizen participation in local communities, health, and governance. All these communities would benefit from further structure, provenance models, and guided knowledge collection. Despite their popularity, social content collection sites currently have important limitations. First, because the content has very little structure they cannot aggregate information and answer many simple questions. Second, contributors have uneven expertise and skills and therefore the content is of very varying quality, yet there is no assistance for consumers to tell apart the valuable from the dubious. Third, these sites depend on the initiative of contributors to figure out how the content needs to grow, and there is no systematic analysis to expose knowledge gaps and guide contributors proactively. This research project addresses all three of those issues."
"1111246","HCC: Large: Collaborative Research: Information Technology, Remote Socialization, and the Development of Occupational Identity","IIS","Cyber-Human Systems","08/01/2011","08/10/2011","Paul Leonardi","IL","Northwestern University","Standard Grant","William Bainbridge","07/31/2015","$442,746.00","","leonardi@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7925","$0.00","This project will explore how remote socialization enabled by information and communication technologies (ICTs) is transforming four occupations: graphic design, automotive engineering, banking, and Internet entrepreneurship. Following a comparative, field-based research design, this research will examine the effects of both organizational environments and socialization tactics on ICT use and consider issues of technology use, socialization, and the changing nature of work. In today's workplaces, it is increasingly common to encounter arrangements in which occupational members are geographically distributed from one another. This new reality calls into question existing theories of socialization and learning practices that highlight the importance of collocated interaction and in situ knowledge transfer. By focusing on how individuals use ICTs to learn what it means to be an occupational member, this research will contribute to a new breed of theory on socialization that indicates the processes, practices, and strategies individuals can use to become effective members of an occupation even though they work remotely from others. By drawing on recent theorizing, which suggests that ICTs may provide particular affordances for interaction that non-mediated (e.g. face-to-face) contexts do not, it will explore the possibility that remote socialization may, in fact, help occupations to transform themselves. One aim is to build theory about the mechanisms by which technology leads to occupational transformation. <br/><br/>Occupational skill is critical to economic success, social progress, and individual well-being. However, many occupations seem to be failing to adapt quickly to changes in science, technology, and policy. The failure of occupations to change and refashion themselves to meet new social and technological pressures portends job loss from reduced skill for American citizens, and potentially increased outsourcing to other countries. This study will provide insight into how technology-enabled remote socialization may be able to contribute to faster occupational transformation. Although, for many years, ICT-mediated communication has been seen to be impoverished when compared to face-to-face communication, but now that it has developed considerably, ICT-mediated communication may provide more opportunities for workers to break free from the inertia of established occupations and develop new work practices and strategies that move the occupation forward. Additionally, it is imperative that new occupational members learn how to effectively acquire the knowledge and skills they need to perform their jobs well when they work remotely from others. This study will provide insight into effective practices of remote socialization and occupational learning such that individuals who are attempting to learn new work practices and knowledge will be successful in their efforts."
"1414780","WORKSHOP: ACM Group 2014 Conference Doctoral Research Consortium","IIS","Cyber-Human Systems","12/15/2013","12/19/2013","Daniel Cosley","NY","Cornell University","Standard Grant","Ephraim P. Glinert","11/30/2014","$22,278.00","","drc44@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) for approximately 12 graduate students, along with a panel of 3 distinguished research faculty mentors. The event will take place in conjunction with the 2014 International Conference on Supporting Groupwork (GROUP 2014), to be held November 9-12 on Sanibel Island, Florida, and sponsored by the Association for Computing Machinery's Special Interest Group on Computer-Human Interaction (ACM SIGCHI). For over 25 years, the bi-annual GROUP conferences have been a leading international forum for the presentation and discussion of research and practice on organizational behavior, information systems, social informatics, human-computer interaction (HCI), and computer supported cooperative work (CSCW), providing a showcase for innovative work on the development, introduction, management, deployment, and analysis of computer-based collaborative systems. A strong emphasis of the GROUP conferences is to foster discourse on collaborative technology that bridges the fields of CSCW, information systems, technology enhanced learning, and learning at the workplace; relevant issues include the design, implementation, deployment, evaluation, and impact of these systems, as well as examinations of relevant research methodologies. Research reports published in the GROUP conference proceedings are competitively reviewed and widely cited. More information about the conference may be found online at http://www.acm.org/conferences/group/conferences/group14/. <br/><br/>The GROUP 2014 Doctoral Consortium (DC) will be a research-focused day-long meeting on Sunday, November 9, with follow-up events that take place during the conference's main technical program. Student participants will be later stage doctoral students from both the United States and abroad, who represent the various disciplines and subfields of interest to the conference. The goals of the workshop are to build a cohort group of young researchers who will then have a network of colleagues spread across the world, to guide and shape the work of the new researchers by having experts serve as mentors and give advice, to provide encouragement and support for the selection of GROUP research topics, to make it possible for promising new entrants to the field to attend a leading research conference and to illustrate for them the interrelationship and diversity of GROUP research, and in general to make the new entrants' experience at the GROUP conference enjoyable and rewarding, so that they will be encouraged to return and submit to future conferences in the series.<br/><br/>Broader Impacts: The GROUP conferences represent a critical link between the research communities supported by CISE/IIS and the broader social, behavioral, and management sciences. Maintaining and fostering research dialog among these diverse disciplines will result in synergistic and transformative research collaborations. Further, developing young researchers who can effectively bridge two or more of the broader CISE/IIS, social and management sciences is an important goal to ensure the future vitality of the IIS research community. The GROUP 2014 DC will bring together the best of the next generation of organizational systems, information systems, social informatics, and CSCW researchers. The social network among this next generation of researchers, and the relationships with senior researchers, created by the workshop will play a critical role in their enculturation into the profession. The organizers will be proactive in order to ensure that both students and faculty are a diverse group across multiple dimensions including nationality, scientific discipline, gender, institutional affiliation, and under-represented minority status. To further ensure diversity, no more than 2 student participants will be accepted from any one institution."
"1320350","HCC: Small: Getting a Grip on the Numerical World: Kinestheic Interaction with Simulations to Support Collaborative Discovery in Systems Biology","IIS","Cyber-Human Systems","09/01/2013","08/21/2013","Alexandra Mazalek","GA","Georgia Tech Research Corporation","Standard Grant","Kevin Crowston","08/31/2016","$499,086.00","","mazalek@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7923","$0.00","Computational techniques have greatly extended the range of problems that can be solved by numerical analysis. However, few tools support the combined practice of collaborative learning and discovery in the computational sciences. This project draws on recent work in embodied cognition, which suggests that the process of building models--particularly models with dynamic visualizations--can aid conceptual understanding in complex problem domains. The researchers will develop a system to support and enhance collaborative discovery by re-representing abstract scientific problems in an embodied way. The proposed system will allow researchers to couple visuo-spatial skills with computational techniques to develop understanding and collaborate in the modeling of complex biological systems. Simultaneously, the project will develop techniques to support collaborative modeling in science and engineering. The project will thus test how theories from embodied cognition can inform interaction design and create explicit knowledge about how collaborative discovery happens in the sciences. <br/><br/>By changing the way abstract scientific problems and techniques are represented, the proposed system will make these scientific problem easier for researchers to understand and manipulate through embodied experience. This re-representation of complex problems may have several benefits: 1) help researchers find solutions to problems that would otherwise take too long or seem too difficult to solve; 2) enhance problem-driven learning approaches in science and engineering disciplines; 3) enable interdisciplinary groups of learners or researchers to come together and work on (and develop a shared representation of) complex problems in a hands-on manner; and 4) make complex science and engineering problems more accessible to everyday citizens. The project may also have significant impacts on emerging interactive technologies by establishing embodied cognition as a framework for interaction design."
"1319897","HCC: Small: Creating a Data-Driven World: Situated Practices of Collecting, Curating, Manipulating, and Deploying Data in Healthcare","IIS","Cyber-Human Systems","09/01/2013","08/21/2013","Melissa Mazmanian","CA","University of California-Irvine","Standard Grant","William Bainbridge","08/31/2016","$500,000.00","Kathleen Pine","mmazmani@uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7923","$0.00","This project will study the situated practices, human assumptions, and organizational routines that transform ""little data"" into mineable stores of ""big data"" harnessed for measures and metrics. Currently, our knowledge about the origins of big data and what goes into collecting, curating, manipulating, and deploying these huge information resources is limited. We know even less about the social and cultural implications of these activities, particularly in non-academic contexts. A growing group of scholars urge critical interrogation of the methods, analytical assumptions, and underlying biases of big data science. A nuanced understanding of the situated practices through which big datasets are assembled and manipulated is required before we can comprehend their social and political implications, particularly if we are to evaluate the quality of the scientific results based on analysis on the manipulation of such datasets.<br/><br/>The research will be carried out through a multi-sited ethnography of obstetrical data production in healthcare, an area where big data and associated metrics are both important and problematic. First, it will examine the situated practice and lived experience of creating the massive amounts of information that come to form the datasets. Second, it will trace how the results emerge through automatized measures and algorithms and affect the very environments they are supposed to reflect. This research spans the lifecycle of data. It will investigate how information is collected by practitioners, clerks, and coders and transformed into local repositories of supposedly ""clean"" data to be manipulated by performance improvement specialists. It will then trace how information is transferred and refined further in a statewide data center and deployed by a major quality improvement organization. Finally, the research will follow the aggregated data back to the local hospitals themselves and assess how data visualizations and performance measures affect local decisions and hospital functioning.<br/><br/>The broader impacts of this project include both near and long-term benefits. In the short term, this research will benefit the individuals and organizations struggling with questions about how to organize local resources to produce and deploy big data in service of management and performance improvement goals. In the long term, this research will generate foundational conceptual models that help to create design recommendations and practice guidelines regarding the social, ethical, and political implications of creating and using big data."
"1314399","HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","IIS","Cyber-Human Systems","08/01/2013","08/07/2013","Andrew Ko","WA","University of Washington","Standard Grant","Ephraim P. Glinert","07/31/2017","$356,216.00","","ajko@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7367, 7925","$0.00","In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br/><br/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask ""why"" questions to understand the differences among variations of a system. For novices, an ""Idea Garden"" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br/><br/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students."
"1319567","HCC: CGV: Small: Eyeglass-Style Multi-Layer Optical See-Through Displays for Augmented Reality","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","09/15/2013","09/02/2013","Henry Fuchs","NC","University of North Carolina at Chapel Hill","Standard Grant","Anthony Hornof","08/31/2016","$499,997.00","","fuchs@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7367, 7453","7367, 7453, 7923","$0.00","For over two decades, researchers have shown the potential of augmented reality (AR) to transform computer graphics into an everyday extension of human vision that can enhance such diverse applications as medicine, manufacturing, maintenance, smart offices, and navigation. However, there is virtually no use of augmented reality by the public or industry today. The investigators believe that this discrepancy is due largely to the lack of suitable high performance and widely applicable augmented reality displays on which applications can be deployed. The most capable AR displays available today, optical see-through head-mounted displays (HMDs), generally lack four key qualities that prevent their widespread use: wide field-of-view, non-encumbering, support for mutual occlusion, and preservation of most depth cues. The investigators know of no existing or proposed displays that feature all, or even most, of these capabilities. This project takes a radically different approach to optical see-through design that offers the potential to deliver all four missing qualities in a compact form factor that approaches ordinary glasses. The approach relies on a multi-layer display architecture that follows the principles of the emerging field of computational displays - simple optical devices whose functionality and complexity generally lies in software. This project applies existing multi-layer optimization techniques from desktop 3D displays to optical see-through HMDs, while exploring new approaches such as perceptual error metrics, the use multiple layers for occlusion masks, and field of view zone prioritization. This knowledge will be used to build prototype optical see-through displays while handing such challenges as calibration, tracking, computational complexity, and latency. The performance of this approach will be robustly tested and evaluated in simulation, with calibrated cameras, and with human viewers. The target device will transform augmented reality, allowing society to take advantage of the diverse set of applications that have been studied in AR. The proposed design is a radically different approach to optical see-through displays that uses spatial light modulators and software optimization to replace conventional reflective, refractive, and diffractive optics. The ability to produce a focused image on a display placed closer than the eye can accommodate without the use of lenses will be investigated. Sharing of display components for both image formation and occlusion masking will also be researched. The investigators will also explore the use of multi-layer optimization to create multi-focal imagery, prioritize different areas over the viewer's field of view, and facilitate eye tracking.<br/><br/>Broader Impacts: Research and practice have shown the promise of augmented reality to improve such diverse areas as medicine, accessibility, worker efficiency and communications. However, to date there is very little use of augmented reality by the public or industry. This project will lead to a high performance augmented reality display that is badly needed to make the field practical and allow the public to reap the benefits of years of visionary augmented reality research. The science and technology developed in this project will open the use of augmented reality to a wider class of researchers, similar to how the recent development of the commodity depth sensor has permitted new opportunities for scientific inquiry."
"1418922","WORKSHOP: HRI 2014 Pioneers","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems","01/15/2014","01/09/2014","Robin Murphy","TX","Texas Engineering Experiment Station","Standard Grant","Ephraim P. Glinert","12/31/2014","$35,016.00","","murphy@cse.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","1640, 7367","7367, 7556","$0.00","This is funding to support a Pioneers Workshop (doctoral consortium) of approximately 18 graduate students and post-docs (including about 12 U.S. participants) from diverse research communities (e.g., computer science and engineering, psychology, cognitive science, robotics, human factors, human-computer interaction design, and communications), along with distinguished research faculty. NSF funding will be used solely to cover travel, housing, and subsistence for eligible U.S. attendees. The event will take place on Monday, March 3, 2014, immediately preceding the Ninth International Conference on Human Robot Interaction (HRI 2014), to be held March 4-6 in Bielefeld, Germany, and which is jointly sponsored by ACM and IEEE. HRI is a single-track, highly selective annual international conference that seeks to showcase the very best inter- and multi-disciplinary research in human-robot interaction with roots in social psychology, cognitive science, HCI, human factors, artificial intelligence, robotics, organizational behavior, anthropology and many more, and invites broad participation. The theme of HRI 2014 is ""(E)Merging Perspectives"" which seeks to combine both user and system perspectives to advance new and possibly unorthodox methodologies. To extend the current singular approaches, this year's conference emphasizes papers that demonstrate the usage of novel empirical methods, the integration of empirical findings into complex robot systems, and holistic approaches in system evaluation. More information about the conference is available online at http://humanrobotinteraction.org/2014. <br/><br/>The Pioneers Workshop is designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference. During the workshop, participants will talk about the important upcoming research themes in the field, encouraging the formation of collaborative relationships across disciplines and geographic boundaries. To these ends, the workshop format will include oral presentations from 2 student attendees, poster presentations from all attendees, a hands-on meet-and-greet session, two alumni speakers, a keynote, and a panel presentation by senior researchers. The oral presentations and the interactive poster sessions will provide a forum for participants to share their research, enabling them to receive feedback on their work and to gain perspective on the field. The hands-on meet-and-greet session will involve networking and the cultivation of cross-disciplinary ideas. The alumni presentations will provide advice for short-term goals and a recent perspective on looking for jobs within the community. The keynote lecture will provide a global and future vision for HRI. The panel presentation will feature five senior HRI researchers from both academia and industry who will share insights about their own careers, answer career path questions, and provide insight into the interdisciplinary nature of the HRI community. The conversations between the panel and participants will continue over lunch and during dinner.<br/><br/>Broader Impacts: This workshop will afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities (including but not limited to computer science and engineering, psychology, robotics, human factors and ergonomics, and HCI). This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives. Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years. Participants will also gain leadership and service experience, as the workshop is largely student organized and student led. The PI has expressed her strong commitment to recruiting women and members from under-represented groups. To further ensure diversity the event organizers will consider an applicant's potential to offer a fresh perspective and point of view with respect to HRI, and will limit the number of participants accepted from a particular institution to two, with one being a woman if two are accepted"
"1017826","HCC: SMALL: Wearable computation and feedback for real-time movement training","IIS","Cyber-Human Systems","09/01/2010","07/06/2011","Mark Cutkosky","CA","Stanford University","Standard Grant","Ephraim P. Glinert","08/31/2014","$500,000.00","Thor Besier","cutkosky@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7367","7923","$0.00","Movement is a basic feature of human existence and is intimately connected to our quality of life. Movement training can prevent injury, improve athletic performance, delay musculoskeletal disease and accelerate rehabilitation. Until now, training has been limited in scope to specialized training facilities and limited in effectiveness to the verbal recommendations of physical trainers. In this project, the PI's goal is to expand the scope and effectiveness of human movement training in order to extend health and lifestyle benefits to the general public. The primary outcome of this research at the intersection of robotics, biomechanics and human-computer interaction will be gait modeling software that integrates sensor data in real time to compute kinematics, kinetics and joint/tendon forces to predict adjustments to motion parameters to achieve an end goal. The PI's hypothesis is that wearable computation can fundamentally change the way people move. The miniaturization of computational hardware, as well as advances in movement analysis algorithms, wearable sensors and feedback devices, all serve as catalysts for a new level of human interaction. The work will focus on everyday repetitive dynamic activities like walking, running and jumping, whose nature is that information gathered and analyzed during one cycle can be applied to subsequent cycles to achieve gradual improvement. Feedback that builds upon advances in robotics, motion tracking and biomechanical modeling (that have led to efficient monitoring and simulation of complex multi-degree of freedom systems) will be provided in real time and will be adaptive, robust with respect to cycle-to-cycle variations, and user specific. For maximum impact, movement training will be accessible to the average citizen instead of confined to the laboratory or clinic. To this end, the PI will create a system that could be used while walking around the house, hiking outdoors or running in a gymnasium. Preliminary experiments in motion tracking, dynamic analysis and wearable feedback for gait retraining to reduce knee loading associated with injury and arthritis will be extended to evaluate which types of sensing and feedback, in combination with algorithms to detect and analyze motion anomalies, are effective outside of the laboratory. The PI will conduct a series of experiments to validate the portable solution, comparing it with results obtained in a fully instrumented laboratory setting and assessing how the effects of training are retained over time. <br/><br/>Broader Impacts: The PI argues that with wearable retraining devices middle-aged women could be taught to walk in a way that slows or prevents osteoarthritis as well as injury at the hips, ankles, etc., college athletes could be trained to jump and land while playing volleyball so as to prevent ACL and other common sports-related injuries (while perhaps improving performance as well), and victims of stroke and other neurological disorders could be rehabilitated at home instead of at the clinic. This project will focus initially on walking and knee joint loading, a problem of immediate importance for the aging U.S. population. The PI will provide open source software (e.g., for monitoring sensors and predicting target gait parameters) and wearable hardware licensing to promote adaptation of project outcomes to other applications."
"1415879","WORKSHOP: Student Consortium at the 2014 ACM Conference on Intelligent User Interfaces","IIS","Cyber-Human Systems","12/15/2013","12/18/2013","Joyce Chai","MI","Michigan State University","Standard Grant","Ephraim P. Glinert","02/28/2015","$19,250.00","","jchai@cse.msu.edu","CONTRACT AND GRANT ADMINISTRATIO","EAST LANSING","MI","488241046","5173555040","CSE","7367","7367, 7556","$0.00","This is funding to provide financial support for 10 graduate students (all from U. S. universities and working towards either their Master's degree or a Doctorate) to attend the 2014 International Conference on Intelligent User Interfaces (IUI 2014), to be held February 24-27 in Haifa, Israel, as participants in a special Student Consortium (workshop), as presenters in the main conference, and as attendees at the conference for general training purposes. Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent and interactive user interfaces; they are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place. Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter. Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc. IUI 2014 will be the 17th conference in the series; topics of interest this year include: intelligent interactive interfaces, systems, and devices; ubiquitous interfaces; smart environments and tools; human-centered interfaces; mobile interfaces; multimodal interfaces; pen-based interfaces; spoken and natural language interfaces; conversational interfaces; affective and social interfaces; tangible interfaces; collaborative multi-user interfaces; adaptive interfaces; sensor-based interfaces; user modeling and interaction with novel interfaces and devices; interfaces for personalization and recommender systems; interfaces for plan-based systems; interfaces that incorporate knowledge- or agent-based approaches; help interfaces for complex tasks; example- and demonstration-based interfaces; interfaces for intelligent generation and presentation of information; intelligent authoring systems; synthesis of multimodal virtual characters and social robots; interfaces for games and entertainment; for learning-based interactions and for health informatics; empirical studies and evaluations of IUI interfaces; and new approaches to designing intelligent user interfaces. More information about the conference is available online at http://iuiconf.org/. <br/><br/>The IUI 2014 Student Consortium will build on the success of the previous two such events. The heart of the Consortium will be a full-day workshop on February 24, immediately preceding the conference, and will be structured to give student trainees exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of senior researchers. Group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors. The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field. The IUI conference organizers will pay for audio-visual services, two coffee breaks, and space for accommodating attendees in the student session; no funds are requested for these items from NSF.<br/><br/>Broader Impacts: This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons. It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement. The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants. The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference. The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community. Women, minority students, the disabled, and veterans all will be encouraged to participate. To further assure diversity, no more than one student will be accepted from any given institution."
"1350764","WORKSHOP: Computer Supported Cooperative Work 2014 Doctoral Research Colloquium","IIS","Cyber-Human Systems","11/01/2013","11/07/2013","Darren Gergle","IL","Northwestern University","Standard Grant","Kevin Crowston","10/31/2014","$25,049.00","","dgergle@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 7556","$0.00","This award supports a research development workshop for promising doctoral students to be held in conjunction with the 2014 ACM Conference on Computer Supported Cooperative Work (CSCW 2014). CSCW 2014 will take place in Baltimore, Maryland, USA on February 15-19, 2014 and will be attended by approximately 500 CSCW professionals from around the world. Research reports published in the CSCW Conference Proceedings are heavily refereed and widely cited.<br/><br/>The Doctoral Colloquium (DC) is a research-focused meeting of 12 selected Ph.D. candidates and a panel of 4-6 research mentors. Prior colloquia have helped launch the careers of many outstanding CSCW researchers. The colloquium seeks to (a) build a cohort group of new researchers who will then have a network of colleagues spread out across the world, (b) guide the work of the new researchers by having the experts in the research field give advice, (c) encourage and support the selection of CSCW research topics, (d) enable new entrants to the field to attend a key research conference, (e) illustrate the interrelationship and diversity of CSCW research, and (f) make the new entrants' experience at CSCW an intellectually stimulating and rewarding experience, encouraging them to return and submit papers, panels, demonstrations, and posters, to the conference. Key efforts of the organizers will encourage participation from diverse fields and underrepresented populations and universities.<br/><br/>The primary intellectual contributions of this project lie in close intellectual mentoring of the selected Ph.D. participants and the development of a cohort of future leaders within the CSCW community. Furthermore, bringing together these students with the faculty panel, both during the workshop and during the conference poster presentations, will support the development of interdisciplinary dialogs, creating an environment for exchange and conversation that will further enable progress on every project represented at the DC. The specific projects of students selected for the DC will generate additional intellectual contributions.<br/><br/>The consortium will have considerable benefits to society and the CSCW community, both short and long-term. In the short term, the panelists will provide significant feedback to the students participating in the DC. In the long-term, the expectation is that students who have participated in the DC will give back to the community by engaging as mentors to undergraduate students, and in the future to doctoral students. Furthermore, these exceptional students are anticipated to be among the future leaders of the CSCW community, and it is durable long-term benefit to that community to support them in their early research. These values of continuity and knowledge community will be explicitly expressed at the consortium."
"1018124","HCC: Small: Collaborative Research: Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children","IIS","Cyber-Human Systems, EXP PROG TO STIM COMP RES","09/01/2010","08/19/2010","Thamar Solorio","AL","University of Alabama at Birmingham","Standard Grant","Ephraim P. Glinert","08/31/2014","$301,055.00","","solorio@cis.uab.edu","AB 1170","Birmingham","AL","352940111","2059345266","CSE","7367, 9150","7923, 9102, 9150","$0.00","It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development. Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds. Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills. These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions. Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced. Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones. At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children. With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts. Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country). Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities. Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children. <br/><br/>Broader Impacts: This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date. Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general. Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains. In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used."
"1012947","HCC: Large: Collaborative Research: Delivery of Personalized Reading Strategies for People with Cognitive Impairments in Post-Secondary Settings","IIS","Cyber-Human Systems","08/15/2010","08/19/2010","Michael Sullivan","OR","Portland VA Research Foundation","Standard Grant","Ephraim P. Glinert","07/31/2015","$104,928.00","","sullivan@ohsu.edu","3710 SW US Veterans Hospital Roa","Portland","OR","972390539","5032735228","CSE","7367","7925","$0.00","Abstract <br/>Reading comprehension deficits are pervasive for a disproportionate number of post-secondary students. These students have cognitive impairments that impact high level text processing skills and result in diverse reading profiles with difficulties in skills such as discerning between relevant and irrelevant information, drawing inferences, connecting background knowledge to new learning, and retaining and applying what was learned at a later date. Typically such deficits are managed by teaching the use of study-skills strategies. While there is strong face validity for these practices there is a lack of evidence-based practice, and virtually no information on candidacy or what types of deficits respond best to what types of strategies and supports. On the technology side, the popularity of electronic reading tablets offers a platform to deliver supports to improve reading comprehension and retention that could be adopted by college students. This project seeks to bridge the gap by developing the technology to support a diverse set of reading strategies in a highly adoptable form for college students with high-level reading impairments, by doing the science necessary to define a process that can assess each individual student, and by prescribing a set of strategies that eventually will be delivered in a hardware-software package. By using an iterative design process and a participatory action research model, this research will make the following contributions: a dynamic assessment process that matches reading profiles/impairments to strategy supports; a mapping of reading impairments to reading strategies; translation of reading strategies to delivery on electronic reading tablets; a demonstration that personalization and adaptation are possible using our software engineering models; and a dissemination package that uses open source software and hardware to deliver a research tool that could be used by companies designing commercialized reading tablets. To achieve these goals, the PI will partner with three institutions that have large populations of struggling readers in post-secondary educational settings: two VA facilities that support and train veterans returning to educational settings, and a student disability services program at a large urban state university. These groups have experience with the pervasive, high level reading challenges preventing educational success, and provide the natural contexts to evaluate the PI's models and shape the tools generated from this research. Pilot studies, laboratory experiments and longitudinal studies will be employed to develop and evaluate the technology for a dynamic reading assessment and support tool. <br/><br/>Broader Impacts: A growing population not able to meet the reading demands of college and community college courses is the large number of veterans returning form Iraq and Afghanistan seeking education and training benefits. It is estimated that 15-20% of these veterans have suffered mild brain injury sufficient to affect academic ability. Another large group of post-secondary students that is challenged by difficulties with reading comprehension are those with developmental conditions including adult attention deficit and hyperactivity disorder (ADHD) and attention deficit disorder (ADD). Estimates regarding the number of students enrolled in colleges who report clinically significant ADHD or ADD symptoms vary between 2% to 8%; approximately 25% of students receiving disability support services are receiving those for ADHD. The PI expects two important outcomes from this work: the science missing from the literature that links reading impairments with reading strategies; and a demonstration tool, built on the science, that supports an assessment process and a delivery mechanism. With this latter outcome in mind, the PI intends to devote a large part of Year 5 of the project to making his tool highly attractive to companies who have the infrastructure to deliver products to the target populations."
"1313847","WORKSHOP: Student Consortium at the 2013 ACM Conference on Intelligent User Interfaces","IIS","Cyber-Human Systems","02/01/2013","01/17/2013","Henry Lieberman","MA","Massachusetts Institute of Technology","Standard Grant","Ephraim P. Glinert","01/31/2015","$10,368.00","","lieber@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367","7367, 7556","$0.00","This is funding to provide financial support for 10 graduate students (at least 8 of them registered at U.S. universities and working towards either their Master's degree or a Doctorate) to attend the 2013 International Conference on Intelligent User Interfaces (IUI 2013), to be held March 19-22 in Santa Monica, California, as participants in a special Student Consortium (workshop), as presenters in the main conference, and as attendees at the conference for general training purposes. Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent and interactive user interfaces; they are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place. Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter. Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc. IUI 2013 will be the 16th conference in the series; topics of interest this year include: intelligent interactive interfaces, systems, and devices; ubiquitous interfaces; smart environments and tools; human-centered interfaces; mobile interfaces; multimodal interfaces; pen-based interfaces; spoken and natural language interfaces; conversational interfaces; affective and social interfaces; tangible interfaces; collaborative multi-user interfaces; adaptive interfaces; sensor-based interfaces; user modeling and interaction with novel interfaces and devices; interfaces for personalization and recommender systems; interfaces for plan-based systems; interfaces that incorporate knowledge- or agent-based approaches; help interfaces for complex tasks; example- and demonstration-based interfaces; interfaces for intelligent generation and presentation of information; intelligent authoring systems; synthesis of multimodal virtual characters and social robots; interfaces for games and entertainment; for learning-based interactions and for health informatics; empirical studies and evaluations of IUI interfaces; and new approaches to designing intelligent user interfaces. More information about the conference is available online at http://iuiconf.org/. <br/><br/>The IUI 2013 Student Consortium will build on the success of the first such event last year. The heart of the Consortium will be a full-day workshop on March 19, immediately preceding the conference, and will be structured to give student trainees exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of 4-5 senior researchers. Group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors. The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field. The IUI conference organizers will pay for audio-visual services, two coffee breaks, and space for accommodating attendees in the student session; no funds are requested for these items from NSF.<br/><br/>Broader Impacts: This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons. It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement. The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants. The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference. The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community. Women, minority students, the disabled, and veterans all will be encouraged to participate. To further assure diversity, no more than one student will be accepted from any given institution."
"1322254","VOSS: Collaborative Research: Is Larger Smarter? Investigating the Effect of Group Size on Collective Intelligence","ACI","Cyber-Human Systems, VIRTUAL ORGANIZATIONS","10/01/2013","08/30/2013","Thomas Malone","MA","Massachusetts Institute of Technology","Standard Grant","Almadena Y. Chtchelkanova","09/30/2016","$328,416.00","","malone@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7367, 7642","7642, 9102, 9179, 7367, 8031","$0.00","From Wikipedia to Linux to scientific and business work-groups all over the world, both online and off-line groups are becoming a pervasive part of modern life. It is becoming increasingly important, therefore, to understand how to improve the performance of these groups. The work proposed here will use a new measure of generalized group effectiveness -- called ""collective intelligence"" -- to help do this. <br/><br/>Building on previous work by the investigators, the project will first develop an online test for collective intelligence. Then it will compare the results of online and face-to-face groups taking this new test with previous results for groups taking an offline version of the test. This will help clarify the degree to which online and off-line groups differ in their general effectiveness on a wide range of different tasks. Next the project will use this test to systematically measure the collective intelligence of online groups that range in size from 2 to 20 people. This will lay the foundation for exploring whether larger online groups can take advantage of the increased resources that more people bring, without suffering as much from the process losses that usually accompany increased group size in face-to-face groups. Finally, the project will systematically measure the collective intelligence of online groups with varying proportions of women. In doing so, the project will also test one particularly promising explanation for a gender effect on group performance: that groups with more women are less interpersonally competitive, and that this lower intra-group competitiveness leads to higher collective intelligence. <br/><br/>While there have been decades of research on factors that affect the performance of groups, almost all these studies have each focused on a single task. Thus, strictly speaking, the lessons to be learned from this previous work are limited to the specific tasks studied. The work proposed here uses the perspective of collective intelligence to investigate, not just the ability of a group to perform a single task, but the group's general ability to perform a wide range of tasks. Since many real-world groups must cope with a wide range of problems, just such a perspective may be needed to systematically predict their performance. In addition, the approach developed here can provide a significant economy of effort in evaluating potential ways of improving online group effectiveness. Instead of testing interventions on many different specific tasks, researchers will be able to test the interventions once with this general measure, and then have some basis for predicting the effects of the intervention on many other tasks. By making an online test of collective intelligence available to other researchers, the project will help advance scientific practice in this area. More generally, by providing a firmer scientific foundation for measuring and improving the performance of groups, the project may help our society address many of its most important problems more effectively. For instance, with the right kinds of collaboration tools, online groups may be able to be much more effective than face-to-face groups, taking advantage of the simultaneous efforts of far more people without the coordination losses that usually occur in larger groups. And understanding the dynamics of gender diversity may help to improve the collaboration of the groups in which both men and women work, by giving everyone's best ideas a better chance to be heard. And perhaps, someday, this will help create groups that are more collectively intelligent than any groups have ever been before."
"1353723","EAGER: Designing Reflective Opportunities in Human-Computer Interaction","IIS","Cyber-Human Systems","09/15/2013","09/04/2013","Deborah Tatar","VA","Virginia Polytechnic Institute and State University","Standard Grant","Kevin Crowston","08/31/2014","$115,972.00","Steve Harrison","tatar@cs.vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7367","7367, 7916","$0.00","Many people presently interact more with and through computers than they do with other people directly but such interaction may have negative effects that go unobserved. These balance of positive and negative effects could be considered more thoughtfully if the design of the technology created opportunities for reflection, e.g., by creating ""seams"" in interaction that make the balance between the machine's influence and the human push-back more obvious, or by allowing people to nudge one another and themselves in particular directions. The goal of this project is to create at least one proof-of-concept implementation and demonstration of such a reflective design that will provide a paradigm or model for similar development and serve as a basis for future research. The pilot project has four parts: development of a task and example reflective opportunity, technology and experimental development, conduct of an experiment and analysis. <br/><br/>The project is important because of the enormous role that computer systems play in the interstices of everyday existence, because the influences that computer systems have are not necessarily well-understood by users, creators or analysts and because of the potential for novel and more beneficial approaches to design that bring these influences to greater awareness. If the project succeeds in demonstrating the value of a reflective design approach, it may influence the ways people in society conceptualize computation, increasing their awareness of the need to cultivate a pro-active stance as users and designers and so provide a new paradigm for human-computer interaction research and development."
"1351131","CAREER: Enabling expert crowdsourcing via coordination, targeted contribution and education","IIS","Cyber-Human Systems","01/01/2014","01/13/2014","Michael Bernstein","CA","Stanford University","Continuing grant","Kevin Crowston","12/31/2018","$112,362.00","","msb@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7367","1045, 7367","$0.00","Crowdsourcing systems typically draw on the work of non-experts, as expert crowds are difficult to gather and coordinate. To extend the reach of crowdsourcing, this project investigates interactive systems, platforms and computational techniques to integrate experts as core participants of crowdsourcing systems. The project will develop and evaluate three related systems that improve the coordination, participation and education of expert crowds. First, the project will develop modular, composable workflows to guide paid expert crowds to accomplish complex tasks such as design and engineering. A second system seeks to attract a new form of expert participation by reaching out to experts in their spare moments. A final system will enable crowd workers to learn new skills by leveraging existing tasks as work-study opportunities. This research will produce three concrete types of results: 1) techniques and patterns for guiding expert crowds and their contributions, 2) scientific results and evaluations that depict the strengths and weaknesses of expert crowds, and 3) open, public platforms and systems to recruit, guide, and train members of expert crowds.<br/><br/>Crowd work has the potential to employ millions of full-time workers and grant them the flexibility to guide their own careers. The proposed work advances a vision of how experts can engage in the future crowd-work economy, contribute to projects while improving their own skills, and be supported by practical knowledge and new sociotechnical systems. The project also includes a plan to use expert work-study techniques to provide realistic training in Stanford?s HCI curricula and develop a peer mentoring system to scale advising and informal learning."
"1054332","CAREER: Improving the Accessibility and Trust of Voice-based Social Media for Small Farmers in Developing Regions","IIS","Cyber-Human Systems","08/01/2011","03/21/2011","Tapan Parikh","CA","University of California-Berkeley","Standard Grant","Ephraim P. Glinert","07/31/2016","$499,948.00","","parikh@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7367","1045, 1187, 7367","$0.00","World food security depends on improving the productivity and profitability of small farmers across the developing world. Unfortunately, many of these farmers do not benefit from the latest information and technologies. With the right access, these farmers could solve their own problem. Unfortunately, due to their often limited education and technological access, the text-based, English-dominated Internet is not a useful resource for most small farmers across the world. On the other hand, low-cost mobile phones and wireless connectivity are revolutionizing communications. This research seeks to understand how voice-based social media, deployed on mobile phones, can be used by agrarian communities for collaborative problem-solving, information access and knowledge generation. In particular, the investigators are interested in the following research questions. 1) How can we make voice-based user interfaces more intuitive and accessible for users with limited formal education? 2) How can we make voice-based information more trust-worthy for users with no prior experience assessing online information resources? 3) What is the economic impact of providing access to new sources of information and advice?<br/><br/>Answering these questions can improve the design and adoption of voice-based social media applications worldwide. Advances could also make information access more intuitive for other inexperienced users, such as the elderly. Making information and services more accessible to marginalized groups holds tremendous potential for benefiting society. By making more voices heard, governments and service organizations can better understand and address their needs. This research will be conducted in collaboration with local non-profit organizations and community groups in India, who are actively developing and deploying real, working voice applications. By designing and testing proof-of-concept applications, we can influence wider scaling through empirical demonstrations of usability, adoption and impact. This research provides opportunities for students to develop new sustainable enterprises and working products. By conducting fieldwork abroad, U.S.-based students will develop a broader understanding of the opportunities and challenges of working there. Such opportunities can attract diverse new students to Computer Science - including women and minorities."
"1016713","RI: Small: Decision-Theoretic Control of Crowd-Sourced Workflows","IIS","Cyber-Human Systems, ROBUST INTELLIGENCE","09/15/2010","04/11/2012","Daniel Weld","WA","University of Washington","Standard Grant","Todd Leen","08/31/2014","$320,669.00","Mausam Mausam","weld@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367, 7495","7923, 9251, 7367","$0.00","Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people as an open request for services. Requesters use crowd-sourcing for a wide variety of jobs like dictation-transcription, content screening, linguistic tasks, user-studies, etc. These requesters often use complex workflows to subdivide a large task into bite-sized pieces (including the management of these tasks), each of which is independently crowd-sourced. These workflows are paramount to the success of crowd-sourcing, still, there has been little attention paid to methods for dynamically optimizing the throughput of a workflow. Controlling and optimizing such a workflow is an excellent application for AI research for two reasons. First, it is challenging in that the agent has to understand the dynamics of an uncertain, real-time environment and reason about distinct choices for a decision. More importantly, the domain has significant economic value -- progress can potentially impact hundreds of thousands of people and spur economic development in a fast growing sector.<br/><br/>This project is investigating complex workflows using a decision-theoretic framework that optimizes for a quality/price trade-off, with aims of (1) building statistical models of worker behavior derived from a large corpus of online behavior, (2) defining a declarative representation language to describe a wide range of workflows, and (3) developing an automated scheme that optimizes a general workflow resulting in an automated controller for making informed decisions at various stages of the process and for monitoring worker accuracies and computing corrections based on them. In the longer term, perhaps beyond the scope of this project, is (4) development of an interface optimizer that automatically learns the best user interface for a task based on user behavior increasing throughput of the workflow, and (5) integrating these ideas in an open-source, software toolkit to directly benefit the various requesters in managing their tasks."
"0905228","HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction","IIS","Cyber-Human Systems, TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace","09/01/2009","05/02/2012","Holly Yanco","MA","University of Massachusetts Lowell","Standard Grant","Ephraim P. Glinert","08/31/2014","$560,000.00","Kristen Stubbs","holly@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7367, 7795, 8060","7218, 7367, 7924, 9102, 9178, 9218, 9251, HPCC, 9215, 7795","$0.00","It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified. As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems. A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger. This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time. Using this information, the robot will be able to adjust its interaction accordingly. <br/><br/>Promoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities. The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots. Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance."
"1047715","EAGER: Bridging Geometric Manifold Theory and Higher-Dimensional Data Modeling for Visual Computing","IIS","Cyber-Human Systems, GRAPHICS & VISUALIZATION","11/01/2010","10/28/2013","Hong Qin","NY","SUNY at Stony Brook","Standard Grant","Jie Yang","10/31/2014","$118,792.00","","qin@cs.sunysb.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7367, 7453","7916","$0.00","The long-term goal of this research aims to systematically trailblaze a novel geometric manifold theory founded upon continuous polynomial representations, and to apply this mathematically-rigorous theory to both shape geometry and higher-dimensional, multi-attribute data modeling, analysis and visualization, with a special emphasis on visual computing applications. The research team is exploring new geometric manifold theory at the interface of differential geometry, numerical approximation theory, computational topology, and linear algebra. The study of new and important geometric manifold theory enables the accurate and effective modeling of higher-dimensional, multi-attribute volumetric datasets which are of complicated geometry, arbitrary topology, and with rich geometric features. This theory-centered research provides a sound theoretical foundation for rapid data modeling and data analysis. It has a potential to streamline the entire virtual prototyping processes for digital engineering in the future with longer-term research efforts by expediting data transformation from discrete samples to continuous manifold and spline-centric visual data representations."
"1017097","HCC: Small: Human-Driven Spatial Language for Human-Robot Interaction","IIS","Cyber-Human Systems","09/01/2010","07/31/2010","Marjorie Skubic","MO","University of Missouri-Columbia","Standard Grant","Ephraim P. Glinert","08/31/2014","$499,512.00","Laura Carlson","skubicm@missouri.edu","310 JESSE HALL","COLUMBIA","MO","652111230","5738827560","CSE","7367","7923","$0.00","When people communicate with each other about spatially oriented tasks, they more often use qualitative spatial references (such as ""behind"" in the spatial description ""Your eyeglasses are behind the lamp."") rather than precise quantitative terms. Although natural for people, such qualitative references are problematic for robots that ""think"" in terms of mathematical expressions and numbers. Yet, providing robots with the ability to understand and communicate with these spatial references has great potential for creating a more natural interface mechanism for robot users. This would allow users to interact with a robot much as they would with another human, and is especially critical if robots are to provide assistive capabilities in unstructured environments occupied by people. This project will do the following: empirically capture and characterize the key components of spatial descriptions that indicate the location of a target object in a 3D immersive task embedded in an eldercare scenario; develop and refine algorithms that enable the robot to produce and comprehend descriptions containing these empirically determined key components within this scenario; and assess and validate the robot spatial language algorithm in virtual and physical environments. This project will train graduate students in an interdisciplinary setting that encompasses psychology, computer science and engineering), and will directly involve undergraduate students in the robotics work at Missouri and in the human subject experimentation work at Notre Dame. This project will lead to a better understanding of how robots can and should be used for this class of assistive tasks in an eldercare scenario."
"1018008","HCC: Small: Life-Work Bridges: Design Knowledge for Information Systems that Connect Homeless Young People to Institutions","IIS","Cyber-Human Systems","09/01/2010","07/12/2012","David Hendry","WA","University of Washington","Continuing grant","Ephraim P. Glinert","08/31/2014","$352,992.00","","dhendry@u.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7367","7923","$0.00","Homeless young people, like most adolescents in American society, frequently use digital media, for life and work. Even if gaining access to computers is difficult, homeless youth, aged 13-25, go online for many purposes: to communicate with family and friends; to find and apply for jobs; to participate in popular culture; and in general to seek and use information in all its forms. Yet, this adoption of digital media presents a significant challenge to community-based service agencies. These organizations, focused on supporting youth's basic needs, are largely unprepared for bringing digital media into their programs. To tackle this challenge, this three-year project will first investigate how homeless young people conduct themselves in relation to digital media, especially at social networking sites such as MySpace. Then, seeking to accommodate their abilities and interests, this project will develop a web application that positions youth to successfully communicate with employers. Specifically, the system will enable youth to create appropriate online identities, to build dignified resumes, to find and apply for suitable work-related openings, and to share experiences. Finally, the system will be deployed at a service agency located in Seattle, WA and evaluated for its overall effectiveness in brokering relationships between youth and employers. In summary, this project will discover social and technology approaches for developing usable information systems that enable homeless young people to better communicate with institutions. Research findings, including theory, design methods, and guidelines, will contribute to a national dialog about the use of digital media for escaping homelessness."
"1018361","HCC: III: Small: Diffusion and Ranking in Social Media: A Computational Examination of the Role of Influence and Authority","IIS","Cyber-Human Systems","09/01/2010","06/10/2013","William Rand","MD","University of Maryland College Park","Standard Grant","William Bainbridge","08/31/2014","$552,840.00","Yogesh Joshi, Louiqa Raschid","wrand@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","7367, 7923, 9251","$0.00","The proposal aims at studying authorship flows in information diffusion in social media. The proposal takes an individual level approach to understanding diffusion and authorship flow as compared to existing macro level approaches. The proposed approach is to study the impact of factors such as the type of media format, the type of topics diffused and the valence of the information in information diffusion and authorship flow. An initial taxonomy will be used to classify the type of media format that may evolve with the study. Three models will be combined in the research. The dataset to be used large-scale blogs and tweets. If successful, the project can help to establish a theoretical foundation for understanding the diffusion and authority in digital media."
"1025428","RUI: VOSS: The Potential for Social Networking Cyberinfrastructure to Facilitate Virtual Organization Breeding Grounds","ACI","Cyber-Human Systems, VIRTUAL ORGANIZATIONS","09/01/2010","08/16/2010","Dhiraj Murthy","ME","Bowdoin College","Standard Grant","Kevin Crowston","08/31/2014","$399,553.00","","dmurthy@bowdoin.edu","6000 COLLEGE STA","Brunswick","ME","040111845","2077253767","CSE","7367, 7642","7642, 9150, 9229, 7367","$0.00","Virtual organizations have experienced an exponential growth due to their flexibility, cost effectiveness, efficiency, and ability to overcome geographic constraints. This project investigates how two scientific virtual organization breeding environments (online communities of practice) in the life sciences use social networking site technology to understand the potential of this cyberinfrastructure to foster trust and social cohesion among potential virtual organizations team members and lead to virtual organization formation and success. The research uses ethnographic and case study data (including visual maps of two virtual organization breeding environments and their interactions) to build theory and hypotheses about whether the use of social networking site technology in virtual organization breeding environments promotes virtual organization development and innovation (and, if it does, how). Quantitative data will be derived from monitoring and coding patterns of communication among participants from both VBEs. The research will also develop and extend Actor-Network-Theory and Social Network Analysis to virtual organization breeding environments improving our understanding of them as sociotechnical communities in which associations can be traced and analyzed.<br/><br/>The formation of virtual organizations is an important issue in many fields of science and engineering, as well as in industry. This research focuses explicitly on understanding the role of women in science and attracting women (an under-represented group) into the sciences. It will improve our understanding of the role of Web 2.0 technologies in interactions between scientists and of virtual organization development. Addressing the central question of whether social network systems meaningfully facilitate the social interactions that are required for a successful virtual organization, this project will provide a rich understanding of the formation, evolution and success of virtual organizations to guide the development of cyberinfrastructure. Results will be disseminated through a Facebook group, Twitter page, project website, and a public workshop."
"0905569","HCC: Medium: Collaborative Research: Generating Effective Dynamic Explanations in Augmented Reality","IIS","Cyber-Human Systems","09/01/2009","07/23/2012","Steven Feiner","NY","Columbia University","Continuing grant","William Bainbridge","08/31/2014","$803,216.00","","feiner@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7924, 9215, HPCC","$0.00","To survive and flourish, people must interact with their environment in an organized fashion. To do so, they need to learn, imagine, and perform an assortment of transformations on and in the world. Primary among these are manipulation of objects and navigation in space. This project integrates research in computer science and cognitive science to develop and evaluate augmented reality tools to create effective dynamic explanations that enhance manipulation and navigation, in conjunction with identification and visualization. Augmented reality refers to user interfaces in which virtual material is integrated with and overlaid on the user?s experience of the real world; for example, by using tracked head-worn and hand-held displays. Dynamic explanations are task-appropriate sequences of actions, presented interactively, with appropriate added information. The tools will be created in collaboration with subject matter experts for exploratory use in indoor and outdoor real world domains: navigating and identifying landmarks in a wooded park area, assembling a piece of furniture, and navigating and visualizing for planning the site of a new urban campus. Cognitive science research will determine the best ways to convey explanations and information to people. Computer science research will address the design and implementation of systems that embody the best candidate approaches for identifying objects and locations, specifying actions, and adding non-visible information. In situ experiments will be used to assess and refine the systems. <br/><br/>Manipulation, navigation, identification, and visualization are representative of important things that people do every day, ranging from fixing broken equipment to reaching a desired destination in an unfamiliar environment. The ways in which we perform these tasks could potentially be improved significantly through augmented reality systems designed using the principles to be developed by this project. Both the cognitive principles and the augmented reality tools will have broad applicability. The systems developed will inform the design of future systems that can aid the general public, for educational and recreational ends, as well as systems that can assist people with auditory, visual, or physical impairments."
"1049217","EAGER: Creativity in the Wild: Insight and Discovery with Wearable Sensors","IIS","Cyber-Human Systems","09/01/2010","06/03/2013","Frank Shipman","TX","Texas Engineering Experiment Station","Standard Grant","Ephraim P. Glinert","08/31/2014","$141,000.00","Steven Smith, Ricardo Gutierrez-Osuna","shipman@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7367","7367, 7788, 7916, 9251","$0.00","This project uses the capabilities of wearable sensors for two inquiries into creativity. The first inquiry investigates the potential for analysis and visualization tools to help users generate novel mental models from wearable sensor data and explore the implications of such models on their lifestyle and wellbeing. The ability to monitor internal state and relate it to behavior and environment can be transformational, because it allows users to develop insights and provides them with hard data with which to monitor their own progress. By focusing on minimally-invasive and inexpensive sensors the developments will have broad appeal for the general public. Prior research in wearable sensors has mainly focused on predicting psychological state (e.g., affect) from physiological signals, and characterizing the users? environment (e.g., from accelerometers, audiovisual sensors). However, relatively little research has been devoted to exploring the relationship between the internal (i.e. physiological) state of users and their environments; unfortunately, one cannot be understood without the other. Study of this relationship is an area where we believe visual workspaces can have a significant impact. <br/><br/>The second inquiry seeks to explore how wearable sensors may support research in creativity outside of controlled laboratory settings. Experimental methods for creative cognition in laboratory settings have been very successful in identifying a number of cognitive processes and general principles of creativity that apply across a number of domains, from engineering design to the visual arts. However, these studies do not inform us about how creative processes take place in the real world, when users must deal with the demands of their lives and distractions in their environments. Wearable sensors provide an opportunity for the researcher (and the user) to develop an understanding of how physiological variables and real-world environments affect the creative processes. Studies of creative cognition in natural settings, correlating cognitive and behavioral metrics with data from wearable sensors, can validate and greatly extend our scientific understanding of creative thinking in the real world. Whereas retrospective reports of one?s creative ideas are limited by participants? memories and by their subjective introspection, probing people in real-world settings, as proposed in our experiments, requires neither introspection nor retrospection. Thus, validated metrics of creative ideation can be applied in natural contexts without the reactivity that results from laboratory and field experiments."
"0963404","Collaborative Research: Measuring and Modeling Collective Intelligence","IIS","Cyber-Human Systems","01/01/2010","01/11/2010","Christopher Chabris","NY","Union College","Standard Grant","Ephraim P. Glinert","12/31/2014","$173,908.00","","chabrisc@union.edu","807 Union Street","Schenectady","NY","123083103","5183886101","CSE","7367","9215, HPCC","$0.00","The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research. But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence. One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College. The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems. For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups. Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups. Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups. A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems. This research will provide powerful new tools for managing and designing such systems. Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors. Imagine that this test could predict the team's future performance on a wide range of important tasks. And imagine that the test could also help suggest changes to the team that would improve its flexibility. Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks. From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently. This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts: With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it. With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems. The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
"0968470","SOCS: Socially Intelligent Computing to Support Citizen Science","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems, IIS SPECIAL PROJECTS, SOCIAL-COMPUTATIONAL SYSTEMS","09/01/2010","05/20/2013","Kevin Crowston","NY","Syracuse University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$533,449.00","","crowston@syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","1640, 7367, 7484, 7953","7367, 7495, 7752, 7953, 9251","$0.00","The NSF-funded project conducted by Kevin Crowston at Syracuse University will investigate the capabilities and potential of social-computational support systems in the context of citizen science, defined as ""partnerships between volunteers and scientists that answer real-world questions"". The research will examine nature of the computational systems currently used in a number of citizen science projects and will use these insights to improve computational support for different kinds of citizen science projects. The project will focus on the following three goals: (1) developing a practical understanding of the conditions under which social computation can enhance science and education; (2) generating new research models of social-computational systems that support large-scale public participation in scientific research; and (3) developing and testing social-computational systems that incorporate explicit knowledge about human cognitive and social abilities.<br/><br/>The project will produce societal benefits by investigating how involving the public in scientific research can advance scientific goals while contributing to the science education of the volunteer participants, determining the conditions under which citizen science can prove beneficial for large-scale data collection and analysis, and providing guidelines for improving the design and implementation of computational support systems for citizen science projects."
"0917401","HCC: Small: From Local Ties to Transnational Connections: The Role of Computer-mediated Communication in Relational Maintenance","IIS","Cyber-Human Systems","09/15/2009","03/08/2013","Paul Dourish","CA","University of California-Irvine","Standard Grant","William Bainbridge","08/31/2014","$499,999.00","Irina Shklovski","jpd@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7367","7367, 7923, 9215, HPCC","$0.00","The United States is a multi-cultural society, where uses of communication technology have become ubiquitous and routine. Although there has been a substantial amount of research on computer-mediated communication, very little has been said on the issue of cultural differences in assessing the uses and interpretations of current technologies. The very ubiquity of social computing applications makes the study of cultural differences in their use for relational maintenance difficult. Focusing on environments where social relationships are paramount for survival and where computer-mediated communication applications are relatively limited in number can help us examine how cultural preferences, social needs and constraints of available infrastructure shape the use of computer-mediated communication for relational maintenance. The goal of this research is to make empirical and theoretical contributions to ongoing research on cultural differences in the use of computer-mediated communication through the investigations of the role of social media in transnational contexts. This research will also contribute to the development of theory of the basic processes underlying social relationships through empirical investigations of non-western relational maintenance practices.<br/><br/>The results of this research will address how cultural differences can shape future development and design of human-centered computing applications and will enhance ongoing efforts to promote design and deployment of computer-mediated communication technologies in digitally nascent societies. By turning attention to the cultural contexts of technology use for relational maintenance, we also seek to engage with people whose perspectives are often unheard, including transnational migrants. Contextual study of Internet and social network site use is especially valuable in a culture that differs from the predominantly Western perspective that developed or provided templates for the development of the majority of current social computing applications."
"0917321","HCC:Small:Computational Studies of Social Nonverbal Communication","IIS","Cyber-Human Systems","09/01/2009","08/20/2010","Louis-Philippe Morency","CA","University of Southern California","Continuing grant","William Bainbridge","08/31/2014","$495,920.00","","morency@ict.usc.edu","University Park","Los Angeles","CA","900890701","2137407762","CSE","7367","7367, 7923, 9215, HPCC","$0.00","This research will create a new generation of computational tools, called contextual prediction models, for analyzing and modeling social nonverbal communication in human-centered computing. This computational study of nonverbal communication not only encompass the recent advances in machine learning, pattern analysis and computer vision, but goes further by developing and evaluating new algorithms and probabilistic models specifically designed for the domain of social and nonverbal communication. The ability to collect, analyze and ultimately predict human nonverbal cues will provide new insights into human social processes and new human-centric applications that can understand and respond to this natural human communicative channel. <br/><br/>This new endeavor will advance through the development of prediction models and their accompanying selection algorithms and feature representations for predicting human nonverbal behavior given a social context (such as the immediately preceding verbal and nonverbal behaviors of a conversational partner). The investigator's previous work has demonstrated the feasibility of using machine learning approaches to model nonverbal communication. Probabilistic sequential models were shown to improve performance of nonverbal behavior recognition during human-robot interactions and make possible the natural animation of virtual humans. This project addresses three fundamental challenges directly: feature representation (optimal mathematical representation of social context), feature selection (subset of social context relevant to prediction of nonverbal behaviors) and probabilistic modeling (efficiently learning the predictive relationship between social context and nonverbal behaviors). This research will evaluate and test the generalization of the computation tools using a large corpus of natural interactions in different settings (human-human, human-robot and human-computer) and domains (e.g., storytelling, interview, and meetings). <br/><br/>These prediction models will have broad applicability, including the improvement of nonverbal behavior recognition, the synthesis of natural animations for robots and virtual humans, the training of cultural-specific nonverbal behaviors, and the diagnoses of social disorders (e.g., autism spectrum disorder). The code resulting from this work will be made available to the research community through an open-source Matlab toolbox. The outcome of this research effort will produce state-of-the-art computational models more accessible to researchers who aim to analyze social nonverbal communication and develop natural and productive human-centered computing technologies."
"0916217","HCC: Small: Energy Signature of Interaction Techniques for Low Power Bi-Stable Displays Information Appliances","IIS","Cyber-Human Systems","09/01/2009","05/25/2010","Francois Guimbretiere","NY","Cornell University","Standard Grant","Ephraim P. Glinert","08/31/2014","$505,519.00","Rajit Manohar","francois@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923, 9215, 9251, HPCC","$0.00","Looking back at Weiser's 1991 vision of ubiquitous computing, many of his predictions have been surpassed, often by several orders of magnitude: information appliances sport ever more powerful processors, store in excess of 64 GB of data onto solid state chips, and have constant high-bandwidth access to the network. Yet one prediction that has not been realized, as anybody who uses mobile computers today can attest, is the ability to use information appliances for several days before recharging them. While battery life is the cornerstone (without sufficient battery life the burden of maintaining multiple mobile devices outweighs the advantages), three emerging technologies may significantly alter the energy footprint of information appliances: bi-stable displays which only consume energy when they are refreshed; Magnetic RAM (MRAM) which combines the speed of SRAM, the density of DRAM, and the non-volatility of FLASH memory; and a new generation of powerful embedded processors that support aggressive power saving strategies, and which offer a preview of the potential of energy efficient asynchronous processors. Combined, these technologies will make it possible to create systems where power consumption is near zero while quiescent, a significant departure from the behavior of current devices. The PI's goal in this project is to investigate how the various interaction techniques we know of today might benefit a low energy architecture enabled by the aforementioned emerging technologies. The team has extensive experience with hardware design, hardware simulation, and empirical evaluation. Project outcomes will contribute to a better understanding of the parameters influencing the design of very low power interfaces, and will include: an openly available hardware test bed for evaluating interaction technique energy signatures; the first systematic evaluation of the energy footprint of command selection and navigation techniques to complement the extensive performance data already gathered; an evaluation of the potential of sensor-assisted techniques to reduce the energy consumption of information appliances; and the first evaluations of the potential of asynchronous design to enable very low power information appliances. Evaluations will be performed in the lab and through longitudinal deployments, considering a variety of tasks, to further increase the external validity of the results.<br/><br/>Broader Impacts: Project outcomes will establish the empirical foundations for very low energy interface designs that will help researchers and designers better understand the energy implications of various interaction techniques. They will offer researchers and practitioners the tools and toolkits they need to quickly implement and evaluate the overall energy footprint of a design, and thus will significantly lower the barrier to entry into this research area. Furthermore, they will support new curricula that focus on energy consumption. Given that information appliance use is accelerating, and since the distinction between information appliances and personal computers is blurring, this work will have a great impact on reducing the overall energy consumed for our everyday information needs."
"1402723","Workshop on Frontiers in Image and Video Analysis","IIS","ROBUST INTELLIGENCE","01/15/2014","01/10/2014","Rama Chellappa","MD","University of Maryland College Park","Standard Grant","James Donlon","12/31/2014","$55,850.00","Larry Davis","rama@cfar.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7556","$0.00","The bombing attacks at the Boston Marathon in April 2013 presented the law enforcement community with significant challenges in terms of the volume and variety of video and still images acquired in the course of the investigation. Tens of thousands of individual media files in multiple formats were submitted from a variety of sources. These sources included broadcast television feeds, private Close-Circuit Television (CCTV) systems, mobile device photographs and videos recovered from the scene, as well as photographs and videos submitted by the public. Teams of analysts reviewed this evidence using mostly manual processes to determine the sequence of events before and after the bombing, ultimately leading to a quick resolution of the case. In the aftermath, it has become evident that the proliferation of video and image recording devices in fixed and mobile devices make it inevitable that a similar situation will occur in future events. As a result, it is incumbent upon the law enforcement community and the U.S. Government at large to further explore the use of automated approaches, available today or in the coming years, to better organize and analyze such large volumes of multimedia data. The findings of this workshop will help define the future research agenda. <br/><br/>The problem of searching for actionable intelligence information from unconstrained images and videos is an unsolved problem. Solving this involves addressing many sub-problems such as video summarization, shot detection/scene change detection, geo-tagging, robust face recognition, human action recognition, semantic description, image recognition and designing human in the loop systems. In addition, issues such as data collection and performance evaluation have to be addressed. Given that several hundreds of videos and a large collection of still images may be available for analysis, there is a great need to develop robust computer vision techniques. While many existing computer vision algorithms perform reasonable well in constrained acquisition conditions, their performance when unconstrained images and videos are given, is less than satisfactory. This workshop precisely addresses the challenges that arise in analyzing a large collection of unstructured image/video collection. This workshop explores the state of the art in algorithms being developed in academia that can support forensic analysis and identification in large volumes of images and videos (e.g., multimedia). The workshop informs long- and near-term research and development efforts aimed at optimally addressing this situation in the future. The workshop identifies those video and image analysis problems which are: (1) Considered solved (i.e., ready to deploy in specific operational scenarios); (2) Nearly solved (i.e., could lead to solutions with one to three years of development); and (3) Over-the-Horizon problems (i.e., those challenges requiring concerted effort over the next 3-5 years and beyond)."
"1258330","EAGER: Exploratory Research in Automated Computational Analysis of Inorganic Materials Libraries","IIS","INFO INTEGRATION & INFORMATICS","01/01/2013","09/06/2012","Carla Gomes","NY","Cornell University","Standard Grant","Sylvia J. Spengler","12/31/2014","$133,440.00","Robert van Dover","gomes@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7364","7364, 7916","$0.00","Combinatorial Materials Science represents a potentially powerful approach to identifying new and unexpected materials. This involves the rapid, high-throughput synthesis, measurement, and analysis of a large number of different materials. Understanding the functional behavior of the materials requires a characterization of the structure-property relations. Crystalline structure information can be obtained through X-ray diffraction studies. An unsolved challenge is to develop automated techniques for identification of unique diffraction patterns and to cluster the resulting patterns into contiguous phase fields corresponding to regions with different material composite structures. <br/><br/>Intellectual Merit: This exploratory project is aimed at establishing the feasibility of a unique interdisciplinary approach, involving a team of materials scientists and computer scientists, to address the challenge of structure (crystalline phase) identification of the composite materials. Specifically, the PIs propose to extract the key diffraction pattern features from the raw experimental data as a first step towards the development of computational methods for the identification of crystalline phases. <br/><br/>Broader Impacts: The project, if successful, will establish the feasibility of a key first step in an overall methodology to significantly speed the materials scientific discovery process in general, and in the search for new materials for the next generation fuel-cell technology in particular. The project brings together faculty and students, providing training in materials science, engineering, and computer science."
"1212948","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","01/08/2014","Marshall Tappen","FL","University of Central Florida","Standard Grant","Jie Yang","09/30/2017","$545,454.00","Hassan Foroosh","mtappen@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1144985","III: EAGER: A Framework for Large Data Analysis","IIS","INFO INTEGRATION & INFORMATICS, Software Institutes","09/01/2011","07/27/2011","Alin Dobra","FL","University of Florida","Standard Grant","Sylvia J. Spengler","08/31/2014","$100,000.00","Sanjay Ranka","adobra@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7364, 8004","7916, 8004, 7364","$0.00","Modern multicore architectures, that provide high raw gigaflops and teraflops, have deep memory hierarchies and low overhead threading capabilities. Lack of support for directly exploiting these capabilities leads to severe under-utilization especially for data intensive applications. This project expects to develop methods that efficiently use the available computational power to provide cost improvement for large scale data processing systems. <br/><br/>This project will develop a highly efficient computation framework called GLADE that will support a large class of data intensive applications, and will be based on a novel computational model called generalized linear aggregates. The commutative and associative properties of Generalized Linear Aggregates facilitate highly efficient parallel and distributed computation as well as exploitation of deep memory hierarchies, especially when multiple queries are simultaneously executed as is typical in many data-processing tasks. The resulting one to two orders of magnitude improvement in computational efficiency can be expected to yield corresponding reduction in cost and energy requirements of data processing tasks which in turn will make it feasible to analyze much larger data sets than currently possible.<br/><br/>The proposed work will make the synergistic combination of high performance computing and large scale data analysis widely available to researchers, and other interested groups in government, industry, and education. The enabling of a large number of data intensive application using inexpensive computers that cost in low tens of thousands of dollars will broaden the use of data analysis, exploration and mining for a wide variety of existing and emerging applications. Examples of such applications include network intrusion detection, social network analysis, climate data, ecosystem analysis, and customer relationship management. Additional information about the project can be found at: http://sites.google.com/site/sanjayranka/glade."
"1152576","EAGER: Visual Saliency with Discriminancy, Sparsity and Connectivity","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","01/01/2012","08/26/2011","Ming-Hsuan Yang","CA","University of California - Merced","Standard Grant","Jie Yang","12/31/2014","$135,742.00","","mhyang@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2092284318","CSE","7364, 7495","7916","$0.00","This project explores new directions to solving top-down modulated visual saliency maps with three basic principles: discriminancy, sparsity and connectivity. The research identifies key factors for advancing the state-of-the-art and presents a novel latent variable model, which extends the classical conditional random field with an embedded layer of latent variables to exploit the sparsity nature of features for saliency maps. This sparse latent variable conditional random filed model can be considered as a joint optimization of group sparse coding and conditional random field, which can be solved with an efficient stochastic gradient descent algorithm. Unlike bottom-up saliency, this model facilities high-level visual recognition tasks by learning sparse image structures from objects of interest. The key intellectual contributions of this project are a novel formulation that considers all three important properties for visual saliency in a unified framework, and an efficient learning algorithm to estimate the model parameters. <br/><br/>With the developed techniques, the search regions of these vision tasks can be constrained and thereby reduce the computational complexity and enhancing robustness. Effective top-down modulated visual saliency algorithms have broad applications including object detection, object recognition, visual tracking, scene analysis, image compression, surveillance, and robotics. It also provides a crucial tool for studying and analyzing fixations of eye movements in cognitive science. The research results including code and data are made public on the project web site."
"1065219","III: Medium: Scalable and Secure Database as a Service","IIS","INFO INTEGRATION & INFORMATICS","04/01/2011","07/22/2013","Samuel Madden","MA","Massachusetts Institute of Technology","Continuing grant","Frank Olken","03/31/2015","$1,200,000.00","Nickolai Zeldovich, Hari Balakrishnan","madden@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7364","7364, 7924","$0.00","The CirrusDB project seeks to address several key challenges that arise when building a ""database as a service"". The goal of such a service is to provide a SQL interface to many applications, storing data that today might be spread across hundreds or thousands of separate database management systems. This is attractive because the costs incurred by individual users in the form of software licensing, hardware, management, and energy can be substantially lowered because it will be possible to multiplex many different databases onto a smaller footprint. Moreover, the costs can be made proportional to actual usage, saving significant up-front investments by application developers. <br/><br/>The intellectual merit of CirrusDB relates to three key challenges in this area:<br/><br/>1) Multi-tenancy, in which the resource use of a complex set of database workloads are monitored and the databases are consolidated on to a minimum number of physical machines while ensuring performance isolation and live migration with no downtime. Unlike existing work on large-scale multi-tenancy, which has focused on co-locating tenants with similar schemas, CirrusDB attempts to co-locate tenants which have resource utilization profiles that will not exceed the capacity of the machine on which they are hosted.<br/><br/>2) Scalability in which the responsibility for query processing (and the corresponding data) is partitioned amongst multiple nodes in the service to achieve high throughput, using a novel graph partitioning strategy.<br/><br/>3) In which the DBaaS infrastructure executes SQL queries issued by applications over encrypted data, enabling complete SQL processing over fully private data. The key idea is to use the notion of ""adjustable security"" by encrypting the data in layers in a way that allows not just equality checks but also range queries, sorting operations, and joins to be executed efficiently.<br/><br/>CirrusDB will have broad impact in that it will result in database solutions that will a enable large, multi-node database service to be deployed both on a public cloud as well as in private data centers, providing multi-tenancy, scale-out using automatic partitioning, and privacy for SQL query execution. This will result in significantly lower administrative and capital costs required to run large-scale databases. CirrusDB will also reduce the barrier to entry for applications that use databases, because it will not be necessary to have in-house database expertise even when one needs high transactional performance.<br/><br/>For further information see the project web site at the URL: http://db.csail.mit.edu/cirrusdb/"
"1111328","RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","IIS","ROBUST INTELLIGENCE","09/01/2011","08/26/2011","Wilson Geisler","TX","University of Texas at Austin","Standard Grant","Kenneth C. Whang","08/31/2015","$302,048.00","","geisler@psy.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7925","$0.00","How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br/><br/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br/><br/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing."
"1150186","CAREER: Unlocking the neural code with spikes, currents and conductances","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE, ACTIVATION","09/01/2012","08/31/2012","Jonathan Pillow","TX","University of Texas at Austin","Continuing grant","Kenneth C. Whang","08/31/2017","$433,000.00","","pillow@mail.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","1640, 7495, 7713","1045, 8750","$0.00","This project aims to develop new mathematical and computational tools for understanding the basic information-processing strategies of neurons and neural populations in the brain. Recent technological advances have enabled large-scale recordings of neural activity from intact neural circuits, but there is a severe shortage of theoretical methods for revealing what this activity means--that is, what information it carries, and how it gives rise to behavior. The research described in this proposal will address these questions using novel statistical techniques for studying the neural code in single neurons and neural populations, using both extracellularly and intracellularly recorded neural data. <br/><br/>There are at least two important statistical aspects to the proposed research: first, new methods for reliably estimating the neurobiological variables of interest (e.g., spikes, membrane currents, synaptic conductances, etc.) from noisy experimental recordings; and second, powerful, flexible, model-based methods for understanding the complex, high-dimensional, and time-dependent relationship between sensory stimuli, behavioral responses, and neural activity. The three specific aims of the proposal focus on: (1) the encoding and decoding of decisions from multi-neuron spike trains in parietal cortex; (2) intracellular signals in visual cortex, at the level of membrane potential and synaptic currents, and their relationship to the information conveyed in spike trains; and (3) advanced methods for adaptive, ""closed loop"" neurophysiology experiments, leading to more informative experimental designs and more interpretable neural datasets. All three aims will involve intensive collaborations with experimental groups and will tightly integrate theory and experiment.<br/><br/>The proposed research will reveal new features of visual and cognitive representations in cortex, and will unlock the neural code at multiple levels of biophysical detail in sensory, motor and cognitive systems. More broadly, the research will shed new light on information flow in groups of neurons, with implications for both the treatment of brain disorders and the design of new technology."
"1016312","RI: Small: Perceptually Grounded Learning of Instructional Language","IIS","ROBUST INTELLIGENCE","09/01/2010","06/10/2011","Raymond Mooney","TX","University of Texas at Austin","Continuing grant","Tatiana D. Korelsky","08/31/2014","$450,000.00","","mooney@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7923","$0.00","This project is developing methods that allow a computer to automatically learn to understand and generate instructions in human language. Traditional approaches to natural-language learning require linguistic experts to laboriously annotate large numbers of sentences with detailed information about their grammar and meaning. In this project, instructional language is initially learned by simply observing humans following instructions given by other humans. Once the system has learned reasonably well from observation, it also actively participates in the learning process by following human-given instructions itself, or giving its own instructions to humans and observing their behavior. The approach is being evaluated on its ability to interpret and generate English instructions for navigating in a virtual environment (e.g. ""Go down the hall and turn left after you pass the chair.""). A novel machine learning method infers a probable formal meaning for a sentence from the resulting actions performed by a human follower, and then existing language-learning methods are used to acquire a language interpreter and generator. The learned system is being evaluated in a range of virtual environments, testing its ability to follow human-provided natural language instructions to achieve prescribed goals, as well as to generate natural language instructions that humans can successfully follow to find specific destinations. The methods developed for this project will contribute to the development of virtual agents in games and educational simulations that learn to interpret and generate English instructions, and eventually aid the development of robots that can learn to interpret human language instruction from observation."
"1065390","RI: Medium: Collaborative Research: Semantically Discriminative : Guiding Mid-Level Representations for Visual Object Recognition with External Knowledge","IIS","ROBUST INTELLIGENCE","08/01/2011","09/26/2013","Kristen Grauman","TX","University of Texas at Austin","Continuing grant","Jie Yang","07/31/2015","$498,994.00","","grauman@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7495, 7924","$0.00","This project explores (semi-)automatic ways to create ""semantically discriminative"" mid-level cues for visual object categorization, by introducing external knowledge of object properties into the statistical learning procedures that learn to distinguish them. In particular, the PIs investigate four key ideas: (1) exploiting taxonomies over object categories to inform feature selection algorithms such that they home in on the most abstract description for a given granularity of label predictions; (2) leveraging inter-object relationships conveyed by the same taxonomies to guide context learning, so that it captures more than simple data-driven co-occurrences; (3) exploring the utility of visual attributes drawn from natural language, both as auxiliary learning problems to bias models for object categorization, as well as ordinal properties that must be teased out using non-traditional human supervision strategies; (4) mining attributes that are both distinctive and human-nameable, moving beyond manually constructed semantics.<br/><br/>The project entails original contributions in both computer vision and machine learning, and is an integral step towards semantically-grounded object categorization. Whereas mainstream approaches reduce human knowledge to mere category labels on exemplars, this work leverages semantically rich knowledge more deeply and earlier in the learning pipeline. The approach results in vision systems that are less prone to overfit incidental visual patterns, and representations that are readily extendible to novel visual learning tasks. Beyond the research community, the work has broader impact through inter-disciplinary training of graduate and undergraduate students, and outreach to pre-college educators and students through workshops and summer camps encouraging young students to pursue science and engineering."
"1148973","EAGER: Noise and strong analog error-correcting codes in neural computation","IIS","ROBUST INTELLIGENCE","10/01/2011","08/31/2011","Ila Fiete","TX","University of Texas at Austin","Standard Grant","Kenneth C. Whang","09/30/2014","$175,000.00","","ilafiete@mail.clm.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7916","$0.00","This project aims to uncover the existence of a qualitatively better class of analog error-correcting codes than previously known in the brain, show how such codes can be used and decoded, and develop the theory for quantifying the performance of such codes. <br/><br/>Information theory was introduced into neuroscience relatively early, and the theory of efficient (source) coding has been widely embraced in the sensory neurosciences. However, the second branch of information theory, which deals with the maximally parsimonious addition of redundancy to recover signal from noise, has curiously not made inroads in neuroscience. Shannon's channel coding theorem revealed the existence of codes that make possible error correction at efficiencies previously thought impossible.<br/><br/>The investigator's central hypothesis is that the brain routinely employs such error correcting codes and the machinery required to decode and work with them. The hypothesis is motivated by a recent analysis of the grid cell code for animal location by the investigator and colleagues, showing it has unprecedented error-correction properties compared to known population codes in the brain (Sreenivasan & Fiete, 2011). The investigator proposes to: 1) Develop definitions and constraints for analog neural codes, to apply the channel coding framework to neural codes and thus characterize their ""goodness"" on error-correction. 2) Identify high-level coding properties that enable strong error-correction, and search for these properties in observed but poorly understood neural codes. At the same time, explore strong theoretical error-correcting codes that the brain may plausibly implement. 3) Model plausible neural mechanisms for decoding such codes. Decoding is inference, so this question can be more generally thought of as exploring neural mechanisms for hierarchical inference. <br/><br/>This project is computational and theoretical, and also involves close collaboration with neurophysiologists, to apply quantification techniques to neural data and work with experiments to inform the theories and test predictions."
"1320746","AF:Small: Divide-and-Conquer Numerical Methods for Analysis of Massive Data Sets","CCF","ROBUST INTELLIGENCE, NUM, SYMBOL, & ALGEBRA COMPUT","09/01/2013","08/07/2013","Inderjit Dhillon","TX","University of Texas at Austin","Standard Grant","Balasubramanian Kalyanasundaram","08/31/2016","$491,044.00","","inderjit@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495, 7933","7923, 7933","$0.00","Data is being generated at a tremendous rate in diverse applications, such as health care, genomics, energy management and social network analysis. Indeed, the recent moniker of Big Data emphasizes that massive volumes of data are ubiquitous. Thus, there is a great need for developing scalable and sophisticated methods for analyzing these data sets. This project is aimed towards one aspect of this challenge, namely, developing scalable and state-of-the-art numerical methods for modern problems that arise in machine learning. <br/><br/>This project will aim to develop divide-and-conquer methods for representative, concrete problems that arise in contemporary applications. These include (a) classification: kernel support vector machines, (b) regression: kernel regression and high-dimensional sparse approximation, (c) structure learning: graphical model estimation, (d) spectral approximation: multi-scale SVD computation, and (e) missing value estimation: matrix factorization. The project will develop specialized algorithms for each of these problems, in particular, developing tailored ways of dividing the problem into subproblems, solving the subproblems, and finally conquering the subproblems. Thus, general principles for applying the divide-and-conquer approach to other problems in large-scale machine learning will be uncovered. The project will lead to software for large-scale data analysis that will be efficient on modern multi-core computers. Impact of the new algorithms on various application areas, such as bioinformatics and network analysis, will be studied. Within computer science and applied mathematics, the project will have a broad impact on research in a variety of disciplines, including numerical analysis, numerical optimization, statistics, machine learning, data mining and parallel computing."
"1320894","RI: Small: Collaborative Research: Statistical ranking theory without a canonical loss","IIS","ROBUST INTELLIGENCE","08/01/2013","08/08/2013","Pradeep Ravikumar","TX","University of Texas at Austin","Standard Grant","Todd Leen","07/31/2016","$223,572.00","","pradeepr@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7495, 7923","$0.00","The problem of ranking objects occupies a central place in key technologies such as web search and recommendation systems. These technologies have a tremendous daily impact on the lives of millions of people. Moreover, the enormous scale of data on the web makes the use of machine learning especially attractive in constructing ranking algorithms. A huge amount of research effort has been devoted to developing efficient ranking algorithms that can deal with a variety of data sets encountered in web search and recommendation systems.<br/><br/>This project develops unifying mathematical theory that will provide a basis for understanding and categorizing existing algorithms and, more importantly, lead to deeper insights and new algorithms for the problem of learning to rank. The investigators also apply ranking algorithms to new domains. For example, ranking chemical reactions based on their plausibility will help chemists discover much-needed reaction bases for technologies such as carbon dioxide reduction, and conversion of natural gas into gasoline. <br/><br/>Fundamental advances in the statistical theory of ranking will be incorporated into undergraduate and graduate courses. Data sets and software developed will be made freely available to the scientific community. The investigators will also organize a workshop with a focus on interdisciplinary participation and involvement of under-represented groups in computer science and statistics.<br/><br/>The primary technical challenge in developing statistical ranking theory is the absence of a universally agreed-upon loss functions for ranking. This is in contrast to classic machine learning problems such as classification and regression, where there are only a few natural possibilities for the loss function and these are well-understood theoretically. The project addresses this gap by investigating how different loss functions for ranking affect fundamental theoretical properties such as learnability, and by creating a theory of convex surrogates that is applicable when loss functions abound. The project re-examines existing statistical literature on ranking with a computational lens. This will enable development of flexible and efficient plug-in decision rules that model the conditional probability of labels given inputs.<br/><br/>By incorporating the results of this research into courses and survey articles, the PIs help train a new generation of machine learning researchers and practitioners who will view ranking as a learning problem on par with classification and regression in mathematical depth as well as practical importance. Theoretical guidance for practitioners formulating new algorithms for ranking will improve the most common applications on the web."
"0915038","RI: Small: Learning Strategic Behavior in Sequential Decision Tasks","IIS","ROBUST INTELLIGENCE","09/01/2009","08/21/2009","Risto Miikkulainen","TX","University of Texas at Austin","Standard Grant","Todd Leen","08/31/2014","$455,000.00","","risto@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7495, 7923, 9215, HPCC","$0.00","Many routine, real-world tasks can be seen as sequential decision tasks. For instance, navigating a robot through a complex environment, driving a car in congested traffic, and routing packets in a computer network requires making a sequence of decisions that together minimize time and resources used. It would be desirable to automate these tasks, yet it is difficult because the optimal decisions are generally not known. Many existing learning methods lead to reactive behaviors that perform well in short term, but do not amount to intelligent high-level behavior in the long term. <br/><br/>This project is developing methods for learning strategic high-level behavior. Strategic methods need to (1) retain information from past states, (2) learn multimodal behavior, (3) choose between the different behaviors based on crucial detail, and (4) implement a sequential high-level strategy based on those behaviors. The neuroevolution methods developed in prior work solve the first problem by evolving (through genetic algorithms) recurrent neural networks to represent the behavior. To solve the remaining problems, these methods are being extended in the proposed work with multi-objective optimization, local nodes with cascaded structure, and with evolution of modules and their combinations. Preliminary results indicate that this approach is indeed feasible. <br/><br/>In the long term, developed technology will make it possible to build robust sequential decision systems for real-world tasks. It leads to safer and more efficient vehicle, traffic, and robot control, improved process and manufacturing optimization, and more efficient computer and communication systems. It will also make the next generation of video games possible, with characters that exhibit realistic, strategic behaviors: Such technology should lead to more effective educational and training games in the future. The OpenNERO open source software platform developed in this work will be made available to the research community."
"0917122","RI: Small: Efficient Reinforcement Learning for Generic Large-Scale Tasks","IIS","ROBUST INTELLIGENCE","09/01/2009","05/25/2010","Peter Stone","TX","University of Texas at Austin","Standard Grant","James Donlon","08/31/2014","$501,000.00","","pstone@cs.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","7495","7495, 7923, 9215, 9251, HPCC","$0.00","Recent advances in autonomous agents research are pushing our society closer to the brink of the widespread adoption of autonomous agents in everyday life. Applications that incorporate agents already exist or are quickly emerging, such as domestic robots, autonomous vehicles, and financial management agents. Reinforcement learning (RL) of sequential decision making is an important paradigm for enabling the widespread deployment of autonomous agents. However, a few notable successes notwithstanding, state-of-the-art reinforcement learning algorithms are not yet fully capable of addressing generic large-scale applications. <br/><br/>This project is advancing in four directions to scale-up application of RL systems. Specifically, the project is (1) developing algorithms to automatically structure the input, output, and policy representations for learning; (2) introducing parallelizable reinforcement learning algorithms so as to exploit modern parallel architectures; (3) unifying abstraction and hierarchical reasoning with model-based learning for the purpose of enabling intelligent exploration of large-scale environments; and (4) enabling reinforcement learning algorithms to benefit from low-bandwidth interactions with human users. Finally, we intend to unify the four research thrusts above into a single algorithm and conduct empirical evaluation on real-world/large-scale applications, to include biped robot balancing and walking, robot soccer in simulation and with real robots, and a full-size autonomous vehicle capable of planning paths in an urban environment.<br/><br/>In addition to research advances and implications for improving national infrastructure, the project will contribute to undergraduate and graduate curriculum development."
"1013278","CAREER: Towards Interactive Simulation of Giga-Scale Agent-Based Models on Graphics Processing Units","CCF","PARAL/DISTRIBUTED ALGORITHMS, HIGH-PERFORMANCE COMPUTING, INFO INTEGRATION & INFORMATICS, ALGORITHMIC FOUNDATIONS","08/16/2009","05/02/2013","Roshan D'souza","WI","University of Wisconsin-Milwaukee","Continuing grant","Almadena Y. Chtchelkanova","02/28/2015","$387,020.00","","dsouza@uwm.edu","P O BOX 340","Milwaukee","WI","532010340","4142294853","CSE","7934, 7942, 7364, 7796","1045, 1187, 7364, 9218, HPCC","$0.00","This research investigates techniques for efficient simulation of large scale agent-based models (ABMs). ABMs are increasingly being used to understand complex multi-scale behaviors in many natural, built and social systems. Although ABMs have the necessary structure to capture complex model characteristics in these systems, this very structure makes them computationally challenging. Current techniques for desktop computing and extensions to traditional high performance computing are incapable of efficiently handling this computational complexity. This has severely limited the applicability of ABMs. This research investigates novel techniques designed to leverage the massive computing power available on commodity graphics processing units (GPUs). It greatly expands the availability and applicability of agent-based modeling by effectively democratizing super computing for ABM simulation. Furthermore, it enables virtual testing of ""what-if"" scenarios in public policy, contingency planning for disaster relief, drug therapy design etc., on inexpensive desktop computers at realistic levels of detail. <br/><br/>The main challenge in this research is the re-formulation of ABM computation tofit the data-parallel model of GPUs. Specific research topics include representation of agent data, functions for agent motion, replication, decimation, communication, representation and manipulation of non-spatial agent networks, adaptive behaviors, run-time user interaction, fast visualization, hardware and model-aware automatic code optimization, and multi-level parallelism for multi-GPU platforms. The techniques developed are being applied to two specific problems in medicine: simulation of tuberculosis and systemic inflammatory response syndrome. These models enable efficient simulation of disease pathology and in-silico testing of novel therapeutic drug protocols. Educational topics include development of courses, outreach to K-12 students through development of ABM themed video games, undergraduate involvement in research, and the development of a comprehensive dissemination web page."
"1320410","Integrating low-level speech features into a model of speech perception","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","09/01/2013","09/16/2013","Naomi Feldman","MD","University of Maryland College Park","Standard Grant","Betty H. Tuller","08/31/2015","$179,724.00","","nhf@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","SBE","7252, 7495","7252, 7495, 9251, 9178","$0.00","Why are humans so much better than machines at recognizing speech? This research aims to measure differences between humans and machines in how they compute similarities between sounds. A computational model of speech perception will be trained on speech production data, using several types of features that are typically used in speech recognitions systems. It will then be tested on its ability to predict human listeners' responses in speech sound discrimination tasks. Results are expected to provide information about how the speech that listeners hear shapes their perception of sounds, as well as how well the information used by automatic speech recognition systems matches the information used by human listeners.<br/><br/>By allowing us to compare how humans and speech recognition systems use information when perceiving speech, this research will provide a tool that can help make speech recognition systems more human-like. Reverse engineering human perception can improve the way these systems generalize to new dialects, talkers, and noise conditions. This has the potential to facilitate the construction of systems for low-resource languages, broadening the impact of speech recognition technologies.<br/><br/>[Supported by SBE/BCS/PAC and CISE/IIS/RI]"
"0801528","CAREER: Knowledge Enhanced Clustering Using Constraints","IIS","INFO INTEGRATION & INFORMATICS","08/17/2007","01/14/2011","Ian Davidson","CA","University of California-Davis","Continuing grant","Christopher Clifton","08/31/2014","$458,490.00","","davidson@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7364","1045, 1187, 7364, 9216, HPCC","$0.00","This project addresses the development of general principled methods<br/>to efficiently include domain knowledge expressed as constraints into <br/>clustering algorithms. This not only allows improved clustering quality <br/>and algorithm performance but also finding insights that are novel and <br/>useful with respect to existing domain expertise. For example, phylogenetic <br/>trees built using hierarchical clustering should be consistent with existing <br/>domain knowledge such as that several species could not have evolved from <br/>one another. <br/><br/>Existing clustering under constraints work has focused on non-hierarchical <br/>clustering with conjunctions of must-link and cannot-link constraints that <br/>assert that two objects must or must not be in the same cluster. This work <br/>can be interpreted as expressing knowledge using a limited logic comprised <br/>of instances as objects, two binary relations (must-link and cannot-link) <br/>and a single connector (and).<br/><br/>This project will make three primary contributions. Firstly, it will examine <br/>a more complete logic to represent knowledge by adding in new relations, a <br/>complete set of connectives (not, and, or, implication), universal and <br/>existential quantifiers and new objects. This logic can express a large <br/>variety of knowledge such as minimum/maximum cluster separation, cluster <br/>width and even forcing distributions of certain objects across clusters. <br/>Secondly, it will investigate incorporating constraints beyond non-hierarchical <br/>clustering algorithms into algorithms for hierarchical agglomerative clustering, <br/>graph and social network clustering, and feature selection for clustering. <br/>Lastly, it will explore the computational challenges of using constraints by <br/>identifying easy to satisfy sets of constraints and developing a framework to <br/>explain why some constraint sets are more useful than others. <br/><br/>This project will demonstrate and validate its technical contributions on two <br/>core application domains: analysis of pandemic micro-simulations results to <br/>aid in disaster preparation and image mining. The long term vision is to <br/>incorporate knowledge efficiently in a principled manner into other data mining <br/>tasks such as classification, anomaly detection and association rules. <br/><br/>Project outreach for high school and undergraduates students will be in the <br/>form of hands-on discovery learning courses with emphasis on the two core <br/>application domains. For graduate students and researchers the tutorial slides, <br/>papers, datasets and software generated from the project will be freely <br/>available. <br/><br/>Further information on this project may be found at the URLs <br/>http://www.constrained-clustering.org and http://www.cs.albany.edu/~davidson."
"0844654","CAREER: Analyzing the Sequential Structure of Music Audio","IIS","INFO INTEGRATION & INFORMATICS","02/01/2009","05/13/2013","Juan Bello","NY","New York University","Continuing grant","Maria Zemankova","01/31/2015","$560,504.00","","jpbello@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7364","1045, 1187, 7364, 9216, HPCC, 9251","$0.00","The proposal offers an innovative approach to automatic music audio analysis using signal processing and harmonic methods. This is a contribution to the field of Music Information Retrieval (MIR) based on isolating chord sequences in western tonal music archives. The approach is modeled in part on work in bioinformatics, particularly work in structure alignment. The proposed work intends to expand on current approaches to music analysis whcih are limited because of insufficient attention to temporality - a key aspect of musical composition. A new signal processing method is proposed for the isolation of chords and chord sequences."
"1161860","RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","IIS","ROBUST INTELLIGENCE","06/01/2012","09/26/2013","Ramin Zabih","NY","Cornell University","Continuing grant","Jie Yang","05/31/2015","$431,512.00","","rdz@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495","7924, 7495, 9251","$0.00","Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection.<br/><br/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers."
"1347214","EAGER: Formal models of intention","IIS","ROBUST INTELLIGENCE","09/01/2013","08/23/2013","Yoav Shoham","CA","Stanford University","Standard Grant","James Donlon","02/28/2015","$150,000.00","","shoham@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7495, 7916","$0.00","The project conducts formal, basic research into the modeling of ""intention''. This under-researched and ill-understood concept underlies many applications, including online search, calendars, intelligent dialog systems, security applications, self-driving cars, military applications, and many more. This particular project is concerned with domain-independent, formal models underlying all such applications. 'informational attitudes' such as knowledge and belief which capture the information available to the agent, and 'motivational attitudes' such as goals, preference and utility which capture what the agent cares about, have been studied extensively. In contrast, and despite their importance, ""action attitudes"" which capture the agent's attitude towards different actions she might take in light of her motivations and the information available to her, have been poorly studied. This is true in particular of intention, perhaps the most basic action attitude, and the focus of this project.<br/><br/> The project is grounded in the Principal Investigator's prior work, in which he laid out a computational point of view, dubbed the ""database perspective''. That work, which offered an axiomatic theory of the joint revision of belief and simple ('atomic') action intention, is being extended along multiple dimensions:<br/><br/>-- Modeling complex intentions, using Dynamic Epistemic Logic (DEL).<br/>-- Modeling achievement intentions.<br/>-- Modeling teleology.<br/>-- Developing a quantitative (""probabilistic"") theory of intention."
"1319318","RI: Small: Closing the Loop: Inducing High-Precision Grammars for Generating Disambiguating Paraphrases","IIS","ROBUST INTELLIGENCE","09/01/2013","12/19/2013","Michael White","OH","Ohio State University","Continuing grant","Tatiana D. Korelsky","08/31/2015","$307,982.00","","mwhite@ling.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7495","7495, 7923, 9251","$0.00","This project investigates trainable methods of paraphrasing natural language sentences to effectively disambiguate their meaning, using precise, bidirectional grammars induced from corpora to ""close the loop""' between parsing and generation. The approach generalizes previous work on probabilistically avoiding ambiguity in natural language generation to a broad coverage setting, disambiguating only as necessary in order to better balance clarity and readability. Generating disambiguating paraphrases in a broad coverage setting makes it possible to explore ways of adapting parsers to new domains using crowd-sourced judgments of meaning similarity. Accordingly, the project explores methods of (1) inducing OpenCCG grammars from the dependency output of parsers such as the C&C parser, (2) generating paraphrases with OpenCCG that explicitly aim to avoid likely distractor interpretations, (3) collecting meaning similarity judgments between the original sentence and paraphrases of its most likely interpretations, and (4) retraining the parser using the collected judgments. To evaluate the approach while also conducting outreach, the project involves data collection and experimentation at Ohio State's language research pod at the COSI science museum, in addition to the use of Amazon's Mechanical Turk.<br/><br/>By closing the loop between interpretation and generation, the project promises to dramatically enhance the prospects for using crowd-sourcing to adapt natural language processing tools to new domains. The project will also enable international collaborations with the University of Sydney, and help to educate the public about language science and technology, providing an inspirational example of science in action to the children who attend COSI."
"1218277","III: Small: Optimization Techniques for Scalable Semantic Web Data Processing in the Cloud","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/11/2013","Kemafor Anyanwu-Ogan","NC","North Carolina State University","Continuing grant","Frank Olken","08/31/2015","$446,942.00","","kogan@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7364","7923","$0.00","The use of cloud-based data processing platforms is an increasingly attractive alternative for large-scale data processing. There is active investigation into their use for various types of processing tasks on large-scale unstructured and structured data. However, due to an increased interest in many communities to enable more automatic sharing and exchange of data on the Web using Semantic Web techniques, there is a rapid surge in the availability of very large, real-world, Semantic Web datasets. Such data are semi-structured and have more complex processing requirements than relational data processing due to the fine-grained modeling of data and also the need for inferencing during processing. Consequently, existing optimization techniques for cloud data processing platforms which often adapt relational processing optimization techniques do not address the needs of such workloads. Further, such techniques do not adequately account for the nuances of cloud runtime platforms such as Hadoop e.g., dataflow length as a cost metric, no a-priori existence of indexes and statistics. <br/><br/>This project contributes insight into query optimization requirements for Semantic Web data processing on Map Reduce platforms. Its contributions include a novel Nested TripleGroup data model and Algebra (NTGA), algebraic and dynamic cost query optimization techniques; inter and intra-work sharing techniques, data representation formats and system architecture issues of integrating Semantic Web optimization techniques into frameworks such as Apache Pig. The impact of this project will cut across the increasing range of communities that are aggressively adopting Semantic Web tenets such as, scientific, business, government and other general-purpose communities."
"1217183","RI: Small: Collaborative Research: Exploring Audiovisual Emotion Perception using Data-Driven Computational Modeling","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","09/01/2012","12/06/2013","Emily Provost","MI","University of Michigan Ann Arbor","Continuing grant","Kenneth C. Whang","08/31/2014","$256,622.00","","emilykmp@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7252, 7495","7252, 7495, 7923, 9251","$0.00","This project explores perception-driven models of human audio-visual emotion using statistical analyses, data-driven computational modeling, and implicit sensing. Emotion underlies and modulates human communication. It is used in the diagnosis of many mental health conditions and is tracked in therapeutic interventions. Research in emotion perception seeks to identify models that describe the felt sense of 'typical' emotion expression -- i.e., an observer/evaluator's attribution of the emotional state of the speaker. This felt sense is a function of the methods through which individuals integrate the presented multi-modal emotional information. However, the nature of the interaction of the multi-modal cues is still an open question. This project will investigate multi-modal cue integration by studying how emotional inconsistency affects human perceptual judgment. In pursuit of this goal, the research objectives of this proposal are (1) to identify and validate primary and secondary audio-visual cues responsible for emotion perception, (2) to create a data-driven model to automatically predict the emotion perception of an evaluator, and (3) to predict evaluator state using implicit physiological and body gesture cues. <br/><br/>The first research objective addresses the open question of how distal cues, the encoding of a speaker's communicative goals, interact and result in the felt sense of specific emotion states. Novel techniques will be used to identify emotionally salient distal cues using emotionally consistent and inconsistent audio-visual information. This identification has implications in the design of emotion classification algorithms and the emotional behavior of affective agents. The second research thrust addresses the open question of how human-centered models (rather than data-driven models) can be designed for use in emotion classification tasks. The project will investigate the efficacy of novel dynamic structures to model emotionally inconsistent information. These new structures will provide insights into the development of human-centered emotion classification inspired by the emotion perception process, rather than solely on data fluctuations. The third research objective addresses the open question regarding the effect of audio-visual emotion evaluation tasks on the evaluator's internal state. We will assess evaluator inattention in the context of emotional evaluation tasks. Models that can accurately predict evaluator inattention have applications in long-term human-computer and human-robot interaction platforms. The insights gained from this project will facilitate the design of emotion-focused algorithms that replicate the process by which humans interpret and integrate emotional audiovisual signals. It will also aid in the creation of emotional interfaces for health informatics applications, which will lead to more specifically targeted interventions and treatments for many mental health conditions including schizophrenia, depression, and autism."
"1318638","RI: Small: Robotic Search of Transient Objects","IIS","ROBUST INTELLIGENCE","09/15/2013","09/02/2013","Dezhen Song","TX","Texas Engineering Experiment Station","Standard Grant","Satyandra Gupta","08/31/2016","$349,971.00","","dzsong@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9794587617","CSE","7495","7495, 7923","$0.00","Searching for objects in physical space is one of the most common tasks for robots. Transient targets refer to a class of objects which are not identifiable unless momentary sensing and/or signaling conditions are satisfied. The transient property is often introduced by target attributes, privacy concerns, environment constraints, and/or sensing limitations. For example, searching for a black box on the ocean floor after an airplane crash is a typical transient target search (TTS) task because the search relies on the transient radio/sonar signals emitted from the black box. This project develops the theoretical foundations for TTS problems that will impact a large group of real world applications. Due to their stochastic nature, TTS problems are challenging because the transient property is often coupled with factors such as sensing range limits, various coverage functions, constrained mobility, signal correspondence, limited number of searchers, and a vast searching region. Extensive modeling and analysis will be performed to understand the various factors in the searching process. As the result, a new computation framework consisting of models, metrics, and algorithms that integrate the resource to improve TTS performance will be developed with three focuses: searching time analysis that addresses the critical performance issue, multi-target search that focuses on unique signal correspondence and collaborative sensing issues, and planning for coordination of robots which includes both centralized and decentralized approaches. This project also develops new course materials for undergrad and graduate students to better understand algorithms and robust intelligence in robotic searching applications."
"1219278","III: Small: Algorithms and Computations for RNA Structure Prediction","IIS","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, Physiolg Mechansms&Biomechancs","10/01/2012","09/09/2012","Daniel Gusfield","CA","University of California-Davis","Standard Grant","Sylvia J. Spengler","09/30/2015","$499,444.00","Patrice Koehl","gusfield@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","1165, 1640, 7364, 7658","7923, 8750","$0.00","This project concerns the development of efficient algorithms and programs for RNA structure prediction, using both established models of RNA structure and dynamics, and emerging new models. Computational RNA structure prediction is a classic area of research, starting more than thirty years ago, and yet it is still a vital and open area. The motivation for this project is based on three fairly recent developments. First, in the last decade, there has been a huge growth in understanding of the varied biological roles and properties of RNA. Second, there has been recent, yet still limited, progress on experimentally determining new RNA structures and dynamics. Finally, and most central to this project, there have been recent theoretical and practical advances in the time and space-efficiency of solutions to classic problems of RNA structure prediction. This also points to the fact that additional powerful algorithmic techniques developed in the computer science community have not been fully exploited (or in some cases ever applied) to problems of RNA structure prediction. This provides a clear and compelling opportunity to improve computational RNA structure prediction, i.e., through improvement in the efficiency (in time and space) of computational methods, and by incorporating new biological and structural insights into the formulation of computational models and problems.<br/><br/>This project will improve the efficiency of algorithms for a variety of RNA structure prediction problems through the further development and exploitation of known, powerful algorithmic techniques that have not been previously introduced or fully exploited in addressing RNA structure problems. The project will also provide implementations of these ideas as computer programs and empirically validate the theory. The project will also articulate new computational problems and models for RNA structure and dynamics, driven by new and emerging biological and structural results."
"1218275","III: Small: Computational Inference of Microbial Community Structures from Environmental Shotgun Reads","IIS","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, Physiolg Mechansms&Biomechancs","10/01/2012","09/04/2012","Xiaoman Li","FL","University of Central Florida","Standard Grant","Sylvia J. Spengler","09/30/2015","$373,945.00","","xiaoman@mail.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078821120","CSE","1165, 1640, 7364, 7658","7923, 8750","$0.00","Microbes play important roles in our everyday life. However, the majority of microbial species cannot be readily studied because they cannot be separated from their environments, i.e., microbial communities. Based on mixed DNA sequences directly extracted from microbial communities, metagenomics has emerged as an important field studying microbes and microbial communities. ""Community structure identification"" is one of the core problems in metagenomics. The goal is to identify species present in a specific microbial community and their relative abundance from the extracted mixed DNA sequences. <br/><br/>Because of the taxanomic bias towards culturable species in public databases and short DNA sequences from next generation sequencing platforms, there is an urgent need to create computational methods that can effectively address the ""community structure identification"" problem. In order to minimize the effect of the taxonomic bias and the short length of DNA sequences, the proposed research will create a statistical framework to bin reads that are likely from the same species based on k-tuple frequencies. With this framework, a series of algorithms will be designed to infer the community structures by integrating large-scale genomic sequences and their annotations. The research activities will be evaluated based on both simulated and experimental data. An accompanying software package will also be developed and released to the research community for free. The proposed methods and tools will help lay the foundation for further studying the microbes towards significantly advancing the scientific understanding of microbes and microbial communities.<br/><br/>This project will provide research experience for minority high school students and undergraduates. It will also educate undergraduates and graduates in metagenomics through curriculum development, seminars, mentoring activity, and annual research symposiums. In addition, this project will disseminate the research results on metagenomics through publications, conference presentations, free software development, and others. Finally, by attacking a core problem in metagenomics and providing a variety of accurate inferences, this research will greatly advance the current knowledge of microbes and microbial communities."
"1218201","III: Small: Topology-based approaches to integrated analysis of transcriptomic, protein interactomic and phenotypic data","IIS","ADVANCES IN BIO INFORMATICS, INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS, Physiolg Mechansms&Biomechancs","10/01/2012","07/15/2013","Jianhua Ruan","TX","University of Texas at San Antonio","Continuing grant","Sylvia J. Spengler","09/30/2015","$452,657.00","","jruan@cs.utsa.edu","One UTSA Circle","San Antonio","TX","782499113","2104584340","CSE","1165, 1640, 7364, 7658","7923, 8750","$0.00","High-throughput technology now allows measuring the activities and interactions of tens of thousands of molecules in the cell simultaneously, opening new doors to systems-level scientific exploration in biology. Advanced computational methods are in development to analyze the huge amount of data to extract patterns that represent knowledge and to construct predictive models that have the promise to determine the characteristics of an organism, such as cancer outcomes or plant growth phenotypes. To help achieve these goals, this project aims at developing efficient and effective computational algorithms and tools to integrate heterogeneous and noisy high-throughput data, and to analyze them in ways that treat genes as inter-connected rather than independent components of the cell. <br/><br/>Biological networks are mathematical models that describe the interactions among molecules in the cell and are critical to the modeling and understanding of complex biological systems. However, the large sizes and complexity of biological networks as well as the noisy and incomplete data pose critical challenges to network-based data analysis. To tackle these challenges, a practical and intuitive strategy is to analyze/utilize such networks on the level of functional pathways, i.e., genes/proteins involved in similar biological processes, which would significantly reduce the complexity of biological networks and improve the understanding of complex phenotypes. As the current knowledge of functional pathways is rather limited for most species, this project will develop a set of algorithms and software tools for fully automated discovery of dense subnetworks as candidate functional modules, and develop functional module-oriented algorithms for analyzing/utilizing biological networks for several real applications. First, this project will develop algorithms to improve network quality and network module discovery using information embedded in network topology. For networked (e.g. protein-protein interaction) data, topology is utilized to improve edge reliability, and subsequently module discovery, using a novel topological similarity measurement based on random walks on graphs. For non-networked (e.g., transcriptomic) data, global network topology is utilized to construct an ""optimal"" network that enables fully automated module discovery without any user-specified parameters. Second, this research will develop computational methods to systematically investigate the relationship between network topology and biological functions, which is expected to advance the current understanding of the organizing principles of biological networks, and facilitate prioritizing genes in disease studies. Finally, this project proposes a novel Steiner tree based algorithm for identifying potential causal genes associated with cancer phenotypes, and a novel similarity metric to compare patients based on pathway/subnetwork-level gene expression patterns, which can be easily combined with existing clustering/classification algorithms for network-based prediction of cancer outcomes. <br/><br/>The final outputs of this project will include both bioinformatics tools for integrative data analysis and databases of biological knowledge discovered from different input datasets. These tools and resources will be made freely available on the web, which can be used by a broad range of researchers who are interested in bioinformatics algorithm development or applications. These tools and resources will be applied to study several biological processes of central interests to collaborators, who have committed to validate some of the computational predictions. These include identifying novel plant hormone response genes, predicting and characterizing DNA damage response genes, and predicting metastasis potentials for breast cancer patients, by integrating protein-protein interaction and transcriptomic data. This project will also contribute to the advancement of computing with the development of novel network link prediction and module discovery algorithms and network-constrained clustering/classification methods that are expected to have immediate applications in other domains besides biological sciences. The activities undertaken as part of this research will be incorporated into several courses and will expand the educational and research opportunities available at the University of Texas at San Antonio, a minority-serving institute where the majority of undergraduates are from under-represented minorities, and is expected to increase the geographic and ethnic diversity and encourage the participation of minority groups in bioinformatics and computational biology research."
"1320366","RI: Small: Collaborative Research: Towards Modeling Source Separation from Measured Cortical Responses","IIS","ROBUST INTELLIGENCE","09/15/2013","09/08/2013","Edward Chang","CA","University of California-San Francisco","Standard Grant","Kenneth C. Whang","08/31/2015","$180,006.00","","changed@neurosurg.ucsf.edu","1855 Folsom St Ste 425","SAN FRANCISCO","CA","941430812","4154762977","CSE","7495","7495, 7923","$0.00","This project will use new technologies for measuring brain activity to understand in detail how human listeners are able to separate competing, overlapping voices, and thereby to help design automatic systems capable of the same feat. Natural environments are full of overlapping sounds, and successful audio processing by both humans and machines relies on a fundamental ability to separate out sound sources of interest. This is commonly referred to as the ""cocktail party effect,"" based on the ability of people to hear what a single person is saying despite the noisy background audio from other speakers. Despite the long history of research in hearing, this exceptional human capability for sound source separation is still poorly understood, and efforts to automatically separate overlapping voices by machine are correspondingly crude: although great advances have been made in robust processing of noisy speech by machine, separation of complex natural sounds (such as overlapping voices) remains a challenge. Advances in sensor technology now enable the modeling of this function in humans, giving an unprecedented, detailed view of sound representation processing in the brain. This project works specifically with measurements of neuroelectric response made directly on the surface of the human cortex (currently with a 256-electrode sensor array) for patients awaiting neurosurgery. Using such measurements made for controlled mixtures of voices, the project will endeavor to both develop models of voice separation in the human cortex by reconstructing an approximation to the acoustic stimulus from the neural population response, and in the process learning the linear mapping between the neural response back to a spectrogram measure of the stimulus. To attempt to significantly improve the ability of machine algorithms to mimic human source separation capability, the project will also focus on a signal processing framework that supports experiments with different combinations of cues and strategies to optimize agreement with the recordings of neural activity. The engineering model is based on the Computational Auditory Scene Analysis (CASA) framework, a family of approaches that have shown competitive results for handling sound mixtures."
"1200592","Novel Efficient Clustering Techniques for Data Mining, Ranking, Pattern Recognition and Segmentation of Large Scale Data Sets","CMMI","INFO INTEGRATION & INFORMATICS, OPERATIONS RESEARCH","09/01/2011","10/06/2011","Dorit Hochbaum","CA","University of California-Berkeley","Standard Grant","Sheldon Jacobson","07/31/2015","$325,000.00","","hochbaum@ieor.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","7364, 5514","072E, 073E, 077E, 7364, 9102, 5514","$0.00","The goal of this research is to investigate and develop discrete optimization algorithms for problems of clustering, pattern recognition, data mining and image processing. The research will address the theory and practice of such discrete optimization techniques, and will compare them to traditional approaches including variational models, spectral analysis, support vector machines and Principal Component Analysis. Algorithms will be implemented and their practical performance will be evaluated in applications of medical imaging; security detection; and image segmentation. The theoretical analysis will address the performance of algorithms for several clustering problems, which cannot be solved efficiently and optimally. For such known hard problems the performance will be evaluated in terms of how close the solutions attained are to the optimum, or the worst case error ratio. Efficient implementations will be developed to solve quickly pattern recognition and clustering problems on a sequence of data-sets that differ slightly from each other (e.g. for dynamically changing images, as in video). <br/><br/>The results of this research are expected to improve automated or semi-automated methodologies for pattern recognition, image segmentation, clustering and co-segmentation. The anticipated benefits include the reduction in cost and the frequency of human error in image analysis. In particular, automatic identification of unusual or pathological features is expected to improve diagnosis and reduce the cost of evaluating medical images by introducing accurate and fast automated procedures. The high speed of the proposed methodologies will permit real time deployment and mayl contribute to speeding up the rate of research and development in health-care, biological sciences and homeland security applications."
"1162581","RI: Medium: Quantifying and utilizing confidence in machine learning","IIS","INFORMATION TECHNOLOGY RESEARC, ROBUST INTELLIGENCE","09/01/2012","08/31/2012","Yoav Freund","CA","University of California-San Diego","Standard Grant","Todd Leen","08/31/2016","$1,000,000.00","Kamalika Chaudhuri, Sanjoy Dasgupta","yfreund@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","1640, 7495","7924","$0.00","This project defines meaningful notions of confidence in prediction, designs procedures for computing such notions, and applies these procedures to core machine learning tasks such as active learning, crowd-sourced learning, and tracking. In many applications it is helpful to have classifiers that output, together with each prediction, a rating of the confidence that the prediction is in fact correct. Existing literature either provides various ad-hoc ways for computing such ratings which typically lack a rigorous mathematical footing, or provides mathematically consistent methods (in the Bayesian framework) for computing confidence ratings under very strong assumptions that are unlikely to hold in practice. The research team investigates methods of computing measures of confidence that are mathematically rigorous while making minimal assumptions on the way data is generated, and use these measures to further develop solutions to core machine learning tasks.<br/><br/>Defining and computing mathematically sound measures of confidence lies at the heart of machine learning, pattern recognition and uncertainty in AI. Confidence-rated prediction, active learning, and tracking are fundamental tasks of machine learning and statistics that arise repeatedly in large-scale problems; this project will develop rigorous solutions to these problems. The algorithms developed in this work are tested and used in the Automatic Cameraman project, an interactive, audio-visual installation in the UCSD Computer Science department. The interactive Automatic Cameraman system are used an educational tool to be extended in many different directions, by teams of students at a variety of skill levels."
"1320059","RI: Small: Binaural Sound Source Separation Robust to Listener Head Movements","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/01/2013","08/06/2013","Jonas Braasch","NY","Rensselaer Polytechnic Institute","Standard Grant","Tatiana D. Korelsky","07/31/2015","$186,624.00","","braasj@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7252, 7495","7495, 7923","$0.00","The goal of this project is to develop a new binaural model to separate sounds in complex environments. The new aspect of the model is that it can utilize head movements to improve its localization performance by analyzing dynamic localization cues and combining these with information about its own head position. In addition, the model uses a dual approach to eliminate the influence of room reflections on sound source localization and segregation. In the first stage, specular reflections are eliminated using an autocorrelation- based algorithm. In the second stage, diffuse reverberation is removed by measuring interaural cross correlation across time/frequency bins, knowing that these values decrease with decreasing direct-to- reverberant energy ratio. The model development is accompanied by a behavioral study to better understand the underlying principles of how humans can perform robustly in complex scenarios. The results are also used as a benchmark test for the model algorithms.<br/><br/>This project intends to bridge the gap that exists between fundamentally knowing how the auditory system processes binaural tasks for simple multiple-sound-source scenarios, and understanding and modeling how it performs when the environment reaches real-life complexity. The resulting model is expected to operate in real time to localize sound sources in robot or surveillance applications or serve as a front end for sound- source separation algorithms, speech recognizers, predictors for acoustical quality of rooms, and Computational Auditory Scene Analysis (CASA) models."
"1251450","Discourse and prosody in non-native speakers' reference resolution","BCS","LINGUISTICS, ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","09/01/2013","08/13/2013","Therese Gruter Nell","HI","University of Hawaii","Standard Grant","William J. Badecker","02/28/2017","$286,827.00","Amy Schafer","theres@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","SBE","1311, 7495, 9150","1311, 7495, 9150","$0.00","Pronouns like 'he' and 'she' are among the most frequently used words in English. Yet neither a dictionary nor a grammar book will satisfy a learner of English as a second language who is trying to understand their full meaning and use. Pronouns often occur in contexts that contain more than one possible referent. Native speakers accumulate knowledge of patterns in the language that shift the interpretive preference one way or another. One such pattern involves the nature of the event being described: for example, a pronoun is more likely to refer to the doer of the last-mentioned action when that action is incomplete. Another pattern involves prosody, that is, what parts of a sentence receive emphasis. Native speakers deftly integrate such information to unconsciously anticipate how a conversation is going to continue, building expectations about who will be referred to next even before a name or pronoun is heard.<br/><br/>This project investigates how Japanese- and Korean-speaking learners of English interpret pronouns, asking specifically whether their interpretation is affected by patterns of event structure and prosody. Early evidence indicates that even when learners have advanced knowledge of English grammar, they may have a reduced ability to generate expectations during language comprehension, resulting in interpretation of pronouns different from that of native speakers. Five experiments will examine how native speakers versus learners continue written and spoken stories with pronouns, and how their eye fixations reveal, in a fraction of a second, which person in a story they think is most likely to be referred to next. <br/><br/>There are more second language users of English worldwide than there are native speakers as a first language. Understanding the nature of their language comprehension has the potential to improve strategies for successful communication, language teaching techniques, and our general understanding of how the human mind functions."
"1044693","EAGER: Collaborative Research: Modeling Distinctive Partners in Adaptive Spoken Dialog","IIS","ROBUST INTELLIGENCE","09/01/2010","04/08/2013","Marilyn Walker","CA","University of California-Santa Cruz","Standard Grant","Tatiana D. Korelsky","08/31/2014","$184,000.00","","mawalker@ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7495","7495, 7916, 9251","$0.00","The human ability to use language flexibly is a hallmark of robust intelligence. In interactive dialog, utterances are dynamically tailored to the common ground or specific context with specific partners. However, interaction with spoken dialog systems is highly constrained and constraining, allowing speakers very little flexibility in what they can say while the system presents pre-determined messages. To make interactive dialog technology broadly useful, this exploratory interdisciplinary project collects a corpus of dialogs exhibiting some important sources of variation, analyzes the corpus, and uses the resulting analyses to develop models and prototype implementations of dynamic dialog strategies. The ultimate goal of this effort is to support the synthesis of entirely new, flexible, and robust spoken dialog systems that are capable of adapting on-line. <br/><br/>The Walking-Around corpus consists of 40 human-human dialog interactions where a remotely located person gives directions to a pedestrian walking around in an urban or campus environment. The experimental paradigm varies the friendship relationship of the dialog partners, whether the director can see what the pedestrian sees, and the familiarity of both the director and the pedestrian with the environment. No other existing direction-giving corpora model dialog interaction in an outdoor real-time environment where the physical context grounds the dialog context. The resulting corpus is used to test hypotheses about, and develop models of, the evolution of local and global dialog adaptation strategies. Key to our effort is determining which adaptations are actually functional, that is, beneficial for a particular task or context in spoken dialog systems."
"0917397","RI: Small: Kernelization with Outer Product Instances","IIS","ROBUST INTELLIGENCE","09/01/2009","08/21/2009","Manfred Warmuth","CA","University of California-Santa Cruz","Standard Grant","Todd Leen","08/31/2014","$455,000.00","","manfred@cse.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7495","7495, 7923, 9215, HPCC","$0.00","Thus far kernel methods have been mainly applied in cases where observations or instances are vectors. We are lifting kernel methods to the matrix domain, where the instances are outer products of two vectors. Matrix parameters can model all interactions between components and therefore take second order information into account. We discovered that in the matrix setting a much larger class of algorithms based on any spectrally invariant regularization can be kernelized. Therefore we believe that the impact of the kernelization method will be even greater in the matrix setting. In particular we will show how to kernelize the matrix versions of the multiplicative updates. This family is motivated by using the quantum relative entropy as a regularization. Most importantly we will use methods from on-line learning to prove generalization bounds for multiplicative updates that grow logarithmic in the feature dimension. This is important because it lets us use high dimensional feature spaces. <br/><br/>We will apply our methods to collaborative filtering. In this case an instance is defined by two vectors, one describing a user and another describing an object. The outer products of such pairs of vectors become the input instances to the machine learning algorithms. The multiplicative updates are ideally suited to learn well when there is a low-rank matrix that can accurately explain the preference labels of the instances. The kernel method greatly enhances the applicability of the method because now we can expand the user and object vectors to high-dimensional feature vectors and still obtain efficient algorithms."
"1018954","RI: Small: A Human-Level, Real-Time, Integrated Agent","IIS","ROBUST INTELLIGENCE","09/01/2010","04/19/2011","Arnav Jhala","CA","University of California-Santa Cruz","Standard Grant","James Donlon","08/31/2014","$464,090.00","Michael Mateas","jhala@soe.ucsc.edu","1156 High Street","SANTA CRUZ","CA","950641077","8314595278","CSE","7495","7495, 7923, 9251","$0.00","This project is developing and integrating statistical and symbolic methods of Artificial Intelligence in an agent architecture and evaluating the agent in a competitive domain, notably the real-time strategy game StarCraft. Real-time strategy (RTS) games provide several interesting research challenges including real-time decision making, enormous state spaces and imperfect information. StarCraft is a popular commercial RTS game that has several professional gaming leagues, and therefore ideal for evaluating the performance of AI agents. Professional StarCraft players reason about and react to strategic decisions at multiple levels of abstraction, sometimes executing over 300 game actions per minute, so developing competition-level StarCraft agents presents extraordinary challenges. <br/><br/>More specifically, the project is using novel supervised and unsupervised learning algorithms to automatically learn domain knowledge from collections of professional gameplay traces; the agent is being implemented within the reactive planning architecture ABL (A Behavior Language). The ABL reactive planner provides the glue for integrating multiple, heterogeneous reasoners within a real-time execution environment. <br/><br/>This work is expected to make significant contributions to the understanding of decision making processes in a complex, real-time domain. This understanding will contribute to the development of robust, intelligent systems that can be deployed within real-world environments. This work will motivate AI researchers to build integrated agent architectures. As a well-known game with very high-level professional play, research in StarCraft AI has the potential to attract significant attention to AI research. The StarCraft competition being hosted by our lab has attracted significant interest both within and outside academia, and at the high-school, undergraduate and graduate level. Thus, this work has the potential to raise general public awareness in research in human-level AI, and will encourage high-school students to pursue careers in computer science and game design."
"1254108","EAGER: Investigating linguistic dimensions in cross-domain authorship analysis","IIS","ROBUST INTELLIGENCE","09/01/2012","08/30/2012","Thamar Solorio","AL","University of Alabama at Birmingham","Standard Grant","Tatiana D. Korelsky","08/31/2014","$45,084.00","","solorio@cis.uab.edu","AB 1170","Birmingham","AL","352940111","2059345266","CSE","7495","7495, 7916, 9150","$0.00","The ability to analyze a text and determine with certainty the author of that document, a task known as Authorship Attribution (AA), can help build a case against an online abuser, determine the trustworthiness of a document, and can also support this country's fight against terrorism by analyzing online communities of interest. This EArly Grant for Exploratory Research investigates new approaches for AA in two specific cross-domain settings: where both the topic and genre of the test documents differ from those of the training data. The research study departs from the standard single feature vector representation in text classification settings and follows a framework where the writeprint of authors is represented as a set of linguistic dimensions. The goal is to understand how each dimension will change in the new domain. <br/><br/>The findings from this exploratory research will show the feasibility of building new text representations and approaches for text classification problems where there are larger domain shifts between the training and testing data and the breakout representation into linguistic dimensions is suitable. The results and findings from this work will contribute to building longer-term research projects which will be able to tackle more challenging cross-domain settings."
"1159679","RI: Medium: Bringing Sentiment Analysis and Social Network Analysis Together","IIS","ROBUST INTELLIGENCE","06/01/2012","09/26/2013","Christopher Potts","CA","Stanford University","Continuing grant","Tatiana D. Korelsky","05/31/2015","$1,006,337.00","Daniel Jurafsky, Daniel McFarland, Jurij Leskovec","cgpotts@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7924, 7495","$0.00","Recent years have seen extraordinary breakthroughs in computational sentiment analysis and social network analysis. This research has helped to reveal that robust language understanding --- in dialogue, in text, on the Web --- depends on accurately identifying attitudes, emotions, and social relationships. However, missing from the current scientific and technical picture is a deep understanding of the ways in which sentiment affects, and is affected by, our interpersonal relationships and social networks. The central goal of this project is to fill this gap by developing algorithms, methods, and data sets for modeling sentiment as social and interpersonal. The approach balances fine-grained sociological and linguistic study, computational modeling, and large-scale data-mining of weblogs and other interactive social media.<br/><br/>This research aims to reshape the field of sentiment analysis by moving it towards inferential models of emotional language as situated in specific social contexts. It also provides social network analysis with rich features for characterizing social ties, thereby facilitating the identification of new latent structure in social networks. The work addresses a wide variety of social and political issues, including the extent of media polarization, the effects of bias and framing, and the role of emotional content in shaping the flow of information. It can also inform the creation of the next generation of communication tools --- software for virtual meetings and online collaboration that intelligently tracks users' evolving attitudes, social networking platforms that distinguish relationship types, and data-mining tools relevant for legal discovery, intelligent tutoring, and media analytics."
"1257163","EAGER: Smart Space-Time Sampling for Recovering and Recognizing Dynamic Scenes","IIS","ROBUST INTELLIGENCE","09/15/2012","07/30/2013","Jinwei Gu","NY","Rochester Institute of Tech","Standard Grant","Jie Yang","08/31/2014","$91,512.00","","jwgu@cis.rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757525","CSE","7495","7495, 7916","$0.00","Traditional, dynamic scenes are captured as video frames sampled at regular space-time grids. For many computer vision tasks, however, this uniform sampling may be either inefficient (e.g., low light, high-speed motion) or unnecessary (e.g., motion/change/event detection). This project explores non-uniform, adaptive sampling schemes that exploit the underlying structures of space-time volumes (e.g., sparsity, temporal coherence, statistical priors). These sampling schemes are implemented with novel programmable pixel-wised coded exposure and aperture in cameras. The captured information-rich coded projections of space-time volumes are used for video reconstruction or directly as features for motion/event detection. In addition to higher efficiency in imaging and higher signal-to-noise ratio in reconstructed results, the method also provides benefits in data security and privacy protection for video surveillance because decoding the captured images requires the knowledge of coded patterns and dictionaries. <br/><br/>This research has many applications in surveillance, machine vision inspection, and high-speed imaging. The developed technology is being tested in transportation imaging for traffic monitoring and accident detection. A database of high-speed videos of traffic scenes and events is being captured and plan to be released online when it is finished. In addition to videos, the technical approach can also be applicable to other high-dimensional signals such as light fields or light transport matrices."
"0515873","Integrated Transduction, Actuation, and Control for Cell-Based Sensing [UOM_FY05_059]","IIS","INFO INTEGRATION & INFORMATICS, , , , ","03/15/2005","09/10/2013","Pamela Abshire","MD","University of Maryland College Park","Standard Grant","Sylvia J. Spengler","09/30/2014","$1,435,666.00","Elisabeth Smela, Benjamin Shapiro","pabshire@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","V918, T377, T489, T885, H186, 7364, I153, I331, I435, J265","9218, HPCC, 1640, 9216, 9178, 9251, SMET, 7484, 9102","$0.00","ABSTRACT<br/>IIS-0515873<br/>Abshire, Pamela<br/><br/>The goal is to develop and demonstrate enabling technology for cell-based<br/>sensing. Cell clinics are microenvironments that enable the capture and characterization of cells. Each ""clinic"" is a micro-electro-mechanical system fabricated on a CMOS chip. Biological systems have high specificity, sensitivity, and adaptability that can be part of a highly integrated sensor. The first goals are sample preparation, cell loading, and system miniaturization using the tools of feedback control, integrated circuits, and microfluidics. Results will leveraged into two ongoing efforts in olfactory sensing and low-false-positive pathogen detection. Three aspects of the system will be demonstrated. (1) Electroosmotic flow control will remove all optically visible (>5 micron) particles from the sample. This will remove dirt, dust, and bacteria and leave behind odorants for presentation to the olfactory cell sensors. This system shall be capable of sufficiently high throughput to be used in real time. (2) Dielectrophoretic actuation for steering cells in three-dimensions will be used to position cells in the plane and to direct them into the cell clinic vials. (3)In order to develop field utility cell-based sensors, a vision system with the same dimensions as cell clinics for cell steering will be developed. The proposed technological advances will allow cell-based sensing to move toward actual implementation and use with real samples. <br/><br/>Cell-based sensing has the potential for selectivity, sensitivity, and speed that far exceed<br/>today's chemical and biological sensors. Problems of olfactory sensing and pathogen detection are of immediate relevance to national security. This technology has clear applications in other diverse fields such as health care, pharmaceutical development, and environmental monitoring. The integrated transduction-actuation-control approach is expected to have an impact outside of cell-based sensing to labs-on-a-chip, microfluidics, and nanotechnology by developing basic technology and techniques for sophisticated manipulation of particles at the micro-scale. The PIs are engineers in several disciplines (fluids and controls, micro-fabrication and conjugated polymers, integrated circuits and biosensors) working closely with cell biologists, molecular pathologists, and experts in bio-functionalized surfaces and quantum dots. The PIs are pioneering the development of MEMS education kits that can be used outside of a clean room."
"0917151","RI: Small: Region-based Probabilistic Models for Descriptive Scene Interpretation","IIS","ROBUST INTELLIGENCE","09/01/2009","08/08/2013","Daphne Koller","CA","Stanford University","Standard Grant","Jie Yang","08/31/2014","$499,999.00","","koller@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7923, 9215, HPCC","$0.00","This project focuses on the task of providing a consistent, semantic interpretation of all components of an image of an outdoor scene. The image is automatically segmented into large regions, each of which is a coherent scene component that is labeled with a rough geometric configuration (distance from the camera and surface normal), and with one of a subset of semantic classes, which include both background classes (such as water, grass, or road) and specific object classes (such as person, car, cow, or boat). The approach is based on the development of a holistic probabilistic model (a Markov random field) whose parameters are automatically learned from data. The model exploits both scene features and contextual relationships between scene components (e.g., cows are typically found on grass and boats on water). It also utilizes object shape and appearance models to identify specific object instances in the image. To address the complexities of reasoning using these richly structured models, new probabilistic inference algorithms are developed.<br/><br/>This project helps train graduate and undergraduate students within the PI's group, as well as students in an annual project class in this area. The project also develops significant infrastructure, including an extensive data set of labeled images and efficient inference algorithms, which are freely distributed to the research community. <br/><br/>The ability to provide a coherent interpretation of a scene composition is an important step towards automatic image annotation, with benefits both for image retrieval and for providing image summaries to visually impaired users."
"1217952","III: Small: A Development Environment for Query Optimizer Engineering","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/29/2012","Mitch Cherniack","MA","Brandeis University","Standard Grant","Frank Olken","08/31/2015","$434,363.00","Olga Papaemmanouil","mfc@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","CSE","7364","7923","$0.00","Novel hardware technologies and application requirements have recently triggered a flurry of research and development into new data management systems. These systems challenge the hegemony of ossified, legacy database systems which lack the agility to adapt to these new constraints. But features pioneered by legacy systems (e.g., declarative query processing) are still desirable, and therefore, much work is being devoted to designing components that provide these features in new systems.<br/><br/>The goal of this project is to support research and development of (query) optimizers in data management systems. Optimizers, which translate declarative descriptions of data (queries) into executable plans, are inherently complex but nonetheless, there are no software engineering tools dedicated to their development. Therefore this project aims to design and build DEVEL-OP: a dedicated DEVELopment Environment for OPtimizers consisting of the following suites of tools:<br/><br/> 1) Component Generators, which use declarative specifications of components to produce executable code. Developers can use generators to rapidly prototype alternative versions of components encompassing different optimization approaches,<br/><br/> 2) Profiling Tools, which help developers identify bugs or performance bottlenecks in generated components, and<br/><br/> 3) Component Benchmarks, which enable the evaluation of optimization approaches (as manifested in generated components) in terms of their effectiveness and robustness in contributing to optimization as a whole.<br/><br/>DEVEL-OP provides a sandbox where optimizers can be quickly prototyped, refined and compared with minimal effort. Therefore, its impact will be in applying software engineering methodologies to the inherently difficult and complex development process for this key component of data management systems."
"1149417","CAREER: MUSE: An Integrated Approach to Managing Uncertain Scientific Experimental Data","IIS","INFO INTEGRATION & INFORMATICS","04/01/2012","03/15/2012","Tingjian Ge","MA","University of Massachusetts Lowell","Continuing grant","Frank Olken","03/31/2017","$312,030.00","","ge@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7364","1045","$0.00","Science is becoming increasingly data intensive. As the experimental data starts to accumulate within or across institutions and over time, it is indeed a valuable wealth of information. However, little has been done to query the data repository in an integrated manner, mainly because the results among different replicates of an experiment often show a large degree of inconsistency and variance. This database poses unique challenges in data types, query types, and accuracy of distributions, etc. The broad goal of the project is to solve some major query processing challenges in such a database.<br/><br/>Specific techniques used to achieve this goal include: (1) Coupling top-k query answering with computation of the score distribution of top-k tuples, and the novel usage of this framework in a number of contexts; (2) Measuring the accuracy of probability distributions which affects user?s perception of query results, and devising new predicates for decision making; (3) Proposing novel semantics and efficient query processing for join queries on uncertain data; and (4) Designing a suite of algorithms for approximate substring matching and windowed subsequence matching for online monitoring queries.<br/><br/>The ability to effectively and accurately share, query, and monitor diverse scientific experimental data on a large scale will greatly benefit the science community. The extra data analysis capability provided to scientists can even change the way they conduct their research. The education plan includes teaching both computer science students on managing scientific data and science major students on relevant database techniques, attracting middle school and college students into computer science, and inspiring students of underrepresented groups."
"1114833","RI: Small: Temporal and Spatiotemporal Processing in Recurrent Neural Networks with Unsupervised Learning","IIS","ROBUST INTELLIGENCE","09/01/2011","09/09/2011","Dean Buonomano","CA","University of California-Los Angeles","Standard Grant","Kenneth C. Whang","08/31/2014","$249,616.00","","dbuono@ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7923","$0.00","The brain's ability to perform complex forms of pattern recognition, such as speech discrimination, far exceeds that of the best computer programs. One of the strengths of human pattern recognition is its seamless processing of the temporal structure and temporal features of stimuli. For example, the phrase ""he gave her cat food"" can convey two different meanings depending on whether the speaker emphasizes the pause between ""her"" and ""cat,"" or ""cat"" and ""food."" Attempts to emulate the brain's ability to discriminate such patterns using artificial neural networks have had only limited success. These models, however, have traditionally not captured how the brain processes temporal information. Indeed most of these models have treated time as equivalent to a spatial dimension, in essence assuming that the same input is buffered and played at different delays. Similarly, more traditional approaches to pattern recognition, which generally rely on discrete time bins, also do not capture how the brain processes temporal information. The goal of the current research is to use a framework, referred to as state-dependent networks or reservoir computing, to simulate the brain's ability to process both the spatial and temporal features of stimuli. A critical component of this framework is that temporal information is automatically encoded in the state of the network as a result of the interaction between incoming stimuli and internal states of recurrent networks.<br/><br/>This project will develop a general model of spatiotemporal pattern recognition focusing on speech discrimination. The model will incorporate plasticity, a critical characteristic of the brain that has eluded previous state-dependent network models. Plasticity is a cardinal feature of the brain's computational power. For example, in the context of speech recognition, even at the age of 6 months, the brains of babies are tuned to recognize sounds of their native language. This ability is an example of experience-dependent cortical plasticity and it relies in part on synaptic plasticity and cortical reorganization. Incorporating synaptic plasticity into recurrent networks has proven to be a very challenging problem as a result of the inherent nonlinear and feedback dynamics of recurrent networks. The current project will use a novel unsupervised form of synaptic plasticity--based on empirically observed forms of plasticity referred to as homeostatic synaptic plasticity--to endow state-dependent networks with the ability to adapt and self-tune to the stimulus set the network is exposed to. This project interfaces recent advances in theoretical neuroscience and novel approaches in machine learning. The results will help develop artificial neural networks that capture the brain's ability to process temporal information and reorganize in response to experience."
"0910884","DC: Large: Collaborative Research: Mining a Million Scanned Books: Linguistic and Structure Analysis, Fast Expanded Search, and Improved OCR","IIS","DATA-INTENSIVE COMPUTING, INFO INTEGRATION & INFORMATICS","10/01/2009","07/03/2012","James Allan","MA","University of Massachusetts Amherst","Continuing grant","Sylvia J. Spengler","09/30/2014","$2,146,756.00","Raghavan Manmatha, David Smith","allan@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7793, 7364","7793, 7925, 9216, HPCC, 9251","$0.00","The Center for Intelligent Information Retrieval at UMass Amherst, the Perseus Digital Library Project at Tufts, and the Internet Archive are investigating large-scale information extraction and retrieval technologies for digitized book collections. To provide effective analysis and search for scholars and the general public, and to handle the diversity and scale of these collections, this project focuses on improvements in seven interlocking technologies: improved OCR accuracy through word spotting, creating probabilistic models using joint distributions of features, and building topic-specific language models across documents; structural metadata extraction, to mine headers, chapters, tables of contents, and indices; linguistic analysis and information extraction, to perform syntactic analysis and entity extraction on noisy OCR output; inferred document relational structure, to mine citations, quotations, translations, and paraphrases; latent topic modeling through time, to improve language modeling for OCR and retrieval, and to track the spread of ideas across periods and genres; query expansion for relevance models, to improve relevance in information retrieval by offline pre-processing of document comparisons; and interfaces for exploratory data analysis, to provide users of the document collection with efficient tools to update complex models of important entities, events, topics, and linguistic features. When applied across large corpora, these technologies reinforce each other: improved topic modeling enables more targeted language models for OCR; extracting structural metadata improves citation analysis; and entity extraction improves topic modeling and query expansion.The testbed for this project is the growing corpus of over one million open-access books from the Internet Archive."
"1217615","III: Small: Combinatorial Optimization Methods for Problems in Molecular Biology and Genetics","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","07/26/2013","Eran Halperin","CA","International Computer Science Institute","Continuing grant","Sylvia J. Spengler","08/31/2014","$497,380.00","","heran@icsi.berkeley.edu","1947 CENTER ST STE 600","BERKELEY","CA","947044115","5106662900","CSE","7364","7923","$0.00","In virtually every area of science, engineering and commerce, optimization problems arise for which no known solution method is guaranteed to yield satisfactory solutions to large instances using a reasonable amount of computation time. Computational complexity theory confirms the intractability of most of these problems. Nevertheless, these problems demand to be solved in practice, and very often heuristic algorithms work quite well in most cases, although not in the worst case. The unreasonable success of heuristic algorithms is one of the great mysteries in computer science.<br/><br/>This project will undertake four case studies in the design of heuristic algorithms. 1. Implicit hitting set problems are a class of constraint satisfaction problems in which the constraints are too numerous to list explicitly. Many classic optimization problems fit this model. A generic approach will be investigated which aims to enumerate a small set of constraints sufficient to determine the optimal solution. This approach has proved successful in solving a significant group of genome alignment problems. 2. Integer programming can be used to reconstruct a network of interacting genes and proteins from experimental data. A network is modeled as a wiring diagram of interconnected gates, and integer programming is used to reconstruct the logical functions of the gates. The method has successfully mapped the subnetwork of TLM genes that control telomere length in yeast, and will be applied to other models. 3. Another focus of the research is the discovery of aggregates of interacting proteins that form regulatory modules conserved in evolution. Given such a module in one species, the problem of finding a corresponding module in a second species is abstracted as a graph-theoretic problem called the colorful subgraph problem. The plan is to develop fast and accurate heuristic algorithms for the solution of this problem. 4. The final problem is partitioning a graph into a large number of small dense clusters. An application is given from genetics, involving the automatic inference of the familial relationships among a group of genetically related individuals.<br/><br/>The problems studied in this project can serve as test cases for understanding the applicability of fundamental algorithmic strategies such as constraint relaxation, integer programming and local search."
"0803148","RI-Medium: Collaborative: Corpus-Based Studies of Lexical, Acoustic-Prosodic, and Discourse Entrainment in Spoken Dialogue","IIS","ROBUST INTELLIGENCE, COLLABORATIVE RESEARCH","09/01/2008","08/13/2013","Julia Hirschberg","NY","Columbia University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$449,911.00","","julia@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495, 7298","7495, 9102, 9215, HPCC, 5937, 5948, 5979, 9251","$0.00","Participants in human-human conversation often entrain to one another, adopting the vocabulary and other behaviors of their partners.<br/>Evidence of this has been found from laboratory studies and observations of real life situations. We are investigating many types of entrainment in two large corpora of human-human conversations to improve system behavior in Spoken Dialogue Systems (SDS). We want to discover which types of entrainment occur generally across speakers and which seem to be speaker-specific, which types of entrainment can be reliably linked to task success and perceived naturalness, and which types of entrainment can be automatically modeled in SDS.<br/><br/>Our research has importance for the construction of better SDS.<br/>Currently, research SDS have attempted to entrain users to system vocabularies to improve speech recognition accuracy: Since users are likely to employ the same vocabulary in their answers that systems use in their queries, systems have a better chance of recognizing user input correctly if they can predict word usage. However, there has been little attempt to create SDS that entrain to user behavior, despite evidence that human beings rate humans and systems that behave more like them more highly than those that do not. Our work focuses on determining which types of system entrainment to users will be most important to users and most feasible for SDS. Our results will be disseminated through papers and presentations at speech and language conferences. We will also provide publicly available annotated corpora for future research by others."
"1234983","SAVI: PRAGMA - Enabling Scientific Expeditions and Infrastructure Experimentation for Pacific Rim Institutions and Researchers","ACI","INTERNATIONAL RES NET CONNECT, NAT ECOLOGICAL OBSERVATORY NET, INFO INTEGRATION & INFORMATICS, Science Across Virtual Instits","10/01/2012","05/17/2013","Peter Arzberger","CA","University of California-San Diego","Standard Grant","Kevin L. Thompson","09/30/2017","$5,711,897.00","Philip Papadopoulos","parzberger@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7369, 7350, 7364, 8077","7433, 1061, 5919, 5924, 5927, 8058, 9200, 9251, 7350, 7364, 7369","$0.00","The Pacific Rim Applications and Grid Middleware Assembly (PRAGMA), which began as a workshop series, explores the technical, organizational, and trust dimensions that enable small-to-medium-sized international networks of research scientists to address common scientific questions.<br/><br/>This award uses international scientific expeditions to forge teams of domain scientists and cyberinfrastructure researchers. Together, they develop and test the underlying technologies that are needed to create usable, international-scale, cyber environments. This award includes not only technology developers but also domain scientists in lake ecology, biodiversity and computer-aided drug discovery. In technology development, the award will: rebuild PRAGMA's technical infrastructure as a multi-provider/multi-institution cloud with a unique control approach; test and develop new analysis and provenance tools to track how data are utilized by the expeditions; enhance data sharing with user-controlled trust envelopes enabled by IPv4 and IPv6 overlay networks; and advance sensor network cyberinfrastructure. Education and training programs will be dramatically expanded through an international student association. New collaborations with a refined focus on common questions that affect India, China, and Southeast Asia will be developed as expeditions. This award broadens engagement of US researchers through a partnership that includes: University of Florida, Indiana University, University of Wisconsin, and led by the University of California, San Diego.<br/><br/>PRAGMA complements key international research network activities and large-scale production resources. It leverages significant investments in people, expertise, tools and infrastructure made by international members.<br/><br/>The intellectual merit is developing practical approaches to enable groups to collaborate through the cyberinfrastructure. The broader impacts are to fundamentally enable large numbers of small groups to work together on scientific problems where international perspective is essential; better inform the US research community of tools and experts out-side of the US; and create professional networks for the next generation of students. The transformational impact will be a model for building people networks to conduct science across international boundaries.<br/><br/>This award is designated as a Science Across Virtual Institutes (SAVI) and is being co-funded by NSF's Office of Cyberinfrastructure; Directorate for Biological Sciences; Directorate for Computer and Information Science and Engineering; and Office of International Science and Engineering."
"0829683","CPATH CDP: An Integrated, Multidisciplinary and Cross-Fertilizing Model for Computing Education","IIS","CPATH, INFO INTEGRATION & INFORMATICS","09/01/2008","07/22/2013","Francois Modave","TX","University of Texas at El Paso","Standard Grant","Sylvia J. Spengler","08/31/2014","$211,563.00","Oscar Varela, Vanessa Lougheed, Eric Freudenthal","fmodave@utep.edu","ADMIN BLDG RM 209","ElPaso","TX","799680587","9157475680","CSE","7640, 7364","7640, 9216, 9218, HPCC, 7218","$0.00","The United States continues to face a crisis in the development of highly-skilled workers in science, engineering, and technology. Computing has deeply permeated every aspect of our society, and every field has been transformed by the recent arrival of affordable high-performance computing. Despite this pervasive growth of computation throughout engineering and science, university level computing education is still largely separated from other disciplines. It is crucial to develop a scientific and engineering workforce with a thorough understanding of the fundamental conceptual ideas from computer science and software engineering that pertain to a specific domain and the skills necessary to apply them to their field of expertise. The University of Texas at El Paso proposes a Conceptual and Development Planning (CDP) project that will support the institutional groundwork to develop synergistic multidisciplinary curricula combinations across the departments of Computer Science, Biological Sciences and Economics and Finance that will provide students with substantive content in domains not typically provided by traditional academic degrees. The overarching goal of this project is to support the conceptual design and planning for the creation of a computing-centric, interdisciplinary, and cross-fertilizing model that spans the institution?s academic structures. This proposal addresses these needs by developing a comprehensive approach to developing skills in relevant aspects of computation and algorithm design in students in a wide variety of scientific disciplines. The team will develop a new computational curriculum suitable for students whose careers will overlap. The principal focus is the development of multidisciplinary academic programs, built from collaborative work between the involved constituents, rather than the creation of new academic units. These multidisciplinary academic programs will convey sufficient depth to prepare students to make significant contributions in their respective fields. This project will permit the investigation of the assertion that collaborative work between computer science, and disciplines where the participation of women is more reflective of the population, e.g., biology and social sciences, can help reverse the trend of a small proportion of women graduating with a computing related degree or an engineering degree."
"1302212","III: Medium: Collaborative Research: Citing Structured and Evolving Data","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","08/22/2013","Susan Davidson","PA","University of Pennsylvania","Standard Grant","Sylvia J. Spengler","07/31/2016","$849,090.00","Susan Davidson, Val Tannen, O. Peter Buneman","susan@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7364","7364, 7924","$0.00","Citation is an essential part of scientific publishing and, more generally, of scholarship. It is used to gauge the trust placed in published information and, for better or for worse, is an important factor in judging academic reputation. Now that so much scientific publishing involves data and takes place through a database rather than conventional journals, how is some part of a database to be cited? More generally, how should data stored in a repository that has complex internal structure and that is subject to change be cited?<br/><br/>The goal of this research is to develop a framework for data citation which takes into account the increasingly large number of possible citations; the need for citations to be both human and machine readable; and the need for citations to conform to various specifications and standards. A basic assumption is that citations must be generated, on the fly, from the database. The framework is validated by a prototype system in which citations conforming to pre-specified standards are automatically generated from the data, and tested on operational databases of pharmacological and Earth science data. The broader impact of this research is on scientists who publish their findings in organized data collections or databases; data centers that publish and preserve data; businesses and government agencies that provide on-line reference works; and on various organizations who formulate data citation principles. The research also tackles the issue of how to enrich linked data so that it can be properly cited."
"0916610","RI: Small: Organizing recognition: the uses of perceptual organization","IIS","ROBUST INTELLIGENCE","09/15/2009","08/08/2013","John Oliensis","NJ","Stevens Institute of Technology","Standard Grant","Jie Yang","08/31/2014","$376,685.00","Philippos Mordohai","oliensis@cs.stevens-tech.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7495","7495, 7923, 9215, HPCC","$0.00","Recognizing objects in images is the central problem of computer vision. One approach (``bag of words'') compiles simple statistics on the image brightness patterns and recognizes by correlating these statistics, via learning, with the imaged objects. It cannot exploit important information on the image's spatial layout. Another approach, perceptual organization (PO), computes a distinctive, structural description of the image contents and recognizes based on this. Researchers agree that PO is a crucial early stage of recognition--and that its results are unreliable. (Images compress the 3D world and are ambiguous; PO cannot eliminate the ambiguity since it has no high-level knowledge of what the image is ``about.'') This leads to a fundamental dilemma: How can a recognition system use the result of PO if it cannot be trusted?<br/><br/>To exploit perceptual organizations without succumbing to their unreliability, this project uses a strategy that averages over all possible organizations weighted by their probability, instead of computing a single, ``most likely'' image description. This strategy is applied to diverse tasks such as matching images by the shapes of the objects within; recognizing articulated objects such as people and animals; tracking objects through video; and computing stable perceptual organizations. The project also studies the integration of this approach with older ones into a flexible and capable recognition system. The result will be new techniques for the analysis, manipulation, and search of images. The methods developed will be integrated in the curriculum and disseminated to researchers, and the software will be made publicly available."
"1302236","III: Medium: Collaborative Research: Citing Structured and Evolving Data","IIS","INFO INTEGRATION & INFORMATICS","08/01/2013","07/24/2013","James Frew","CA","University of California-Santa Barbara","Standard Grant","Sylvia J. Spengler","07/31/2016","$250,364.00","","frew@bren.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7364, 7924","$0.00","Citation is an essential part of scientific publishing and, more generally, of scholarship. It is used to gauge the trust placed in published information and, for better or for worse, is an important factor in judging academic reputation. Now that so much scientific publishing involves data and takes place through a database rather than conventional journals, how is some part of a database to be cited? More generally, how should data stored in a repository that has complex internal structure and that is subject to change be cited?<br/><br/>The goal of this research is to develop a framework for data citation which takes into account the increasingly large number of possible citations; the need for citations to be both human and machine readable; and the need for citations to conform to various specifications and standards. A basic assumption is that citations must be generated, on the fly, from the database. The framework is validated by a prototype system in which citations conforming to pre-specified standards are automatically generated from the data, and tested on operational databases of pharmacological and Earth science data. The broader impact of this research is on scientists who publish their findings in organized data collections or databases; data centers that publish and preserve data; businesses and government agencies that provide on-line reference works; and on various organizations who formulate data citation principles. The research also tackles the issue of how to enrich linked data so that it can be properly cited."
"1218488","III: Small: A Theoretical Framework for Practical Entity Resolution in Network Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/28/2012","Lise Getoor","MD","University of Maryland College Park","Standard Grant","Frank Olken","08/31/2015","$500,000.00","","getoor@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923","$0.00","In an era of information overload and big data, there is a pressing need to analyze, protect, prioritize and utilize data. Much of this data is inherently relational; thus, it is crucial to understand the benefits, challenges and potential hazards of exploiting the relational properties. Integrating, cleaning, and linking relational data requires matching and resolving references in the data. At the same time, matching and linking pose significant privacy risks. The proposed work develops a theoretical understanding of entity resolution in network data with the goal of developing tools and methods which can tell us how easy or difficult it will be to resolve data in different settings. Making use of the theory, new entity resolution algorithms will be developed with accuracy guarantees and for scaling entity resolution to large-scale data sources. These research results will enable more informed data sharing and usage decisions by individuals, industry, and government. Accurate analysis of network data is of utmost importance to science, medicine and national security. Whether studying socioeconomic trends, integrating data from large microarrays, analyzing organized crime or terrorist networks, or mining financial data for corporate misconduct, accurate network data, and its associated statistics, are crucial. At the same time, understanding how entity resolution effects privacy guarantees, and educating the public about the impact of releasing identifying information, is equally important."
"1143585","EAGER: Exploring and Linking Widely Distributed Data on the Semantic Web","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/16/2011","James Hendler","NY","Rensselaer Polytechnic Institute","Standard Grant","Sylvia J. Spengler","08/31/2014","$197,407.00","","hendler@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7364","7364, 7916","$0.00","The goal of this project is to explore key algorithms, technologies and protocols that will lead to the next level of development of the original Semantic Web vision of the 'Web of Data', a Web in which the unstructured texts of the current Web are integrated in a seamless way with information currently locked in structured databases. While a huge amount of open data is being made available on the Web, especially in the 'Open Government Data' arena, traditional computing techniques are inadequate for finding this data, for linking it to other data, and for reusing and repurposing the data resources. The project aims to show that an innovative combination of Semantic Web technologies will provide the basis for a new approach to large-scale, on-line, data integration and use.<br/><br/>The research team will demonstrate our techniques by showing their efficacy on a combination of Open Government datasets being released around the world. There are already hundreds of thousands of these databases made available in machine-readable formats by countries, municipalities and cities, and the number is growing exponentially. This makes Open Government Data a large-scale testbed for Web-based data integration. The research team has collected the metadata for close to 400,000 datasets from more than 60 catalogs, from 20 countries, which are published in fourteen different languages. The project will show how the combination of linked-data representations, machine-readable metadata and Semantic Web ontologies will provide an ability to federate data across these catalogs, domains, and cultures. The researchers will develop the foundational algorithms that make it possible for researchers to find, access, integrate and analyze ad hoc combinations of these many datasets integrated on the fly. <br/><br/>Thus, the outcome of this project will be to demonstrate techniques, and develop a proof-of-concept demonstration, showing that the integration of multiple data sources across the Web can be accomplished by the application of a combination of semantic information of different kinds. The researchers will show that it is possible to build search and reuse tools that function across large distributed data collections, and we will explore the key research challenges in creating Web-scale linked-open-data repositories. The success of this project will demonstrate that by bridging the gap between structured and unstructured sources, it is possible to develop techniques that set the stage for a second generation of more powerful Semantic Web tools. Such tools will allow scientists, engineers, and eventually end users to perform a range of analyses without needing the large proprietary data resources currently available to only a small set of researchers working in companies with access to 'big data'. Additional information about the project can be found at: http://data.rpi.edu"
"0917104","CIF: Small: Nonintrusive Digital Speech Forensics: Source Identification and Content authentication","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","09/12/2009","Carol Espy-Wilson","MD","University of Maryland College Park","Standard Grant","Sylvia J. Spengler","08/31/2014","$499,943.00","","espy@glue.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7364, 7923, 9102, 9216, HPCC","$0.00","Current digital media editing software allows malicious amateur users to perform imperceptible alterations to digital speech communications This creates a serious threat to the ""knowledge life cycle"". The proposal seeks to develop theories, methods and tools for extracting and visualizing evidence from digital speech content for the purpose of media source identification and content authentication. The strategy will be based on the important paradigm of nonintrusive media forensics. The hypothesis is that the physical devices and associated signal processing chains may leave behind intrinsic ""fingerprint"" that are detectable by statistical methods. The hypothesis clearly indicates the purpose of the project."
"1353235","EAGER: A Local-Global Approach Towards Omnipresent Vision","IIS","ROBUST INTELLIGENCE","09/15/2013","09/04/2013","Ko Nishino","PA","Drexel University","Standard Grant","Jie Yang","08/31/2015","$184,416.00","","kon@drexel.edu","3201 Arch Street","Philadelphia","PA","191042737","2158955849","CSE","7495","7495, 7916","$0.00","This project constructs an Omnipresent Vision system - a computational system that allows us to navigate, share, enhance, and understand the visual data captured by a slew of fixed and moving cameras. The society is flooded with various cameras. Almost every cell phone has a video camera and wearable cameras are starting to permeate our lives. These local cameras capture visual experiences from personal perspectives. Static cameras at various outdoor and indoor locations are also constantly capturing videos. These fixed-view cameras offer global, persistent looks into our daily lives. The key idea of this project is to fully leverage the combination of these local and global cameras to enable new visual experiences and facilitate the understanding of the scene and the people within. This is achieved with novel algorithms and computational tools that bring together the local and global views into an integrated platform, model the dynamic scene by joining those two sets of perspectives, and recognize the actions and events in them. <br/><br/>The research, at a personal level, enables the spatio-temporal and contextual expansion of the person's view, and at a scene level, it enables the interpretation of the scene at various scales of spatial and temporal resolutions. It also provides new means to understand people and scenes. For instance, it facilitates the understanding of people who cannot communicate their intentions. The research activities also furnish graduate and undergraduate students educational opportunities to take part in spawning this new area of research."
"1252987","EAGER: Memory-based learning of effective actions","IIS","ROBUST INTELLIGENCE","09/01/2012","09/05/2012","Benjamin Kuipers","MI","University of Michigan Ann Arbor","Standard Grant","James Donlon","08/31/2014","$80,000.00","","kuipers@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7495","7495, 7916","$0.00","This project addresses the foundational question in Robust Intelligence of how an autonomous agent can learn use low-level sub-symbolic (pixel-level) sensorimotor experiences with its environment to learn higher level effective concepts, ranging from learning to use a hand to manipulate objects on a tabletop, to learning to balance and walk, to learning to move through a complex environment without collisions with walls or pedestrians. This project will develop computational models of how this learning process could take place and will implement and test these computational models on an actual robot. Understanding such autonomous concept learning has the potential to impact a range of disciplines including Cognitive Science, Psychology, AI in general, and robotics, computer vision, and machine learning in particular. Understanding how concepts come into being and evolve in the specific domain of robot navigation also has the potential to contribute to advances in systems that help persons with physical and learning disabilities.<br/><br/>The project draws on insights from two different approaches from the PI's lab that have complementary strengths: (1) QLAP (Qualitative Learner of Action and Perception), and (2) MPEPC system (Model Predictive Equilibrium Point Control). The QLAP system exploits a qualitative abstraction of continuous sensor input in order to learn causal contingencies, DBN (Dynamic Belief Network) and MDP models of the causal world, and to build a hierarchy of action models. It uses perception with laser rangefinders and correlation peaks between changes to the motor vector and events in the sense vector -- so-called contingencies -- to discern motor signals that produce resulting perceptual events that may be more than random variation. Reliable episodes can be remembered as cases and used in learning. The MPEPC system factors the continuous navigation problem for a mobile robot into a local unconstrained control and a global optimization process that balances constraints such as progress and collision avoidance. Both methods have a local phase (learning contingencies and local control laws), and a global phase (learning a hierarchy of actions and finding extended routes that balance constraints). These two approaches will be augmented by learning methods from Case-Based Reasoning (CBR) that use features of the presenting case to retrieve related cases from case memory. Two levels of case representation will be employed. The lowest level case representation is a simple feature vector: in the case of local motion control, it specifies the target pose location in the egocentric frame of reference, along with the parameters of the motion control law that attempts to reach it, and the quality of the resulting trajectory. Retrieval will be done using Nearest Neighbor, combining information from the retrieved cases by Locally Weighted Regression or Locally Weighted Projection Regression. At the higher level of action learning, a case is to be described by identifying the critical environmental constraints that determine the global structure of the action."
"1152819","Language Processing as Boundedly Optimal Control of Memory, Perception, and Action","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","05/01/2012","07/30/2013","Richard Lewis","MI","University of Michigan Ann Arbor","Continuing grant","Anne Cleary","04/30/2015","$401,267.00","Satinder Baveja","rickl@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","SBE","7252, 7495","7252, 7495","$0.00","Language comprehension, whether listening or reading, is a rapid skill that requires the coordination of perception (e.g., recognizing printed words on a page), action (e.g., controlling the movement of the eyes), memory (e.g. remembering what came in earlier parts of a sentence to relate them to later parts), and linguistic knowledge (e.g., using the order of words to constrain possible relations among them). Understanding how these processes are combined on a moment-to-moment basis has been a major challenge for cognitive science. This project will develop and test a new theory of language comprehension from an adaptive perspective. The hypothesis is that language processing may be understood as the coordinated, adaptive control of both internal (and limited) cognitive processes and external perceptual-motor actions so as to maximize specific task goals. To apply this idea to language, the investigators will formalize and implement optimal control models of limited Bayesian perception and memory for different reading tasks. These Bounded Optimal Control models will generate predictions that will be tested by monitoring the eye-movements and responses of humans.<br/><br/>Bounded Optimal Control is a new approach to language, thought, and action, with possibly major long-term implications for how we understand and address individual differences and deficits in reading ability. It represents a shift in scientific focus from seeking to describe the perceptual and cognitive strategies that the mind and brain employ during reading, to specifying clearly the problems for which these strategies are the solutions. There is no canonical strategy because there is no canonical problem. Thus, the best cognitive and perceptual strategies are determined by specific task goals and individual constraints. This has the potential to change our approach to reading deficits: rather than asking how an individual's reading strategies deviate from normal, it is possible to ask instead whether those strategies are the best possible strategies, taking into account both task goals and idiosyncratic cognitive constraints. Revealing the true nature of the gaps between actual behavior and ""bounded optimal"" behavior is an important step in understanding how to go about closing them."
"1355633","EAGER: Physio-linguistic Models of Deception Detection","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/09/2013","Mihai Burzo","MI","University of Michigan Ann Arbor","Standard Grant","Frank Olken","08/31/2015","$300,000.00","Rada Mihalcea","mburzo@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364","7364, 7916","$0.00","The goal of this Early-concept Grant for Exploratory Research is to explore a new generation of computational tools for joint modeling of physiological and linguistic signals of human behavior. The project is the first to investigate physio-linguistic models for deception analysis. To achieve this goal, the following three research objectives are pursued. First, a novel physio-linguistic dataset of deceit is built, covering several different domains. Second, rule-based classifiers for deception detection are explored, using physiological features (e.g., heart rate, respiration rate, galvanic skin response, skin temperature), as well as linguistic features. Third, data-driven learning approaches for multimodal deception detection are developed, taking advantage of the recent progress in early, late, and temporal fusion models. <br/><br/>The project is exploratory in nature, and acts as a catalyst for novel research problems. First, it explores rich sets of multimodal features extracted from physiological and linguistic modalities, analyzing their effectiveness in the recognition of deceit. Second, it also explores the integration of multiple physio-linguistic modalities, through experiments with rule-based and data-driven techniques that fuse multimodal features into joint deception analysis models. To address the challenges of multimodal research work, the team working on this project brings together experts from the fields of bio-sensors, computational linguistics, and physiology and behavioral sciences.<br/><br/>The project has high potential payoffs, as models of deception detection have broad applicability, including: the development of critical tools for various applications in fields such as criminal justice, intelligence, and security; the enhancement of applications that can be negatively affected by the presence of deceit, such as opinion analysis or modeling of human communication; and a deeper understanding of fundamental aspects of human behavior, which can positively impact medical applications in psychiatry and psychology. The tools and datasets produced during this project will be made freely available for the research community.<br/><br/>For further information see the project web site at: http://web.eecs.umich.edu/~mihalcea/deceptiondetection/"
"0916099","III: Small: Optimizing News and Opinion Aggregators for Diversity","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","03/15/2010","Paul Resnick","MI","University of Michigan Ann Arbor","Standard Grant","Maria Zemankova","08/31/2014","$515,312.00","","presnick@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","7364","7364, 7923, 9216, HPCC, 9251","$0.00","Observers have raised alarms about increasing political polarization of our society, with opposing groups unable to engage in civil dialogue to find common ground or solutions. Aggregators such as Digg, Reddit, and Google News rely on ratings and links to select and present subsets of the large quantity of news and opinion items generated each day. If a majority of the raters or linkers share a political viewpoint, minority viewpoints may get little representation in the results, creating an echo chamber for the majority. Even if a site selects items based on votes or links from people with diverse views, algorithms based solely on popularity may lead to a tyranny of the majority that effectively suppresses minority viewpoints. This work is the first attempt to formalize several different instances of the general concept of diversity of viewpoints and to devise algorithms that optimize for these measures. The techniques are likely to be applicable to other domains where selecting a diverse set of items is valuable, such as search engine results and audience voting on questions to ask of a conference speaker or public official. The goals of this research are to: 1) form alternative measures of diversity for result sets; 2) develop algorithms for selecting result sets that jointly optimize for diversity and popularity; 3) assess the impacts of alternative selection and presentation methods on people's willingness to use an aggregation service, their exposure to diverse opinions, and the size of their argument repertoires.<br/><br/>The results of the project will provide a better understanding of alternative notions of what it means for a set of items to be diverse or balanced, and the range of reactions that different people have to varying levels and presentations of diversity. Insight into people's preferences for acceptable support and challenge may also allow for the creation of news and opinion aggregators that cause people to choose to expose themselves to greater diversity, thus reducing polarization and enhancing democracy. Results, including open source software, will be distributed via the project web site: (http://si.umich.edu/balance/)."
"0931474","CPS: Medium: Learning to Sense Robustly and Act Effectively","CNS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2009","06/23/2010","Benjamin Kuipers","MI","University of Michigan Ann Arbor","Standard Grant","Sylvia J. Spengler","08/31/2014","$1,466,731.00","Silvio Savarese","kuipers@umich.edu","3003 South State St.","Ann Arbor","MI","481091274","7347636438","CSE","1640, 7364","7918, 7924, 9216, 9218, HPCC, 9178, 9251","$0.00","The physical environment of a cyber-physical system is unboundedly complex, changing continuously in time and space. An embodied cyber-physical system, embedded in the physical world, will receive a high bandwidth stream of sensory information, and may have multiple effectors with continuous control signals. In addition to dynamic change in the world, the properties of the cyber-physical system itself ? its sensors and effectors ? change over time. How can it cope with this complexity? The hypothesis behind this proposal is that a successful cyber-physical system will need to be a learning agent, learning the properties of its sensors, effectors, and environment from its own experience, and adapting over time. Inspired by human developmental learning, the assertion is that foundational concepts such as Space, Object, Action, etc., are essential for such a learning agent to abstract and control the complexity of its world. To bridge the gap between continuous interaction with the physical environment, and discrete symbolic descriptions that support effective planning, the agent will need multiple representations for these foundational domains, linked by abstraction relations. To achieve this, the team is developing the Object Semantic Hierarchy (OSH), which shows how a learning agent can create a hierarchy of representations for objects it interacts with. The OSH shows how the ?object abstraction? factors the uncertainty in the sensor stream into object models and object trajectories. These object models then support the creation of action models, abstracting from low-level motor signals. To ensure generality across cyber-physical systems, these methods make only very generic assumptions about the nature of the sensors, effectors, and environment. However, to provide a physical test bed for rapid evaluation and refinement of our methods, the team has designed a model laboratory robotic system to be built from off-the-shelf components, including a stereo camera, a pan-tilt-translate base, and a manipulator arm. For dissemination and replication of research results, the core system will be affordable and easily duplicated at other labs. There are plans to distribute the plans, the control software, and the software for experiments, to encourage other labs to replicate and extend the work. The same system will serve as a platform for an open-ended set of undergraduate laboratory tasks, ranging from classroom exercises, to term projects, to independent study projects. There is a preliminary design for a very inexpensive version of the model cyberphysical system that can be constructed from servo motors and pan-tilt webcams, for use in collaborating high schools and middle schools, to communicate the breadth and excitement of STEM research."
"1218683","RI: Small: Collaborative Research: Detecting Abnormalities in Images","IIS","ROBUST INTELLIGENCE","05/15/2013","05/07/2013","Ali Farhadi","WA","University of Washington","Standard Grant","Kenneth C. Whang","04/30/2016","$120,000.00","","ali@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7923","$0.00","Computer interpretation of images has taken huge strides in recent years, but even the most modern algorithms can't come close to matching human capabilities on simple visual tasks. For example, in a brief glance at an image, people reflexively classify the objects in it in terms of the categories they belong to--people, animals, tools, and other significant classes. This allows us to understand the objects' meaning in the image, for example understanding that a scene with many pieces of food might be a dinner table. Because even modern computer vision systems can't make such a classification, they can't automatically detect when an object in a scene doesn't belong, that is, when it is abnormal relative to the categories present in the scene. Detecting such ""oddball"" or atypical objects is essential to understanding visual scenes, because objects that don't belong are often the ones that play the most important role and require immediate action (like a cat on the dinner table). Studies of human subjects have shown that humans are indeed especially adept at detecting atypical items, which often draw our visual attention even before we become consciously aware of them.<br/><br/>This project aims at developing algorithmic techniques to endow computer visions systems with the same ability. By adapting modern vision techniques to mimic the way human observers classify visual atypicality, researchers will develop computer systems that can examine an image and automatically detect abnormal objects, as well as identifying the nature of the abnormality and quantifying the degree of abnormality. The project involves a collaboration among researchers at multiple universities and multiple scientific specialties, including both computer vision and human vision. The result will be a new and useful class of computer vision techniques that can be applied to visual image understanding in many contexts."
"1240710","Support for student participation in a 2012 AAAI Fall Series Symposium","IIS","ROBUST INTELLIGENCE","09/01/2012","08/27/2012","Victor Raskin","IN","Purdue University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$12,000.00","Julia Taylor","vraskin@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495","7495, 7556","$0.00","The American Association for Artificial Intelligence (AAAI) Fall Series Symposium (FSS) is the first international gathering in North America in the field of computational aspects of affective narrative, bringing together participants from a long list of contributing disciplines. One of the aims of the Symposium is to attract students to a new and exciting multidisciplinary area, where it is still easier to attract the experts' attention and mentoring. The goal of this grant is to subsidize travel, registration fees, and housing expenses of students selected to participate in the Symposium which will be held, along with several other AAAI Fall Symposia, on November 2-4, 2012, in Arlington, VA. <br/><br/>The Symposium calls for long and short papers both from leaders in the field of computational aspects of affective narrative and pertinent areas and from graduate students as well as poster presentations from the undergraduate students interested in the subject. Papers from undergraduates, attracted through Research Experience for Undergraduates (REU) and Senior Research Opportunity Program (SROP) networks as well as solo graduate contributions will be carefully mentored to the level of poster or short paper eligibility. The multi-format program of the Symposium will also accommodate special student sessions, especially for promising but not fully developed ideas. <br/><br/>The AAAI FSS Symposium on computational aspects of affective narrative provides a valuable opportunity for the next generation of multidisciplinary researchers in a variety of pertinent disciplines to enter the computational affective narrative research community. It is expected that the Symposium will attract underrepresented populations as well as provide benefit to future development of computational systems from better understanding of affective narrative as the inherently human phenomenon."
"1318733","RI: Small: Probabilistic Goal-Based Imitation Learning","IIS","ROBUST INTELLIGENCE","08/01/2013","08/06/2013","Rajesh Rao","WA","University of Washington","Standard Grant","James Donlon","07/31/2016","$400,000.00","Dieter Fox, Andrew Meltzoff","rao@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7923","$0.00","Humans are extremely adept at learning new skills by watching and imitating others. Attempts to endow robots with a similar ability have failed to generalize beyond specific tasks, partly because the focus has been on following the trajectory of an action demonstrated by an expert. <br/><br/>The current project investigates a new interdisciplinary approach to imitation learning that is inspired by how humans learn via goal-based imitation. The project's specific objectives include: (1) a new method for imitation based on inferring the underlying goals of human actions rather than following trajectories: actions are executed based on sequences of inferred goals and successfully executed action sequences are cached as higher level goals, leading to hierarchical goal-based imitation; (2) a new approach based on hierarchical Bayesian models (HBMs) is proposed for generalization across objects and tasks, and (3) developmental studies of goal-based imitation learning are proposed for testing predictions of the project?s models in imitation learning experiments with children. <br/><br/>The project represents one of the first efforts to develop rigorous probabilistic models of goal-based imitation learning based on insights from human learning. The results are expected to pave the way for a new generation of machines that can interact fluently with humans, learn new skills from human teachers, and cooperatively solve problems with human partners. The project also provides graduate and undergraduate students with multidisciplinary training in computer science and cognitive science, with K-12 outreach activities aimed at encouraging students from underrepresented groups to pursue careers in science and engineering."
"1258741","RI: Small: GraphLab 2: An Abstraction and System for Large-Scale Parallel Machine Learning on Natural Graphs","IIS","CI REUSE, ROBUST INTELLIGENCE","08/01/2012","09/07/2012","Carlos Guestrin","WA","University of Washington","Standard Grant","Kenneth C. Whang","07/31/2015","$450,000.00","","guestrin@cs.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","6892, 7495","6892, 7433, 7923","$0.00","With the growth of the Web and improvements in data collection technology in Science, datasets have been rapidly increasing in size and complexity, necessitating comparable scaling of machine learning algorithms. However, designing and implementing efficient parallel machine learning algorithms is challenging and time consuming. To address this challenge, we recently released GraphLab, a framework providing an expressive and efficient high-level abstraction satisfying the needs of a broad range of machine learning algorithms. The performance of our system has attracted significant attention, receiving thousands of downloads from many universities and companies.<br/><br/>Currently, GraphLab only addresses batch processing in multicore settings. In this project, we are developing GraphLab 2: addressing the much more challenging online and distributed settings, tackling: 1) Cloud-based distributed machine learning. 2) Natural graphs, with very high-degree vertices that are not amenable to graph partitioning methods. 3) Online tasks, where data and queries are streaming over time. 4) Off-core computation, since huge problems may not fit into memory, even across the cloud.<br/><br/>One of the key contributions of the project is the continual dissemination and transfer of our technology. Our open-source software releases will continue to enable large-scale machine learning applications in science and engineering.<br/><br/>Our ambitious broader impact goals, beyond theory and systems, include the development of a new curriculum focused on preparing students for the industrial and scientific needs in this field. Our proposed courses include ""Machine Learning on the Web"" and ""Cloud Computing for Big Machine Learning and Data Mining."""
"1302672","Collaborative Research: RI: Processing Opinion Sharing Dialogue in Social Media","IIS","ROBUST INTELLIGENCE","09/01/2013","09/05/2013","Craig Martell","CA","Naval Postgraduate School","Interagency Agreement","Tatiana D. Korelsky","08/31/2016","$28,832.00","","cmartell@nps.edu","1 University Circle","Monterey","CA","939435000","8316562271","CSE","7495","7495, 7924, 170E","$0.00",""
"1352249","EAGER: Generating and Understanding Narratives for Dynamic Environments","IIS","ROBUST INTELLIGENCE","09/01/2013","08/29/2013","Hanna Hajishirzi","WA","University of Washington","Standard Grant","James Donlon","02/28/2015","$149,857.00","","hannaneh@uw.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7916","$0.00","Narrative generation is the process of generating textual descriptions of action in dynamic environments such as movies, sports events and educational programs. On-line narration of a dynamic environment is beneficial in a wide range of contexts, from entertainment to training and education. For example, successfully narrating a video would allow blind and visually-impaired people to follow visual cues that are important to understanding the video. Key to attaining this goal is the ability to translate natural language into a form that is understandable by computers. A particular challenge is to do this not for a specifically chosen domain, but in a general way that is suitable for adaptation to a wide range of natural dynamic environments. This project explores new directions to tackle these extremely challenging, yet crucial, issues, undertaking exploratory research towards building essential components of a domain-adaptive framework that learns to understand and generate narratives on-line for natural dynamic environments with minimal supervision by human experts. This research explores methods to generate narratives on-line by learning the natural dynamics of the environment, automatically forming templates, and deciding when and what to mention. <br/><br/>Many natural language applications are concerned with recognition of paraphrases and semantic understanding. The software and data resulting from this project are potentially useful for semantic analysis in natural language processing, and is being made available for research purposes. This work is designed for significant social impact through a broad range of applications including educational, entertainment, and accessibility. A narrative generation system could be beneficial to visually-impaired people to better understand videos over the internet. In addition, such a system can help broadcasting companies to report news or sports events with customized commentaries for different users. This project also provides research and collaborative work experience to undergraduate and graduate students including under-represented and minority groups."
"1056125","CAREER: Bridging dynamical and statistical models of neural circuits -- a mechanistic approach to multi-spike synchrony","DMS","MATHEMATICAL BIOLOGY, STATISTICS, ROBUST INTELLIGENCE","03/01/2011","02/20/2011","Eric Shea-Brown","WA","University of Washington","Standard Grant","Mary Ann Horn","02/29/2016","$469,114.00","","etsb@amath.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","MPS","7334, 1269, 7495","1045, 1187","$0.00","Questions of neural synchrony -- correlations in cell-to-cell spiking -- have <br/>driven decades of research. However, recent technological and theoretical <br/>advances have thrust open two lines of inquiry. The first is understanding <br/>the combinatorial scale of the correlations that occur in natural and model <br/>neural networks. It is well known that describing neural activity requires <br/>pairwise statistical interactions -- but we do not yet understand when network <br/>dynamics produce patterns of correlations that extend beyond this pairwise <br/>description, when the pairwise descriptions will be complete, and what the <br/>overall implications are for neural coding and signal processing. <br/>The Principal Investigator will address these questions for a set of ""canonical"" <br/>neural circuits, or motifs, and will build toward networks of gradually <br/>increasing complexity in their dynamics and architecture. Further, extending <br/>beyond intrinsic network dynamics, he will ask how these basic network properties <br/>determine the ways in which patterns of synchrony can be controlled by external stimulation. <br/>Answering these complementary questions requires synergies between methods of <br/>stochastic processes, dynamical systems, and statistical inference.<br/><br/>How do how networked neurons work together to produce the brain's astonishing <br/>computational ability? Such coordinated neural dynamics are characterized by <br/>synchrony among different neurons. One prospect is that this coordinated <br/>activity opens new channels for signal processing: there is a combinatorial <br/>explosion in the number of possible multi-neuron patterns that can occur in <br/>increasingly large networks. However, we only have the first hints at whether <br/>and when these patterns systematically occur in the brain's networks, and what <br/>information they might (or might not) carry. Shea-Brown will study the <br/>fundamental properties of neural dynamics, connectivity, and noise that <br/>determine the level and impact of multi-neuron synchrony in a series of <br/>networks of gradually increasing complexity. He will use <br/>interdisciplinary tools from both deterministic and statistical branches of <br/>applied mathematics to understand how levels of synchrony are created, <br/>destroyed, and manipulated by external stimulation. These findings will <br/>contribute to experimental and clinical neuroscience: working in <br/>collaboration with experimentalists, the investigator will make predictions for light stimuli <br/>that evoke higher-order correlations in the retina, and for electrical stimuli <br/>that suppress pathological synchrony in neurodegenerative disease. These <br/>questions, as part of theoretical neuroscience -- an emerging field that is <br/>rich in open questions and highly varied interdisciplinary techniques -- <br/>present a strong opportunity for recruiting, engaging, and training <br/>undergraduates in the mathematical sciences. Shea-Brown will direct this opportunity <br/>toward the underrepresented groups from which new scholars are most urgently <br/>needed, through an integrated four-year research pathway for undergraduates. <br/>This will be developed together with newly designed units in the computational <br/>science and mathematical biology courses taught by the investigator."
"0916951","RI: Small: Simplifying Text for Individual Reading Needs","IIS","ROBUST INTELLIGENCE","09/01/2009","08/10/2012","Mari Ostendorf","WA","University of Washington","Standard Grant","Tatiana D. Korelsky","08/31/2014","$463,210.00","","mo@ee.washington.edu","4333 Brooklyn Ave NE","SEATTLE","WA","981959472","2065434043","CSE","7495","7495, 7923, 9102, 9215, HPCC","$0.00","A surprisingly large number of Americans read below their grade level, either because of limited education or because their native language is not English. Low reading levels impact a child?s progress in school and an adult?s job opportunities as well as limiting information access. <br/>This project aims to improve access by developing new language processing technology for selecting and transforming text to obtain material at lower reading levels, extending current paraphrasing work that focuses on summarization as compression to include explanatory expansions. In addition, the goal is to develop adaptive models that can be tuned to a specific domain and an individual's needs. The approach involves analyzing corpora of comparable text collected from the web, developing models of paraphrasing aimed at generating simplified English, developing a discourse-sensitive clause selection method for expanding or omitting details, and exploring representations of language that facilitate domain and user adaptation. The language processing contributions of this work include development of text resources to support language technology in education applications, new representations of reading difficulty, and advances in automatic methods of paraphrasing. The broader impact of this project includes making information more accessible to people with limited English reading proficiency. In addition, students working on the project will have the opportunity to interact with teachers from a local school so as to better understand the impact of their work and guide their approach, and their work will be showcased in University of Washington diversity-oriented outreach programs."
"1161586","III: Medium: Collaborative Research: Developing a 3D Browser to Explore Genomes","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/06/2012","Jijun Tang","SC","University South Carolina Research Foundation","Standard Grant","Sylvia J. Spengler","09/30/2016","$444,302.00","","jtang@cse.sc.edu","901 Sumter Street","COLUMBIA","SC","292080001","8037777093","CSE","7364","7924, 9150","$0.00","New genome technologies enabled us to analyze the spatial conformation and interaction of chromatin together with their functional implication in important cellular activities such as gene regulation and cell state determination. With the influx of new details about the higher-level structure and dynamics of the genome, novel techniques will be required to visualize and model the full extent of genomic interactions to gain insight about genome functions. Current genome browsers are specifically aimed at viewing primary sequence information. Although supplemental information can be annotated via new tracks, representing structural hierarchies and interactions is quite difficult in these browsers, particularly across non-contiguous genomic segments. In addition, in spite of many recent efforts to measure and model the genome structure at various resolutions and detail, little work has focused on combining these models or taken advantage of the large amount of genomic and epigenomic data generated from new high-throughput approaches. To address these issues, the team has created a proof-of-concept interactive 3D viewer, Genome3D, to enable integration and visualization of genomic and epigenomic data in three dimension. Substantial development is needed to take advantage of the newest genomic technologies and to enable its integration with analysis pipelines. While enormous amount of spatial information for eukaryotic chromosomes have been generated, the size and complexity of these data require the design and development of new algorithms and methods in data integration and model construction. The goal is to develop a full-fledged, platform independent system that enables biologists to build and refine their own 3D genome models to analyze their data. <br/><br/>The intellectual merits of the research include: 1) Implementing a novel strategy to employ new engines with strong interactive design element to transform the prototype into a cloud-based 3D genome browser that can be used on various platforms including web browsers and tablets, making 3D structural genome information available to a broader research community. 2) Adding integrated tools that can analyze 3D features of genomes and support model building and validation. 3) Designing and providing robust set of APIs and scripting for customized data analysis. 4) Collaborating with other researchers to explore and visualize new three dimensional genome models.<br/><br/>There are a number of broader impacts in this research. A multi-scale three dimensional genome browser is crucial to achieve fuller understanding of genome functions and will provide a new way to teach genomics. Exploring genomes through 3D visualization will significantly advance genome research and will have a profound impact on comparative genomics and genetics. The use of new user interaction-intensive engines into scientific research tools and will encourage researchers in every area to use interactive visualization to analyze data. New algorithms to analyze models and visualize genomic information can be extended to problems of similar size in other fields and form the basis for new computational approaches. This project provides valuable interdisciplinary training experiences to undergraduate and graduate students and will attract more students to computational biology research. Results and the new browser will be disseminated through publications, workshops and tutorials and will enable customized development by providing detailed APIs and tutorials."
"1360568","CAREER: Holistic 3D Brain Image Parsing by Integrating Implicit and Explicit Models","IIS","ROBUST INTELLIGENCE","07/01/2013","09/24/2013","Zhuowen Tu","CA","University of California-San Diego","Continuing grant","Kenneth C. Whang","06/30/2015","$197,514.00","","zhuowen.tu@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7495","1045, 1187, 9215, HPCC","$0.00","Designing automated algorithms to extract and analyze anatomical brain structures from neuro-images is of significant scientific and clinical importance in detecting abnormal brain patterns, analyzing various brain diseases, and studying the brain growth.<br/><br/>This project will develop a general statistical modeling/computing framework to perform 3D holistic brain image understanding. The framework emphasizes rigorous, efficient, and effective learning-based statistical models to integrate the complex appearances, varying 3D shapes, and the large spatial configuration of anatomical brain structures.<br/><br/>Implicit models through discriminative approaches have the advantages of fusing a large amount of information and obtaining decisions quickly. Explicit models through generative approaches can directly represent the information and thus, better explain the structure and model the transformation and scale change. The PI explores harmonic relationships between discriminative and generative models for 3D image parsing by combining implicit and explicit models along several directions: (1) learning-based models with rich appearance, and implicit shape and context; (2) integrating skeleton with surfaces for 3D shapes; (3) effective 3D shape representation and similarity measure; (4) component-based simultaneous registration and segmentation.<br/><br/>This research will contribute to automating the process of extracting a large number of anatomical structures, and enhancing the shape analysis needed for detecting brain diseases, monitoring health conditions, studying drug effects, and discovering brain functions. The scope of the proposed model goes beyond medical image analysis and can be applied in other problems of statistical modeling/computing, computer vision, multi-variate labeling in machine learning."
"1318145","RI: Small: Dynamic Invariants for Video Scenes Understanding","IIS","ROBUST INTELLIGENCE","09/01/2013","08/21/2013","Octavia Camps","MA","Northeastern University","Standard Grant","Jie Yang","08/31/2016","$454,999.00","Mario Sznaier","camps@ece.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7495","7495, 7923","$0.00","This project aims to use a combination of elements from dynamic vision, dynamical systems theory, optimization and semi-algebraic geometry to develop a computationally tractable, scalable framework for automatic dynamic scene understanding from multiple, potentially incomplete and corrupted data streams. The long-term vision is to lay the foundations for synthesizing provably robust vision systems, capable of sustained successful operation in complex dynamic scenarios.<br/><br/>The core of the project is a unified vision, centered on the use of dynamical invariants as information encapsulators, and emphasizing robustness and computational complexity issues. In this approach, the observed data is treated as the output of an underlying model, typically a difference inclusion, which has associated certain quantities (for example order, embedding manifold, subspace spanned by its trajectories) that are invariant to coordinate transformations, initial conditions, viewpoint changes, synchronization, etc. These invariants compactly capture spatio-temporal information from video data and lead to robust, computationally efficient algorithms for automatic video scene understanding. For instance, in this context video data can be efficiently segmented by detecting changes in these dynamic invariants or clustered according to a suitable defined distance. An application domain directly impacted by this research is aware environments for public space safety, where the co-PIs have been provided access to real data and given a venue for real time testing of the algorithms."
"0964465","NetSE: Medium: Collaborative Research: Privacy Preserving Social Systems","IIS","NETWORK SCIENCE & ENGINEERING, INFO INTEGRATION & INFORMATICS","09/15/2010","03/26/2013","Alan Mislove","MA","Northeastern University","Standard Grant","Sylvia J. Spengler","08/31/2014","$339,891.00","","amislove@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173732508","CSE","7794, 7364","7924, 9215, 9251, 7794","$0.00","The success of the future Internet will not be measured by performance alone, but by its social and societal effects that alter our quality of life. The next-generation Internet must connect not only machines but also users: families and friends, representatives and rights advocates. There are immense technical challenges in facilitating communication while protecting user privacy and guarding their security. We address three key challenges. First, we apply user-focused research into developing practical secure communication between friends, laying the groundwork for social messaging without trusting centralized authorities to provide identities. Second, we develop advanced cryptographic techniques for processing private data without divulging it to application providers, placing private social applications on a solid theoretical foundation. Finally, we propose to fundamentally change how cooperation is encouraged and misbehavior is punished in distributed applications by embedding social network data into the design of applications.<br/><br/>This work has important broader impacts. Social networking is incredibly popular and maintaining privacy is a significant problem within these systems. The desire for privacy prevents individuals from participating fully and makes those who do participate vulnerable to various problems including potential identity theft. Because of the importance of the problem and problem domain, the results of our research will have significant public impact. Graduate and undergraduate students working on this proposal will gain experience with social applications, evaluating cryptographic protocols, and building systems that combine social data. We have actively involved undergraduate students in our research, and expect to continue."
"1331534","Travel Support: 9th International Symposium on Bioinformatics Research and Applications","IIS","INFO INTEGRATION & INFORMATICS, INFORMATION TECHNOLOGY RESEARC","10/01/2013","09/25/2013","Cynthia Gibas","NC","University of North Carolina at Charlotte","Standard Grant","Sylvia J. Spengler","09/30/2014","$20,000.00","Zhengchang Su","cgibas@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","7364, 1640","7364, 7556, 9102","$0.00","The International Symposium on Bioinformatics Research and Applications (ISBRA) is in its 9th year. This year's meeting will be held at the University of North Carolina at Charlotte, an emerging research university that has invested substantially in the development of research and educational programs in Bioinformatics since 2004. The International Symposium on Bioinformatics Research and Applications (ISBRA) will contribute to the rapid dissemination of latest research results and to foster the formation of collaborations between researchers with the multidisciplinary expertise required to analyze the enormous datasets accumulated in modern biological research. The conference content will encompass diverse topics from comparative and functional genomics, to systems biology, to population biology and genetics. ISBRA will provide important formative experiences to graduate students and post-doctoral scholars, helping them to become future leaders in the field. In 2013, when other popular bioinformatics conferences are being held outside the US, ISBRA will provide a valuable opportunity for resource-limited U.S.-based students and PIs to present research and interact with colleagues."
"1149787","CAREER: Multimodal and Multialgorithm Facial Activity Understanding by Audiovisual Information Fusion","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","03/01/2012","02/27/2012","Yan Tong","SC","University South Carolina Research Foundation","Standard Grant","Jie Yang","02/28/2017","$443,803.00","","tongy@cec.sc.edu","901 Sumter Street","COLUMBIA","SC","292080001","8037777093","CSE","7495, 9150","1045, 9150","$0.00","This project develops a unified multimodal and multialgorithm fusion framework to recognize facial action units, which describe complex and rich facial behaviors. The information from voice is incorporated with visual observations to effectively improve facial activity understanding since voice and facial activity are intrinsically correlated. The developed framework systematically captures the inherent interactions between the visual and audio channels in a global context of human perception of facial behavior. Advanced machine learning techniques are developed to integrate these relationships together with uncertainties associated with various visual and audio measurements in the fusion framework to achieve a robust and accurate understanding of facial activity. It is these coordinated and consistent interactions that produce a meaningful facial display.<br/><br/>The research work from this project fosters computer vision and machine learning technologies with applications across a wide range of fields varying from psychiatry to human-computer interaction. The new audiovisual emotional database constructed in this research facilitates benchmark evaluations and promotes new research directions, especially, in human behavior analysis. An integration of research and education promotes cutting-edge training on human-computer interactions to K-12, undergraduate, and graduate students, especially encourages the participation of women in engineering and computing."
"0953503","CAREER: Algorithms for Minimalist Robot Teams","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","08/15/2010","02/06/2010","Jason O'Kane","SC","University South Carolina Research Foundation","Standard Grant","Todd Leen","07/31/2015","$464,466.00","","jokane@cse.sc.edu","901 Sumter Street","COLUMBIA","SC","292080001","8037777093","CSE","7495, 9150","1045, 9215, HPCC, 1187, 9150","$0.00","The objective of this project is to design algorithms that allow teams of simple mobile robots to complete a wide range of tasks reliably. The key insight is that effective planning is possible for such teams, even in spite of significant uncertainty stemming from both sensing and motion. This approach builds upon existing work on minimalism for single robots, but must also overcome substantial complications that arise from coordination and communication between the robots. A distinguishing feature of this work is that the problems are complex and nontrivial at multiple scales: Planning for the multi-robot teams cannot be fully decoupled from the planning and control issues for individual robots.<br/><br/>The project combines three related research endeavors. First, it investigates techniques for representing each robot's uncertainty about its own state, and about the state and knowledge of the other robots. Second, it develops energy-efficient and robust strategies for communication between robots. Third, it applies these techniques in specialized planning algorithms to allow robot teams to complete their tasks in a decentralized manner.<br/><br/>This research will result in a collection of new algorithms that will allow teams of simple robots to manage uncertainty, communication, and planning in order to complete broad classes of tasks. These algorithms will enable simpler, more autonomous teams of robots to be deployed with less expense. Such robots will have significant positive impact on many sectors of our society, including transportation, space exploration, and agriculture. Broader impact will include development and distribution of ""covertly educational"" game software for middle school students, and training of undergraduate and graduate student researchers."
"1146926","Collaborative:EAGER: A Model Based System for the Automated Design of Synthetic Genetic Circuits by Mathematical Optimization","CCF","INFO INTEGRATION & INFORMATICS, ALGORITHMIC FOUNDATIONS","09/01/2011","04/11/2012","Ilias Tagkopoulos","CA","University of California-Davis","Standard Grant","Mitra Basu","08/31/2014","$287,100.00","Matthias Koeppe","iliast@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7364, 7796","7364, 7916, 7931, 9251","$0.00","Synthetic Biology is a nascent field with applications that range from bio-fabrication to alternative energy. Despite its significance, engineering of biological circuits still relies on trial-and-error tinkering techniques, with limited computational support. If Synthetic Biology is to advance to more complex synthetic systems that go beyond a handful of interacting parts, a scalable, integrative, methodological approach is necessary. In an analogy to integrated circuits, when it comes to circuit engineering, the role of detailed computer models, optimization methods, simulators and design tools is paramount.<br/><br/>Intellectual Merit: This project aims to pave the way towards an optimization-based, automated design framework for synthetic gene circuits that adhere to user-defined constraints. A synthetic gene circuit is a collection of one or more genes, together with elements (promoters, ribosome binding sites, etc.) that influence gene expression. The wiring, i.e. the order and position of every element, within a synthetic gene circuit determines the gene expression pattern, and overall behavior of the circuit. These circuits are introduced, usually as part of a plasmid(s), in a host organism that can be readily manipulated in order to achieve a desired outcome (e.g. specific temporal behavior, or production of an enzyme). <br/><br/>To facilitate faster time-to-market solutions and more robust, predictable designs, PIs will develop a design and optimization tool prototype. To that end, PIs propose a new optimization formulation that encompasses multiple biological models relevant to synthetic genetic circuit design. In addition, they propose a hybrid optimization-simulation technique to capture additional effects related to cell division, noise, and evolutionary processes. The investigation will focus on how state-of-the-art techniques from combinatorial optimization can be applied to find the optimal circuit for a specific task. Since the tool will need a library of well-characterized components to operate, PIs will create a mutant library of three widely-used regulators, then quantitatively characterize them, and store this information in a publicly available database. As a proof-of-concept experiment, they will assess their integrative approach by constructing an automatically-designed synthetic circuit, measuring its output and deviation from the desired goal, and then comparing it to other similar designs that have been already available in literature. <br/><br/>Broader Impact: An optimization-based, design tool for synthetic biology has the potential to provide a service to the academic community by reducing drastically the time-to-market aspect of synthetic designs, and providing insight on biological function, thus accelerating research in an exponentially growing field. All components and characterized libraries that will be developed as part of this award will be publicly available, deposited in the synthetic biology community?s standard Parts Registry. Furthermore, this award will partially support the work and training of the UC Davis IGEM team, a synthetic biology undergraduate team who competes in the annual IGEM competition. Knowledge from this project will be directly transferred into classrooms through the course ECS 289K ""Computational Challenges in Systems and Synthetic Biology"" (UC Davis), and the course CSC 450/550 ""Algorithms for Bioinformatics"" (U. Arizona)."
"1055107","CAREER: Scrapple: Fast Analytical Query Evaluation via Advanced Query Recycling Techniques","IIS","INFO INTEGRATION & INFORMATICS","01/01/2011","08/25/2011","Todd Green","CA","University of California-Davis","Continuing grant","Frank Olken","12/31/2015","$204,459.00","","green@cs.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956180000","5307547700","CSE","7364","1045, 1187, 7364","$0.00","The complex analytical queries characterizing decision support applications can be very expensive to compute, and the value of such applications is directly correlated to the speed at which answers can be returned to the user. Typically, once queries have been answered, database systems simply discard the results. However, a huge optimization opportunity is missed by doing this: there is tremendous latent energy in the discarded query results, if we only knew how to recycle them to help answer subsequent related queries. The goal of the project is to develop Scrapple, a principled database management system that aggressively reuses old query results to speed up the answering of new queries, resulting in potentially dramatic performance gains for a large class of decision support applications.<br/><br/>Scrapple's basic strategy is to view cached query results (and their intermediate subresults) as materialized views, and then employ advanced techniques for optimizing queries using materialized views to answer subsequent queries. To execute this strategy, the project develops: (1) a novel and comprehensive theory of differential reformulation strategies; (2) a set of unifying principles connecting incremental view maintenance and optimization of queries using materialized views; (3) a novel and comprehensive theory of data provenance for aggregate queries; and (4) practical implementation techniques for recycling cached results via cost-based search strategies. By using fully automated techniques, Scrapple will dramatically reduce the total cost of ownership of a typical data warehouse. Moreover, the techniques at the heart of our approach have wide application in areas such as data integration, data exchange, view maintenance, and data provenance. The research will also be used to develop lecture and project materials for new course modules. These educational materials, along the Scrapple source code and publications, will be made freely available at the project Web site, http://www.cs.ucdavis.edu/~green/scrapple."
"1319914","RI: Small: A Generic Mid-Level Representation as Object Part Hypotheses for Scalable Object Category Recognition","IIS","ROBUST INTELLIGENCE","09/15/2013","09/11/2013","Benjamin Kimia","RI","Brown University","Standard Grant","Jie Yang","08/31/2016","$450,000.00","","Benjamin_Kimia@Brown.Edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495","7495, 7923, 9150","$0.00","This project develops a fragment-based intermediate-level representation for images based on shape and appearance, with shape playing the primary role. The representation can be populated in a bottom-up, category-independent fashion, which at the same time can be efficiently accessible by top-level, category dependent processes. The inherent ambiguity in generating object part hypotheses is resolved by combinatorially forming alternative image fragments by standard as well as novel perceptual operations, taking into account both shape and appearance, and both region-based and boundary-based cues. The exponential growth of the number of fragments is managed under a best-first graph representation that avoids duplication, leading to a sufficient number of diagnostic recognizable object parts among a vast pool of fragments. The project also explores an embedding of these fragments in a metric similarity space via proximity graphs and a geometric index structures for efficient nearest neighbor search. The final outcome is a representation space and an index for scalable, logarithmic object category recognition. A key aspect of this work is that categories themselves are also represented in a hierarchical similarity space, and this computationally implements ideas akin to Rosch?s basic level categorization. <br/><br/>The broader impacts of this activity spans a vast number of applications: any application which benefits from scalable object recognition such as indexing into databases, e.g., searching in a database of trademarks, engineering drawings and computer generated graphics, content-based web search, aerial tracking and recognition of vehicles, automated animal behavior analysis, and many others."
"1319941","EAGER: Aggregating Online Information in Science","IIS","ROBUST INTELLIGENCE","09/15/2013","09/10/2013","Bruce Buchanan","CA","American Association for Artificial Intelligence","Standard Grant","James Donlon","08/31/2015","$71,832.00","","buchanan@cs.pitt.edu","2275 E BAYSHORE RD STE 160","Palo Alto","CA","943033224","6503283123","CSE","7495","7495, 7916","$0.00","This project continues the development of the AITopics information portal, a service to the Artificial Intelligence research community and an educational resource for the general public. The portal can be found at www.aitopics.org. This site was originally conceived as a compendium of introductory and historical articles about artificial intelligence for use by the AI community as well as the general public. The initial prototype was a manual effort conducted by volunteers at the Association for the Advancement of Artificial Intelligence (AAAI). Following this, an NSF-funded effort was undertaken in 2012 to reduce the time required of volunteers without reducing the quality of information provided. This project advances the sophistication of the portal by automating the time-consuming process of selecting content from the literature to post on the website, and by enhancing a deployed AI news finder program employed to feed the site with fresh content. The ultimate goal of this work is to build a generally useful content management framework that would be applicable to such outreach effort across all sciences. <br/><br/>The project activities include A) development of the NewsFinder program to browse online AI journals as well as current periodicals to find interesting overview articles; B) creation of additional content management technology including tools for user interaction and feedback; creation of meta-data for search engines, creation of summary descriptions; automatically learning criteria for interesting items; and creation of tools to identify new topics as the field changes; C) continued curating of online versions of classic books and papers, including scanning material only available in hard copy; D) extension of NewsFinder to find articles describing new applications in each Applications area; E) as well as to provide useful information to practitioners in a new area of technology, including classification of IAAI papers by industry and type of problem; and F) expansion of the use of social media and mobile devices to refine and deliver information."
"1308159","CRCNS: Collaborative Research: The role of inhibition and correlated dynamics in cortical visual processing","IIS","ROBUST INTELLIGENCE","10/01/2013","09/09/2013","Ralf Wessel","MO","Washington University","Standard Grant","Kenneth C. Whang","09/30/2016","$363,388.00","","rw@wuphys.wustl.edu","ONE BROOKINGS DRIVE, CAMPUS BOX","SAINT LOUIS","MO","631304899","3148895100","CSE","7495","7327, 9150","$0.00","The cerebral cortex is comprised of two competing types of brain cells: inhibitory neurons tend to suppress brain activity while excitatory neurons do the opposite. This project will illuminate principles governing the balance of inhibition versus excitation. Focusing on the role of inhibition, the project will test the hypothesis that a particular intermediate level of inhibition is optimal for sensory information processing, because it places the cortex network in a special operating regime called criticality. <br/><br/>When inhibition is too high, cortical neurons are suppressed and act largely independently. When inhibition is too low neurons are hyperactive and act largely in unison. Neither extreme is conducive to effective information processing. However, gradually decreasing inhibition from a high level can result in an abrupt onset of correlated, intense activity among the neurons. The tipping point of this onset is called criticality. Importantly, computer models and cortex slice investigations predict that at criticality certain types of information processing are optimized. However, the potentially pivotal role of criticality in processing real sensory input in an intact sensory system remains untested. Such tests will be undertaken here in an in vitro whole-brain preparation that allows the researchers to precisely manipulate levels of global inhibition, record cortical activity with microelectrode arrays for many hours, and stimulate the retina with naturalistic images. Employing novel, statistically rigorous, multifaceted, quantitative tests of criticality, the proposed research will determine the roles of inhibition and criticality in intact cortex during visual processing. Specifically, the experiments are designed to determine whether information transfer from visual stimulus to cortical response is maximized at an intermediate level of inhibition which manifests as criticality.<br/><br/>This project represents the first experimental test of the hypothesized functional benefits of criticality in real sensory processing. It builds on a strong conceptual foundation combining statistical physics and computational neuroscience, and may open a new paradigm for investigating cortical visual processing in large neural networks. This new paradigm is particularly relevant in light of emerging new technologies that enable the recording of activity from thousands of neurons. From the medical perspective this contribution is significant because it is expected to illuminate the etiology of numerous brain disorders with abnormal inhibition. Finally, the project brings the excitement of research into Missouri and Arkansas high schools with teacher training and classroom presentations. Newly fostered interest in STEM research will be assessed by longitudinal measures."
"1320357","III: Small: Cumulon: Easy and Efficient Statistical Big-Data Analysis in the Cloud","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/09/2013","Jun Yang","NC","Duke University","Continuing grant","Frank Olken","08/31/2016","$330,438.00","Michael Ward, Sayan Mukherjee, Shivnath Babu","junyang@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7364","7923, 7364","$0.00","""Big data"" have been growing in volume and diversity at an explosive rate, bringing enormous potential for transforming science and society. Driven by the desire to convert data into insights, analysis has become increasingly statistical, and there are more people than ever interested in analyzing big data. The rise of cloud computing in recent years offers a promising possibility for supporting big data analytics. However, it remains frustratingly difficult for many scientists and statisticians to use the cloud for any non-trivial statistical analysis of big data. <br/><br/>The first challenge is development---users need to code and think in low-level, platform-specific ways, and, in many cases, resort to extensive manual tuning to achieve acceptable performance. The second challenge is deployment---users are faced with a maddening array of choices, ranging from hardware provisioning (e.g., type and number of machines to request), software configuration (e.g., number of parallel execution slots per machine), to execution parameters and implementation alternatives.<br/><br/>This project aims to build Cumulon, an end-to-end solution for making statistical computing over big data easier and more efficient in the cloud. For development, users can think and code in a declarative fashion, without worrying about how to map data and computation onto specific hardware and software. For deployment, Cumulon presents users with best ""plans"" meeting their requirements, along with completion time and monetary cost to help them make decisions. A plan encodes choices of not only implementation alternatives and execution parameters, but also cluster resource and configuration parameters. This project develops effective cost modeling and efficient optimization techniques for the vast search space of possible plans. Cumulon addresses the challenges of uncertainty and extensibility (in terms of not only functionality but also optimizability). Cumulon also features a performance trace repository, which collects data from past deployments and uses them to improve cost modeling and optimization.<br/><br/>Cumulon aims to make statistical computing over big data easier and more cost-effective for a wide range of users including scientists and statisticians. Besides leveraging the cloud to provide on-demand, pay-as-you-go access to computing resources, Cumulon further simplifies development and deployment, reduces reliance on programming and tuning support, and accelerates data-driven discoveries. More than a one-shot solution, Cumulon is designed as a basis for an evolvable, open-source ecosystem that keeps up with advances in big-data analytics. Its repository of performance traces benefits the community in independent ways. <br/><br/>With the growing importance of quantitative, data-driven methods, Cumulon can impact many domains. The interdisciplinary team of PIs---from computer science, statistics, etc. ---is applying Cumulon to concrete applications in biomedical research and computational journalism. Through collaboration, the PIs seek to attract diverse talents, motivate them to work on problems with potential societal impacts, and help prepare them for the new challenges of big data.<br/><br/>For further information see the web site at: http://db.cs.duke.edu/projects/cumulon"
"1321000","III: Small: Genome-Wide Algorithms for Haplotype Reconstruction and Beyond: A Combined Haplotype Assembly and Identical-by-Descent Tracts Approach","IIS","INFO INTEGRATION & INFORMATICS","10/01/2013","09/09/2013","Sorin Istrail","RI","Brown University","Standard Grant","Sylvia J. Spengler","09/30/2016","$499,998.00","","sorin@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7364","7923, 9150","$0.00","The project will develop rigorous and fast (practical) graph-theoretic genome-wide algorithms associated with genome sequence data and graphs within an integrated set of research and educational activities designed to intertwine synergistically with statistical modeling; apply these to the solution of real-world problems and long-standing computer science and mathematics questions that impact molecular biology; and make these techniques accessible to students, researchers, and practitioners in the corresponding fields. The project focuses on algorithms for haplotype reconstruction from genome sequence data of various organisms and genomes having different polyploidy number, i.e., number of haplotypes. The mammalian genomes, human included, are diploid genomes. However, the polyploidy number varies across the life spectrum from 1 (bacteria) to more than 100 (adder's-tongue fern). The HapCompass graph-theoretic framework associates genome sequencing read mappings with the genome-wide SNP data in the human genome.The HapCompass algorithm uses local optimization algorithms on the spanning tree cycle basis of HapCompass graphs for objective functions that model various measures of error correction in haplotype reconstruction. Earlier work provided a combinatorial framework for error-correction models for diploid haplotype assembly, a framework embraced by the large literature on the topic in the following decade. The fundamental case of diploid genomes and the HapCompass graph theory, data structures and algorithms set the stage for generalizations to polyploidy and integrative genome-wide haplotype reconstruction in samples of individuals that share haplotypic regions identical by descent. In addition, curriculum development is plan that covers the topics from both a computing and the user perspective. All materials and software, source code, and documentation will be available. Software will rely on the open-source model.<br/><br/>This project intertwines computer science with statistical models and an impact in genomics and molecular biology. Faster and more accurate algorithms for diploid haplotype assembly based on multi-criteria optimization using multiple models of error correction on the spanning-tree cycle bases of compass graphs will be developed. In addition, robust generalizations of the graph theory and algorithms for polyploid genomes that permit a common algorithmic strategy are planned. The team also is developing an optimal linear time algorithm for shared IBD tract identification in the case of phased genotype data, and efficient and exact algorithms for IBD haplotype tract identification for shared IBD tracts in unphased genotype data that are linear in the number of haplotypes and subquadratic in the number of genotypes to enhance efficiency. The final product of the work will be an algorithmic framework for genome-wide haplotype reconstruction created by combining the new algorithms and Clark Consistency Graph data structures and algorithms."
"1147499","Testing and improving methods for efficient annotation through the construction of a large parsed corpus","BCS","LINGUISTICS, ROBUST INTELLIGENCE","07/15/2012","09/14/2013","Anthony Kroch","PA","University of Pennsylvania","Standard Grant","William J. Badecker","12/31/2014","$344,865.00","Seth Kulick","kroch@ling.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","SBE","1311, 7495","1311, 9251, 7434, 9179, 7495, SMET","$0.00","Electronic corpora annotated with linguistic information play a crucial role in natural language processing (NLP) and in linguistic research. Treebanks (corpora annotated with syntactic information) are especially important since they mark the grammatical structure necessary for understanding sentence and discourse meaning. For NLP, treebanks provide testbeds for developing language understanding systems. For linguistic research, they provide the basis for precise and replicable studies of the patterns of use of syntactic forms. Unfortunately, accurate annotation is difficult. Automatic parsers have relatively high error rates and the correction of these errors by human annotators is both slow and itself error-prone. Based on recent advances that Dr. Kroch and his collaborators have made in the creation and quality control of three large treebanks for different languages, Dr. Kroch proposes a major effort to improve corpus construction through the creation of a two-million-word English treebank. Along with this useful and substantial result, the project will develop and test hypotheses on speeding up treebank construction. The work will be guided by two complementary strategies. The first aims to reduce the parser's error rate by enhancing the part-of-speech (POS) tagged input to the parser while the second aims to make the correction of residual errors more efficient by shifting some of the burden from human to automatic error detection and correction. Speeding up the construction of accurate, consistent treebanks will improve the size and quality of training data for parsers, leading to improved performance in real-world NLP applications that rely on parsing. The availability of larger treebanks and of better methods for constructing them will also improve linguistic research. Moreover, as treebanks grow in size, they will become more useful in literary and historical studies, where the rhetorical structure of texts will become investigable in a more precise way than is currently possible.<br/><br/>In addition to the intellectual merit of the proposed research and the impact it can be expected to have on text-based research that relies on automated processing techniques, the project will provide valuable training opportunities for graduate and undergraduate students. In contributing to improvements in automated techniques for language processing, this project may also benefit the analytic needs in industry and government security."
"1354459","NRI: NSF: Challenges and Opportunities in Utilizing Robotics in Small and Medium Manufacturing Enterprises","IIS","ROBUST INTELLIGENCE","10/01/2013","09/11/2013","Henrik Christensen","GA","Georgia Tech Research Corporation","Standard Grant","Jie Yang","09/30/2014","$48,935.00","","hic@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7556","$0.00","This grant supports organization of the workshop that brings together thought leaders from industry and academia to discuss use-case scenarios for use of robots in small and medium sized enterprises. The objective of the workshop is (1) to present and discuss industry use-cases for robotics in manufacturing and in particular examples where a move from fixed automation to flexible automation is an economic enabler and (2) to have broad discussions across academia and industry to internalize a common set of challenges and opportunities. The workshop participants gain new insights into what advances needed to deploy robotics in small and medium manufacturers. The workshop report provides a roadmap of challenges and research opportunities to guide the robotics community. The workshop stimulates future research towards development of robots for manufacturing applications. These activities directly impact the U.S. manufacturing."
"1302256","RI: Medium: Collaborative Research: BCSP: Automated Parameter Tuning of Large-Scale Spiking Neural Networks","IIS","ROBUST INTELLIGENCE","09/15/2013","09/10/2013","Kenneth De Jong","VA","George Mason University","Standard Grant","Kenneth C. Whang","08/31/2016","$474,996.00","","kdejong@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7495","7495, 7924","$0.00","A framework will be developed to help scientists and engineers create brain-inspired, brain-sized networks that can carry out practical applications. Large-scale spiking neural networks, which follow the brain's architecture and activity, have been used to successfully model phenomena such as learning and memory, vision, auditory processing, neural oscillations, and many other important aspects of neural function. Additionally, spiking neural networks are particularly well suited to run on neuromorphic hardware, state of the art computers that emulate the brain?s structure and dynamics. These neuromorphic systems depend on the binary nature of spikes to lower communication bandwidth and energy consumption. Although significant progress has been made towards the specification and simulation of large-scale spiking neural networks on a variety of hardware platforms, many challenges remain before these neurobiologically inspired algorithms can be used in practical applications. While biology does provide increasingly abundant empirical data that can constrain these systems, many parameter values must be chosen manually by the designer to achieve appropriate neuronal dynamics, a task that is extremely tedious and often error-prone. To meet this challenge, an automated parametertuning framework will be developed that is capable of quickly and efficiently tuning large-scale spiking neural networks. The framework will leverage recent progress in evolutionary algorithms and optimization techniques for off-the-shelf graphics processing units (GPUs). The parameter search will be guided by the idea in neuroscience that biological networks adapt their responses to increase the amount of transmitted information, reduce redundancies, and span the stimulus space. This notion of efficient coding will guide the tuning process of the artificial spiking neural networks. Computer scientists and engineers will be able to use the resulting automated parameter-tuning framework to create brain inspired applications, such as vision and memory systems, on neuromorphic hardware. Moreover, the resulting framework will allow neuroscientists to more readily create models that better describe their empirical data and generate new quantitative hypotheses that can be tested in the laboratory."
"1302125","RI: Medium: Collaborative Research: BCSP: Automated Parameter Tuning of Large-Scale Spiking Neural Networks","IIS","CROSS-EF ACTIVITIES, ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC, ACTIVATION","09/15/2013","09/10/2013","Jeffrey Krichmar","CA","University of California-Irvine","Standard Grant","Kenneth C. Whang","08/31/2016","$474,998.00","Nikil Dutt","jkrichma@uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7275, 7495, 1640, 7713","7495, 7924, 8750","$0.00","A framework will be developed to help scientists and engineers create brain-inspired, brain-sized networks that can carry out practical applications. Large-scale spiking neural networks, which follow the brain's architecture and activity, have been used to successfully model phenomena such as learning and memory, vision, auditory processing, neural oscillations, and many other important aspects of neural function. Additionally, spiking neural networks are particularly well suited to run on neuromorphic hardware, state of the art computers that emulate the brain?s structure and dynamics. These neuromorphic systems depend on the binary nature of spikes to lower communication bandwidth and energy consumption. Although significant progress has been made towards the specification and simulation of large-scale spiking neural networks on a variety of hardware platforms, many challenges remain before these neurobiologically inspired algorithms can be used in practical applications. While biology does provide increasingly abundant empirical data that can constrain these systems, many parameter values must be chosen manually by the designer to achieve appropriate neuronal dynamics, a task that is extremely tedious and often error-prone. To meet this challenge, an automated parametertuning framework will be developed that is capable of quickly and efficiently tuning large-scale spiking neural networks. The framework will leverage recent progress in evolutionary algorithms and optimization techniques for off-the-shelf graphics processing units (GPUs). The parameter search will be guided by the idea in neuroscience that biological networks adapt their responses to increase the amount of transmitted information, reduce redundancies, and span the stimulus space. This notion of efficient coding will guide the tuning process of the artificial spiking neural networks. Computer scientists and engineers will be able to use the resulting automated parameter-tuning framework to create brain inspired applications, such as vision and memory systems, on neuromorphic hardware. Moreover, the resulting framework will allow neuroscientists to more readily create models that better describe their empirical data and generate new quantitative hypotheses that can be tested in the laboratory."
"1149260","CAREER: Discovering Common Human Brain Architecture","IIS","ROBUST INTELLIGENCE, OTHER GLOBAL LEARNING & TRNING","09/01/2012","09/09/2013","Tianming Liu","GA","University of Georgia Research Foundation Inc","Standard Grant","Kenneth C. Whang","08/31/2017","$459,279.00","","tliu@uga.edu","200 D.W. Brooks Drive","ATHENS","GA","306025016","7065425939","CSE","7495, 7731","1045, 7495, 5946, 5979","$0.00","Is there a common human brain architecture that can be quantitatively encoded and precisely reproduced across individuals? This CAREER project aims to discover and represent common human brain architecture through a map of Dense Individualized and Common Connectivity-based Cortical Landmarks (DICCCOL). Each of the landmarks will be defined by group-wise consistent white matter fiber connection patterns derived from diffusion tensor imaging (DTI) data. In parallel, large-scale multimodal fMRI and DTI datasets will be employed to determine predictive relationships between DICCCOLs and functional localizations. The resulting DICCCOL representation of common brain architecture will be applied to create a universal and individualized brain reference system, construct human brain connectomes, and elucidate the brain's functional interactions. The education objective of this CAREER project is to create and assess a fundamentally novel interdisciplinary higher education approach, namely, transformative interdisciplinary group learning (TIGL). Students and instructors from three courses that are related but emerge from different disciplinary perspectives (Biomedical Image Analysis, Introduction to MRI Physics, and Functional Brain Imaging) will work together in one classroom. During these common sessions, the students will have synergistic learning activities, engage in interdisciplinary group discussions, and design and conduct interdisciplinary group projects.<br/><br/>The discovery and representation of common brain architecture will fundamentally advance scientific understanding of the human brain. Broad dissemination of the DICCCOL map and its prediction framework will transform numerous applications that rely on structural/functional correspondences across individuals. The DICCCOL map offers a generic bridge to compare and integrate neuroimaging data across laboratories, which will stimulate and enable plentiful collaborative efforts. While this project has a focus on brain imaging, the general methodology of predictive modeling of structure and function is expected to influence many other imaging domains. The TIGL approach will advance fundamental understanding of interdisciplinary learning. The TIGL approach will be scaled up to other institutions and disciplines, and will be widely disseminated. This continuous effort will establish the TIGL approach as a general interdisciplinary education methodology to increase the capacity of the next generation of scientists who have an interdisciplinary mindset."
"1308174","CRCNS: Collaborative Research: The role of inhibition and correlated dynamics in cortical visual processing","IIS","ROBUST INTELLIGENCE, GRAPHICS & VISUALIZATION","10/01/2013","09/09/2013","Woodrow Shew","AR","University of Arkansas","Standard Grant","Kenneth C. Whang","09/30/2016","$361,347.00","","shew@uark.edu","210 Administration Building","FAYETTEVILLE","AR","727011201","4795753845","CSE","7495, 7453","7327, 9150","$0.00","The cerebral cortex is comprised of two competing types of brain cells: inhibitory neurons tend to suppress brain activity while excitatory neurons do the opposite. This project will illuminate principles governing the balance of inhibition versus excitation. Focusing on the role of inhibition, the project will test the hypothesis that a particular intermediate level of inhibition is optimal for sensory information processing, because it places the cortex network in a special operating regime called criticality. <br/><br/>When inhibition is too high, cortical neurons are suppressed and act largely independently. When inhibition is too low neurons are hyperactive and act largely in unison. Neither extreme is conducive to effective information processing. However, gradually decreasing inhibition from a high level can result in an abrupt onset of correlated, intense activity among the neurons. The tipping point of this onset is called criticality. Importantly, computer models and cortex slice investigations predict that at criticality certain types of information processing are optimized. However, the potentially pivotal role of criticality in processing real sensory input in an intact sensory system remains untested. Such tests will be undertaken here in an in vitro whole-brain preparation that allows the researchers to precisely manipulate levels of global inhibition, record cortical activity with microelectrode arrays for many hours, and stimulate the retina with naturalistic images. Employing novel, statistically rigorous, multifaceted, quantitative tests of criticality, the proposed research will determine the roles of inhibition and criticality in intact cortex during visual processing. Specifically, the experiments are designed to determine whether information transfer from visual stimulus to cortical response is maximized at an intermediate level of inhibition which manifests as criticality.<br/><br/>This project represents the first experimental test of the hypothesized functional benefits of criticality in real sensory processing. It builds on a strong conceptual foundation combining statistical physics and computational neuroscience, and may open a new paradigm for investigating cortical visual processing in large neural networks. This new paradigm is particularly relevant in light of emerging new technologies that enable the recording of activity from thousands of neurons. From the medical perspective this contribution is significant because it is expected to illuminate the etiology of numerous brain disorders with abnormal inhibition. Finally, the project brings the excitement of research into Missouri and Arkansas high schools with teacher training and classroom presentations. Newly fostered interest in STEM research will be assessed by longitudinal measures."
"1318957","III: Small: Collaborative Research: Anomaly Detection in Graph Streams","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/09/2013","William Eberle","TN","Tennessee Technological University","Standard Grant","Frank Olken","08/31/2016","$208,994.00","","weberle@tntech.edu","Dixie Avenue","Cookeville","TN","385013405","9313723374","CSE","7364","7923, 7364, 9150","$0.00","The main objective of this project is to develop scalable algorithms for learning normative patterns and anomalies in graph streams, where the patterns are known, unknown but fixed, or changing over time. The project team is pursuing several techniques, including partitioning the graph over time, processing only the changes to the graph over time, and parallel implementations on high-performance computing platforms. They are evaluating the effectiveness and efficiency of these algorithms in terms of expected data sizes, data rates, and recall/precision using several real-world, large, dynamic datasets as well as synthetic data. They are also evaluating the discovered patterns and anomalies for their significance in the target domains. This research is advancing the knowledge and understanding of how to efficiently process large, high-rate data streams represented as a graph in order to learn structural patterns and detect structural anomalies in real time. The algorithms developed under this project represent a new level of scalability that is necessary to address today?s massive, dynamic data environments, as well as users' needs to quickly discover actionable intelligence in the form of trends and anomalies. <br/><br/>This project impacts the scientific research community by advancing the state-of-the-art in mining graphs for patterns and anomalies in large, dynamic data streams, and disseminating these research results via publications, software tools and data to be provided on the project website. This project also impacts education via the inclusion of research results into existing courses at the teams' institutions, and the dissemination of these curricular materials via the project website. The project supports the research training of two graduate students, utilizing recruiting efforts from underrepresented groups to assist in the selection of these students. The project benefits society by providing efficient and effective tools for detecting patterns and anomalies in data that can lead to new discoveries in a variety of domains where large amounts of dynamic data are available, including national security, cyber-security, and social media.<br/><br/>For further information see project website: http://ailab.wsu.edu/adgs"
"1344219","INSPIRE Track 1: Nanotechnology for Adaptive Optics","CBET","BIOPHOTONICS, IMAGING &SENSING, CROSS-EF ACTIVITIES, ORGANIZATION, INSPIRE, BIOMEDICAL ENGINEERING, ROBUST INTELLIGENCE, IIS SPECIAL PROJECTS, INSTRUMENTAT & INSTRUMENT DEVP, INFORMATION TECHNOLOGY RESEARC","10/01/2013","09/09/2013","Edward Boyden","MA","Massachusetts Institute of Technology","Continuing grant","Leon Esterowitz","09/30/2016","$833,999.00","","esb@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","ENG","7236, 7275, 7712, 8078, 5345, 7495, 7484, 1108, 1640","004E, 005E, 024E, 027E, 137E, 8653, 7237","$0.00","ABSTRACT<br/>This INSPIRE award is partially funded by the Biophotonics (7236)and Biomedical Engineering (5345) programs in the CBET Division in the Directorate for Engineering; the Robust Intelligence (7495) program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering; and the the Organization (7712) program in the Division of Integrative Organismal Systems in the Directorate for Biology and the Instrumentation and Instrument Development (1108) program in the Division of Biological Infrastructure, also in the Directorate for Biology. Emerging Frontiers (7275) money was provided for the Organization and Instrumentation and Instrument Development programs by the Directorate for Biology.<br/><br/><br/>The ability to optically image real-time physiological processes in living systems is of central importance for understanding how biological systems compute and function. In order to enable the imaging of deep, arbitrary-scale tissues, the PI proposes to address one of the fundamental limitations in live tissue imaging: the scattering of light by live tissues. Much work has been devoted to adaptive optics using conventional off-the-shelf spatial light modulators, interferometers, cameras, and other hardware. Here the PI proposes to create new technologies for adaptive optics based instead upon nanotechnology, which can help correct optical imaging for the scattering properties of living tissues. The project goal is nothing less than that of making real-time physiological processes visible throughout live tissues and organs, important for understanding how biological computations occur. The impact will be large for any field where understanding complex 3-D systems is key - for the study of live organs such as heart and brain, for the immune system, for the study of metabolism, for the study of development and aging, and for cancer biology. <br/>They will distribute all tools as freely as possible, and pursue distribution mechanisms to maximize the availability of tools, at cost whenever possible. The proposed innovations will also benefit the field of optogenetic control of complex systems. These innovations will also greatly help with teaching of biology and medicine at all levels of education, since the ability to visualize things is powerful in education; we will incorporate these tools into teaching both at MIT and elsewhere, engaging scientists-in-training, as well as the public. Through both direct impact of tool usage, as well as via teaching, they anticipate that these proposed technologies will result in a more scientifically literate workforce. they also anticipate commercial impact, in the creation of new methods of diagnostics and medicine. The ability to hunt down better disease mechanisms, or mechanisms of disease treatment, may accelerate the development of new drugs and therapies. Some of the technologies here proposed could also lead to new companies, or new products, thus contributing to economic development, as well as helping with dissemination of the tools."
"1318913","III: Small: Collaborative Research: Anomaly Detection in Graph Streams","IIS","INFO INTEGRATION & INFORMATICS","09/15/2013","09/09/2013","Lawrence Holder","WA","Washington State University","Standard Grant","Frank Olken","08/31/2016","$249,796.00","","holder@wsu.edu","NEILL HALL, ROOM 423","PULLMAN","WA","991643140","5093359661","CSE","7364","7923, 7364","$0.00","The main objective of this project is to develop scalable algorithms for learning normative patterns and anomalies in graph streams, where the patterns are known, unknown but fixed, or changing over time. The project team is pursuing several techniques, including partitioning the graph over time, processing only the changes to the graph over time, and parallel implementations on high-performance computing platforms. They are evaluating the effectiveness and efficiency of these algorithms in terms of expected data sizes, data rates, and recall/precision using several real-world, large, dynamic datasets as well as synthetic data. They are also evaluating the discovered patterns and anomalies for their significance in the target domains. This research is advancing the knowledge and understanding of how to efficiently process large, high-rate data streams represented as a graph in order to learn structural patterns and detect structural anomalies in real time. The algorithms developed under this project represent a new level of scalability that is necessary to address today?s massive, dynamic data environments, as well as users' needs to quickly discover actionable intelligence in the form of trends and anomalies. <br/><br/>This project impacts the scientific research community by advancing the state-of-the-art in mining graphs for patterns and anomalies in large, dynamic data streams, and disseminating these research results via publications, software tools and data to be provided on the project website. This project also impacts education via the inclusion of research results into existing courses at the teams' institutions, and the dissemination of these curricular materials via the project website. The project supports the research training of two graduate students, utilizing recruiting efforts from underrepresented groups to assist in the selection of these students. The project benefits society by providing efficient and effective tools for detecting patterns and anomalies in data that can lead to new discoveries in a variety of domains where large amounts of dynamic data are available, including national security, cyber-security, and social media.<br/><br/>For further information see project website: http://ailab.wsu.edu/adgs"
"1252951","CAREER: Computational mechanisms of rapid visual categorization: Models and psychophysics","IIS","ROBUST INTELLIGENCE, CAREER: FACULTY EARLY CAR DEV","09/15/2013","09/08/2013","Thomas Serre","RI","Brown University","Standard Grant","Kenneth C. Whang","08/31/2018","$500,001.00","","Thomas_Serre@brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7495, 1045","1045, 9150","$0.00","Primates can recognize objects embedded in complex natural visual scenes at a glance. Despite the ease with which we see, visual recognition -- one of the key issues addressed in computer vision -- is quite difficult for machines. Understanding which computations are performed by the visual cortex would give scientists a powerful tool to uncover key mechanisms of human perception and cognition as well as to create a new generation of 'seeing' machines. <br/><br/>The PI's central research goal is to identify the perceptual principles and model the neural mechanisms underlying rapid visual categorization. By forcing processing to be fast, rapid visual categorization paradigms help isolate the very first pass of visual information before more complex visual routines take place. Hence, understanding 'vision at a glance' is arguably a necessary first step before studying natural everyday vision where eye movements and attentional shifts are known to play a key role.<br/><br/>Specifically, this proposal will lead to the development of a computational neuroscience model of rapid visual recognition in the primate visual system, which is both consistent with physiological properties of cells in the visual cortex and able to predict behavioral responses (both correct and incorrect responses as well as reaction times) from human participants across a range of conditions. The proposed model will integrate recent developments in computational models of vision and decision making with large-scale machine learning techniques. New stimulus sets will be generated, which are optimally tailored for testing among alternative visual representations and computations against human psychophysics data. These experiments will, in turn, enable the refinement of computational models.<br/><br/>The computational models developed as part of this proposal will be integrated in courses and disseminated broadly via a web graphical interface. Overall the interdisciplinary nature of the proposal will give students the opportunity to experience a research environment that crosses traditional boundaries across disciplines and departments. Increased undergraduate participation in computational neuroscience will help integrate this area into the mainstream computer science and neuroscience curricula."
"1320490","RI: Small: Qualitative Relational Navigation using Minimal Sensing","IIS","ROBUST INTELLIGENCE","09/15/2013","09/08/2013","Mark Campbell","NY","Cornell University","Standard Grant","Satyandra Gupta","08/31/2016","$425,000.00","","mc288@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495","7495, 7923","$0.00","The goal of this research is to develop a navigation methodology for robots using relational geometric models that are constructed and evaluated using minimal sensing. The use of qualitative states is both intuitive to human perception, and amenable to long-term operations in robotics because of the inherent scalability and simplicity in sensing. The technical approach consists of four tasks. The first task is to create a mathematical representation that supports relational sensing/maps/navigation. The second task is to extend the representation and methods to include uncertainties, which allows the work to be of practical significance. The third task is to develop a hypothesis based navigation methodology that naturally enables planning over minimal, uncertain relational maps and sensor data. Finally, the theory will be validated using an increasingly complex set of experimental validation tests. This research enables robust navigation of robots in applications such as autonomous driving and personal robotics, as well as applications that have unstructured environments with no GPS access, such as exploration (under water, planetary, caves), disaster relief and search and rescue. The research is particularly well suited to robots that have sensing and computational constraints. In the long term, it is envisioned that the algorithms and software enable life-long learning in robotics because of the ability to scale to long-term operations."
"1209118","Collaborative Research: Statistical Modeling and Inference for High-dimensional Multi-Subject Neuroimaging Data","DMS","STATISTICS, MSPA-INTERDISCIPLINARY, ADVANCES IN BIO INFORMATICS, CROSS-EF ACTIVITIES, ROBUST INTELLIGENCE","09/01/2012","08/30/2012","Tingting Zhang","VA","University of Virginia Main Campus","Standard Grant","Gabor J. Szekely","08/31/2015","$101,600.00","James Coan","tz3b@virginia.edu","P.O. BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","MPS","1269, 7454, 1165, 7275, 7495","1165, 8007","$0.00","This project consists of two components, each motivated by the inference problem for functional magnetic resonance imaging (fMRI) data. In the first part, within the framework of generalized functional linear model (GFLM), a flexible semi-parametric model for neural hemodynamic response in the form of slope functions is introduced. To accommodate the variation of brain activity across different regions, stimulus types, and subjects, the new approach assumes the slope functions share the same but unknown functional shape for a given region and stimulus, while having subject-specific height, time to peak, and width. Several fast algorithms based on B-spline smoothing are proposed to estimate the model parameters for whole-brain analysis. The second part of the research focuses on building a novel Bayesian variable selection framework to study the relationship between individual traits and brain activity. The spline estimates of the brain hemodynamic responses from the first part are taken as predictors in a regression model where the response is the individual traits. Two types of priors are introduced jointly to achieve simultaneous variable selection and clustering.<br/><br/>FMRI is one of the most effective neuroimaging technologies for understanding brain activity. In recent years, fMRI data collected from complex studies with multiple subjects have been widely used in psychological and medical research. This project will provide tools for modeling, analysis and computation for this type of fMRI data. Project findings will advance basic understanding of the inter-relations between nature and nurture in shaping individual differences in brain function and behavior, and suggest new directions for interdisciplinary research that combines statistics, neuroscience and psychology. The open source R/Matlab software developed from the research will provide valuable data analysis and educational tools for the scientific community."
"1321083","III: Small: Analysis and Models of Social Network Structure, Growth and Dynamics","IIS","INFO INTEGRATION & INFORMATICS","10/01/2013","09/05/2013","Ben Zhao","CA","University of California-Santa Barbara","Continuing grant","Frank Olken","09/30/2016","$352,347.00","Haitao Zheng","ravenben@cs.ucsb.edu","Office of Research","SANTA BARBARA","CA","931062050","8058934188","CSE","7364","7923, 7364","$0.00","Online social networks (OSNs) such as Facebook and LinkedIn are valuable infrastructures for communication and interactions between a large volume of Internet users. For years, researchers have been trying to answer fundamental questions about the formation of these complex networks, their ongoing evolution, formation of internal structures, and change at different time scales. Since answering these questions requires real dynamics datasets at scale, most prior studies have been significantly constrained by a lack of data. The Principal Investigators have been granted access by an OSN provider to a uniquely detailed and complete trace of dynamics over 2+ years of a social network. The goal is to mine and analyze the traces of network dynamics to validate existing models and guide new models for fine grain network dynamics. Objectives include analysis of the preferential attachment model at different stages of network growth, developing new models of network dynamics at fine granularity in both time and graph topology, and explorations of applications driven by novel metrics of graph dynamics.<br/><br/>The work has the potential to dramatically change our understanding of dynamics in online social networks. By taking an empirical, data-driven approach to network modeling, they can shed light on how traditional models of network dynamics deviate from ground truth. In addition, they are developing empirical models that are more effective at accurately predicting network events at small scales. Both PIs Zhao and Zheng are heavily invested in educational and outreach programs for female and minority students: female students and postdocs often outnumber male counterparts in their lab. The PIs will disseminate their results to their collaborators atRenren and LinkedIn, and also share results with researchers at Twitter, Zynga, Facebook and Google through existing technical contacts and informal visits/talks. <br/><br/>For further information, please see the project webpage at: http://sandlab.cs.ucsb.edu/dynamics"
"0904325","III: Medium: Collaborative Research: Optimization with Sparse Priors -- Algorithms, Indices, and Economic Incentives","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","07/30/2012","Ashish Goel","CA","Stanford University","Continuing grant","Maria Zemankova","08/31/2014","$698,070.00","","ashishg@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7364","7364, 7924, 9216, HPCC","$0.00","This is a collaborative research project combining the expertise of Ashish Goel, Stanford University (IIS-0904325) and Sanjeev Khanna, University of Pennsylvania (IIS-0904314).<br/><br/>Traditionally, content has been generated by a limited number of publishers (such as book houses, music companies, and newspapers), and its quality then evaluated by professional editors and reviewers. In recent years, however, individuals have become mass producers of content, generating images, blogs, opinions, and recommendations, in a decentralized manner. This content is then discovered and consumed by other users, and centralized review is rendered infeasible by the sheer magnitude of available content. Consequently, there is a need to utilize user feedback, both explicit and implicit, in order to provide optimum rankings and recommendations to Internet users. The same broad problem occurs in online advertising, automatic moderation of discussion boards, and automated deductions of user preference on social networks. In addition to being very large, user activity data on the Internet is also typically very sparse, since each user only performs a small share of possible actions (e.g., searches for a small fraction of keywords, reviews or purchases a small fraction of products).<br/><br/>This project aims to design algorithms and optimization techniques to effectively utilize such data. The sparse data is treated as a ""prior belief"" on user preferences. The project also aims to design economic incentives to obtain useful and corrective data, robust to manipulation. The two parts of this research interact strongly with each other, since the algorithmic component can identify valuable pieces of additional information to acquire. Together, these two parts can help users derive optimum value from Internet data. <br/><br/>Results of this project will improve search engine performance and facilitate web applications that employ user feedback. The project Web site (http://www.stanford.edu/~ashishg/sparse_opt.html) will be used to disseminate results."
"1331047","Collaborative Research: Building a Unified Theory-Driven Methodology for Identification of Elementary Cognitive Systems","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","09/15/2013","09/06/2013","James Townsend","IN","Indiana University","Standard Grant","Anne Cleary","08/31/2016","$353,292.00","","jtownsen@ucs.indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","SBE","7252, 7495","","$0.00","Instant by instant, we take in all of the information that we can gather with our senses, and we organize that information into objects and events. This is the foundation for our ability to function in the real world. While we can talk in general terms about how and why we function with such effectiveness and efficiency, a satisfactory scientific explanation requires much more. In particular, it requires a way of relating the things we can measure---specifically, the frequency with which we choose certain to choose certain actions and the time it takes to make those choices---to each other and to our hypotheses for how and why we do these things. Currently, there is no general way of doing this: the work to be accomplished with this support will fundamentally change this state of affairs.<br/><br/>The creation of a unified theoretical approach to characterizing the ways in which we organize our perception of the world will open up numerous avenues of research linking behavior and neurobiology. With the aid of the theoretical language that this project will produce, there will be systematic and well-defined ways of testing competing hypotheses for both what we do with perceptual information and how we do it. Critically, because this language will be extremely general and will not be tied to a particular set of ideas or theory, scientists from competing perspectives will be able to frame their ideas using a common vocabulary, something that is not currently possible. In addition, since this language will be mathematical, it will possess an exceptional level of rigor and internal consistency. Finally, this language will demonstrate its utility and power by being applied to a set of thorny issues in the contemporary study of perceptual organization."
"1254123","CAREER: Characterizing feature selectivity and invariance in deep neural architectures","IIS","ROBUST INTELLIGENCE, CAREER: FACULTY EARLY CAR DEV","09/15/2013","09/05/2013","Tatyana Sharpee","CA","The Salk Institute for Biological Studies","Continuing grant","Kenneth C. Whang","08/31/2018","$453,000.00","","sharpee@salk.edu","10010 N TORREY PINES RD","LA JOLLA","CA","920371002","8584534100","CSE","7495, 1045","1045","$0.00","The goals of this CAREER proposal are to help elucidate the principles that make robust object recognition possible. Object recognition is a problem that must be solved by all living organisms, from single-cell organisms to humans. Although the physical signals for recognition based on chemical events, light or sound waves are different, the computational requirements for analyzing these events appear to be similar. Specifically, there are two main properties that any system that mediates robust object recognition must have. The first property is known as ""invariance."" It endows neurons with a similar response to the same object observed from different viewpoints. The second property is known as ""selectivity."" Selectivity requires that neurons produce different responses to potentially quite similar objects (such as different faces) even when presented from similar viewpoints. It is straightforward to make detectors that are invariant but not selective or selective but not invariant. The difficulty lies in making detectors that are both selective and invariant. <br/><br/>This CAREER project will develop statistical methods for simultaneously characterizing both the invariance properties of neurons and their selectivity to specific features in the environment. The developed methods will have three distinguishing characteristics. First, it will be possible to recover new types of invariance without any prior assumptions of what the dominant type of invariance is for any given neuron or brain region. Second, they will make it possible to characterize imperfect and approximate types of invariance. Third, the methods will be geared towards stimuli typical of the natural sensory environment that are rich in objects and elicit robust responses from neurons from all stages of sensory processing. These three properties of the developed methods will make it possible to simultaneously study multiple neurons both within and across different regions, without the need to adjust stimuli to a particular neuron or brain region. Application of the developed methods to responses of neurons that mediate visual and auditory object recognition in the brain will help reveal the common principles of sensory processing in the brain and may ultimately lead to improved designs of artificial recognition systems, including sensory prostheses.<br/><br/>This research will be integrated into education and outreach activities involving K-12 students, undergraduate and graduate students. The educational component will help integrate knowledge acquired in computer science, physics, and neuroscience, training a new generation of scientists that are proficient in these disciplines. Outreach to local schools and museums, as well as the creation of an online course will help reach a diverse range of students both locally and worldwide."
"1319708","III: Small: MicSynth: Enhancing and Reconstructing Sound Scenes from Crowdsourced Recordings","IIS","INFO INTEGRATION & INFORMATICS, GRAPHICS & VISUALIZATION","09/15/2013","09/05/2013","Paris Smaragdis","IL","University of Illinois at Urbana-Champaign","Standard Grant","Maria Zemankova","08/31/2016","$500,000.00","","paris@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364, 7453","7364, 7923, 7453","$0.00","There is no doubt that we live in an environment that is massively recorded by multiple people at any point in time. Although we have the technology to combine such information in the visual space (e.g., with PhotoSynth), there is currently no good way to combine audio streams from multiple recordings of the same event. This projects fills that gap by developing new techniques in spectral decompositions and landmark-based localization methods to support taking large amounts of low-level audio recordings of the same event and resynthesize them as one high-quality version, eliminating the artifacts and noise of each individual recording while taking advantage of their strong points.<br/><br/>This project aims to introduce new computational tools to combine uncurated recordings at a large scale, and produce information that no single recording can provide. Combining all available information and producing objective representations will enable effective sifting through data from massively recorded events (e.g., social unrest, natural disasters, historical moments) and focus on the needed information. The resulting tools will support creation of high-quality recordings from historical events that might not otherwise be well documented, by using the power of the crowds. The project web site (http://www.cs.illinois.edu/~paris/crowdmic) will provide access to the research results, including a service that allows the consolidation from user-submitted recordings, publication and source code in order to to stimulate activity in this field. Research results will also be incorporated in the development of classes on social and crowdsourcing aspects of audio and signal processing."
"1219023","III: Small: Issues in the Management of GeoMultimedia Data","IIS","INFO INTEGRATION & INFORMATICS, IIS SPECIAL PROJECTS, SPECIAL PROJECTS - CISE","09/01/2012","09/04/2013","Hanan Samet","MD","University of Maryland College Park","Standard Grant","Maria Zemankova","08/31/2015","$538,108.00","","hjs@umiacs.UMD.EDU","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364, 7484, 1714","7364, 7923, 7484, 1714, 9251","$0.00","The growth of the Internet has led to a dramatic increase in the rate at which information is generated and delivered. This is especially true for the news cycle which has become instantaneous and often resulting in social networks, most notably Twitter, being the medium of choice to deliver late breaking news. This is usually in the form of links to more details which include news articles and multimedia data (news photos and videos). One problem lies in identifying reliable news gatherers which is done by noting if they are the first to report on a topic in contrast to being a re-poster and their frequency. Other issues in providing access to news content involve making the news automatically indexable (instead of by human tagging) both by content (regardless of the language of creation and the nature of the media) and by the location of the content (i.e., geotagging) rather than the location or affiliation of its creator. In the case of location, the challenge lies in devising language-independent geotagging techniques. Machine learning based methods are investigated and are expected to work better than rule-based methods due to a reduced reliance on language-specific rules and a greater reliance on examples. Access to the images is facilitated by indexing them by the words associated with the news articles containing them. This indexing technique is meant to be used as a filter for finding similar or near-duplicate images where the similarity is based on image features. The access by location is facilitated by the use of a map query interface. This is important as it corresponds to enabling the use of spatial synonyms thereby permitting a wider range of queries to be posed. A novel aspect of the research is the incorporation of non-English content which is facilitated by the use of computerized translation services which will be evaluated on their ability to capture the content on the basis of clustering similar articles in different languages rather than on the basis of factors such as proper grammar, etc. <br/><br/>In today's rapidly changing world, the tools that are developed in this project will make this information more accessible as users are enabled to focus on a geographical area of interest as well as have access to content in their own language. This is of utility to a number of organizations and attempts will be made to collaborate with potential users on tailoring the tools for their needs. In addition, the project will provide research experience to undergraduate and graduate students who will be involved in developing some of the components. These tools are also a step in the growth of the nascent field of computational journalism. The project web site (http://www.cs.umd.edu/~hjs/geomultimedia.html ) will provide access to results of this and related research."
"1352950","EAGER: Investigating the Role of Discourse Context in Speech-Driven Facial Animations","IIS","ROBUST INTELLIGENCE","09/01/2013","08/30/2013","Yang Liu","TX","University of Texas at Dallas","Standard Grant","Tatiana D. Korelsky","02/28/2015","$82,552.00","Carlos Busso","yangl@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7495, 7916","$0.00","This EArly-concept Grants for Exploratory Research analyzes the role of discourse and dialog context in the generation of believable, human-like behaviors for conversational agent (CA), i.e., a virtual agent that interacts with a user. CAs aim to engage the users by displaying human-like behaviors not only through speech by also through facial gestures. One useful modality to drive facial behaviors is speech. Spoken language carries important information beyond the verbal message that a CA engine should capitalize on. A challenge in speech-driven animation is to generate behaviors that respond to the discourse context. This proposal presents a top-down approach to explore the importance of considering contextual information in the modeling of speech-driven facial gestures. The project starts with speech-driven models, based on dynamic Bayesian networks, which do not capture the specific discourse context, responding only to the properties of the acoustic features. Then, the study considers discourse-specific models in which the intent of the gestures is known. The study defines a specific, controlled domain as testbed, recording multiple human interactions. Similar speech-driven models are trained constrained by the specific discourse function. The study evaluates the differences in the perceived naturalness, appropriateness and rapport of generated facial gestures. <br/><br/>The study explores which discourse aspects affect the facial animation models, and which are more domain specific or independent. By incorporating the intrinsic discourse information, the proposed models generate behaviors that respond to conversational functions, addressing one of the limitations in speech-driven facial animations. The findings have a longterm impact in variety of health care applications, such as helping hearing impaired individuals and teaching social skills to autistic children. Likewise, discourse-dependent speech-driven models can play a key role in better tutoring systems that display human-like behaviors to communicate and engage with the students."
"1349285","EAGER: Cost- and Energy-Aware Query Processing in Mobile Clouds","CCF","INFO INTEGRATION & INFORMATICS","09/01/2013","08/29/2013","Le Gruenwald","OK","University of Oklahoma Norman Campus","Standard Grant","Almadena Y. Chtchelkanova","08/31/2015","$200,000.00","","ggruenwald@ou.edu","201 David L. Boren Blvd.","NORMAN","OK","730195300","4053254757","CSE","7364","7364, 7916, 9150","$0.00","Innovative mobile technologies offer interesting opportunities in many domains, such as health care, transportation, and commerce. They enable distant monitoring and permit consideration of parameters such as patient's and physician's mobility. This makes it possible to develop novel applications, such as mobile health services for telemedicine and assisted ambient living (particularly in rural areas) and mobile traffic services. Nevertheless, the amount of data to be generated and queried is very large and diverse and is collected from multiple sources. The combination of big data and mobility leads to a major challenge: how to efficiently process queries from a myriad of mobile devices on a large amount of data, especially when the data are to be stored in a novel data management system supplied by several cloud providers with possibly different pricing models? To solve this challenge, this project develops novel mobile cloud data management architectures and novel query processing algorithms that leverage mobile users' storage and computation power and take mobile users' mobility, disconnection, energy limitation, and cloud service providers' pricing models into consideration in order to improve query response time, while reducing the amount of money that must be paid to the cloud service providers. The research is evaluated using both real and synthetic datasets by means of prototyping.<br/><br/>The project is an international collaboration effort between the University of Oklahoma (OU) and Blaise Pascal University in France. For research, both universities participate in the design, prototype and evaluation of the architectures and algorithms. For education, via Skype, OU provides lectures on mobile and big data management for the Big Data Management course at Blaise Pascal University, while Blaise Pascal University provides lectures on cloud data management for the Advanced Database Management course at OU. The students in both courses participate in testing the constructed prototype as a part of their class assignments. The project makes important impacts not only on research but also on education as it provides training for graduate and undergraduate students in the areas of critical national needs: cloud and mobile database management systems, big data and high-end computing. The developed architectures, algorithms, prototype, datasets and performance evaluation results are made available to the public at the Website: http://cs.ou.edu/~database."
"1341410","ACM BCB 2013: Conference on Bioinformatics and Computational Biology","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/30/2013","Sridhar Hannenhalli","MD","University of Maryland College Park","Standard Grant","Sylvia J. Spengler","08/31/2014","$20,000.00","","sridhar@umiacs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7556","$0.00","This proposal seeks funding for travel support for students to participate in the ACM BCB (Bioinformatics and Computational Biology) Conference in September 2013 in Washington D.C. The ACM-BCB is expected to be a premier forum in Bioinformatics and Computational Biology. The conference will host three keynote sessions, research sessions, session-specific invited speakers, workshops, tutorials, panel discussion, and poster sessions. Special activities such as a doctoral consortium and student poster session will be specifically targeted for the students. The ACM-BCB conference has been successful in building a bioinformatics and computational biology community through the newly established ACM Special Interest Group in Bioinformatics and Computational Biology (SIGBioinformatics). The proposed grant will broaden the participation graduate students and help develop the next generation of researchers and educators in the computer science, biological science, biomedical science and other related areas."
"1352869","ACM Multimedia 2013 Student Travel Grant","IIS","ROBUST INTELLIGENCE","09/01/2013","08/28/2013","Shih-Fu Chang","NY","Columbia University","Standard Grant","Jie Yang","08/31/2014","$10,000.00","","sfchang@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7495, 7556","$0.00","This student travel grant supports graduate students enrolled in U.S. institutions to attend the premier conference in the multimedia area, ACM Multimedia 2013. It is a top scientific conference in the area of multimedia, covering latest technical trends, system demos, grand challenges, open source software competition, innovative new ideas, doctoral symposium, and many other innovative activities. Participation in such an event allows students to interact with the leading experts from around the world, learn cutting edge research, develop professional networks, and interact with industry leaders involved in practical applications and technology transfer. The opportunity is broadcast to the broad community and students from underrepresented groups are particularly encouraged to apply."
"1348830","Outstanding Student Research at GL2013","IIS","LINGUISTICS, ROBUST INTELLIGENCE","09/01/2013","08/26/2013","James Pustejovsky","MA","Brandeis University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$9,500.00","","jamesp@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","CSE","1311, 7495","7495, 7556","$0.00","This award provides funding for the travel and accommodation expenses for graduate students in computational linguistics whose papers have been selected for presentation at the Sixth International Conference on Generative Approaches to the Lexicon (GL2013) conference in Pisa, Italy, in September 2013. The overall goal of the GL conferences is to bring together researchers in theoretical and computational linguistics, computer science, cognitive science, and lexicography to explore the problem of semantic compositionality -- how the meaning of expressions in natural languages derives from the structure of the lexicon, or dictionary, of semantic formatives (words or idiomatic multi-word expressions) in a natural language. GL2013 specifically aims at exploring the relation and potential synergies between generative approaches, which assume that semantic formatives are structured objects, and distributional semantics, whose proponents typically assume that they are internally unstructured and analyze their semantic contribution by means of their distribution in linguistic contexts. <br/><br/>This award enables talented students working on computational semantics to interact with professionals in a variety of fields and perspectives related to that domain, and to present their work in a major international venue. This in turn will help to nurture a lasting interest in the upcoming generation of computational researchers in what is likely to remain a major area of interdisciplinary study for a very long time."
"1346800","Workshop for Women in Machine Learning","IIS","ROBUST INTELLIGENCE, INFO INTEGRATION & INFORMATICS, National Robotics Initiative","09/01/2013","08/19/2013","Katherine Heller","NC","Duke University","Standard Grant","Todd Leen","08/31/2015","$40,002.00","","kheller@gmail.com","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495, 7364, 8013","7495, 7556","$0.00","Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female researchers in industry and academia, postdoctoral fellows, and graduate students from the machine learning community to exchange research ideas and build mentoring and networking relationships. The one-day workshop has been especially beneficial for junior graduate students, giving them a supportive environment in which to present their research (in many cases, for the first time) and enabling them to meet peers and more senior researchers in the field of machine learning. The networking opportunities provided by the workshop have also helped senior graduate students find jobs following graduation. <br/><br/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration within the machine learning community. As invited speakers, established researchers at top universities and research labs will teach workshop participants about cutting-edge ideas from diverse areas of machine learning. Students will present their own research and receive valuable feedback from both senior researchers and their peers. By enabling women at all stages of their careers in machine learning to exchange research ideas and form new relationships, we expect that new connections and research collaborations will be established, thereby advancing the state-of-the-art of the field. <br/><br/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows, junior and senior faculty, and industry and government research scientists to exchange research ideas and establish networking and mentoring relationships. Undergraduates, particularly those who are interested in pursuing graduate school or industry positions in machine learning, are also welcome to attend. Bringing together women from different stages of their careers gives established researchers the opportunity to act as mentors, and enables junior women to find female role models working in the field of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations looking for female invited speakers. Secondly, co-locating with a major machine learning conference enhances the visibility of female researchers among the wider machine learning community. Thirdly, travel funding provided to workshop participants also facilitates their travel to the co-located conference, which for some participants would otherwise not be possible. Finally, all workshop materials (slides, abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination."
"1056744","CAREER: Integrating Perceptual and Linguistic Information in Models of Semantic Representation","BCS","LINGUISTICS, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","04/15/2011","08/23/2013","Michael Jones","IN","Indiana University","Continuing grant","Betty H. Tuller","03/31/2016","$363,758.00","","jonesmn@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","SBE","1311, 7252, 7495","1045, 1187","$0.00","Humans learn about the meanings of words and larger discourse units from repeated experience with both linguistic and perceptual information. However, current computational models of semantic learning and representation focus only on linguistic structure. This CAREER award explores how humans use multisensory perception and linguistic experience to organize semantic memory. Dr. Michael Jones at Indiana University will use specially designed web-based experiment protocols to collect large amounts of data about the perceptual structure of word referents. For example, a participant presented with a target word will be required to produce a list of verbal properties to describe the word (e.g., given DOG, a participant might produce ""has four legs, has fur, barks"" etc.). A second participant is then provided with only the list of properties and is required to guess what word is being described. Alternatively, the information to the second participant can be a drawing of what the target word represents to the first participant, who has configured predefined object components into a 2D or 3D display. By designing these experiments as internet based, Dr. Jones will collect very large amounts of data to design and test computer models of linguistic and perceptual integration during word learning. <br/><br/>The models resulting from this research may provide a better understanding of the learning disorders characterized by language deficiencies (e.g. many forms of autism) and age-related disorders characterized by semantic disorganization (e.g., dementias such as Alzheimer's Disease). The integration of perceptual and linguistic information could also lead to better applied algorithms for information search (e.g., Internet search engines) if the computer representation can be made to approximate the semantic representation of the human doing the searching."
"1320956","RI: Small: Open Vision - Tools for Open Set Computer Vision and Learning","IIS","ROBUST INTELLIGENCE","09/01/2013","08/21/2013","Terrance Boult","CO","University of Colorado at Colorado Springs","Standard Grant","Jie Yang","08/31/2016","$449,894.00","","tboult@vast.uccs.edu","1420, Austin Bluffs Parkway","Colorado Springs","CO","809183733","7192553153","CSE","7495","7495, 7923","$0.00","When humans ""recognize"" things one of answers can always be ""unknown"" or ""that's new."" Existing vision and machine learning research has made great progress but have done so in a closed set paradigm - which explicitly minimizes risk/errors over what is known. As a computer vision system is moved toward real problems, it must face up to an open world. This project develops technologies for a new fundamental theory of ""open vision"" and corresponding set of tools that are explicitly designed to address open set recognition. At the heart of this research are three key concepts: 1) extending classical learning theory to include the risks of labeling open/unknown spaces, and then building classifiers that balance empirical risk, smoothness and open space risk; 2) meta-recognition - bringing a statistically-grounded probabilistic interpretation to classifiers, improving their ability to produce ""confidence"" in their answers; 3) operational adaptation - developing new approaches to address, at operation/run time, missing data or new data incorporating both open set and meta-recognition technologies. The work is also developing new approaches for open set evaluation, addressing problems in face recognition and visual object recognition as well as adapting classical machine learning datasets.<br/><br/>The open vision paradigm is embodied in open source tools that provide performance at or significantly advancing the state of the art while providing greater protection form unknown unknowns. Since most science is exploring the unknown, providing easy to use open source learning/recognition tools design for both known and unknown data, the project have broad impact to many different applications."
"0808718","III-CXT-Core Large: Computer Vision Research: Promoting Paradigm Shifts in Archaeology","IIS","INFORMATION TECHNOLOGY RESEARC, INFO INTEGRATION & INFORMATICS","09/01/2008","09/12/2012","David Cooper","RI","Brown University","Standard Grant","Maria Zemankova","08/31/2014","$2,845,654.00","Benjamin Kimia, Gabriel Taubin, Katharina Galor","cooper@lems.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","1640, 7364","7364, 7752, 9216, HPCC, 9251, 7721, 9150","$0.00","IIS - 0808718 <br/>III-CXT-Core Large: Computer Vision Research: Promoting Paradigm Shifts in Archaeology<br/>Cooper, David B.<br/>Brown University<br/><br/>This project continues a longer term intellectual program begun under the ITR solicitation and has proven to be innovative in multiple ways. The work is an artful interdisciplinary blend of computer vision, physics, mathematics, algorithm development, efficient computation, graphics and visualization in a rapidly emerging area which might best be termed computational archeology, although the methods are generalized to other domains. The project involves an interdisciplinary team of archeologists and computer vision/graphics/visualization researchers developing methods and software for capturing and analyzing archeological data. In this project The Brown University Division of Engineering, Laboratory for Man/Machine Systems (LEMS), will collaborate with the Brown University Joukowsky Institute for Archaeology and the Ancient World, the nonprofit educational outreach Institute for the Visualization of History, Williamstown, MA, archaeologists at Tel Aviv University, Israel and several computer vision experts from European institutions.<br/><br/><br/>The primary testbed project will be a crusader castle in Israel. There are four sub-projects proposed: a collection system and database for video and 3D data captured on-site during excavation, three-dimensional reconstruction, of both small artifacts and architectural sites, assembly of pottery and glass fragments, and visualization of sites and artifacts. The project builds on and extends earlier work which focused on the Petra archaeological site and assembly of artifact fragments. The advances in computing technologies over the past 5 years in processing power and storage capacity combined with decreases in cost allow the researchers to expand their ambitions and develop more powerful tools and analytic techniques."
"1017862","RI: Small: High Resolution Tactile Sensing.","IIS","ROBUST INTELLIGENCE","09/01/2010","09/03/2010","Edward Adelson","MA","Massachusetts Institute of Technology","Standard Grant","Jie Yang","08/31/2014","$450,000.00","Mandayam Srinivasan","adelson@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7923","$0.00","This project seeks to develop tactile sensing technology that emulates many qualities of human skin. The goal is a sensor that can determine the texture and shape of objects that it touches, as well as the forces distributed across the surface. The new sensor is made of a block of clear elastomer, with a compliance similar to that of the human fingertip, covered with a flexible reflective skin. A small light source and a camera are embedded in the device. When an object contacts the skin, the surface is distorted, leading to a change in the reflected light pattern. Machine vision techniques convert the patterns into estimates of the forces on the skin. The project is testing a number of optical and mechanical designs, and is developing the corresponding image analysis techniques, in order to characterize and optimize the performance. Because the sensor is compliant, it can be built into a human-like robotic finger, providing gripping surfaces that are mechanically stable as well as highly sensitive. The new technology may also be useful in medical applications such as minimally invasive surgery, where it is important for the surgeon to sense the mechanical properties of the tissues that are being explored."
"1318386","III: Small: Algorithms for decoding complex patterns of genomic variation","IIS","INFO INTEGRATION & INFORMATICS","09/01/2013","08/12/2013","Vineet Bafna","CA","University of California-San Diego","Continuing grant","Sylvia J. Spengler","08/31/2016","$311,417.00","","vbafna@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7923, 7364","$0.00","Genomes evolve and diversify through different mechanisms, including small point mutations, and large structural variations (SV). As entire populations of individuals get sequenced, we observe a complex mosaic of patterns. Some of these are characteristic of a selective constraint such as tolerance to lack of oxygen (for highlander populations), or lactose tolerance. In one aim of the proposal, the investigators develop computational techniques for identifying characteristic genetic patterns to identify genes that are adapting to these selective constraints. The other aims to reconstruct regions with complex variation patterns such as the Killer cell Immunoglobulin-like Receptor (KIR) region. KIR diversity plays a significant role in mediating immune response, helping with an understanding of diseases including rheumatoid arthritis, control of HIV disease progression as well as the success rate of cell replacement therapy for certain leukemias (blood cancer). The investigators will use a mix of techniques from combinatorial algorithms, machine learning, and population genetics to decode the genetic patterns. The proposal has broader impact in the field as part of a larger effort to develop efficient computational tools for genetic analysis; a critical problem in the modern era of inexpensive sequencing. The tools and technologies described here will have a direct impact on understanding the genetic diversity of populations, and towards a personalized approach to healthcare.<br/><br/>The proposal seeks to decipher the observed genetic variation across populations using two thrusts. In one thrust, it looks to haplotype genomic structural variation, and discover the genomic architecture of complex immunological regions like KIR and HLA. In a second thrust, the investigators analyze patterns of variation that are indicative of selective constraints. For selection signatures, the investigators will provide a better understanding of currently available tests using the scaled site frequency spectrum, and use an algorithmic approach to identify a better discriminator. For the rearranged genomic regions, the investigators will use optimization algorithms to adjust read coverage in highly repetitive regions. The proposal has broader impact in the field as part of a larger effort to develop effcient computational tools for genetic analysis; a critical problem in the modern era of inexpensive sequencing. The tools and technologies described here as well will have a direct impact on understanding the genetic diversity of under-represented populations, and towards a personalized approach to healthcare. The proposed research is tightly connected to undergraduate and graduate education, as all research here will be directly incorporated in interdisciplinary classes. The PI has a strong track record mentoring womena and other under-represented students in Computer Science."
"1320715","RI: Small: RUI: Image Matching in the Wild","IIS","ROBUST INTELLIGENCE, CDS&E","08/15/2013","08/13/2013","Daniel Scharstein","VT","Middlebury College","Standard Grant","Jie Yang","07/31/2016","$236,087.00","","schar@middlebury.edu","14 OLD CHAPEL ROAD","MIDDLEBURY","VT","057536000","8024435000","CSE","7495, 8084","7495, 7923, 9229, 7433, 9150","$0.00","This project aims to advance stereo vision and optical flow algorithms to work in challenging real-world conditions. It contributes novel algorithmic approaches, new high-resolution datasets with ground truth, and an update to the Middlebury benchmarks.<br/><br/>The algorithmic advances include fast matching algorithms that employ radiometric and geometric self-calibration, including smart data terms that establish noise and color models during the matching process, and novel layer-based surface reconstruction algorithms with explicit reasoning about half-occluded regions, reflections, and transparency. The new datasets reflect current challenges, including high-resolution images of real-world scenes with complex occlusions, specular surfaces and reflections under different illuminations and taken with different cameras. Undergraduate students are actively involved in all components of this research.<br/><br/>The project has strong potential impact along several fronts. The new datasets and benchmarks challenge the community and serve as catalysts for new research. The algorithmic advances allow harnessing the explosion of images available online, and enable real-world applications such as automated driving, geolocation, and automatic 3D reconstruction of whole cities. Finally, the project exposes undergraduates at a liberal-arts college in rural Vermont to the world of research, experimentation, and discovery."
"1319794","RI: Small: Answer Set Programming Modulo Theories","IIS","ROBUST INTELLIGENCE","08/15/2013","08/13/2013","Joohyung Lee","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2016","$315,000.00","","joolee@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Efficient computation of expressive nonmonotonic first-order reasoning is important for realizing robust intelligence. Answer Set Programming (ASP) is a successful nonmonotonic declarative programming paradigm, but is limited in handling first-order reasoning involving functions due to its propositional setting. Satisfiability Modulo Theories (SMT) is a successful approach to solving some specialized first-order reasoning, but is limited in handling nonmonotonic reasoning.<br/><br/>This project aims at correcting these deficiencies by tightly integrating ASP and SMT in the framework of ""Answer Set Programming Modulo Theories"" (ASPMT). ASPMT will enjoy the expressiveness of the ASP modeling language while leveraging efficient constraint / theory solving methods available in SMT and other related computing paradigms. It will provide a viable approach to solving problems that requires both discrete high level reasoning and continuous low level reasoning, and will provide an effective way to handle heterogeneous knowledge and/or computation sources in a uniform framework. The project will also deliver an online computation model of the framework and its implementation.<br/><br/>The success of the project will produce a general method of efficient computation of expressive reasoning by intelligently combining different formalisms and their implementations, and will promote cross-fertilization among the involved communities. The success of this project will have a significant impact on a wide range of domains that can benefit from a powerful declarative programming paradigm. It will provide a practically usable knowledge representation programming language and tools, which can be easily used by non-KR experts while hiding the details of various computational methods."
"1018321","III: Small: Modeling and Inferring Searcher Intent by Mining User Interactions","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/01/2010","Yevgeny Eugene Agichtein","GA","Emory University","Standard Grant","Maria Zemankova","08/31/2014","$500,000.00","","eugene@mathcs.emory.edu","1599 Clifton Rd NE, 4th Floor","ATLANTA","GA","303221620","4047272503","CSE","7364","7923","$0.00","Inferring searcher intent is a central problem in information retrieval and web search: for effective ranking and result presentation, the search engine must know what the user is looking for. Yet, expressing a searcher information need currently relies on entering the ?right? search keywords, which can require multiple rounds of trial-and-error from the searcher. The goal of this project is to develop effective methods for a search engine to automatically infer searcher intent and information needs from the searcher interactions and behavior data. Specifically, the project addresses two main challenges of search intent inference: developing accurate and robust models of searcher intent and behavior, and exploiting these models to infer search intent for each individual user. This project significantly advances previous efforts on implicit feedback and search modeling, by considering a wide range of user interaction and contextual features, and by developing novel techniques for mining and exploiting these signals to improve web search and information access.<br/><br/>To develop robust search intent and behavior models, the project uses machine learning and data mining techniques to model the connection between search actions and result page behavior and the searcher intent. The first stage of the project develops and evaluates these models in controlled lab environments, by combining eye tracking and search interface instrumentation data. The second stage of the project empirically validates the intent inference models through a large-scale collection of search behavior data using a variety of remote user studies with instrumented search interfaces. Finally, the project applies the resulting models and algorithms to improve performance on key information retrieval tasks including result ranking, automatic query expansion, and search result presentation. <br/><br/>The techniques developed in this project are expected to make web search and information access more intuitive and effective for millions of users through collaboration with major search engine companies. Additional broader impacts will be achieved through domain-specific applications of the developed techniques, ranging from improved library search to web-based diagnostics of cognitive impairment. All aspects of the project will involve graduate and undergraduate students, and the resulting tools and datasets are to be integrated into undergraduate course instruction and projects, thus broadening participation in computer science research. The resulting publications, software, and datasets will be made publicly available on the project website (http://ir.mathcs.emory.edu/intent/)."
"0937094","FODAVA: Collaborative Research: Foundations of Comparative Analytics for Uncertainty in Graphs","CCF","FOUNDATIONS VISUAL ANALYTICS, , MSPA-INTERDISCIPLINARY, INFO INTEGRATION & INFORMATICS, GRAPHICS & VISUALIZATION","09/15/2009","06/27/2012","Lise Getoor","MD","University of Maryland College Park","Standard Grant","Maria Zemankova","08/31/2014","$585,094.00","","getoor@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7703, I114, 7454, 7364, 7453","9218, HPCC, 7703, 7364","$0.00","This is a collaborative research effort bringing together expertise of Lise Getoor, University of Maryland College Park (0937094), Alex Pang, University of California-Santa Cruz (0937073) and Lisa Singh, Georgetown University (0937070).<br/><br/>In today's linked world, graphs and networks abound. There are communication networks, social networks, financial transaction networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks and more. Observational data describing these networks can often times be obtained; unfortunately, this graph data is usually noisy and uncertain. In this research, we propose a formalism which allows us to capture and reason about the inherent uncertainty and imprecision in an underlying graph. We begin by proposing probabilistic similarity logic (PSL), a simple, yet powerful, language for describing problems which require probabilistic reasoning about similarity in networked data. We also introduce the notion of visual comparative analysis of PSL models derived using different evidence and assumptions, and illustrate its utility for the analysis of graphs and networks. <br/><br/>Dealing with noise and uncertainty in complex domains, and conducting comparative analytics are core capabilities required for the Foundations on Data Analysis and Visual Analytics (FODAVA) mission. This research focuses on integrating representation, comparative analysis and visualizations methods into an open source toolkit that supports the representation, comparison and visualization of PSL models. In addition to producing the toolkit, the research team is working with researchers in a variety of interdisciplinary domains to validate the utility of our approach, and also developing tutorial and training materials for the tools. <br/><br/>The key broader impact of the work is that the methods for reasoning about sources of noise and uncertainty in graphs, and understanding their impact on results are general and fundamental to the intelligent analysis of today's rich information sources. Results, including open source software will be distributed via the project Web site ( http://www.cs.umd.edu/projects/linqs/fodava/ )."
"1218222","III: Small: Database Processing on GPUs","IIS","INFO INTEGRATION & INFORMATICS","08/01/2012","06/07/2013","Kenneth Ross","NY","Columbia University","Continuing grant","Frank Olken","07/31/2015","$499,996.00","","kar@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7364","7923","$0.00","Modern Graphic Processing Units (GPUs) offer more parallelism and higher memory bandwidth than CPUs. This project aims to take advantage of these properties by developing a system to efficiently process database queries over GPU-resident datasets. To achieve this goal this project employs the following approaches: (a) The development of novel indexing techniques that combine multidimensional partitioning with block-oriented bitmaps, and whose parameters are sensitive to the query distribution;(b) The optimization of memory bank contention and value contention between threads; (c) The efficient implementation of a complete set of relational database operators, including aggregation, joins, and indexed selections; and (d) The evaluation of the performance of the system on query-intensive workloads, using real applications and standard benchmarks. Improvements in database system performance would have wide-ranging impact on the efficiency of many enterprises that employ database systems for analytics. The project supports PhD students working on database system implementation techniques. The innovations and software created during the project will be used to enhance the curriculum of the Database Systems Implementation course at Columbia University. Publications, software, and other project data will be disseminated via the web at our project web site (http://www.cs.columbia.edu/~kar/gpuproject.html)."
"1161814","RI: Small: Statistical Machine Translation Through a Tree Adjoining Grammar with Flexible Parsing Operations","IIS","ROBUST INTELLIGENCE","01/01/2011","04/26/2012","Michael Collins","NY","Columbia University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$401,045.00","","mcollins@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7923, 9215, HPCC","$0.00","Our research involves the development of a syntactic approach for<br/>statistical machine translation that extends a tree adjoining grammar<br/>(TAG) formalism to the translation problem, and frames translation<br/>directly as a parsing problem. The model imposes no constraints on<br/>entries in the phrasal lexicon, thereby retaining the flexible lexical<br/>entries of phrase-based translation systems; it allows straightforward<br/>incorporation of a syntactic language model. The operations used to<br/>combine tree fragments into a complete parse tree are generalizations<br/>of standard parsing operations found in TAG; specifically, they are<br/>modified to be highly flexible, potentially allowing any possible<br/>permutation (reordering) of the initial fragments. This allows the<br/>model a great deal of freedom in capturing differences in word order<br/>between source and target languages.<br/><br/>The use of flexible parsing operations raises a couple of challenges<br/>that are a major focus of our research. First, efficient decoding<br/>algorithms are required for the models. Second, flexible parsing<br/>operations allow the model to capture complex reordering phenomena,<br/>but in addition introduce many spurious possibilities. We are<br/>investigating the use of learned, probabilistic constraints based on<br/>information in the source-language sentence, or in a parse tree for<br/>the source-language sentence, thereby incorporating syntactic<br/>information from the source language.<br/><br/>The end goal of the project is to develop new models for translation<br/>that improve the fluency or grammaticality of translations, improve<br/>the degree to which semantic information (e.g., predicate-argument<br/>structure) is preserved in translation, and improve the treatment of<br/>differing word orders between source and target languages."
"1018110","III: Small: Collaborative Research: Analysis of Multi-Dimensional Protein Design Spaces with Pareto Optimization of Experimental Designs","IIS","INFO INTEGRATION & INFORMATICS","09/15/2010","03/22/2011","Alan Friedman","IN","Purdue University","Standard Grant","Sylvia J. Spengler","08/31/2014","$172,901.00","","afried@bilbo.bio.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7923, 9251","$0.00","In developing variants of natural proteins with improved properties and activities, protein engineers are confronted with large, complex design spaces. The degrees of freedom for producing variants mirror nature but can be specifically targeted experimentally, choosing parent proteins, replacements for some amino acids (site-directed mutation), and locations for crossing over between parents (site-directed recombination). A set of choices, constituting a design, can be evaluated by multiple disparate criteria, including consistency with evolutionary information, energetic favorability with respect to a three-dimensional structure, and incorporation of specific characteristics distinguishing functional subclasses. Unfortunately, the different evaluation metrics may be complementary or even contradictory, and the prior information on which they are based is incomplete, so that the metrics are only more or less accurate in predicting the real-life quality of the designs.<br/><br/>The overall goal of this project is to develop efficient methods to characterize complex protein design spaces and optimize high-quality designs for experimental evaluation. A combinatorial protein engineering approach will be pursued, experimentally constructing a library of related variants and assaying them for properties of interest. Potential scores will evaluate a possible library (without explicitly enumerating its members) with respect to prior information from sequence, structure, and functional subclass. To account for disparate evaluation metrics, design algorithms will focus on the<br/>identification of Pareto optimal designs, those for which no other design is as good or better with respect to all desired criteria. To account for incomplete prior information, design algorithms will trade off between exploitation of the prior information and broader exploration of the design space, seeking to identify a diverse set of designs, each with a diverse set of variants. Markov Chain Monte Carlo sampling algorithms will characterize the overall design space by generating choices for the degrees of freedom and evaluating the designs with the potential scores, using the scores and diversity metrics to appropriately explore the space. Exact algorithms will more precisely focus on regions of interest, dividing and conquering the design space and employing combinatorial optimization algorithms to identify Pareto optimal designs.<br/><br/>The design space approach provides a powerful new mechanism to address protein engineering applications, enabling the engineer to explicitly evaluate and optimize for trade-offs among important criteria and considerations. Interactive tools will help engineers navigate through the regions of interest, visualize designs and perform ""what-if"" analyses, and compare and contrast Pareto optimal designs. A design space repository will enable sharing of analyses and underlying data. The tools and repository will support protein engineering for a range of activities in the national interest, including biosensors, production of novel biological therapeutics and novel enzymes for green chemical synthesis, energy extraction, and bioremediation. As part of the project, the mechanism will be put to use in the engineering of soluble and robust cytochrome P450s that employ the inexpensive and non-toxic hydrogen peroxide to hydroxylate steroids and multi-ring compounds that mimic estrogenic (feminizing) steroids in the environment without the need for living cells or protein cofactors. Such enzymes would be valuable as tools for chemical synthesis, waste treatment, and bioremediation.<br/><br/>This project provides an ideal venue to impart cross-disciplinary training to students by illustrating how computational techniques can be fruitfully integrated with experimentation in answering important biological questions. Aspects of the project will be used in both undergraduate and graduate courses, from an introductory biology course to an advanced bioinformatics course. The project itself will provide the opportunity for inter-disciplinary research training for graduates and undergraduates, including those from underrepresented groups."
"0915956","III: Small: Avoiding Contention on Multicore Machines","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","09/09/2009","Kenneth Ross","NY","Columbia University","Standard Grant","Frank Olken","08/31/2014","$499,978.00","","kar@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7364","7364, 7923, 9216, HPCC","$0.00","To take full advantage of the parallelism offered by a multicore<br/>machine, one must write parallel code. Writing parallel code is<br/>difficult. Even when one writes correct code, there are numerous<br/>performance pitfalls. For example, an unrecognized data hotspot could<br/>mean that all threads effectively serialize their access to the<br/>hotspot, and throughput is dramatically reduced.<br/><br/>This project aims to provide a generic framework for performing<br/>certain kinds of concurrent operations in parallel. Infrastructure is<br/>provided to perform those operations in a scalable way over the<br/>available threads in a multicore machine, automatically responding to<br/>hotspots and other performance hazards. The goal is not to squeeze<br/>the last drop of performance out of a particular platform. Rather,<br/>with the planned system a programmer can, without detailed knowledge<br/>of concurrent and parallel programming, develop code that efficiently<br/>utilizes a multicore machine.<br/><br/>The project involves the development of algorithms and data structures<br/>designed for the efficient parallel execution of generic code<br/>fragments. The primary focus is on data intensive operations as would<br/>typically be found in an in-memory database engine. Critical research<br/>questions include how to design generic multi-threaded operators that<br/>can be applied to a range of computations, how to avoid cache<br/>thrashing, and how to implement the framework in a way that works on a<br/>variety of hardware platforms. Performance improvements in throughput<br/>of an order of magnitude are expected relative to naive solutions that<br/>suffer from contention. The project aims to achieve performance close<br/>to that of hand-tailored expert-written parallel code, with far less<br/>coding effort.<br/><br/>This project has immediate applications in both commercial and<br/>public-domain database systems where performance improvements would<br/>enhance the experience of database system users, and reduce hardware<br/>and energy requirements for a given level of performance.<br/><br/>Programmability improvements would allow programmers without expertise<br/>in parallel programming to effectively use multicore machines. The<br/>project also provides the focus for an advanced-level course on<br/>database system implementation for multicore machines. The software<br/>infrastructure will be made available for research use by others."
"1143807","EAGER: Discovering Emerging Events in Social Media","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/30/2012","AnHai Doan","WI","University of Wisconsin-Madison","Continuing grant","Maria Zemankova","08/31/2014","$150,000.00","","anhai@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7364","7916, 7364","$0.00","Social media have become increasingly critical in many domains, such as commerce, disaster management, science, and national security. In these domains, applications often have to integrate social media to detect emerging events. Today however few solutions for event detection have been developed and they suffer from several important limitations. This exploratory project addresses these limitations and develops a solution that effectively integrates social media to detect emerging events. The solution will focus on the Twittersphere, and will address the following three key challenges: (a) how to exploit characteristics unique to social media to improve the accuracy of detecting events, (b) how to design the solutions such that they scale to high-speed streams of social media (such as 1500 tweets per second), and (c) how to leverage crowdsourcing to find truly interesting events and extract attributes of these events.<br/><br/>The project will be among the first to explore in depth how to integrate social media to detect emerging events, taking into account social media characteristics. As such, it is a high-risk/high-payoff project that can open the door to novel research directions, and help accelerate research into social media integration, an increasingly critical problem that impacts many areas of the society. If successful, the project can also help build practical event discovery tools that can make immediate impacts. Finally, the project will help train a Ph.D. student for two years, and help build and release a set of infrastructure tools and testbeds that can help accelerate subsequent research into social media integration, for both the PI's group and other research groups in social media. The project information will be disseminated via publications, workshops, tutorials, and the Web site (http://www.cs.wisc.edu/~anhai/projects/event-detection.html) that will include the resulting research results, data and system artifacts."
"1218863","RI: Small: Developing Large Scale Distributed Syntactic, Semantic and Lexical Language Models for Machine Translation and Speech Recognition","IIS","ROBUST INTELLIGENCE","08/01/2012","07/23/2013","Shaojun Wang","OH","Wright State University","Continuing grant","Tatiana D. Korelsky","07/31/2015","$460,000.00","Yunxin Zhao","shaojun.wang@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","CSE","7495","7923","$0.00","This project aims to build large scale distributed syntactic, semantic, and lexical language models that are trained by corpora with up to Web-scale data on a supercomputer in order to substantially improve the performance of machine translation and speech recognition systems. It is conducted under the directed Markov random field paradigm to integrate both topics and syntax to form complex distributions for natural language, and uses hierarchical Pitman-Yor processes to model long-tail properties of natural language. By exploiting this particular structure, the complex statistical estimation and inference algorithms are decomposed and performed in a distributed environment. The language models are put into one-pass decoders of machine translation systems, and the lattice rescoring decoder into a speech recognition system. In addition, a principled solution to a long-standing open problem, smoothing fractional counts due to latent variables in Kneser-Ney's sense, might be found. <br/><br/>This project fits into the NSF's strategic long term vision of a Cyber-infrastructure Framework for 21st Century Science and Engineering (CIF21). The project integrates various kinds of known language models and provides a way to overcome the limitations of existing combination methods for language models and to deploy algorithmically interesting methodologies that are scalable to data sets available on the Web. The project provides an environment for interdisciplinary education in information technology that bridges areas of language and speech processing, machine learning, and data-intensive science and engineering to benefit students at several levels."
"1239176","III: Small: Rural: Querying Rich Uncertain Data in Real Time","IIS","INFO INTEGRATION & INFORMATICS","01/20/2012","04/02/2012","Tingjian Ge","MA","University of Massachusetts Lowell","Continuing grant","Frank Olken","08/31/2014","$298,751.00","","ge@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344723","CSE","7364","7923","$0.00","Nowadays, a burgeoning amount of data is made available continuously. Example sources include various sensors, RFID, computer network traffic, phone conversations, and web searches. Much of this data is noisy, inconsistent, or even erroneous. Compared to deterministic data, uncertain data carries more information. Forcing uncertain data to be deterministic (e.g., by taking the expectations) can cause significant information loss in query results, possibly leading to wrong judgments for queries that aid decision making. Moreover, real-time decisions based on these data can have a significant impact on the quality of life, on the economy, and on our security. However, fast and real-time processing of uncertain data is a difficult problem. The broad goal of the RURAL (querying Rich Uncertain data in ReAL time) project is to provide techniques that make this query processing task feasible. To achieve this goal the project includes: (1) integrating data cleansing, distribution learning, and query processing through pipelining; (2) developing fast and online query processing algorithms on uncertain data; (3) providing a rich treatment of uncertain data distributions including compression, sharing, and gauging their reliability; (4) using predictive models to infer uncertain data distributions; and (5) answering top-k queries with consideration of typicality of results.<br/><br/>The RURAL project extends the state of art in real-time query processing of uncertain data for decision-making. It is used by the Kentucky Transportation Center for the application of dynamic traffic routing and control, and by the Biomedical Division at the University of Kentucky for real-time monitoring applications. The research results are integrated with education through class projects in Computer Science graduate courses at the University of Kentucky and tutorials at conferences. Further information on the project can be found on the project web page: http://protocols.netlab.uky.edu/~ge/projects/rural."
"1217686","III: Small: Collaborative Research: Learning to Model Sequences","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","07/22/2013","Thorsten Joachims","NY","Cornell University","Continuing grant","Maria Zemankova","09/30/2015","$314,000.00","","tj@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7364","7923","$0.00","This collaborative research project involves faculty and students from Cornell University (IIS-1217686) and Ithaca College (IIS-1217485) in an interdisciplinary project. The ability to learn predictive models of sequences is a component in several application problems, ranging from language models for machine translation to the recommendation of material to read in order to master a subject. The goal of this project is to develop new machine learning algorithms that can learn sequence models for items that are difficult to describe by attributes. In particular, the project develops models that automatically embed items in a latent feature space based on training sequences, that can integrate partial and noisy side information, and that have the ability to model long-range dependencies.<br/><br/>The resulting predictive models have a potential to be employed in science and education and can support the economic shift towards online business applications. The project focuses on the recommendation of music playlists as the main testbed. A deployed online music recommendation system not only provides the framework for testing and evaluation, this application domain helps to attract a broad spectrum of students from collaborating institutions, Cornell University and Ithaca College (an undergraduate institution), enabling the integration of undergraduates in the research. Project results, including open source software and annotated data set, are disseminated via the project Web site (http://www.cs.cornell.edu/People/tj/playlists/)."
"0963993","III: Medium: Energy-Efficient Data Processing","IIS","INFO INTEGRATION & INFORMATICS, CI REUSE","10/01/2010","07/26/2013","Jignesh Patel","WI","University of Wisconsin-Madison","Continuing grant","Sylvia J. Spengler","09/30/2014","$783,846.00","Miron Livny","jignesh@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7364, 6892","7924","$0.00","The energy cost of operating large server farms is now a sizable portion of their total-cost-of-ownership. The focus of the ecoDB project is to design, develop and evaluate methods that improve the energy efficiency of such server farms for data-intensive applications. ecoDB will investigate a range of issues, including ""global"" issues that considers the entire server farm as a holistic single large computing system and uses energy-aware workload management and data placement strategies. These global techniques will be implemented in various existing distributed systems, including the Condor system. At the other end of the spectrum, this proposal plans to investigate ""local"" techniques that can be used to improve the energy efficiency of an individual server by synergistically exploiting the underlying hardware and/or software characteristics. A crucial aspect of the ecoDB project is to focus on techniques that systematically trade performance for energy efficiency, essentially treating ""energy consumption"" as a first-class metric in data processing systems. The repercussions of this approach percolate through various aspects of a data processing systems ranging from query/workload optimization and evaluation to replication management and job scheduling in large-scale parallel and distributed data processing systems.<br/><br/>This project will also facilitate the training of graduate students in the emerging area of energy-efficient data processing methods. The broader impacts of this proposal also include benefits to society by producing techniques that can potentially reduce the energy consumption of data centers, which in turn has beneficial environmental and economical effects. <br/><br/>This project is partially funded by the OCI CF21 Venture Fund for promoting the reuse of Cyberinfrastructure (CI) elements. <br/><br/>For further information, please see: http://pages.cs.wisc.edu/~jignesh/ecodb/"
"1346942","EAGER: Decision-Theoretic and Scalable Algorithms for Computing Finite State Equilibrium","IIS","ROBUST INTELLIGENCE","08/01/2013","07/31/2013","Prashant Doshi","GA","University of Georgia Research Foundation Inc","Standard Grant","James Donlon","07/31/2015","$150,153.00","","pdoshi@cs.uga.edu","200 D.W. Brooks Drive","ATHENS","GA","306025016","7065425939","CSE","7495","7495, 7916","$0.00","This project is exploring algorithms for computing multiagent strategies that are in exact and approximate equilibrium. The context involves economic games that are played repeatedly by agents each of whom privately observes noisy signals about other players' actions. A complete characterization of equilibria for such games, missing until recently, introduces the concept of a finite state equilibrium in which each player's strategy is represented as a finite state automaton. Players' strategies are verified to be in equilibrium by solving a partially observable Markov decision process. The research is building on this surprising and deep application of decision theory toward equilibrium analysis in a pragmatic class of games, which provides a bold and innovative bridge between decision and game theories. It is designing novel algorithms that utilize approximate and error-bounded solutions of partially observable Markov decision processes for computing approximate finite state equilibrium in games with increasing dimensions.<br/><br/>This research is contributing insights for broader classes of games such as stochastic games with noisy signals. The interdisciplinary outcomes of this research are being integrated into courses and conference tutorials on multiagent decision making for dissemination. New international research collaborations with eminent multiagent researchers in Japan are being established.<br/><br/>This research is bringing together the disciplines of decision and game theories with mutual benefit. Key outcomes include scalable algorithms for solving highly complex games thereby contributing to the understanding of sophisticated interactions under uncertainty. Applications include analyzing auctions without release of public information, covert price wars between firms, and managing resource congestion."
"1018475","III: Small: Issues in Understanding, Indexing, Querying, and Visualizing Spatio-Textual Spreadsheets on the Web","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","03/22/2011","Hanan Samet","MD","University of Maryland College Park","Standard Grant","Frank Olken","08/31/2014","$508,000.00","","hjs@umiacs.UMD.EDU","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923, 9251","$0.00","Numerous organizations including government agencies are sitting on <br/>mountains of spreadsheet data that are becoming increasingly common on <br/>the web, but whose contents remain out of reach via search engines <br/>because direct links to the contents of their constituent cells are<br/>rare. Thus spreadsheet data represent legacy databases, especially<br/>since many of their underlying schemas are no longer accessible. The<br/>goal of this research is to discover the schema according to which the <br/>spreadsheet is constructed. The focus is on the spatio-textual<br/>spreadsheet which is a spreadsheet where the values of the spatial<br/>attributes are specified textually. Such spreadsheets support spatial<br/>searches whose output is visual and whose utility is enhanced by being<br/>able to handle spatial synonyms. This is done, in part, by devising<br/>methods to automatically discover the spatial attributes of the<br/>spreadsheet as well as how to distinguish between several instances of<br/>them which arise due to the presence of a containment hierarchy. In<br/>particular, use is made of spatial coherence which is manifested by<br/>observing that spatial data in the same column are usually of the same<br/>spatial type, while spatial data in the same spreadsheet row usually<br/>exhibit a containment relationship. Moreover, adjacent or nearby rows<br/>exhibit spreadsheet coherence in that they are usually similar. The<br/>broad impact of this research is to make spreadsheet data a first<br/>class citizen on the web with the same chances of being discovered and<br/>accessed as data found in other documents. Reports describing<br/>results of this and related research will be available at<br/>http://www.cs.umd.edu/~hjs/spreadsheets.html"
"0914988","RI:Small:RUI:Intelligent Soundscape Analysis and Generation","IIS","ROBUST INTELLIGENCE","09/01/2009","08/26/2009","Judy Franklin","MA","Smith College","Standard Grant","James Donlon","08/31/2014","$266,929.00","","jfrankli@scinix.smith.edu","10 ELM STREET","NORTHAMPTON","MA","010636304","4135842700","CSE","7495","7495, 7923, 9102, 9215, HPCC","$0.00","This project investigates hierarchical machine intelligence for modeling and composing complex soundscapes. We adapt methods for extracting time-dependent information from text documents to the problem of extracting spectral (graphical) patterns and the probabilities that they occur or co-occur in soundscapes. We are analyzing the spectral patterns that emerge from sound files of many types, including recordings of building interiors with regular foot traffic, musical files, and synthesized sound. A significant part of the research is in devising spectral features that are important for this kind of mapping/identification. <br/><br/>Research under this award is also investigating the use of reinforcement learning (RL) to identify time-dependent 'landmarks' from soundscape models, and we employ RL agents to compose large soundscapes from thousands of millisecond length grains of sound in a process called granular synthesis. Systems of RL agents enable us to study distributed time-dependent RL agents in a complex environment, with the ability to produce aural demonstrations of the agents' learning. We also expect the system to produce some compositions that are pleasing in the electronic music sense.<br/><br/>This research will have an impact on curricular efforts in Arts and Technology at Smith College, supporting the Computer Science Department's efforts to attract more students, especially to research."
"1144034","EAGER: Learning to Efficiently Rank with Cascades","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","07/20/2012","Jimmy Lin","MD","University of Maryland College Park","Continuing grant","Maria Zemankova","08/31/2014","$150,000.00","","jimmylin@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7916, 7364","$0.00","Text search is undeniably vital to today's information-based societies, helping users locate relevant information in web pages, journal articles, news stories, blogs, emails, tweets, and a myriad of other sources. Naturally, users desire results that are not only good but also fast. Learning to rank, the dominant approach to information retrieval (IR) today, focuses almost exclusively on effectiveness, often neglecting the runtime speed (i.e., efficiency) of the ranking functions. This project contributes to the emerging research area of learning to efficiently rank, which aims to let algorithm designers capture, model, and reason about tradeoffs between effectiveness and efficiency in a unified framework. <br/><br/>Specifically, this project explores a novel cascade model for retrieval, where ranking is broken into a finite number of distinct stages. Each stage considers successively richer and more complex features, but over successively smaller candidate document sets. The intuition is that although complex features are more time-consuming to compute, examining fewer documents offsets the additional overhead. In other words, the cascade model views retrieval as a multi-stage progressive refinement problem. Based on the survey of the current state-of-the-art, knowledge, this is the first project to explore this approach to the ranking problem, marking a substantial departure from previous ""monolithic"" ranking functions. Although exploration in this uncharted area carries some risk, this research promises to open up a new frontier in IR research. <br/><br/>This project aims to narrow the chasm between academic and industrial IR research by bringing together theoretical IR research and practical considerations in ""real-world"" search. It is expected that the cascade model will be of interest to web search engine companies, thus providing a path from the exploratory research results to significant impact in production systems. Furthermore, this work dovetails with the emerging area of green computing: more efficient algorithms use less energy, hence help reduce the environmental footprint of web-scale services. The project web site (http://www.umiacs.umd.edu/~jimmylin/projects/) includes more information about this project and will be used for the release of a prototype as part of the Ivory open-source retrieval toolkit."
"0914783","RI:Small:Collaborative Research: Infinite Bayesian Networks for Hierarchical Visual Categorization","IIS","ROBUST INTELLIGENCE","09/01/2009","08/25/2009","Max Welling","CA","University of California-Irvine","Standard Grant","Todd Leen","08/31/2014","$300,000.00","","welling@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","7495, 9215, HPCC","$0.00","Humans possess the ability to learn increasingly sophisticated representations of the world in which they live. In the visual domain, it is estimated that we are able to identify in the order of 30,000 object categories at multiple levels of granularity (e.g. toe-nail, toe, leg, human body, population). Moreover, humans continuously adapt their models of the world in response to data. Can we replicate this life-long-learning capacity in machines?<br/><br/>In this project, the PIs build hierarchical representations of data streams. The model complexity adapts to new structure in data by following a nonparametric Bayesian modeling paradigm. In particular, the depth and width of our hierarchical models grow over time. Deeper layers in this hierarchy represent more abstract concepts, such as ?a beach scene? or ?chair?, while lower levels correspond to parts, such as a ?patch of sand? or ?body part?. The formation of this hierarchy is guided by fast hierarchical bottom up segmentation of the images.<br/><br/>To process large amounts of information, the PIs distribute computation across many CPUs /GPUs. They develop novel fast inference techniques based on variational inference, memory bounded online inference, parallel sampling, and efficient data-structures.<br/><br/>The technology under development has a large number of potential applications ranging from organizing digital libraries and the worldwide web, building visual object recognition systems, successfully employing autonomous robots and training a ?virtual doctor? by processing worldwide information from hospitals about diseases, diagnosis and treatments.<br/><br/>Results are disseminated through scientific publications and publicly available software."
"1018961","III: Small: Database-driven Ajax applications","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","03/14/2012","Yannis Papakonstantinou","CA","University of California-San Diego","Standard Grant","Frank Olken","08/31/2014","$532,000.00","","yannis@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7923, 9251","$0.00","AJAX programming enables superior performance and interface quality that is comparable to desktop applications, despite the fact that the users? browsers interact with a remote server on the cloud. The challenge is that AJAX programs are hard to write since they are essentially distributed programs combining three different languages: browser-side Javascript, a server side programming language (e.g., Java, PHP, etc) and database access with SQL. <br/><br/>The proposal develops a framework for the rapid creation of fully-fledged AJAX-based web application pages from declarative, data-driven, SQL-based specifications. The proposal delivers an architecture and SQL-based page specification language that is sufficiently abstract and declarative to enable rapid development, while it is also (a) performant and (b) enables the same class of data-driven web applications with what can be manually coded. Novel incremental view maintenance, distributed query processing and concurrency control techniques enable performance, while the component-based structuring of pages blends the data aspects of the language with front-end mechanisms for creating rich interfaces.<br/><br/>Declarative specifications lead to rapid programming, fewer bugs and easy application maintenance and evolution, while the framework solves performance optimization and correctness problems and provides functionalities that otherwise the developer would need to take care of with tedious custom AJAX code. The results are carried over besides Ajax to Adobe's Flash, the recent Microsoft's Silverlight and the emerging mobile application platforms. Furthermore, they contribute to UCSD?s web application development curriculum by providing a principled method of architecting and implementing interactive data-driven applications. The information about the project can be found at http://db.ucsd.edu/NSF10FWD/"
"1216739","RI: Small: BCSP: The Whole Worm: A Brain-Body-Environment Model of Nematode Chemotaxis","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC, ACTIVATION","10/01/2012","09/04/2012","Randall Beer","IN","Indiana University","Standard Grant","Kenneth C. Whang","09/30/2015","$489,440.00","","rdbeer@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7495, 1640, 7713","7923, 8750","$0.00","The overall goal of this work is to construct, analyze and experimentally test a brain-body-environment model of orientation in an invertebrate. Even relatively simple animals exhibit a remarkable combination of flexibility and robustness to their behavior that would be extremely useful to the design of artificial systems. How do animals achieve this difficult balance? <br/><br/>Understanding how animals operate as integrated wholes requires building brain-body-environment models of complete animals. This in turn requires an animal system for which detailed behavioral, biomechanical, and neuronal information is available. In this regard, knowledge of the behavior, anatomy, genetics, development and neural connectivity of the nematode worm C. elegans is perhaps the most complete of any animal, with significant progress now also being made on the electrophysiology of its nervous system. Success also requires a modeling methodology that can work cooperatively with experimental methods throughout the project lifecycle and that can provide a theoretical framework for interpreting the integrated functioning of the system. <br/><br/>In order to demonstrate the feasibility of whole-animal modeling, this proposal describes a project to construct and analyze an integrated brain-body-environment model of C. elegans klinotaxis, a form of salt chemotaxis in which changes in direction are oriented towards the source through gradual continual adjustments. The approach described here combines connectome data-mining and a novel bracketing methodology, parameter optimization and clustering techniques for working with populations of models, and dynamical and information-theoretic analysis of representative motifs with behavioral manipulations, neuronal ablation and photo-stimulation, and electrophysiological studies on the biological system by an experimental colleague."
"1018433","IIS: RI: Small: Nonlinear Dynamical System Theory for Machine Learning","IIS","ROBUST INTELLIGENCE","09/01/2010","08/18/2010","Max Welling","CA","University of California-Irvine","Standard Grant","Todd Leen","08/31/2014","$450,000.00","Anton Gorodetski","welling@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","7923","$0.00","Learning complex statistical models from data is intractable for many models of interest. The PIs are studying a new approach to learning from data that formulates learning as a weakly chaotic nonlinear dynamical system. They show that this dynamical system, which they call ?herding?, combines learning and inference into one tractable forward mapping. They study the abstract mathematical properties of this nonlinear mapping, such as the properties of its attractor set and the topological and metric entropy of the mapping. They then relate these to properties of learning systems. <br/><br/>The PIs apply herding systems to a wide range of applications in machine learning. In supervised learning they show that herding suggests a natural extension to the ?voted perceptron algorithm? by including hidden variables. In unsupervised learning, herding is used to train Markov random field models from data. Herding is also extended to Hilbert spaces where it naturally leads to a deterministic sampling algorithm. Due to negative autocorrelations, this ?kernel herding? generates samples that have superior convergence properties than random sampling. They also apply herding to active learning problems. <br/><br/>Herding has the potential to radically transform the way we view learning systems. It connects learning to the vast field of nonlinear dynamical systems and chaos theory. As such the impact on machine learning is significant. Scientific results will be disseminated through journal publications and conference proceedings. The PIs also introduce a new course on learning, chaos and fractals to expose students to the intriguing connections between these fields."
"1017837","III: Small: Information Recommendation for Online Scientific Communities","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/18/2010","Luo Si","IN","Purdue University","Standard Grant","Sylvia J. Spengler","08/31/2014","$498,431.00","Gerhard Klimeck, Michael McLennan","lsi@cs.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","7923","$0.00","There has been an increasing shift away from traditions of individual based scientific research toward more collaborative models via online scientific communities. One famous example of scientific online communities is nanoHUB.org powered by the HUBzero platform. nanoHUB has been well received by nanotechnology community and has attracted more than 90,000 active users by providing thousands of resources such as simulation tools, teaching materials and publications. The rapid growth of information in scientific online communities demands intelligent agents that can identify the most valuable to the users. Existing solutions of information recommendation are not adequate for online scientific communities. For example, users in online scientific communities undertake different types of tasks (e.g., seeking teaching materials or conducting experiments for dissertation work) and require recommendation that distinguishes different tasks, which is not provided by existing recommendation solutions. Furthermore, a substantial amount of information from users of online scientific communities is implicit feedback (e.g., click through data). However, most existing recommendation solutions focus on explicit feedback information (e.g., user ratings of movies).<br/><br/>The proposed research seeks to overcome the limitations of existing recommendation solutions with a new integrated information recommendation framework for online scientific communities. The proposed research thrusts include: (1) Task-Specific Recommendation: estimate possible tasks undertaken and incorporate the estimation results into the process of making recommendation; (2) Intelligent Hybrid Recommendation: integrate collaborative recommendation and content-based recommendation techniques within a single model that intelligently tunes the weights of content based information and collaborative usage information; (3) Pairwise Comparison Approach for Implicit Feedback: model users? implicit feedback information of recommended resources in a probabilistic model with a natural assumption of pairwise comparison; (4) System Development and Evaluation: integrate proposed algorithms into the HUBzero platform. The research results will be evaluated in carefully designed user studies as well as in real world operational environments (i.e., nanoHUB). <br/><br/>The proposed research will yield substantial benefits in broad areas. The information recommendation tool will be incorporated into nanoHUB to benefit a large number of users. The source code of proposed algorithms will be released with the HUBzero platform to enable further advance and development in information recommendation. The proposed information recommendation solutions can be adapted and used in other general purpose social network applications like LinkedIn/Facebook. Some research topics will be integrated into the courses that the PIs teach. The PIs will encourage the involvement of underrepresented students in the research project."
"1218367","III: Small: Collaborative Proposal: Towards Robust Uncertain Data Management","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","07/05/2013","Amol Deshpande","MD","University of Maryland College Park","Continuing grant","Frank Olken","09/30/2015","$248,627.00","","amol@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923","$0.00","The goal of this project is to develop a systematic framework to enable ""robust"" query processing in presence of data uncertainties that arise naturally in a wide variety of application domains. Data uncertainties may take the form of missing or incomplete data, inherent noise in the data, trust or reputation scores assigned to data based on their sources of origin, or confidences in predictions made using automated modeling tools. The input uncertainties naturally lead to uncertainties in the results of any queries or analyses performed on such data. To enable robust and systematic reasoning over such uncertain query results, efficient algorithms and practical tools are developed to: (a) identify the input uncertainties to which query results are most sensitive, (b) decide how to use scarce resources like subject matter experts to resolve uncertainties in query results, and (c) incorporate user feedback to improve the robustness of the input uncertainty parameters themselves. The tools have the potential to make it easy and intuitive to process and analyze uncertain data and extract useful information from it in a wide range of real-world application domains including social media analysis, scientific and biological data management, sensor data management, web data integration, and information extraction. This project provides research opportunities for graduate and undergraduate students, and is aligned with several advanced graduate courses offered by the PIs. The prototype implementation of the framework, publications, and experimental data, will be disseminated via the project web site: http://www.cs.umd.edu/~amol/RPrDB."
"0917261","III: Small: An Architecture and Platform for Frictionless Information Systems","IIS","INFO INTEGRATION & INFORMATICS","09/15/2009","06/21/2013","Lawrence Birnbaum","IL","Northwestern University","Continuing grant","Maria Zemankova","08/31/2014","$504,400.00","Kristian Hammond","birnbaum@cs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7364","7364, 7923, 9216, HPCC, 9251","$0.00","This project designs and implements tools for frictionless information systems that work behind the applications that people use in their work and everyday lives, automatically finding and presenting contextually relevant, useful, and interesting information. To be relevant to a user's information needs in a given context, information must add something new: it must be similar in certain respects to the context, but dissimilar in certain other respects. The technology utilized in this project explicitly and specifically searches or filters for interestingly different information, dissimilar in systematic ways that reflect information attributes relevant to a user's goals.<br/><br/>The project develops useful information attributes and dimensions of dissimilarity as well as technologies that can utilize these attributes and dimensions to find useful and relevant information based on the user?s current context. The particular dimensions that matter in a given context will depend upon the user, task, and domain at hand. To address this variability, the project is aimed at a general architecture and a set of tools and libraries that will support the rapid development of frictionless information systems for a wide range of application settings.<br/><br/>The results are expected to lead to development of information systems that can provide people with information that is contextually relevant, genuinely interesting, and diverse, resulting in broader and deeper understanding. The results will be disseminated in academic venues as well as through public release of prototype systems via the project Web site (http://infolab.northwestern.edu/). The project is well integrated with educational activities. Relevance Engine platform will be utilized in class projects for advanced undergraduates and graduate students, and some of these systems may be aimed at educational settings. Students will be involved in development of corpora for testing prototypes, informal assessment of prototypes using web resources, and gain valuable experience in research, design and implementation, and validation."
"1320589","III: Small: Causal and Statistical Inference in the Presence of Confounding Factors","IIS","INFO INTEGRATION & INFORMATICS","06/01/2013","06/04/2013","Eleazar Eskin","CA","University of California-Los Angeles","Standard Grant","Sylvia J. Spengler","05/31/2016","$499,919.00","","eeskin@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7923","$0.00","Technical:<br/>The presence of unmeasured confounding factors can result in incorrect statistical and causal inferences if the confounding factors are correlated with the observed data. This phenomenon has been well documented in at least two important applications. One application is identifying genetic variation involved in disease from populations of related individuals. A second application is identifying genes active in a disease when comparing disease and health samples. In this proposal we propose a new approach to correct for unobserved confounders in taking advantage of insights into how confounders affect high dimensional data. These insights motivate a formal definition for a specific type of confounder which we term a 'low-rank confounder.' Formalizing this definition allows us to motivate methods for correcting for the effects of these types confounders even when the confounders are not observed. Our proposal will develop a theory of how confounders affect data and under what conditions unobserved confounders can be corrected. The proposed theory is related to recent developments in understanding sparsity which has been well studied in electrical engineering, computer science and statistics. The result of our proposed methods will lead to improved methods for applications where such confounders are present.<br/><br/>Non-technical:<br/>Inference of knowledge from high dimensional data is a fundamental problem affecting virtually all areas of science including physics, astronomy, chemistry, computer science, social science and many areas of biology. Many of these problems are driven by recently available large sources of data and advances in measurement or data collection technologies. A major challenge is the presence of unknown (and unmeasured) confounding factors. Confounding factors are variables that are often not observed in the data, but are correlated with various features of the data. Unfortunately, confounding factors can cause incorrect inferences. This phenomenon has been well documented in at least two important applications: one application is identifying genetic variation involved in disease from populations of related individuals, and a second application is identifying genes active in a disease when comparing disease and health samples. There are traditional approaches to perform inference if the confounders are observed in the data. However, dealing with unobserved confounders is more difficult. This project will develop and study a new approach to correct for unobserved confounders, taking advantage of insights into how confounders affect high dimensional data. The project has broad impact due to its utility in a wide range of scientific questions, through the interdisciplinary research opportunities provided to undergraduate and graduate students, and through the distribution of software and data."
"0915315","Small: The MCDB Database System for Managing and Modeling Uncertainty","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","09/01/2009","Christopher Jermaine","TX","William Marsh Rice University","Standard Grant","Frank Olken","08/31/2014","$500,000.00","","Christopher.m.jermaine@rice.edu","6100 MAIN ST","HOUSTON","TX","770051827","7133484820","CSE","7364","7923, 9216, HPCC","$0.00","The MCDB Database System for Managing and Modeling Uncertainty<br/>Analysts working with large data sets often use statistical models to<br/>``guess'' at unknown, inaccurate, or missing information associated<br/>with the data stored in a database. For example, an analyst for a<br/>manufacturer may wish to know, ""What would my profits have been if<br/>I'd increased my margins by 5% last year?"" The answer to this<br/>question depends upon the extent to which the higher prices would have<br/>affected each customer's demand, which is undoubtedly guessed via the<br/>application of some statistical model.<br/><br/>The MCDB project is concerned with the design and implementation of a<br/>prototype database system called the ""Monte Carlo Database System,"" or<br/>""MCDB"" for short. MCDB allows an expert-level analyst or statistician<br/>to attach arbitrary stochastic models to the database data in order to<br/>""guess"" the values for unknown or inaccurate data, such as each<br/>customer's unseen demand function. These stochastic models reside in<br/>the database, and are always up-to-date in the sense that they are<br/>parameterized on the current state of the database (using each<br/>customer's most recent purchases in the above example).<br/><br/>The project attacks a number of key intellectual and scientific<br/>challenges. Most of these are related to the fact that for<br/>performance reasons, it is not possible to materialize one thousand<br/>stochastic instances of a one terabyte data warehouse, and query each<br/>of them in sequence. Novel methods for avoiding such materializations<br/>are being considered, such as skipping Monte Carlo trials that produce<br/>data which will never be used to answer a specific query. The project<br/>also considers statistical challenges, such as generating database<br/>instances that fall far out in the tail of the answer distribution,<br/>which is necessary for specific applications such as risk assessment.<br/><br/>Further information is available at http://mcdb.cs.rice.edu."
"1017181","III: Small: Better Sentiment Analysis through Forecasting","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","03/16/2011","Steven Skiena","NY","SUNY at Stony Brook","Standard Grant","Maria Zemankova","08/31/2014","$423,164.00","","skiena@cs.sunysb.edu","WEST 5510 FRK MEL LIB","STONY BROOK","NY","117943362","6316329949","CSE","7364","7923, 7364, 9251","$0.00","The emerging field of sentiment analysis employs algorithmic methods to identify and summarize opinions expressed in text. Both machine learning and ad-hoc approaches lie at the foundations of contemporary sentiment analysis systems, but progress on improving both precision and recall has been slowed by the expense and complexity of obtaining sufficiently broad, general sentiment training/validation data.<br/><br/>Recent work has established that fundamental economic variables can successfully be forecast by applying sentiment analysis methods to news-oriented text streams. This project turns this relation on its head, using such forecasting approaches to improve both the precision and recall of general entity-oriented sentiment analysis methods. In particular, this project provides a three-pronged research effort into entity-level sentiment analysis, focusing on improved assessment and algorithms, with applications to the social sciences and forecasting. In particular: <br/>(1) Developing a complete entity-level, text and language-independent sentiment evaluation environment, both to further the development of the Lydia system and for release to the international sentiment analysis community.<br/>(2) Building on this environment, to develop improved sentiment-detection methods for English news, foreign language news streams, social media such as blogs and Twitter, and historical text corpora.<br/>(3) Finally, applying improved sentiment analysis to a variety of challenges in the social sciences. <br/><br/>This research promises to substantially improve both the precision and recall of sentiment detection methods, by focusing on the weakest link: rigorous yet domain-, source-, and language-independent assessment of sentiment. Beyond improvements in natural language processing (NLP), this includes other issues in opinion mining, including article clustering and duplicate detection, entity-domain context, and combining opinions from large numbers of distinct sources.<br/><br/>The sentiment analysis methods and data developed under this research project are expected to have a broad impact, as the results will be directly applicable in a broad range of social sciences, including sociology, economics, political science, and media and communication studies. The techniques will serve as both an educational and scholarly resource in these fields, empowering students and researchers to conduct their own primary studies on historical trends and social forces. Results will be disseminated to the community through the project website (http://www.textmap.org/III)."
"1036868","Collaborative Research: Workshop for Women in Machine Learning","IIS","ROBUST INTELLIGENCE, INFO INTEGRATION & INFORMATICS","09/01/2010","06/28/2010","Jennifer Vaughan","CA","University of California-Los Angeles","Standard Grant","Todd Leen","08/31/2014","$41,824.00","","jenn@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495, 7364","7495","$0.00","Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br/>learning community to exchange research ideas and build mentoring and networking relationships. The<br/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br/>environment in which to present their research (in many cases, for the first time) and enabling them to<br/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br/>within the machine learning community. As invited speakers, established researchers at top universities<br/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br/>machine learning. Students will present their own research and receive valuable feedback from both<br/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br/>exchange research ideas and form new relationships, we expect that new connections and research<br/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br/>Bringing together women from different stages of their careers gives established researchers the<br/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination."
"1037002","Collaborative Research: Workshop for Women in Machine Learning","IIS","ROBUST INTELLIGENCE","09/01/2010","06/28/2010","Hanna Wallach","MA","University of Massachusetts Amherst","Standard Grant","Todd Leen","08/31/2014","$6,330.00","","wallach@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7495","7495","$0.00","Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br/>learning community to exchange research ideas and build mentoring and networking relationships. The<br/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br/>environment in which to present their research (in many cases, for the first time) and enabling them to<br/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br/>within the machine learning community. As invited speakers, established researchers at top universities<br/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br/>machine learning. Students will present their own research and receive valuable feedback from both<br/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br/>exchange research ideas and form new relationships, we expect that new connections and research<br/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br/>Bringing together women from different stages of their careers gives established researchers the<br/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination."
"1217433","RI: Small: Hard Clustering via Bayesian Nonparametrics","IIS","ROBUST INTELLIGENCE","07/01/2012","06/12/2013","Brian Kulis","OH","Ohio State University","Continuing grant","Todd Leen","06/30/2015","$439,689.00","","kulis.5@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7495","7923","$0.00","Modern machine learning algorithms often encounter a trade off between scalability and modeling power. For the problem of data clustering, Bayesian approaches enjoy numerous modeling advantages over classical methods, but hard clustering methods such as k-means are often preferred in practice due to their simplicity and scalability.<br/><br/>This project explores bridging the gap between classical hard clustering methods and clustering models based on Bayesian nonparametrics. The first step is an asymptotic result connecting the Dirichlet process Gaussian mixture model with a k-means-like algorithm that does not fix the number of clusters in advance. Using this key result, the PI and his team will explore four related research directions which collectively demonstrate the utility of this asymptotic approach: (1) extensions of the analysis to hierarchical Bayesian models, leading to scalable hard clustering methods over multiple data sets; (2) connections to spectral methods and graph clustering, leading to novel and flexible graph clustering methods; (3) extensions beyond the Gaussian setting, leading to new approaches to topic modeling and other discrete-data clustering problems; and (4) extensive experiments in both the computer vision and text domains.<br/><br/>Given that k-means is truly a workhorse of machine learning, these four directions have the potential to impact a wide array of large-scale applications including computer vision, bioinformatics, social network analysis, and many other domains. Furthermore, the research will benefit the broader community through released software and integration into coursework at Ohio State University."
"1018723","III: Small: Towards Agile Information Integration for Large Scale-- Data Aware Indexing and Search over Unstructured Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/01/2010","Kevin Chang","IL","University of Illinois at Urbana-Champaign","Standard Grant","Sylvia J. Spengler","08/31/2014","$500,000.00","William Mischo","kcchang@cs.uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364","7923","$0.00","This proposal aims to enable scalable and adaptable information integration over unstructured data at a large scale. There is a need to be able to do structured queries with unstructured data, for example in executing SQL queries over Web pages. This project will develop a new approach of ""query push-down,"" distinctive from the conventional ""data pull-up"" techniques, as a promising direction for accomplishing agility in integration. The technical objectives will be driven by two application domains: Army land planning and the Illinois digital library. <br/>The team will develop query translation techniques that ""pushes down"" queries to a format that can be executed over unstructured document and feature indexes. This approach will eliminate expensive, inflexible, and often fragile extraction of unstructured data, enabling scalable and adaptable information integration through ""best effort"" semantics. In the query push-down approach, queries are no longer executed by the SQL-like Boolean semantics, but would rather take a maximum likelihood interpretation-- i.e., what are the most likely answers, by properly translating a given query, under the presence of uncertainty and lack of preciseness in data? The team will study the formalism that governs the principles of such probabilistic query execution, for achieving ""best effort"" with probabilities as a formal quality metric. Researchers will build the Data-oriented Content Query System , which will support users of Web data not only keywords but also data types to query for relevant values of their desired data in the contents of the corpus, by specifying flexible patterns and customizing scoring functions. Structured queries will be translated for executing in the system to access and integrate the unstructured contents in the corpus.<br/><br/>The successful results in this proposed research will have significant impacts in two areas. The research community has observed the scalability limitation of the current integration schemes. These observations highlight the urgency of the proposed study for developing large-scale, agile integration techniques. This will formally advance the understanding of large-scale best-effort integration and develop a set of general techniques. Second, the development of the query system engine will provide access to the data-rich Web, with practical deployment at the Illinois Gateway of the UIUC digital library, which will improve students and faculty?s access to online scholarly and open information. Students will be directly involved in the research effort and new curricula are planned."
"1017231","III: Small: Collaborative Research: Analysis of Multi-Dimensional Protein Design Spaces with Pareto Optimization of Experimental Designs","IIS","INFO INTEGRATION & INFORMATICS","09/15/2010","09/16/2010","Christopher Bailey-Kellogg","NH","Dartmouth College","Standard Grant","Sylvia J. Spengler","08/31/2014","$331,802.00","","cbk@cs.dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551404","6036463007","CSE","7364","7923, 9150","$0.00","In developing variants of natural proteins with improved properties and activities, protein engineers are confronted with large, complex design spaces. The degrees of freedom for producing variants mirror nature but can be specifically targeted experimentally, choosing parent proteins, replacements for some amino acids (site-directed mutation), and locations for crossing over between parents (site-directed recombination). A set of choices, constituting a design, can be evaluated by multiple disparate criteria, including consistency with evolutionary information, energetic favorability with respect to a three-dimensional structure, and incorporation of specific characteristics distinguishing functional subclasses. Unfortunately, the different evaluation metrics may be complementary or even contradictory, and the prior information on which they are based is incomplete, so that the metrics are only more or less accurate in predicting the real-life quality of the designs.<br/><br/>The overall goal of this project is to develop efficient methods to characterize complex protein design spaces and optimize high-quality designs for experimental evaluation. A combinatorial protein engineering approach will be pursued, experimentally constructing a library of related variants and assaying them for properties of interest. Potential scores will evaluate a possible library (without explicitly enumerating its members) with respect to prior information from sequence, structure, and functional subclass. To account for disparate evaluation metrics, design algorithms will focus on the<br/>identification of Pareto optimal designs, those for which no other design is as good or better with respect to all desired criteria. To account for incomplete prior information, design algorithms will trade off between exploitation of the prior information and broader exploration of the design space, seeking to identify a diverse set of designs, each with a diverse set of variants. Markov Chain Monte Carlo sampling algorithms will characterize the overall design space by generating choices for the degrees of freedom and evaluating the designs with the potential scores, using the scores and diversity metrics to appropriately explore the space. Exact algorithms will more precisely focus on regions of interest, dividing and conquering the design space and employing combinatorial optimization algorithms to identify Pareto optimal designs.<br/><br/>The design space approach provides a powerful new mechanism to address protein engineering applications, enabling the engineer to explicitly evaluate and optimize for trade-offs among important criteria and considerations. Interactive tools will help engineers navigate through the regions of interest, visualize designs and perform ""what-if"" analyses, and compare and contrast Pareto optimal designs. A design space repository will enable sharing of analyses and underlying data. The tools and repository will support protein engineering for a range of activities in the national interest, including biosensors, production of novel biological therapeutics and novel enzymes for green chemical synthesis, energy extraction, and bioremediation. As part of the project, the mechanism will be put to use in the engineering of soluble and robust cytochrome P450s that employ the inexpensive and non-toxic hydrogen peroxide to hydroxylate steroids and multi-ring compounds that mimic estrogenic (feminizing) steroids in the environment without the need for living cells or protein cofactors. Such enzymes would be valuable as tools for chemical synthesis, waste treatment, and bioremediation.<br/><br/>This project provides an ideal venue to impart cross-disciplinary training to students by illustrating how computational techniques can be fruitfully integrated with experimentation in answering important biological questions. Aspects of the project will be used in both undergraduate and graduate courses, from an introductory biology course to an advanced bioinformatics course. The project itself will provide the opportunity for inter-disciplinary research training for graduates and undergraduates, including those from underrepresented groups."
"0913459","RI: Small: Qualitative Preferences: Merging Paradigms, Extending the Language, Reasoning about Incomplete Outcomes","IIS","ROBUST INTELLIGENCE, COLLABORATIVE RESEARCH","09/01/2009","04/18/2011","Miroslaw Truszczynski","KY","University of Kentucky Research Foundation","Standard Grant","Todd Leen","08/31/2014","$424,685.00","","mirek@cs.uky.edu","109 Kinkead Hall","Lexington","KY","405060057","8592579420","CSE","7495, 7298","7495, 7923, 9150, 9215, HPCC, 9251, 5955, 5979, 7298, 5936","$0.00","The most common approach in decision theory involves preferences expressed numerically in terms of utility functions, while optimization over different choices takes into account the probability distribution over possible states of the world. An alternative approach represents preferences in qualitative terms, and is motivated, in part, by difficulties in building good utility functions, ascertaining accurate probability distributions, and related problems.<br/><br/>This project is advancing qualitative decision theory by focusing on two promising formalisms for representing and reasoning about qualitative preferences: conditional preference networks (CP-nets) and answer-set optimization (ASO) programs. Both CP-nets and ASO programs offer representations for several classes of preference problems, but each has major limitations. This project addresses these limitations by developing a formalism. ASO(CP) programs, which extend both ASO programs and CP-nets by exploiting key properties of both. The project's major objectives are: to introduce formally ASO(CP) programs by integrating into ASO programs generalized conditional (ceteris paribus) preferences of CP-nets; to establish expressivity of ASO(CP) programs, to study properties of preorders that can be defined by means of ASO(CP) programs, and to address relevant computational issues; to investigate a crucial problem of preference equivalence, essential for automated preference manipulation; to study an extension of ASO(CP) programs to the case of incompletely specified outcomes, essential for practical applications; and, to extend ASO(CP) programs to the first-order language extended with aggregate operators.<br/><br/>Representing preferences qualitatively and optimizing over such preferences is a fundamental problem of qualitative decision theory. By integrating and advancing understanding of major types of common preferences that are captured by ASO programs and CP-nets, this project will produce theoretical and practical advances in representation and reasoning about preferences, bringing it to the point where it can be effectively used in practical decision support systems."
"1018967","RI: Small: Collaborative Research: A Scalable Architecture for Image Interpretation","IIS","ROBUST INTELLIGENCE","09/15/2010","09/13/2010","Melanie Mitchell","OR","Portland State University","Standard Grant","Kenneth C. Whang","08/31/2014","$341,269.00","","mm@cs.pdx.edu","1600 SW 4th Ave","Portland","OR","972070751","5037259989","CSE","7495","7923, 9102","$0.00","Seamless understanding of the meaning of visual images is a key property of human cognition that is far beyond the abilities of current computer vision programs. The purpose of this project is to build a computational system that captures the dynamical and interactive aspects of human vision by integrating higher-level concepts with lower-level visual perception. If successful, this system will be able to interpret visual scenes in a way that scales well with the complexity of the scene. Current computer vision systems typically rely on relatively low-level visual information (e.g., color, texture, shape) to classify objects or determine the overall category of a scene. Such categorization is typically done in a ""bottom-up"" fashion, in which the vision system extracts lower-level features from all parts of the scene, and subsequently analyzes the extracted features to determine which parts of the scene contain objects of interest and how those objects should be categorized. Such systems lack the abilities to scale to large numbers of visual categories and to identify more complex visual concepts that involve spatial and abstract relationships among object categories. Visual perception by humans is known to be a temporal process with feedback, in which lower-level visual features serve to activate higher-level concepts (or knowledge). These active concepts, in turn, guide the perception of and attention given to lower-level visual features. Moreover, activated concepts can spread activation to semantically related concepts (e.g., ""wheels"" might activate ""car"" or ""bicycle""; ""bicycle"" might activate ""road"" or ""rider""). In this way there is a continual interaction between the lower and higher levels of vision, which allows the viewer to focus on and connect important aspects of a complex scene in order to perceive its meaning, without having to pay equal attention to every detail of the scene. The system proposed here will model these aspects of human visual perception. <br/><br/>The proposed system, called Petacat, will integrate and build on two existing projects: the HMAX model of object recognition originally developed by Riesenhuber and Poggio, and the Copycat model of high-level perception and analogy-making, developed by Hofstadter and Mitchell. HMAX models the ""what"" pathway of mammalian visual cortex via a feed-forward network that extracts increasingly complex textural and shape features from an image. (HMAX has been reimplemented, as the ""Petascale Artificial Neural Network"" or PANN, by the Synthetic Vision Group at Los Alamos to allow for high-performance computing on large numbers of neurons.) Copycat implements a process of interaction between high-level concepts and lower-level perception, and has been used to model focus of attention, conceptual slippage, and analogy-making in several non-visual domains. This project will marry the feature extraction abilities of HMAX/PANN with the higher-level interactive perceptual abilities of Copycat to build the Petacat architecture. The image interpretation abilities of Petacat will be evaluated on families of related semantic visual recognition tasks (e.g., recognizing, in a flexible, human-like way, instances of ""walking a dog""). The evaluation part of the project will involve the creation of image databases for benchmarking semantic image-understanding systems. The Petacat source code and benchmarking databases will be made publically available via the web."
"0915977","RI:Small:Robust Image Matching with Deformations and Lighting Variation","IIS","ROBUST INTELLIGENCE, SPECIAL PROJECTS - CCF, IIS SPECIAL PROJECTS","09/01/2009","07/14/2011","David Jacobs","MD","University of Maryland College Park","Continuing grant","Jie Yang","08/31/2014","$324,885.00","","djacobs@cs.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495, 2878, 7484","7495, 7923, 9215, HPCC, 2878","$0.00","This project is to develop new, effective distance metrics for comparing two images. These metrics account for two effects. First, pixels can change their position, deforming from one image to another. Second, pixels may change their intensity. In many vision problems, intensity changes are primarily due to lighting variation. The research team first addresses the effect of illumination changes, which enables to develop a new, powerful, robust distance for measuring the effects of lighting variation in an image. The research team combines this with both existing and new methods to develop a robust distance that accounts simultaneously for image deformations and intensity variations. Computing this distance separates these two effects, providing a correspondence between images. This can be used to track objects moving relative to a light, to match images taken at different times of day, or to recognize objects seen under different lighting, from different viewpoints, with variations in their shape.<br/><br/>This new metric provides a theory of computation for deformation and lighting that encodes our notion of image similarity. However, it is still a considerable challenge to find ways to effectively compute with such an image metric. Therefore, the research team also develops computationally effective algorithms based on this new metric. These algorithms improve performance in numerous applications such as face recognition, autonomous navigation, and optical flow and tracking, in which variations in lighting and shape cause significant challenges for existing methods."
"1144157","Future Career Opportunities and Educational Requirements for Digital Curation","ACI","DATANET, INFO INTEGRATION & INFORMATICS","09/01/2011","08/17/2011","Paul Uhlir","DC","National Academy of Sciences","Standard Grant","Robert Chadduck","08/31/2014","$99,999.00","","puhlir@nas.edu","500 FIFTH STREET NW","WASHINGTON","DC","200012721","2023342254","CSE","7726, 7364","7556, 7364, 7726","$0.00","The organizations and institutions which historically have borne the responsibility for the curation, management, preservation, and retrieval of information contained in physical objects now find themselves confronted by the similar need to manage digital data though the challenges of doing so are distinctly different. <br/><br/>This award will convene a committee of experts from the National Research Council's (NRC) Board on Research Data and Information (BRDI) to:<br/>- Conduct a three day public workshop public of key stakeholders for intensive structured discussions in order to obtain a better understanding of the unprecedented challenges of managing what has been called an ""exaflood"" of data. <br/>- Design and implement a focused study to better understand the needs and opportunities for a workforce with blended skills and expertise necessary to effectively manage and preserve diverse digital resources and workforce changes as ""digital natives"" enter the workforce.<br/>- Generate a report that will inform the community on the education and training needs and requirements, career alternatives, and workforce development in regards to digital curation."
"0964385","III: Medium: Collaborative Research: Linguistically Based ASL Sign Recognition as a Structured Multivariate Learning Problem","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE","09/01/2010","05/03/2011","Carol Neidle","MA","Trustees of Boston University","Standard Grant","Sylvia J. Spengler","08/31/2014","$469,000.00","","carol@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7364, 7495","7924, 9251","$0.00","The manifestation of language in space poses special challenges for computer-based recognition. Prior approaches to sign recognition have not leveraged knowledge of linguistic structures and constraints, in part because of limitations in the computational models employed. In addition, they have focused on the recognition of limited classes of signs. No system exists that can recognize signs of all morphophonological types or that can even discriminate among these in continuous signing. Through integration of several computational approaches, informed by knowledge of linguistic properties of manual signs, and supported by a large existing linguistically annotated corpus, the team will develop a robust, comprehensive framework for sign recognition from video streams of natural, continuous signing. Fundamental differences in the linguistic structure of signs, distinguishing signed languages in 4D, with spatio-temporal dependencies and multiple production channels from spoken languages, are critical to computer-based recognition. This is because finger-spelled items, lexical signs, and classifier constructions, e.g., require different recognition strategies. Linguistic properties will be leveraged here for (i) segmentation and categorization of significantly different types of signs, and then, although this subsequent enterprise will necessarily be limited in scope within the project period, (ii) recognition of the segmented sign sequences. Through the 3D hand pose estimation from a team-developed tracker, w significant tracking accuracy, robustness, and computational efficiency will be attained. This 3D information is expected to greatly improve the recognition results, as compared with recognition schemes using only 2D information. The 3D estimated information from the tracking will be used in the proposed hierarchical Conditional Random Field (CRF) based recognition, to allow for tracking and recognition of signs that are distinct in their linguistic composition. Since other signed languages also rely on a very similar sign typology, this technology will be readily extensible to computer-based recognition of other signed languages.<br/><br/>This linguistically-based hierarchical framework for ASL sign recognition?based on techniques with direct applicability to other signed languages, as well?provides, for the first time, a way to model and analyze the discrete and continuous aspects of signing, also enabling appropriate recognition strategies to be applied to signs with linguistically different composition. This approach will also allow the future integration of the discrete and continuous aspects of facial gestures with manual signing, to further improve computer-based modeling and analysis of ASL. The lack of such a framework has held back sign language recognition and generation. Advances in this area will, in turn, have far-ranging benefits for Universal Access and improved communication with the Deaf. Further applications of this technology include automated recognition and analysis by computer of non-verbal communication in general, security applications, human-computer interfaces, and virtual and augmented reality. In fact, these techniques have potential utility for any human-centered applications with continuous and discrete aspects. The proposed approach will offer ways to address similar problems in other domains characterized by multidimensional and complex spatio-temporal data that require the incorporation of domain knowledge. The products of this research, including software, videos, and annotations, will be made publicly available for use in research and education."
"0930643","Facility Support: OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","EAR","INFO INTEGRATION & INFORMATICS, INSTRUMENTATION & FACILITIES","09/15/2009","11/23/2011","J Ramon Arrowsmith","AZ","Arizona State University","Continuing grant","Russell C. Kelz","08/31/2014","$307,462.00","","ramon.arrowsmith@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","GEO","7364, 1580","0000, OTHR","$0.00","0930643<br/>Arrowsmith<br/><br/>This collaborative grant to the Arizona State University and San Diego Supercomputer Center (PI: Baru/EAR-0930731) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http://www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products. The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF/Information Technology Research and EAR/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project. That portal currently hosts and distributes a limited number of data sets acquired through the NSF/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research. This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g., NCALM, USGS, regional consortia, states, etc.) to link to their data archives and/or to host and distribute their data and processing software algorithms through a freely accessible web-interface. High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures. Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense. Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets. These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate. OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal."
"1219263","III: Small: Low latency browser-based web computation","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","06/13/2013","Yannis Papakonstantinou","CA","University of California-San Diego","Standard Grant","Frank Olken","09/30/2015","$516,000.00","","yannis@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7923, 7364, 9251","$0.00","The goal of this project is to provide an efficient platform for browser-based, data-driven web application computation. The platform enables cost-effective development of fast-responding applications that adjust well to accesses from mobile clients (e.g. smart phones, tablets). The project achieves its goal using the following approaches: (1) designing novel high level, location-transparent, declarative, data-driven languages that require much lower coding effort than direct HTML5 coding in order to specify the business process and data access of the applications; (2) developing an optimizer for low latency query execution plans that utilize browser-based storage and asynchronous computation; (3) developing an action scheduler that optimizes the location and execution order of the actions described in the declarative language; (4) developing a user/action concurrency control theory and a dependency analysis algorithm so that the user can view and act while prior actions are still computed; (5) prototyping an application-enabling platform that encompasses the developed languages, algorithms and optimizations; and (6) evaluating the effectiveness of the platform in two aspects: how much it reduces latency and how much it reduces the coding effort.<br/><br/>The project's research will have great impacts on mobile-accessible, data-driven web applications, which, by being written in the proposed automatically optimized, declarative languages, will enjoy both low latency and low development cost. The project supports graduate and undergraduate students. Lectures on the research results will be incorporated into PI's undergraduate-level course on web application development. Publications, software, an online service and experimental data from this research will be disseminated via the project web site (http://www.db.ucsd.edu/browserbasedforward)."
"1016862","RI: Small: Hierarchical Visual Scene Understanding","IIS","ROBUST INTELLIGENCE","09/01/2010","08/27/2010","Aude Oliva","MA","Massachusetts Institute of Technology","Standard Grant","Jie Yang","08/31/2014","$449,184.00","","oliva@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7923, 9102","$0.00","Intelligent systems, both artificial and biological, must find effective ways to organize a complex visual world. The cross-disciplinary field of scene understanding is in need of a comprehensive framework in which to integrate cognitive, computational and neural approaches to the organization of knowledge. <br/><br/>This research program aims to create a framework for organizing knowledge of visual environments that human and artificial systems encounter when navigating in the world or browsing visual databases. The aim is to determine which taxonomies are best suited for solving different visual tasks, and use computer vision algorithms to organize visual environments as humans do. For example, semantic relationships between scenes are well captured by a hierarchical tree (e.g. a basilica is a type of church, which is a type of building) but functional similarities between different environments may be best represented as clusters (e.g. restaurants, kitchens and picnic areas clustered as places to eat; offices and internet cafs as places to work). <br/><br/>Because hierarchies and taxonomies provide a way of formalizing many types of contextual information (spatial, temporal, and semantic), they can be used to enhance the performance of computer vision systems at object and scene recognition, and aid in the development of smarter image search algorithms. <br/><br/>Besides serving as a unified benchmark for comparing different models and theories, this enterprise offers new teaching and applied tools for research and courses, which will be made available through websites and symposia."
"1217302","RI: Small: Mining and Learning Visual Contexts for Video Scene Understanding","IIS","ROBUST INTELLIGENCE","08/01/2012","06/10/2013","Ying Wu","IL","Northwestern University","Continuing grant","Jie Yang","07/31/2015","$428,880.00","","yingwu@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495","7923","$0.00","This project investigates a fundamental and critical, but largely unexplored issue: automatically identifying visual contexts and discovering visual patterns. Many contemporary approaches that attempt to divide and conquer the video scenes by analyzing the visual objects separately are largely confronted. Exploring visual context has shown its promise for video scene understanding. Discovering visual contexts is a challenging task, due to the content uncertainty in visual data, structure uncertainty in visual contexts, and semantic uncertainty in visual patterns. The goal of this project is to lay the foundation of contextual mining and learning for video scene understanding, by pursuing innovative approaches to discovering collocation visual patterns, to empowering contextual matching of visual patterns, and to facilitating contextual modeling for visual recognition. The research team develops a unified approach to mining visual collocation patterns and learning visual contexts, and to provide methods and tools that facilitate contextual matching and modeling. <br/><br/>This research significantly advances video scene modeling and understanding, and produces an important enabling technology for a wide range of applications including image/video management and search, intelligent surveillance and security, human-computer interaction, social networks, etc. This research program contributes to education through curriculum development, student involvements, and workshops and tutorials outside the vision community. This project also outreaches to K-12 education, and it provides datasets and software on its website to the community."
"0916038","RI: Small: Semi-Supervised Learning for Non-Experts","IIS","ROBUST INTELLIGENCE","09/01/2009","05/18/2010","Xiaojin Zhu","WI","University of Wisconsin-Madison","Standard Grant","Todd Leen","08/31/2014","$426,417.00","","jerryzhu@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","7495, 7923, 9215, HPCC, 9251","$0.00","This project develops semi-supervised machine learning algorithms that are practical, and at the same time guided by rigorous theory. In particular, the project is developing learning theory that quantifies when and to what extent the combination of labeled and unlabeled data is provably beneficial. Based on the theory, novel algorithms are being developed to address issues that currently hinder the wide adoption of semi-supervised learning. The new algorithms will be able to guarantee that using unlabeled data is at least no worse, and often better, than supervised learning. The new algorithms will also be able to learn from unlimited amounts of supervised and unsupervised data as they arrive in real-time, something humans can do but computers cannot so far. <br/><br/>This project has a number of broader impacts: (1) An open-source software will be an enabling tool for new discoveries in science and technology, by making machine learning possible or better in situations where labeled data is scarce. Since the software specifically targets non-machine-learning-experts, the impact is expected to be across the whole spectrum of science and technology that utilizes machine learning. (2) It advances our understanding of the learning process via new machine learning theory, which can be applied to both computers and humans. (3) The proposal contains projects ideally suited to engage students in computer science education and research."
"1017992","RI: Small: Plan Execution for Continuous Dynamical Systems Within Risk Bounds","IIS","ROBUST INTELLIGENCE","09/15/2010","09/13/2010","Brian Williams","MA","Massachusetts Institute of Technology","Standard Grant","Todd Leen","08/31/2014","$298,807.00","","williams@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7495","$0.00","In many applications, from undersea to space, an autonomous agent is given a set of operational goals to achieve optimally, while taking into account the uncertainties that arise from uncontrollable events. For example, in a monitoring mission for an autonomous under-water vehicle (AUV), the goal might be to maximize scientific return, while avoiding hazards. Due to uncertainty, it is unrealistic for many real-world mission to guarantee 100% success. One approach explored extensively within the decision-theoretic planning community is to maximize an objective that trades risk for utility. However, this does not provide any hard guarantees. An alternative approach, commonly employed in engineering practice is to specify risk as a hard constraint, in terms of an upper bound on mission failure (called a chance constraint). For example, NASA Mars missions are designed to meet or exceed a requirement on the probability of successful landing; human-rated vehicles are designed to similar requirements. Given a chance-constrained mission, an agent performing the mission may strive to maximize expected reward, while ensuring that the chance constraint and other operating constraints are met. <br/><br/>This research is developing a model-based executive that achieves goal-level plans within specified risk bounds, while attempting to maximize expected reward. Key attributes of this executive include: 1) user specification of time-evolved goal behaviors; 2) plan execution by generating a sequence of discrete and continuous actions for controlling the plant; and 3) optimal, stochastic planning of control actions within risk bounds and dynamic constraints. The research under this grant is laying the groundwork for longer-term objectives of facilitating continuous adaptation of the initial plan and allocation of risk as uncertainties are resolved during plan execution. Among other applications, we plan tests with AUVs engaged in scientific missions, measuring performance within obstacle-related, time and energy bounds."
"1219142","RI: Small: Semantics-Based, Weakly-Supervised Coreference Resolution","IIS","ROBUST INTELLIGENCE","08/01/2012","06/11/2013","Vincent Ng","TX","University of Texas at Dallas","Continuing grant","Tatiana D. Korelsky","07/31/2015","$347,410.00","","vince@hlt.utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7923","$0.00","This research seeks to push the frontiers of coreference resolution research via achieving two objectives. First, it addresses the Winograd Schema Challenge by examining a class of difficult-to-resolve anaphors whose resolution requires commonsense knowledge involving the roles played by the participants in an event and their causal relationships. It adopts a deep text-understanding approach to this problem. Specifically, it ventures into unexplored areas of coreference research, including the use of script-like knowledge and sentiment analysis, as well as an examination of the role of discourse connectives. Second, it enables the acquisition of coreference resolvers for a substantially larger number of natural languages and domains than is currently possible. One of the major obstacles to the deployment of coreference technologies across a large number of languages and domains is the high cost associated with coreference-annotating data in a language and domain. It investigates two cost-effective approaches to data annotation, one involving translation-based projection and the other bootstrapping.<br/><br/>As coreference is an enabling technology for many traditional and emerging text-processing applications, the project has the potential to improve these applications. Through the construction of a multi-lingual, multi-domain coreference resolver and the availability of annotated data produced in the course of this investigation, the project may stimulate research in under-studied languages and domains by a broader community of researchers. Equally importantly, the use of commonsense knowledge in the resolver mimics the human coreference resolution process, bringing artificial intelligence researchers one step closer to building an intelligent agent that can truly understand natural language."
"1054911","CAREER: Learning- and Incentives-Based Techniques for Aggregating Community-Generated Data","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS","06/01/2011","05/24/2013","Jennifer Vaughan","CA","University of California-Los Angeles","Continuing grant","Maria Zemankova","05/31/2016","$285,746.00","","jenn@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364, 7495, 7796","1045, 1187, 7364, 7926","$0.00","The Internet has led to the availability of novel sources of data on the preferences, behaviors, and beliefs of massive communities of users. <br/>Both researchers and engineers are eager to aggregate and interpret this data. However, websites sometimes fail to incentivize high-quality contributions, leading to variable quality data. Furthermore, assumptions made by traditional theories of learning break down in these settings.<br/><br/>This project seeks to create foundational machine learning models and algorithms to address and explain the issues that arise when aggregating local beliefs across large communities, and to advance the state-of-the-art understanding of how to motivate high quality contributions. The research can be split into three directions:<br/><br/>1. Developing mathematical foundations and algorithms for learning from community-labeled data. This direction involves developing learning models for data from disparate (potentially self-interested or<br/>malicious) sources and using insight from these models to design efficient learning algorithms.<br/><br/>2. Understanding and designing better incentives for crowdsourcing. This direction involves modeling crowdsourcing contributions to determine which features to include in systems to encourage the highest quality contributions.<br/><br/>3. Introducing novel economically-motivated mechanisms for opinion aggregation. This involves formalizing the properties a prediction market should satisfy and making use of ideas from machine learning and optimization to derive tractable market mechanisms satisfying these properties.<br/><br/>This research will have clear impact on industry, especially for web-based crowdsourcing. The PI will pursue her long-term goal of attracting and retaining women in computer science via her involvement in workshops and mentoring programs. Results will be disseminated at http://www.cs.ucla.edu/~jenn/projects/CAREER.html."
"1116078","RI: Small: Coordinating Multi-Agent Learning through Emergent Distributed Supervisory Control","IIS","ROBUST INTELLIGENCE","09/01/2011","09/06/2011","Victor Lesser","MA","University of Massachusetts Amherst","Standard Grant","James Donlon","08/31/2014","$450,000.00","","lesser@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7495","7923","$0.00","The project is focused on developing coordination policies for large-scale multi-agent systems operating in uncertain environments through the use of multi-agent reinforcement learning (MARL). Existing MARL techniques do not scale well. This research addresses the scaling issue by using coordination technology to ""coordinate"" the individual agent learning so as to speed up convergence and lead to learned policies that better reflect overall system objectives. This novel idea is being implemented using an emergent supervisory organization with low overhead that exploits non-local information to dynamically coordinate and shape the learning processes of individual agents while still allowing agents to react autonomously to local feedback. A key question is how to automate the development of the supervisory control process (including supervisory information generation and organization formation). One approach to automation is using a formal model of interactions among agents that also includes a model of global system objectives and policy space of agents to derive the information necessary for appropriate supervisory control. Another approach is the formulation of the supervision problem as a distributed constraint optimization problem. The results of this work provide a necessary component for the development of a wide variety of next-generation adaptive applications, such as smart power grids, cloud computing, and large-scale sensor networks. The broader impact stems from the wide applicability of the resulting learning technology for distributed control, undergraduate and graduate educational activities at UMass, dissemination efforts that make the experimental domain and algorithms publically available, and the development of international collaborations."
"1016815","III: Small: Combining Algorithms for Recognition and Retrieval of Mathematics","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","05/13/2013","Richard Zanibbi","NY","Rochester Institute of Tech","Standard Grant","Maria Zemankova","08/31/2014","$432,364.00","","rlaz@cs.rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757525","CSE","7364","7923, 7364, 9251","$0.00","Currently there is a significant need for increasing mathematical literacy in the United States. Among other benefits, this would permit more Americans to pursue careers in STEM (Science, Technology, Engineering and Mathematics) disciplines. The most extensive resource for finding introductory information on math, the internet, primarily supports text-based search. Similarly, current Portable Document Format (.pdf) viewers support search for text, but not math. The goal of this research is to develop a query-by-expression mechanism, where users enter expressions using images, stylus/finger, mouse and keyboard. Users may then search using a combination of the expression appearance, symbols, structure, and mathematical semantics. Expression properties may be combined with text-based search, allowing queries for mathematical information to be more precise than current text-based methods.<br/><br/>For query-by-expression methods to be viable, improvements in math recognition are needed, along with the development of efficient methods for indexing and retrieving mathematical expressions. In particular, the project seeks to improve optical character recognition (OCR) for handwritten and typeset mathematics, along with methods for parsing expression structure. Approach based on Graph Transformer Networks (GTN) and adaptations of boosting techniques is applied to intelligent combination of modules that locate, recognize and relate mathematical symbols with an aim to further improve recognition. Research focuses on identifying appropriate features, distance metrics, indexing and search methods for expression retrieval. Developed techniques are evaluated via user studies both in-lab settings and through the internet. Additional user studies to identify appropriate use cases for query-by-expression are also planned.<br/><br/>This project is expected to produce new query-by-expression methods usable by both math experts and (perhaps more importantly) non-experts. These methods might be adapted to retrieving other non-textual document elements such as chemical diagrams, tables, and figures. Source code and experimental data developed for the project will be made public via the project web site (http://www.cs.rit.edu/~dprl/msearch.html). To promote mathematical literacy, the principal investigator and graduate students working on the project will visit middle schools and talk about the history, recognition and retrieval of mathematical notation. The PI also plans to participate in the McNair Scholars program at RIT, which seeks to provide research experiences to low-income, first-generation college students that are interested in pursuing doctoral studies."
"0905117","III: Medium: Collaborative Research: Computational Methods to Advance Chemical Genetics by Bridging Chemical and Biological Spaces","IIS","INFO INTEGRATION & INFORMATICS","09/01/2009","09/21/2011","Huzefa Rangwala","VA","George Mason University","Continuing grant","Sylvia J. Spengler","08/31/2014","$339,537.00","","rangwala@cs.gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7364","7364, 7924, 9216, HPCC, 9251","$0.00","The recent development of various government and University funded screening centers has provided the academic research community with access to state-of-the-art high-throughput and high-content screening facilities. As a result, chemical genetics, which uses small organic molecules to alter the function of proteins, has emerged as an important experimental technique for studying and understanding complex biological systems. However, the methods used to develop small-molecule modulators (chemical probes) of specific protein functions and analyze the phenotypes induced by them have not kept pace with advances in the experimental screening technologies. Developing probes for novel protein targets remains a laborious process, whereas experimental approaches to identify the proteins that are responsible for the phenotypes induced by small molecules require a large amount of time and capital expenditure. There is a critical need to develop new methods for probe development and target identification and make them publicly available to the research community. Lack of such tools represents an important problem as it impedes the identification of chemical probes for various proteins and reduces our ability to effectively analyze the experimental results in order to elucidate the molecular mechanisms underlying biological processes. <br/><br/>Intellectual Merit <br/>This project will develop novel algorithms in the areas of cheminformatics, bioinformatics, and machine learning to analyze the publicly available information associated with proteins and the molecules that modulate their functions (target-ligand activity matrix). These algorithms will be used to develop new classes of computational methods and tools to aid in the development of chemical probes and the analysis of the phenotypes elicited by small molecules. The key hypothesis underlying this research is that the target-ligand activity matrix contains a wealth of information that if properly analyzed can provide insights connecting the structure of the chemical compounds (chemical space) to the structure of the proteins and their functions (biological space). Novel methods will be developed to: (i) better analyze the screening results and identify high affinity and selective hits, (ii) build models that can predict the compounds that are active against a novel protein target and select a set of compounds to be included in a high-throughput screen that will be enriched in actives, (iii) virtually generate a set of core molecules (scaffolds) for a given protein target that can be significantly different from those currently available in the various libraries and have a high probability of being active against the target, and (iv) identify the proteins being targeted by compounds in phenotypic assays. In addition, the research will be facilitated by creating a database to integrate a large portion of the publicly-available target-ligand binding data along with information about the targets and the compounds involved. The successful completion of this research will transform the &#64257;eld of chemical genetics by establishing a new methodology by which the increasing amount of target-ligand activity information is used in a systematic way to explicitly guide the discovery of new probes and the analysis of phenotypic assays. <br/><br/>Broader Impact <br/>The ability to discover chemical probes for a wide range of novel protein targets will make it possible to identify drugs for pharmaceutically relevant proteins, positively impacting the rate of drug discovery. In addition, it will greatly increase the set of proteins that can be selectively modulated via small organic molecules, expand the various biological processes that can be investigated via chemical genetics approaches, and allow researchers to use chemical genetics techniques to gain insights on the mechanisms of action associated with certain phenotypes. This will provide a better understanding of the dynamics of these processes and will supplement existing approaches based on molecular genetics. To further aid in the broad dissemination of the results and enhance scientific understanding, the computational methods developed will be made freely available via stand-alone or web-based services to aid researchers working in the area of chemical genomics. Finally, the project integrates the research with an educational plan that focuses on interdisciplinary undergraduate, graduate, and post-graduate education in the areas of Computer Science, Medicinal Chemistry, and Chemical Genetics. <br/><br/>Key Words: supervised learning; semi-supervised learning; cheminformatics; structural bioinformatics; data mining; graph algorithms"
"1031903","Levy Distributions in Foraging Games, Scene Perception, and Semantic Memory","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","09/15/2010","09/10/2010","Christopher Kello","CA","University of California - Merced","Standard Grant","Betty H. Tuller","08/31/2014","$316,968.00","Michael Spivey, Teenie Matlock","ckello@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2092284318","SBE","7252, 7495","OTHR","$0.00","All mobile organisms spend much of their lives searching for something, be it food, water, shelter, or others of their kind. Searching uses perception, memory, cognition, and action. It can occur over vast landscapes and periods of time, as in whale migration behaviors. It can occur in under a second on the basis of fleeting bits of sensory evidence, as in frogs searching their visual fields for flies. And it occurs on all scales in between, across organisms but also across different behaviors of a given organism. Human search is especially diverse in this regard because human searches range from subatomic to human to cosmic scales of exploration.<br/><br/>With support from the National Science Foundation, Dr. Christopher Kello is leading a team of researchers at the University of California, Merced, in the study of human search behaviors in three very different but complementary domains: Foraging over large virtual spaces, visual searches over scenes and movies, and memory searches over words and concepts. The generality and evolutionary importance of search suggests that search functions may share common principles across scales and domains. Evidence for this conjecture has been found in ""Levy distributions"" that describe the frequencies with which segments of different lengths occur in search paths. These frequencies are observed to obey a common scaling law across a wide range of different search behaviors but current evidence is not sufficient to determine the meaning of this law.<br/><br/>With mentorship from three faculty members in Cognitive and Information Sciences, undergraduate and graduate students and a postdoctoral fellow will collaborate on experiments and computational models in each of the three domains of interest, in a unique and highly interdisciplinary education and research experience."
"1217676","RI: Small: Collaborative Research: Ontology based Perceptual Organization of Audio-Video Events using Pattern Theory","IIS","ROBUST INTELLIGENCE","09/01/2012","05/13/2013","Sudeep Sarkar","FL","University of South Florida","Standard Grant","Jie Yang","08/31/2015","$257,843.00","","sarkar@cse.usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139745465","CSE","7495","7923, 7495, 9251","$0.00","It is natural that events of interest in observed scenes manifest themselves across multiple sensing modalities - vision, hearing, smell, etc. The remarkable perceptions of audio-video signals by natural systems, such as humans, also points to superiority of inferences drawn across modalities. It, therefore, seems natural to enhance performance of automated systems by using joint, cross-modal statistical inferences. However, the detection, organization, and understanding of cues and events in real-world scenarios are difficult tasks. This project seeks to develop a pattern-theoretic framework for achieving these goals. The main research items are: (1) development of mathematical quantities to represent audio and visual events and their spatiotemporal relations, (2) use domain-specific ontologies to impose semantic structure and to incorporate prior knowledge, and (3) derive algorithms for Bayesian inferences using efficient adaptations of Markov Chain Monte Carlo sampling. <br/><br/>The use of pattern theory allows bridging of gaps between raw signals and high-level, domain-dependent semantics, and helps discovers large groups of audio-visual events likely to represent the same underlying event. This effort combines ideas from perceptual organization in computer vision, computational analysis of auditory signals, pattern theory, and prior developments in ontological structures. The methods developed here are applicable to many scenarios that deploy audio and video sensors, including problems of audio annotations of videos, speaker tracking in teleconferencing, and separation of multiple objects in remote surveillance. Broader impact activities involve the development of teaching modules, innovation and entrepreneurial training of the students, and communication of the findings to the community."
"1217515","RI: Small: Collaborative Research: Ontology based Perceptual Organization of Audio-Video Events using Pattern Theory","IIS","ROBUST INTELLIGENCE","09/01/2012","05/13/2013","Anuj Srivastava","FL","Florida State University","Standard Grant","Jie Yang","08/31/2015","$255,648.00","","anuj@stat.fsu.edu","874 Traditions Way, 3rd Floor","TALLAHASSEE","FL","323064166","8506445260","CSE","7495","7923, 7495, 9251","$0.00","It is natural that events of interest in observed scenes manifest themselves across multiple sensing modalities - vision, hearing, smell, etc. The remarkable perceptions of audio-video signals by natural systems, such as humans, also points to superiority of inferences drawn across modalities. It, therefore, seems natural to enhance performance of automated systems by using joint, cross-modal statistical inferences. However, the detection, organization, and understanding of cues and events in real-world scenarios are difficult tasks. This project seeks to develop a pattern-theoretic framework for achieving these goals. The main research items are: (1) development of mathematical quantities to represent audio and visual events and their spatiotemporal relations, (2) use domain-specific ontologies to impose semantic structure and to incorporate prior knowledge, and (3) derive algorithms for Bayesian inferences using efficient adaptations of Markov Chain Monte Carlo sampling. <br/><br/>The use of pattern theory allows bridging of gaps between raw signals and high-level, domain-dependent semantics, and helps discovers large groups of audio-visual events likely to represent the same underlying event. This effort combines ideas from perceptual organization in computer vision, computational analysis of auditory signals, pattern theory, and prior developments in ontological structures. The methods developed here are applicable to many scenarios that deploy audio and video sensors, including problems of audio annotations of videos, speaker tracking in teleconferencing, and separation of multiple objects in remote surveillance. Broader impact activities involve the development of teaching modules, innovation and entrepreneurial training of the students, and communication of the findings to the community."
"0904093","RI: Medium: Collaborative Research: Real-Time Continuum Manipulation","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC","08/01/2009","06/20/2012","Jing Xiao","NC","University of North Carolina at Charlotte","Continuing grant","Jie Yang","07/31/2015","$437,587.00","","xiao@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","7495, 1640","7495, 7924, 9102, 9215, HPCC, 1504, 9251, 5761","$0.00","The goal of this project is to investigate the potential of fundamentally new modes of robotic manipulation using novel continuum robots in less-structured environments with large uncertainties and even unknowns. A continuum robot, such as a trunk/tentacle robot arm, is in many senses ?dual? to a traditional robot manipulator (consisting of an articulated arm and a gripper or hand), featuring relatively low precision but high compliance: <br/><br/>* Its inherent flexibility and compliance offer greater promise to enable deft manipulation under imprecise and uncertain conditions of objects over a wider range (orders of magnitude) of size and weight, of many different shapes, and with widely different physical characteristics (rigid, soft, flexible, etc.).. <br/><br/>* On the other hand, its inherent lack of precision renders the traditional approaches to planning and control of robot manipulators unsuitable for manipulation with continuum robots. <br/><br/>This project pioneers the study of the basic problem of autonomous manipulation of an object with much uncertainty by a single continuum robot. It introduces a novel and holistic approach that integrates real-time adaptive planning and robust control schemes under real-time sensing and large environmental uncertainty. It next extends the basic approach to address multiple continuum robots working in a common environment, where each robot needs not know the motion of another robot. The research combines theoretical/algorithmic development with real-world validation on an experimental test bed with real trunk/tentacle robots equipped with sensors. The results will be actively disseminated through publications, free software, and real-world demos to impact research, education, and applications."
"0906056","Monte Carlo and Quasi-Monte Carlo Methods for Statistics","DMS","STATISTICS, INFO INTEGRATION & INFORMATICS","09/15/2009","07/19/2012","Art Owen","CA","Stanford University","Continuing grant","Gabor J. Szekely","08/31/2014","$659,759.00","","owen@stat.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","MPS","1269, 7364","0000, OTHR","$0.00","This project has two major components. The first is an investigation of visualization and analysis methods for data sets in high dimensions, with a focus on categorical variables whose number of unique levels is comparable to the total sample size. Examples of such variables include search query strings, ISBNs, song titles, author names, URLs, genotypes, environments, and customer ID numbers. The visualization methods are designed to show broad trends and to highlight anomalies. The inferential methods are of the sample reuse type: the bootstrap and cross-validation. New methods are necessary here because the data sets have complicated interlocking patterns that invalidate any IID sampling assumptions. The second component is better statistical inference by improving on their numerical methods. This includes calibration of empirical likelihood methods to get better coverage and to extend confidence regions for the mean beyond the convex hull of the data points. It also includes the embedding of quasi-Monte Carlo sampling methods into Markov chain Monte Carlo algorithms to combine the accuracy of the former and the wide applicability of the latter.<br/><br/><br/>Exploratory data analysis of categorical variables is useful to see broad patterns including small groups of customers that have similar tastes for a small list of songs or books or movies. It is also useful to identify anomalies that may indicate abusive behavior, including cyber-attack, and what is commonly called spam in the online context. One of the original motivations for the sample reuse methods is in crop science. In some of those problems, a large number of plant varieties (genotypes) are grown under many different environmental conditions. A statistical model is used to determine which varieties to use in each environment. Earlier statistical methods were based on assumptions that don't fit this setting and they often did not select the best model. New methods from this project may therefore be used to select better models which then result in increased production of food and fiber. The empirical likelihood work is basic research aimed at removing unnecessary mathematical assumptions from statistical models in order to widen their applicability. The Monte Carlo sampling component of the project is basic research on a computational technique used extensively in physics as well Bayesian statistical inference."
"1212508","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Roberto Tamassia","RI","Brown University","Standard Grant","Maria Zemankova","09/30/2017","$250,000.00","","rt@cs.brown.edu","BOX 1929","Providence","RI","029121929","4018632777","CSE","7364","7925, 9150","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1219212","RI: Small: Making sense of incomplete sensor data","IIS","INFORMATION TECHNOLOGY RESEARC, CRCNS, ROBUST INTELLIGENCE","10/01/2012","09/06/2012","Friedrich Sommer","CA","University of California-Berkeley","Standard Grant","Kenneth C. Whang","09/30/2015","$427,097.00","","fsommer@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","1640, 7327, 7495","7923","$0.00","This project focuses on how to reveal the whole from only partial measurements. Often, physical variables can only be incompletely measured. For example, the state-of-the-art techniques to record brain activity (multi-electrode recordings of local field potentials or fMRI measurements) give only a partial account of the activity patterns of large numbers of neurons. In the course of this project, Fritz Sommer, Ph.D., and his collaborators from the University of California, investigate and develop methods for recovering complex multi-dimensional data structure from incomplete measurements. In the general case, when measurements are made (or ""subsampled"") at a rate lower than a mathematical limit called the Nyquist limit, the original signal cannot be fully reconstructed. However, the recent theory of compressed sensing (CS) demonstrated that subsampling below the Nyquist limit can be lossless if the signal to be compressed has sparse structure. The established theory of CS explains when full recovery from incomplete measurements is possible and provides efficient algorithms for full data reconstruction. This result is extremely relevant because many important classes of sensor signals, such as natural images and sounds, have an approximately sparse structure.<br/><br/>The current project explores whether the principle of CS can allow reconstruction of data structure from measurements that subsample an unknown signal in an unknown fashion. Standard CS cannot reconstruct the signal in such situations because the algorithm requires knowledge of how the signal was subsampled and what its structure is. Dr. Sommer and his team plan to develop methods for data reconstruction that can be performed with the subsampled data alone. The idea is to combine CS, a principle about measuring a signal with sparse structure, with sparse coding (SC), a principle for learning efficient representations of signals with sparse structure. Preliminary results suggest that this combination of methods, called adaptive compressed sensing (ACS), can indeed ""learn"" the map for recovering the full data from the subsamples alone (Isely et al. 2011). The team will investigate under what conditions a similar result holds for the large class of real-world sensor data that are not exactly sparse but can be well-approximated by sparse representations. Also being developed are methods on how to draw inferences and make decisions based on incomplete measurements. In particular, a pilot investigation in collaboration with Dr. Bosco Tjan's lab at the University of Southern California will explore whether ACS can be applied to improve the decoding of fMRI data."
"1219130","RI: Small: Collaborative Research: 'Houston We Have A Solution': Novel Speech Processing Advancements for Analysis of Large Asynchronous Multi-Channel Audio Corpora","IIS","ROBUST INTELLIGENCE","09/01/2012","08/09/2012","John H. L. Hansen","TX","University of Texas at Dallas","Standard Grant","Tatiana D. Korelsky","08/31/2015","$365,199.00","Abhijeet Sangwan","John.Hansen@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7923","$0.00","This project is focused on developing new speech processing techniques which will transform access to large asynchronous multi-channel and diverse collections of multimedia materials. In particular, the algorithms developed are being employed to create a novel multi-source and multi-scale event reconstruction system that brings together the massive archives of the Apollo lunar missions, to create experiential interaction with historical materials. Specific research advancements are focused on state of the art acoustic environment analysis, speech recognition including keyword spotting, speaker identification under adverse conditions, multimodal content alignment, and automated linking for events and entities from spoken content. Specifically, the research is developing: (i) new techniques for noise- and channel-robust acoustic processing, exploiting missing-features concepts with novel feature extraction and compensation techniques, (ii) a new articulatory framework for speech recognition for robustness to variations in speech production, (iii) environmental ""sniffing"" techniques to automatically characterize acoustic environments to improve robustness, and (iv) automatic detection of novel task-specific audio-events. Since the data is asynchronous, unique speech analytics techniques are being formulated to address the large number of ""local loop"" intercom circuits in the NASA Mission Control Center, audio recorded onboard the two Apollo spacecrafts during specific mission events, and space-to-ground radio circuits. The specific speech, language, and knowledge extraction advancements will be integrated into a new automated evaluation model that reflects specific challenges encountered in the event reconstruction task. This platform will be deployed and evaluated by actual users from the Science and Engineering Education Center (SEEC) of the University of Texas at Dallas. <br/><br/>Integration of robust speech processing algorithms with event reconstruction systems will have a direct and immediate impact on education, society, and government organizations. Working with NASA's Apollo mission data allows for the development of speech technology for challenging audio that contains severe communication channel artifacts, cross-talk/static/tones, and low signal-to-noise ratios. The software being developed in this project will be made available to any non-profit organization for use in audio/video search (download with training modules). Students working on senior design teams will also develop a Contact Science station to be deployed in Dallas, TX and overseen by the University of Texas in Dallas Science and Engineering Education Center to illustrate and assess student use of the advancements. As a lasting legacy for this project, this project team includes eminent historians of human space flight, who will explore opportunities to deploy this event reconstruction system in a museum setting where it can support both scholarship and public engagement, and we will make the system itself available on an open-source basis to support other researchers."
"1218931","RI: Small: Non-parametric Approximate Dynamic Programming for Continuous Domains","IIS","ROBUST INTELLIGENCE","08/01/2012","07/24/2012","Ronald Parr","NC","Duke University","Standard Grant","Todd Leen","07/31/2015","$450,000.00","","parr@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7923","$0.00","This project concerns a machine learning technique known as reinforcement learning, which is related to, but distinct from, the notion of reinforcement learning used in psychology. The common element is that both views study changes in behavior that result from experience. In the machine learning case, the behaviors are often decision making in dynamic environments, such as controlling a robot, a factory, inventory levels for a warehouse or even drug dosage levels. Current theoretical development in this area guarantees that optimal decisions can be made by reinforcement learning algorithms, but only under restrictive assumptions that are difficult to ensure in practice. Efforts to apply reinforcement learning to significant practical problems have enjoyed some success, but such efforts often forgo theoretical guarantees and rely upon tedious parameter adjustments by experts (human trial and error) to achieve success.<br/><br/>This research seeks to reduce the amount of human trial and error needed to make reinforcement learning successful, thereby making it a more accessible tool to a wider range of people. Specifically, it will focus on algorithms for domains described by continuous variables, seeking to provide stronger theoretical guarantees for such domains as well as an approach that balances the anticipated benefit of trying new things with the benefit of sticking to what is already known about a problem (exploration vs. exploitation). A practical benefit of success in this area would be improved techniques that make it easier for people to deploy algorithms that learn and improve performance in a variety of practical tasks like those mentioned above: robot or factory control, inventory management, or drug delivery.<br/><br/>This project plans to use a model helicopter as a challenge domain, but it is not about helicopter control per se. Rather, it seeks to develop general techniques that can apply to many problems, including helicopters, and will use model helicopters as an inexpensive and fun way to motivate students. The project aims to develop a model helicopter simulator (to reduce the cost and risk of trying everything on an actual helicopter) and plans to make this simulator available to the research community, providing a fun and challenging benchmark problem."
"1219252","RI: Small: A Hierarchical Approach to Unsupervised Feature Discovery","IIS","ROBUST INTELLIGENCE, CRCNS","09/01/2012","09/13/2012","Garrison Cottrell","CA","University of California-San Diego","Standard Grant","Kenneth C. Whang","08/31/2015","$400,000.00","","gary@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7495, 7327","7923","$0.00","Contrary to some depictions in popular media, humans are still far better than any computer program at understanding the visual world around them. If we understood how the visual system does this, perhaps better artificial vision systems could be built. The goal of this project is to understand how the brain represents the visual world and why. Following a mantra famously credited to Richard Feynman -- What I cannot create, I do not understand -- this project's approach is to create a computer system that learns from natural input (images, videos), assuming that the visual system operates with the goal of efficiently representing the world. These representations will then be compared to measurements of visual neurons. The long term goal is to understand the functional roles of the early visual processing layers in the human visual pathway.<br/><br/>The model is based on the efficient coding hypothesis, in which the early visual pathway serves to capture the statistical structure of its visual inputs by efficiently coding visual information in its outputs. Most computational models following this hypothesis have focused on modeling only one or two visual layers. In this project, Cottrell's group proposes a hierarchical information processing model, which concurs with the efficient coding hypothesis, yet provides the most complete description so far of the early visual processing layers. In this model, the visual inputs are first compressed to reduce noise using Sparse Principal Components Analysis (SPCA), then the data dimensions are expanded to capture the statistical structure of the visual inputs using overcomplete Sparse Coding. A nonlinear activation function then formats the outputs of this layer for the next layer up, and the whole process is repeated. Preliminary work shows that the resulting hierarchical model can learn visual features exhibiting the receptive field properties of neurons in the early visual pathway, including retinal ganglion cells, LGN, V1 simple and complex cells, and V2 cells."
"1218471","III: Small: Scalable Analytics for Data Bases and Data Streams--a Unified Approach","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/30/2012","Carlo Zaniolo","CA","University of California-Los Angeles","Standard Grant","Frank Olken","08/31/2015","$499,011.00","","zaniolo@CS.UCLA.EDU","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7923","$0.00","The goal of this project is to support the development of big-data analytics and facilitate the deployment of such applications over the different execution environments encountered in the life-cycle of big-data software. The project achieves its goal by (i) designing and implementating a Scalable Analytics Language (SAL) that supports the definition of advanced analytics through user-defined aggregate functions; (ii) developing a compiler for SAL that optimizes parallel MapReduce-oriented executions over distributed systems containing many nodes, and (iii) developing an early accurate result library (EARL) that enhances (ii) with the ability of providing approximate results based on sampling of the data. Using EARL, the analyst can avoid the slow response and long set up-time of MapReduce applications by simply specifying a target accuracy, with no modification of the original program required. The final delivery of the project is a SAL compiler that optimizes parallel execution of continuous analytical queries on massive data streams, by supporting the synoptic and load-shedding primitives needed to achieve quasi real-time response in this environment. These research results are expected to have great impacts in several areas, including domain science, digital government and e-commerce. The project supports Ph.D. students pursuing research on big-data analytics and their management. Publications, technical reports, software, and experimental data from this research will be disseminated via the project web site (http://yellowstone.cs.ucla.edu/nsf-projects/nsf1218471.html)."
"1252318","CAREER: Annotating the Microbiome using Machine Learning Methods","IIS","INFO INTEGRATION & INFORMATICS","03/01/2013","01/31/2013","Huzefa Rangwala","VA","George Mason University","Standard Grant","Sylvia J. Spengler","02/28/2018","$550,000.00","","rangwala@cs.gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7364","1045, 1187","$0.00","This project addresses an important challenge of developing sophisticated and novel machine learning techniques for complex real-world problems. New technologies allow us to determine the genomes of organisms co-existing within various ecosystems ranging from ocean, soil and human-body. Several researchers have embarked on studying the pathogenic role played by the microbiome, defined as the collection of microbial organisms within the human body, with respect to human health and disease conditions. <br/><br/>The research activities in this CAREER project will develop approaches for the identification of taxonomy, function and metabolic potential from the collective genomes samples. A key contribution will be the development of multi-task learning approaches that combine information across multiple hierarchical databases associated with the annotation problems. During research, the PI will investigate the best ways to capture the underlying hierarchical structure, prevalent within different annotation databases. The rationale underlying this proposed research is that there is a wealth of complementary information that exists across several manually curated biological databases. Associating microbiome with phenotype requires integration of various high-throughput omic data sources (genomic, metabolic, proteomic) that may not be uniformly available across all samples. The PI will develop data fusion classifiers within the multi-task learning paradigm to integrate heterogeneous, incomplete data sources for predicting phenotypes. This project will lead to the following key contributions: (i) Improved metagenome annotation models by integration of multiple prediction tasks and associated databases. (ii) Incorporation of hierarchical information within regularized multi-task learning. (iii) Integration of diverse and incomplete information sources. (iv) Scalable algorithms that use hash based feature representations and improve the learning rates.<br/><br/>This project is interdisciplinary and spans the fields of machine learning, bioinformatics, metagenomics, microbiology and environmental ecology. This project will foster the the synergy between teaching and research by providing an environment for all students to develop intellectually and professionally. The project integrates the research with an education plan focused on mentoring of high school, undergraduate and graduate students, curriculum development and laboratory visits. Planned activities include training of inter-disciplinary researchers, integration of microbiome analysis related projects within the classes, curriculum enhancement and implementation of new learning strategies. Open source software and tools will be developed as part of this project, that will enhance scientific understanding and discovery amongst a broad and diverse group of researchers."
"1213013","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Ouri Wolfson","IL","University of Illinois at Chicago","Standard Grant","Maria Zemankova","09/30/2017","$1,166,599.00","Maria Cruz, Bo Xu","wolfson@cs.uic.edu","809 S MARSHFIELD RM 608","CHICAGO","IL","606127205","3129962862","CSE","7364","7925","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1217797","RI: Small: Uncertainty-driven Dynamic 3D Reconstruction","IIS","ROBUST INTELLIGENCE","08/01/2012","07/16/2012","Philippos Mordohai","NJ","Stevens Institute of Technology","Standard Grant","Jie Yang","07/31/2015","$368,003.00","","Philippos.Mordohai@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","7495","7923","$0.00","This project develops technologies of dynamic 3D reconstruction with applications to broader areas, such as free-viewpoint video, markerless motion capture, special effects for 3D and conventional films, and augmented reality. While image and video-based 3D reconstruction of static scenes is well-understood and is among the most active research areas in computer vision, the current 3D reconstruction methods are not be able to reconstruct dynamic scenes containing non-rigidly moving people, animals or objects well. Furthermore, these methods are unable to self-assess their output. This research effort casts dense multi-view 3D reconstruction as an estimation problem with explicit uncertainty modeling distinguishing between geometric and correspondence uncertainty which are due to very different causes. Other innovations include the combined use of viewpoint-based and world-based processing with explicit and implicit representations and uncertainty-driven regularization.<br/><br/>The outcomes of this project improve 3D reconstruction quality and reduce cost for the above applications which have broader impact on different research areas. Ongoing outreach efforts focus on improving Science, Technology, Engineering and Mathematics (STEM) education in several ways: by teaching high school students during the summer, by mentoring them as interns and by training graduate students working with high school STEM teachers. The project also includes a plan of creating the first publicly available dataset of multiple-view dynamic scenes with ground truth depth."
"1213038","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Goce Trajcevski","IL","Northwestern University","Standard Grant","Maria Zemankova","09/30/2017","$300,000.00","","goce@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7364","7925","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1219199","RI: Small: Efficient Learning Algorithms for Modeling Natural Data","IIS","ROBUST INTELLIGENCE","09/15/2012","08/31/2012","Michael DeWeese","CA","University of California-Berkeley","Standard Grant","Kenneth C. Whang","08/31/2015","$449,999.00","","deweese@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","7923","$0.00","The ability to accurately model such complex phenomena as the natural scene statistics inherent in stacks of photographs or movies, or the collective behavior of hundreds of simultaneously recorded neurons in the cerebral cortex, would be transformative for our understanding of the natural world and of human thought. The insights gained would not only enhance our understanding of the brain and the sensory stimuli it can process, but they would confer practical advantages as well -- leading to improvements in automated speech recognition and meaningful analysis of real-time video, for example. The various data needed for these studies is coming online at a rapid pace, but these large and complex data sets defy traditional modeling and analysis techniques. Unfortunately, the complexity and size of many recently acquired corpora in biology, physics, and engineering domains render them incapable of being fit by powerful mathematical models unless they are constrained by strong and unjustified assumptions about the data. This, coupled with the general difficulty of developing general purpose machine learning algorithms has driven most contemporary scientists and engineers to focus on algorithms tailored to narrow problem spaces rather than tackling the more general machine learning problem. Fortunately, some researchers have continued to push for general learning algorithms with capabilities more similar to human intelligence, but they have typically had to rely on ad hoc assumptions or uncontrolled approximations in order to make progress on this daunting problem. This proposal is to further develop a recently introduced machine learning technique, called Minimum Probability Flow learning, so that it is capable of fitting exceedingly general parametric models to much larger data sets than has ever been possible before. In addition, this proposal is to develop novel, complimentary methods for sampling efficiently from a model distribution once the parameters have been fit to data, so that the models can be understood and meaningfully compared with one another. These techniques will be used to study the statistical structure of natural scenes by fitting a new and powerful mathematical model to a database consisting of a large number of photographs. The program proposed here is highly interdisciplinary, drawing ideas and approaches from physics, engineering, computer science, and systems neuroscience."
"1219114","RI: Small: A New Approach to Influence Diagram Evaluation","IIS","ROBUST INTELLIGENCE","09/01/2012","07/24/2012","Eric Hansen","MS","Mississippi State University","Standard Grant","Todd Leen","08/31/2015","$445,000.00","","hansen@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7495","7923, 9150","$0.00","A central goal of research in artificial intelligence, operations research, and related fields is the development of algorithmic approaches to decision making under uncertainty. This project considers influence diagrams, a widely-used graphical model for representing and solving problems of sequential decision-making under imperfect information. Influence diagrams were originally developed to provide a more compact representation of a decision problem than is provided by a decision tree, which suffers from an exponential explosion in the number of its branches as a function of the number of variables in the model. Although influence diagrams provide a compact problem representation, standard algorithms for solving influence diagrams do not represent the solution to a decision problem in a similarly compact form. This project addresses this limitation by introducing a more compact graphical representation of decision strategies that improves the scalability of algorithms for solving influence diagrams, makes it easier for a human user to understand the recommended decision strategy, and allows a principled approach to approximation. In addition, the project develops a new approach to solving influence diagrams based on branch-and-bound search, including an incremental approach to probabilistic inference.<br/><br/>The algorithms and software tools developed from this project will improve the scalability and utility of influence diagrams as an approach to automated decision making under uncertainty. These contributions will have a broad impact in the many disciplines in which influence diagrams are applied, including medical decision analysis and support, therapy plan selection, user modeling, information retrieval, climate change analysis, and many others."
"1217281","III: Small: Topical Positioning System (TPS) for Informed Reading of Web Pages","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/06/2012","James Allan","MA","University of Massachusetts Amherst","Standard Grant","Maria Zemankova","09/30/2015","$499,752.00","","allan@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","7923","$0.00","This work addresses the challenge of increasing the critical literacy of people looking for information on the Web, including information regarding healthcare, policy, or any other broadly discussed topic. The proposed research on Topical Positioning System ""TPS"" drives the vision of developing a browser tool that shows a person whether the web page in front of them discusses a provocative topic, whether the material is presented in a heavily biased way, whether it represents an outlier (fringe) idea, and how its discussion of issues relates to the broader context and to information presented in ""familiar"" sources. This research applies and extends text analysis and comparison techniques to this problem. It uses statistical language modeling, topic modeling, machine learning, and link analysis techniques to represent Web pages and clusters of Web pages. It requires both off-line pre-processing to organize web-scale collections and on-line, query-time fine-tuning of the organization for presentation in a TPS browser add-on. <br/><br/>This research will be the foundation of class projects as well as graduate student research, exposing a large number of students to issues of web-based search and critical evaluation of information. More importantly, however, this work has the potential to impact many people, helping them make more informed choices in response to what they read on the Web and elsewhere. The results of this project will be published in peer-reviewed venues and listed at the project Web site (http://ciir.cs.umass.edu/research/tps). A freely available TPS browser add-on will be available at this Web site."
"1217279","III: Small: Improving Information Retrieval by Analysis of Temporal Evidence in a Unified Model","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/06/2012","Miles Efron","IL","University of Illinois at Urbana-Champaign","Standard Grant","Maria Zemankova","09/30/2015","$408,765.00","","mefron@illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7364","7923","$0.00","Information retrieval (IR) systems are inherently temporal. Documents change, indexes acquire new documents, and systems answer or ""field"" queries differently over time. The vision of this project is to capitalize on this temporality to improve the models used for predicting document relevance. The approach is based on a novel probabilistic framework to allow temporal factors to improve IR effectiveness. The framework situates temporality as a key factor in predicting the document relevance. Initial work focuses on established text retrieval settings, estimating document relevance to keyword queries. However, emerging domains such as social media and volunteer-maintained knowledge bases have an inherent temporality that demands new models. Thus, during the project, research pursues problems of filtering and topic evolution. Methods developed in this project will be experimentally evaluated using standard datasets. The project's expected outcome includes improved models and algorithms for retrieving, filtering, and organizing textual data that arrives incrementally over time. <br/><br/>The project will benefit society in two ways. IR systems play a key role in people?s daily information use. This project will advance the public's ability to negotiate an increasingly complex information landscape, because the expected outcomes will improve search engine technology. Research results will be disseminated primarily via academic conferences and journals. Work will also be stored in an archival institutional repository, affording the public long-term access to results. Progress and general information about the project will be published on the project Web site (http://timer.lis.illinois.edu). The project will provide research experience for students and will advance scientific education. In addition, course materials will be developed to support on-line teaching of information retrieval to non-technical students."
"1212798","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","09/12/2012","Trevor Darrell","CA","University of California-Berkeley","Standard Grant","Jie Yang","09/30/2017","$818,181.00","Jitendra Malik","trevor@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1218159","RI: Small: Collaborative Research: 'Houston, We Have a Solution': Novel Speech Processing Advancements for Analysis of Large Asynchronous Multi-Channel Audio Corpora","IIS","ROBUST INTELLIGENCE","09/01/2012","08/09/2012","Douglas Oard","MD","University of Maryland College Park","Standard Grant","Tatiana D. Korelsky","08/31/2015","$84,102.00","","oard@glue.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7923","$0.00","This project is focused on developing new speech processing techniques which will transform access to large asynchronous multi-channel and diverse collections of multimedia materials. In particular, the algorithms developed are being employed to create a novel multi-source and multi-scale event reconstruction system that brings together the massive archives of the Apollo lunar missions, to create experiential interaction with historical materials. Specific research advancements are focused on state of the art acoustic environment analysis, speech recognition including keyword spotting, speaker identification under adverse conditions, multimodal content alignment, and automated linking for events and entities from spoken content. Specifically, the research is developing: (i) new techniques for noise- and channel-robust acoustic processing, exploiting missing-features concepts with novel feature extraction and compensation techniques, (ii) a new articulatory framework for speech recognition for robustness to variations in speech production, (iii) environmental ""sniffing"" techniques to automatically characterize acoustic environments to improve robustness, and (iv) automatic detection of novel task-specific audio-events. Since the data is asynchronous, unique speech analytics techniques are being formulated to address the large number of ""local loop"" intercom circuits in the NASA Mission Control Center, audio recorded onboard the two Apollo spacecrafts during specific mission events, and space-to-ground radio circuits. The specific speech, language, and knowledge extraction advancements will be integrated into a new automated evaluation model that reflects specific challenges encountered in the event reconstruction task. This platform will be deployed and evaluated by actual users from the Science and Engineering Education Center (SEEC) of the University of Texas at Dallas. <br/><br/>Integration of robust speech processing algorithms with event reconstruction systems will have a direct and immediate impact on education, society, and government organizations. Working with NASA's Apollo mission data allows for the development of speech technology for challenging audio that contains severe communication channel artifacts, cross-talk/static/tones, and low signal-to-noise ratios. The software being developed in this project will be made available to any non-profit organization for use in audio/video search (download with training modules). Students working on senior design teams will also develop a Contact Science station to be deployed in Dallas, TX and overseen by the University of Texas in Dallas Science and Engineering Education Center to illustrate and assess student use of the advancements. As a lasting legacy for this project, this project team includes eminent historians of human space flight, who will explore opportunities to deploy this event reconstruction system in a museum setting where it can support both scholarship and public engagement, and we will make the system itself available on an open-source basis to support other researchers."
"1232676","Collaborative Research: Emotional Sophistication - Studies of Facial Expressions in Decision Making","BCS","ROBUST INTELLIGENCE, DECISION RISK & MANAGEMENT SCI, PERCEPTION, ACTION & COGNITION","09/01/2012","08/27/2012","Marian Bartlett","CA","University of California-San Diego","Standard Grant","Betty H. Tuller","08/31/2015","$332,962.00","","mbartlett@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","SBE","7495, 1321, 7252","6867, 7298","$0.00","Social and economic decisions cannot be fully explained by ""rational"" attempts to maximize monetary gain, even in very simple game-theoretic scenarios. Complex emotional processes such as anger, guilt or generosity act as hidden forces that lead to observable actions. Such ""non-rational"" motivations can drive our own decisions and they affect our beliefs about what motivates others' decisions as well. The goal of this project is to use automatic measurements of dynamic facial expressions, in combination with other measurements such as functional MRI (fMRI) and eye-tracking, to investigate the role of non-rational motivations in social decision making. The core of the approach is to use state-of-the-art computer vision techniques to extract facial actions from video in real-time while participants interact with a computer or with each other, in some cases viewing live video of each others' faces. The investigators will use powerful statistical machine learning techniques to make inferences about the participants' internal emotional states during the interactions. The goal is to use the inferences concerning emotional state (a) to predict participants' behavior; (b) to explain why a decision is made in terms of the hidden forces driving it; and (c) to build autonomous agents that can use this information to drive their interactions with humans. <br/><br/>This multidisciplinary project contributes to several fields such as psychology, neuroscience, and economics. First, it develops new methodologies to study decision processes. Second, it uses these methods to test hypotheses about social decision-making and to bridge the gap between observable actions and the internal states that generated them. Third, the investigators intend to make available a dataset and toolset that should be an extremely useful for other investigators analyzing facial expression in multiple contexts. Additionally, automatic and on-line decoding of internal motivational states lays the groundwork for ""affectively-aware"" interactive computers, or artificial systems that can make inferences about the emotions and intentions of their users. Through the development of these systems, this project will make a significant contribution to the growing field of human-machine interaction.<br/><br/>[Supported by Perception, Action and Cognition, Decision, Risk and Management Sciences, and Robust Intelligence]"
"1212928","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","09/12/2012","Todd Zickler","MA","Harvard University","Standard Grant","Jie Yang","09/30/2017","$1,090,910.00","Kate Saenko","zickler@eecs.harvard.edu","1350 MASSACHUSETTS AVE","Cambridge","MA","021383846","6174955501","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1218524","III: Small: High-Performance Complex Processing of Continuous Uncertain Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","05/06/2013","Yanlei Diao","MA","University of Massachusetts Amherst","Standard Grant","Sylvia J. Spengler","08/31/2015","$511,961.00","Anna Liu","yanlei@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7364","7923, 9251, 7364","$0.00","The objective of this project is to design and develop a data management system that supports query processing on continuous uncertain data by returning a full probability distribution of query output and optimizes such processing for performance. This project includes four thrusts: (1) supporting continuous uncertain data processing using both the traditional relational model and the array model; (2) addressing complex correlation that arises in continuous uncertain data processing using new statistical graphical models; (3) supporting arbitrary user-defined functions, besides standard query operations, by exploring advanced techniques such as Gaussian processes and functional interpolation; and (4) developing a prototype system and evaluating it using real-world applications. Expected results include statistical models and techniques, data storage schemes, query processing and optimization techniques, and a publicly available prototype to fully support query processing on continuous uncertain data. <br/><br/>The results of the project can benefit applications such as severe weather monitoring and computational astrophysics, as well as the broader scientific community. Since applications such as tornado detection may trigger actions based on derived information, the ability to characterize uncertainty of output may result in significant social impacts. This project also integrates research and education with curriculum development and engaging women in research through college outreach and CRA's distributed mentor program. The results of the project are disseminated at the project web site: http://claro.cs.umass.edu."
"1216467","RI: Small: Reinforcement Learning by Mirror Descent","IIS","ROBUST INTELLIGENCE","08/01/2012","07/16/2012","Sridhar Mahadevan","MA","University of Massachusetts Amherst","Standard Grant","Todd Leen","07/31/2015","$449,991.00","","mahadeva@cs.umass.edu","Research Administration Building","AMHERST","MA","010039242","4135450698","CSE","7495","7923","$0.00","A fundamental challenge in machine learning is the design of computational agents that, rather than being explicitly programmed, autonomously learn complex tasks in stochastic real-world environments. Past approaches, such as reinforcement learning algorithms for solving Markov decision processes, scale poorly to large state spaces. The proposed research addresses this curse of dimensionality by investigating a novel framework combining reinforcement learning and online convex optimization, in particular mirror descent and related algorithms. Mirror descent scales significantly better than classical first-order gradient descent in high-dimensional state spaces, by using a distance-generating function specific to a particular state space geometry.<br/><br/>The proposed framework enables several significant algorithmic advances in the design of autonomous machine learning agents: a new class of first-order mirror-descent based methods for learning sparse solutions to Markov decision processes will be developed that scale significantly significantly better than previous second-order methods; novel hierarchical methods for solving semi-Markov decision processes will be investigated; and finally, applications to a variety of high-dimensional Markov decision processes will be explored.<br/><br/>The anticipated outcomes of the proposed work include foundational advances in designing autonomous agents that learn to solve sequential decision-making problems, which will impact a large number of target applications from manufacturing to robotics and scheduling. The educational goal includes the development of a graduate-level course in online convex optimization for sequential decision-making, as well as interdisciplinary tutorials to enhance the cross-fertilization of ideas from applied mathematics and optimization to machine learning and artificial intelligence."
"1231671","SHB: Type I (EXP): Context-aware Ubiquitous Human Health Monitoring","IIS","Smart and Connected Health, ROBUST INTELLIGENCE","09/01/2012","08/31/2012","Weihua Sheng","OK","Oklahoma State University","Standard Grant","Jie Yang","08/31/2015","$350,000.00","Qi Cheng","weihua.sheng@okstate.edu","101 WHITEHURST HALL","Stillwater","OK","740781011","4057449995","CSE","8018, 7495","8018, 8061, 7495, 9150","$0.00","This project develops a ubiquitous human health monitoring system that collects not only vital signs, but also daily activities and environmental context of a human subject in an everyday life setting. From these collected data, higher level knowledge, such as behavioral and vital sign anomalies, is extracted to assist health evaluation, medical diagnosis/prognosis or healthcare delivery. The research team first develops a low-cost and power-aware wearable Smart Health Monitoring (SmartMon) system, which is integrated into human clothing with minimized obtrusiveness to the wearer. The research team then employs a minimalist approach to understand human?s daily activities and environmental context using the data collected by the SmartMon system. The research team further develops adaptive and intelligent signal processing algorithms to detect anomalies in human daily activities and vital signs for health assessment applications. <br/><br/>This research can significantly improve the ubiquitousness, accuracy, and reliability of wearable human health monitoring. The technologies developed in this project have many different applications, from improving quality of life for elderly people to enhancing capability of first responders during emergency responses. Through the involvement of female, minority (Native American) students, this project prepares a more diversified workforce in the area of biomedical engineering for the State of Oklahoma and the nation."
"1255035","EAGER: An Interoperable Information Infrastructure for Biodiversity Research (I3BR)","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/06/2012","John Wooley","CA","University of California-San Diego","Standard Grant","Sylvia J. Spengler","09/30/2014","$300,000.00","","jwooley@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7364","7364, 7916","$0.00","Biodiversity comprises all variations of life at all levels of biological organization, most of which arise from genomic diversity. As genomic technologies become available across the biological sciences, a full characterization of biodiversity demands a full characterization of genomes. Similarly, data synthesis across the full range of biodiversity research domains demands development, implementation, integration and harmonization of data exchange standards. Such interoperable informatics would be transformational for our understanding of biology, with consequent impact on environmental and conservation policy. Adding to the transformational potential is the fact that the microbial world represents half of the world's biomass and nearly all of its biodiversity, yet is still effectively invisible and intractable to traditional biodiversity research. Metagenomic data are not amenable to the concepts, standards, semantics, and methods of traditional eukaryotic biodiversity, and therefore, require an alternate informatics framework.<br/><br/>The EAGER will transform the collaborations between two previously separate research communities: the informaticists of the traditional biodiversity community, who employ the Darwin Core (DwC) as a standard, and the informaticists of the Genomic Standards Consortium (GSC), who have developed the Minimal Information about any Sequence (MIxS) standard for genomics, metagenomics and marker genes. Together, these groups will engage in a unified informatics effort to develop three layers of interoperability. The EAGER will harmonize the observational (DwC) and genomic (MIxS) standards, building on a community dialogue and interdisciplinary networking hosted and established under an NSF Research Coordination Network. Standards interoperability is the basis for the next two layers. Syntactic interoperability (in the context of Internet APIs and a database Reference Model) will be supported. The EAGER will assemble experts from the two communities to (a) devise a database Reference Model that integrates the DwC and GSC MIxS standards; and (b) for effective data management, create specific implementations for different database platforms to foster adoption. The practical implementation of the reference model on/for different database systems will allow, for the first time, systematic comparative testing of technical performance and of use cases (e.g., which implementation best serves which complex data query). The EAGER will create task groups to establish the infrastructure for managing ontologies, and to construct a reference model on the purely semantic level in order to fuse the two worlds of data standards, both of which are advanced enough to engage in useful interoperability.<br/><br/>In developing an interdisciplinary information infrastructure to achieve data interoperability across domains, this EAGER would advance understanding of complex environmental phenomena and, thereby, inform future policy decisions. Indeed, by leading to an informatics standards platform to conceive a novel conceptual and theoretical framework for the world of microbial ?dark matter,? the EAGER would have a transformational impact beyond science."
"1212849","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","09/12/2012","William Freeman","MA","Massachusetts Institute of Technology","Standard Grant","Jie Yang","09/30/2017","$545,454.00","","wtf@ai.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1217798","III: Small: Provisioning for Autonomous Data Analysis and Scenario Exploration","IIS","INFO INTEGRATION & INFORMATICS","09/01/2012","08/27/2012","Val Tannen","PA","University of Pennsylvania","Standard Grant","Frank Olken","08/31/2015","$500,000.00","Zachary Ives","val@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7364","7923","$0.00","In business intelligence and data-driven science, users often wish to consider various ""what-if scenarios"": hypothetical updates and query refinements. Unfortunately current techniques do not support this type of exploration when query answers have high latency, when data sources charge fees, or in mobile, disconnected settings. This project considers how, given a particular set of query aspects and updates, one can precompute a special data representation that can be stored on a client machine and can be used to directly answer queries under a variety of updates and what-if scenarios, without direct access to the data sources. The project achieves this goal by developing ""provisioned representations"" that capture a form of parameterized data instances, from which complex queries (even with multiple levels of aggregation) can be answered. The work develops: (1) the provisioned representation (PR) formalism, (2) means of encoding and storing PRs, (3) a query system and query processing techniques for PRs, (4) a ""wizard"" for generating PRs from parameterized scenarios, and (5) interactive tools for exploring changes to data and queries over PRs. The work will improve decision support systems and help enable ""information foresight"" - the ability to provide, given a question, answers that include additional data relevant to a user's interests. The project supports Ph.D. students, and also develops a new course on networked information management for the University of Pennsylvania's innovative Market and Social Systems Engineering undergraduate degree program on networks and markets. Data and code will be disseminated through public collaborative portals (GitHub, Google Code) and the project Web site (https://dbappserv.cis.upenn.edu/home/?q=node/173)."
"1218043","III: Small: Providing Relevant and Timely Results: Real-Time Search Architectures and Relevance Algorithms","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/11/2012","Jimmy Lin","MD","University of Maryland College Park","Standard Grant","Maria Zemankova","09/30/2015","$499,960.00","","jimmylin@umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7364","7923","$0.00","Information search remains one of the best solutions today for satisfying individuals' problem-solving needs. However, we are inundated with growing quantities of information as its volume on different media grows, and so does its velocity -- the rate at which information is being generated, transmitted, and consumed. The growing importance of social media such as Twitter and blogs further exacerbates this problem. It is clear that better real-time search capabilities are needed. This project aims to advance the state of the art in information retrieval research by tackling the real-time search problem. The effort consists of two themes: the first concerns high-performance search architectures for low-latency, high-throughput query evaluation and indexing; the second concerns relevance algorithms, exploring strategies to model time-varying relevance signals in a learning-to-rank framework. <br/><br/>Enhanced real-time search capabilities promise to provide users more effective access to time-sensitive information. Scenarios include journalists tracking situations around the globe, victims of natural disaster trying to find loved ones, and political analysts digesting reactions to a candidate's speech. This project is expected to yield an open-source demonstration platform for real-time search on tweets and blogs. Close coordination with shared, community-wide evaluations at the NIST-sponsored Text Retrieval Conferences (TREC) further benefits the broader research community. More information is will disseminated via the project web site (http://www.umiacs.umd.edu/~jimmylin/projects/ ). Research results will be incorporated into class material for the large-data computing course that brings cloud computing into the classroom, and graduate students will have an opportunity to gain research and system development experience."
"1218880","RI: Small: Active Learning with Rich Query Types on Networks and Trees","IIS","ROBUST INTELLIGENCE","09/01/2012","07/31/2012","Mark Craven","WI","University of Wisconsin-Madison","Standard Grant","Todd Leen","08/31/2015","$449,917.00","","craven@biostat.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","7923","$0.00","Supervised machine learning is a critical component of software systems in a wide variety of applications. Although models induced via supervised learning algorithms often provide state-of-the-art accuracy, they are not applied as widely as they could be because they require labeled training instances, which are often expensive to acquire. One promising approach to addressing this limitation is to employ active learning algorithms. These methods are able to make queries in which they choose which instances are labeled and added to the training set. The goal of this project is to develop a new class of algorithms for active learning that broadens the applicability of this approach to more complex, realistic settings. Specifically, we will develop methods that (i) address complex learning tasks such as biological network reconstruction and event extraction from natural language, (ii) assemble batches of queries when it is cost effective to do so, (iii) are able to employ a variety of query types, and (iv) reason about the costs incurred for various queries.<br/><br/>Machine learning represents an important methodology for inferring models that can make useful predictions in scientific, educational, health-care, business and consumer applications. The methods to be developed in this project will provide substantial benefits to machine-learning applications in such problem domains by reducing the cost required to obtain enough data to learn accurate models. Moreover, because this project is connected to specific collaborations with biologists, it is likely to have a direct impact on the ability of scientists to design, conduct and interpret experiments investigating networks of complex relationships such as host-virus interactions. The project will also play a role in training undergraduate and graduate students in interdisciplinary research, and in recruiting undergraduate students from under-represented minority groups into scientific careers."
"1162525","RI: Medium: Collaborative Research: Multilingual Gestural Models for Robust Language-Independent Speech Recognition","IIS","ROBUST INTELLIGENCE, INFORMATION TECHNOLOGY RESEARC","10/01/2012","09/18/2012","Carol Espy-Wilson","MD","University of Maryland College Park","Standard Grant","Tatiana D. Korelsky","09/30/2016","$234,868.00","","espy@glue.umd.edu","3112 LEE BLDG","COLLEGE PARK","MD","207425141","3014056269","CSE","7495, 1640","1640, 7924, 7495","$0.00","Current state-of-the-art automatic speech recognition (ASR) systems typically model speech as a string of acoustically-defined phones and use contextualized phone units, such as tri-phones or quin-phones to model contextual influences due to coarticulation. Such acoustic models may suffer from data sparsity and may fail to capture coarticulation appropriately because the span of a tri- or quin-phone's contextual influence is not flexible. In a small vocabulary context, however, research has shown that ASR systems which estimate articulatory gestures from the acoustics and incorporate these gestures in the ASR process can better model coarticulation and are more robust to noise. The current project investigates the use of estimated articulatory gestures in large vocabulary automatic speech recognition. Gestural representations of the speech signal are initially created from the acoustic waveform using the Task Dynamic model of speech production. These data are then used to train automatic models for articulatory gesture recognition where the articulatory gestures serve as subword units in the gesture-based ASR system. The main goal of the proposed work is to evaluate the performance of a large-vocabulary gesture-based ASR system using American English (AE). The gesture-based system will be compared to a set of competitive state-of-the-art recognition systems in term of word and phone recognition accuracies, both under clean and noisy acoustic background conditions.<br/><br/>The broad impact of this research is threefold: (1) the creation of a large vocabulary American English (AE) speech database containing acoustic waveforms and their articulatory representations, (2) the introduction of novel machine learning techniques to model articulatory representations from acoustic waveforms, and (3) the development of a large vocabulary ASR system that uses articulatory representation as subword units. The robust and accurate ASR system for AE resulting from the proposed project will deal effectively with speech variability, thereby significantly enhancing communication and collaboration between people and machines in AE, and with the promise to generalize the method to multiple languages. The knowledge gained and the systems developed will contribute to the broad application of articulatory features in speech processing, and will have the potential to transform the fields of ASR, speech-mediated person-machine interaction, and automatic translation among languages. The interdisciplinary collaboration will facilitate a cross-disciplinary learning environment for the participating faculty, researchers, graduate students and undergraduate students Thus, this collaboration will result in the broader impact of enhanced training in speech modeling and algorithm development. Finally, the proposed work will result in a set of databases and tools that will be disseminated to serve the research and education community at large."
"1162374","III: Medium: Collaborative Research: Toward Robust and Scalable Discovering of Significant Associations in Massive Genetic Data","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/12/2012","Xiang Zhang","OH","Case Western Reserve University","Standard Grant","Sylvia J. Spengler","09/30/2016","$499,591.00","Jing Li","xiang.zhang@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7364","7924","$0.00","A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high-throughput genetic data are still in their infancy. The objective of this project is to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, the team will develop a multi-layer indexing structure for robust and scalable multiple testing correction, a general phylogenetic tree based framework to account for local population structure, and an ensemble learning approach for studying joint effect of multiple genetic factors.<br/><br/>The research provides a computational framework for large scale genotype-phenotype association study. The outcome includes novel methods for addressing sample relatedness, capturing confounding factors, and controlling multiple testing errors which are widely applicable for many common data mining tasks including frequent pattern mining, multitask learning, and ensemble learning among others. Collectively, the theoretic framework and algorithms will provide the research community much better tools to dissect complex relationships between genotypes and phenotypes, and gain deeper understanding of the roles of environmental stimuli.<br/><br/>The proposed research directly involves applications in large scale genome-wide association study. Additional applications exist for biologists in their study of gene-gene interactions, metabolic pathways and protein-protein interaction networks. Beyond the applications proposed here, the algorithms can find wide applications in other areas of biology as well as other scientific disciplines. The methods will be evaluated thoroughly by both simulation and real data collected from yeast, mouse, and human. Early versions of the applications will be made available to the biological community through a web-based server to evaluate efficacy of the methods and to apply them to a broader set of problems.<br/> <br/>The research findings and methods will be integrated into graduate and undergraduate instruction. The team already offer classes in computational biology and data-mining where the proposed tools will aid students in comprehending abstract concepts and data relations. They will also continue their commitment to supporting multidisciplinary educational experiences, and service to the research community, as well and proving research opportunities for undergraduate students."
"1118107","III: Small: From Regular Expressions to Nested Words in Complex Event and Semistructured Information Processing","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","08/08/2011","Carlo Zaniolo","CA","University of California-Los Angeles","Standard Grant","Frank Olken","08/31/2014","$499,999.00","","zaniolo@CS.UCLA.EDU","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364","7923","$0.00","The need for more powerful and efficient query languages to find complex patterns in stored sequences and data streams is shared by a wide spectrum of applications, including software analysis, complex event processing, identification of RNA structures, temporal databases and XML queries. The goal of this project is to develop a unified framework to support very powerful pattern languages and their query optimization techniques for different application domains. To achieve this goal, the project follows the approach of using (i) nested Kleene-closure (K*) constructs to achieve greater levels of expressive power for the query languages, and (ii) Nested Words and Visibly Pushdown Automata as the basis for their unified implementation and query optimization over different application domains. This K*-based approach was previously applied successfully to relational sequences and are now generalized to different computing environments and application domains. Through the unified framework, the project designs and demonstrates XML and temporal query languages that compare favorably in terms of expressive power and performance with existing ones. It then demonstrates the use of the unified framework in new application areas. In particular, it develops efficient query languages for RNA structures and software analysis. These research results will have great impacts on many applications, such as software analysis, genomic databases, complex event processing, digital government and scientific studies. This project supports Ph.D. students to pursue research in the areas of advanced query languages and data stream management systems. A new graduate-level course covering these areas and integrating the research results from the project are introduced into the curriculum. Publications, technical reports, software and experimental data from this research are available via the project web site at: http://yellowstone.cs.ucla.edu/nsf-projects/RegExpr2NestedWords.html."
"1118122","RI: Small: Generalized Anytime Probabilistic Inference","IIS","ROBUST INTELLIGENCE","10/01/2011","08/16/2011","Adnan Darwiche","CA","University of California-Los Angeles","Standard Grant","Todd Leen","09/30/2014","$449,426.00","","darwiche@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7495","7923","$0.00","Probabilistic reasoning is now routinely used in many fields of science and engineering, where it underlies systems that perform tasks such as text classification, social network analysis, medical diagnosis, information extraction, probabilistic planning, vision and robotics. This project aims to develop an anytime and generalized probabilistic inference engine that targets a wide range of probabilistic representations, including classical, propositional representations --- such as Bayesian and Markov networks --- in addition to more expressive representations based on first order logic. The project will also investigate probabilistic queries in complexity classes that have not received much attention in the literature, yet can be used to study the robustness of inferences and decisions based on probabilistic reasoning systems. The targeted inference engine is planned to put the state of the art in exact inference at the service of approximate inference, allowing it to resign to approximations only when exact inference yields. Moreover, the engine is planned to smoothly and incrementally improve its approximations over time. A key emphasis of the project is to accomplish these objectives while using the most general probabilistic representation as an input, to allow for the widest possible adoption of the developed inference engine. Our anticipated results will impact many fields by allowing users to perform more accurate probabilistic inference, on larger models and in different contexts. Through scientific articles, research seminars, conference presentations, and graduate teaching, we expect the obtained results to be widely disseminated so as to maximize the attained benefits by various communities. Moreover, we plan to publicly release software systems that embed our results, continuing with a long tradition of publicly releasing award-winning software systems for probabilistic reasoning."
"1110948","III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","08/18/2011","Jignesh Patel","WI","University of Wisconsin-Madison","Standard Grant","Maria Zemankova","08/31/2015","$370,706.00","","jignesh@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7364","7925","$0.00","This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br/><br/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br/><br/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists ""in the loop"" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http://www.scidb.org/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http://database.cs.brown.edu/projects/scidb)."
"1125098","Collaborative Research: CDI-Type II: BirdCast: Novel Machine Learning Methods for Understanding Continent-Scale Bird Migration","IIS","CDI TYPE II, INFO INTEGRATION & INFORMATICS","09/01/2011","03/20/2012","Steven Kelling","NY","Cornell University","Standard Grant","Sylvia J. Spengler","08/31/2015","$1,229,845.00","Wesley Hochachka, Andrew Farnsworth","stk2@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7751, 7364","7721, 7751, 9251","$0.00","An interdisciplinary team of computer scientists, statisticians, and ornithologists will develop novel computer science methods and apply them to the challenge of understanding the annual migration of birds across North America, which is one of the most complex and dynamic natural phenomena on the planet. While direct observation of migrating birds is limited to a handful of birds wearing tracking devices, other sources of data provide partial information about migration that, when appropriately combined, will provide insight into migration at a scale previously unimaginable. These sources include a continent-wide network of volunteer bird watchers, night flight calls captured by a network of acoustic monitoring stations, continent-scale weather patterns gathered by a network of weather stations, and clouds of migrating birds detected at night by WSR-88D weather radar stations. To analyze these data, the team will develop two innovative machine learning techniques-Collective Graphical Models (CGMs) and Semi-Parametric Latent Process Models (SLPMs). The resulting model will be able to identify the complex conditions governing the dynamics of migration behavior including the choice of migratory pathways, the factors that influence when birds migrate, and the speed and duration of each night's movements. CGMs greatly extend the scope of phenomena that can be captured with graphical models. Under suitable conditions, a CGM is able to recover a model of the behavior of individuals using only collective observations.<br/><br/>For BirdCast, it will construct a model of individual bird dynamics from the collective observations provided by birders, acoustic and weather stations, and weather radar. Once the model is constructed, it will be applied to live data feeds (bird sightings, acoustic detections, radar detections, and weather forecasts) to predict bird migration in real time. SLPMs are an extension of latent process models, such as the CGM for bird migration, in which the dynamics of a process is represented by latent variables that are observed only indirectly. In an SLPM, the conditional probability distribution of each variable is modeled using flexible, non-parametric methods from machine learning, such as boosted regression trees. Introducing such flexible methods such as CGMs and SLPMs into latent variable models raises difficult challenges for model fitting and validation. Preventing over-fitting will require the creation of novel information regularization and latent model cross-validation methods to enforce latent variable semantics.<br/><br/>The proposed work will allow, for the first time, real-time predictions of bird migrations: when they migrate, where they migrate, and how far they will be flying. Accurate models of migration have broad application for basic research by allowing researchers to understand behavioral aspects of migration, how migration timing and pathways respond to variation in climatic conditions, and whether linkages exist between annual variation in migration timing and subsequent inter-annual changes in population size.<br/><br/>BirdCast will expand opportunities for the public to participate in the gathering of data and its analysis. The existing data set has more than 60 million observations, and the size is growing exponentially. Last year, volunteers contributed more than 1.3 million hours observing birds. Student engagement in the research is significant as well."
"1111371","III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","IIS","INFO INTEGRATION & INFORMATICS","09/01/2011","08/18/2011","Samuel Madden","MA","Massachusetts Institute of Technology","Standard Grant","Maria Zemankova","08/31/2015","$556,168.00","Michael Stonebraker","madden@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7364","7925","$0.00","This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br/><br/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br/><br/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists ""in the loop"" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http://www.scidb.org/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http://database.cs.brown.edu/projects/scidb)."
"1149393","CAREER: Sensing the World with the Distributed Camera","IIS","ROBUST INTELLIGENCE, GRAPHICS & VISUALIZATION","03/01/2012","02/29/2012","Noah Snavely","NY","Cornell University","Standard Grant","Jie Yang","02/28/2017","$498,956.00","","snavely@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495, 7453","1045, 7453","$0.00","We live in a world of ubiquitous imagery, where the number of images at our fingertips is growing at a seemingly exponential rate. These images come from a wide variety of sources, including Internet mapping sites, webcams, surveillance and reconnaissance cameras, and millions of photographers around the world uploading billions and billions of images to photo-sharing websites. Taken together, these sources of photos can be thought of as constituting a distributed camera capturing the entire world at unprecedented scale, and continually documenting its cities, mountains, buildings, people, and events.<br/><br/>This research is creating the basic computational tools for ""calibrating"" this distributed camera, through use of a world-wide database of 3D models built from Internet photo collections using computer vision techniques. The focus is on creating faster, more robust algorithms for 3D reconstruction from unstructured photo collections, as well as techniques for world-scale pose estimation--computing precisely where in the world a photo was taken from image data alone. These tools are yielding large, world-wide databases of calibrated imagery that can help answer questions in science (e.g., finding all available photos of Central Park so as to track flowering times of different plants) and engineering (e.g., finding all of the photos ever taken of a particular bridge to help figure out why it collapsed), and have impact other areas including security, consumer photography, and multimedia search. This research is closely integrated with education and outreach, and includes plans for a summer workshop for high-school students to engage with 3D vision technologies."
"1149299","CAREER: Deep sparse dictionary context models and their application to image parsing and neuron tracking for connectomics","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","09/01/2012","08/30/2012","Tolga Tasdizen","UT","University of Utah","Standard Grant","Kenneth C. Whang","08/31/2017","$409,406.00","","tolga@sci.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7495, 9150","9150, 1045","$0.00","The research objective of this proposal is to create novel computational algorithms and image processing tools that will make it possible for biologists to reconstruct large-scale neural circuits from electron microscopy volumes. Electron microscopy is a key technology in reconstruction of neural circuits at the level of individual neurons and synapses, also known as connectomics. While an important motivation of connectomics is providing anatomical ground truth for neural circuit models, the ability to decipher neural wiring maps at the individual cell level is also important in studies of many neurodegenerative diseases. State-of-the-art image analysis solutions are still far from the accuracy and robustness of human vision and biologists are still limited to studying small neural circuits using mostly manual analysis. The proposed computational models will provide biologists a tool for segmenting individual neurons and detecting other structures such as synapses in very large electron microscopy volumes, and proof reading these automatically produced results in a time efficient manner.<br/><br/>Reconstruction of a neural circuit from an electron microscopy volume involves pixel-by-pixel annotation of these images into classes such as cell membrane, mitochondria and synaptic vesicles and the segmentation of individual neurons in three dimensions. This task demands extremely high accuracy. Even with 99% pixel accuracy, an acceptable accuracy for many other applications, it is virtually certain that almost every neuron in a volume will be incorrectly segmented due to their global, tree-like structure and correspondingly large surface area. Therefore, lack of reliable automated solutions is a critical bottleneck in the field of connectomics. In this project, a novel hierarchical model will be created by combining the representation power of sparse dictionaries and their ease of learning with an inference and proof reading capability. Human experts will contribute to the process by providing ground truth for supervised learning and proof reading of automatically produced results. The combination of deep sparse dictionaries with inference using connection weights from conditional probabilities can provide a very fast way to learn hierarchical models. Several variants of the model will be studied for understanding the relative importance of feature representation, inference, symmetric connections, deep and lateral connections. The model will be applied to general object classification and image parsing problems in computer vision as well as connectomics datasets. Success will be evaluated on real datasets annotated by experts."
"1111765","RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","IIS","COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE","09/01/2011","01/24/2012","Bruno Olshausen","CA","University of California-Berkeley","Standard Grant","Kenneth C. Whang","08/31/2015","$704,999.00","","baolshausen@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7298, 7495","5936, 5979, 7495, 7925","$0.00","How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br/><br/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br/><br/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing."
"1143635","RI: EAGER: Exploratory Research on Acquiring and Adapting Sentence Planning Resources for Generating with Discourse Combinatory Categorial Grammar","IIS","ROBUST INTELLIGENCE","09/01/2011","07/14/2011","Michael White","OH","Ohio State University","Standard Grant","Tatiana D. Korelsky","08/31/2014","$149,937.00","","mwhite@ling.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6142923805","CSE","7495","7495, 7916","$0.00","Natural Language Generation (NLG) systems aim to improve the accessibility and impact of information by turning data into coherent and fluent text or speech, automatically. Developing high-quality NLG systems, however, remains a difficult and costly undertaking, in large part because bridging the gap between content planning and surface realization---a task known as \textit{sentence planning}---continues to require extensive knowledge engineering.<br/><br/>This Early Grant for Exploratory Research investigates ways of bridging this gap by employing machine learning together with Discourse Combinatory Categorial Grammar (DCCG). Using a restaurant recommendation application as a proof-of-concept, the project explores methods of (1) adapting previous work on acquiring lexicalized grammar entries for semantic parsing to learn mappings from domain-general semantic dependency representations to application-specific representations of messages; (2) extending the approach to learn rules for combining messages; (3) employing the acquired resources to map content plans to disjunctive logical forms (DLFs), which compactly specify the range of possible realizations of the selected content; and (4) improving the efficiency of realizing DLFs with OpenCCG through grammar specialization.<br/><br/>The project will evaluate the success of these novel methods and assess the portability of the approach. By demonstrating methods for radically simplifying the construction of NLG systems, the project promises to transform the way NLG systems are built, from today's knowledge-intensive approach to one that relies primarily on assembling a parallel corpus of input-output pairs. Ultimately, it will facilitate the development of generation components in data-to-text systems as well as dialogue systems, including ones for the visually impaired."
"1329659","EAGER: Exploring the Use of Synthetic Speech as Reference Model to Detect Salient Emotional Segments in Speech","IIS","ROBUST INTELLIGENCE","03/15/2013","03/13/2013","Carlos Busso","TX","University of Texas at Dallas","Standard Grant","Tatiana D. Korelsky","08/31/2014","$59,338.00","","busso@utdallas.edu","800 W. Campbell Rd.","Richardson","TX","750803021","9728832313","CSE","7495","7495, 7916","$0.00","This EArly Grant for Exploratory Research aims to create neutral reference model from synthetic speech to contrast the emotional content of a speech signal. Emotional understanding is a crucial skill in human communication. For this reason, modeling and recognizing emotions is essential in the design and implementation of interfaces that are more in tune with the user's needs. Starting from the premise that paralinguistic information is non-uniformly conveyed across time, this study aims to identify emotionally prominent regions or focal points across various acoustic features. The study explores a novel approach based on synthetic speech to build reference models characterizing patterns observed in neutral speech. These reference models are used to contrast the emotional information observed in localized segments of a speech signal. The study builds a synthetic speech signal that conveys the same lexical information and is timely aligned with the target sentence in the database. Since it is expected that a single synthetic speech will not capture the full range of variability observed in neutral speech, the study explores approaches to produce different neutral synthetic realizations. After creating a parallel corpus with time-aligned synthetic speech, the study explores how well synthetic speech captures the acoustic patterns and emotional percepts of neutral, nonemotional speech. Then, a target signal from the database is compared with the properties observed across the family of synthesized signals. <br/><br/>The study presents a novel approach to build a robust emotion recognition system that exploits the underlying nonuniform externalization process of expressive behaviors. Algorithms that able to identify localized emotional segments have the potential to shift the current approaches used in the area of affective computing. Instead of recognizing the emotional content of pre-segmented sentences, the problem is formulated as a detection paradigm, which is appealing from an application perspective. These advances represent a transformative breakthrough in the area of behavioral analysis and affective computing. The proposed models and algorithms provide numerous insights to explore and extend theories in linguistic and paralinguistic human behavior. Having established the base infrastructure for this exploratory research, several new scientific avenues will emerge that serve as truly innovative advancements that will impact applications in security and defense, next generation of advanced user interfaces, health informatics, and education. Furthermore, the scientific methods are enriching venues for interdisciplinary training and mentoring for undergraduate and graduate students."
"1065276","III: Medium: Private Identification of Relatives and Private GWAS: First Steps in the New Field of CryptoGenomics","IIS","INFO INTEGRATION & INFORMATICS, COMM & INFORMATION FOUNDATIONS","07/01/2011","06/22/2011","Eleazar Eskin","CA","University of California-Los Angeles","Standard Grant","Sylvia J. Spengler","06/30/2015","$700,000.00","Amit Sahai, Rafail Ostrovsky","eeskin@cs.ucla.edu","11000 Kinross Avenue, Suite 211","LOS ANGELES","CA","900952000","3107940102","CSE","7364, 7797","7364, 7797, 7924, 7936","$0.00","The field of human genetics has undergone a revolution in the past 10 years with the advent of high-throughput genomic technologies which can measure human variation at low cost. The flagship application of these technologies has been the genome-wide association study (GWAS) where genetic variation information is collected from hundreds of thousands of individuals, a portion of which have a specific disease and a portion of which are healthy individuals. Identification of correlation between genetic variants with disease status has led to the identification of hundreds of new genes involved in dozens of human diseases. All applications of these technologies, including GWAS, require individuals to ""share"" their genetic data. In today's typical GWAS, thousands of individuals must consent to have their genetic information collected and incorporated into a database which also contains information on their disease status. Unfortunately, an individual's genetic data is extremely sensitive as it is considered medical information about an individual. In this proposal, the team addresses the natural tension between privacy and the application of personal genomics technologies by capitalizing on recent breakthroughs in cryptography. They present a novel technological approach to keep one's genetic data private, yet taking full advantage of genetic information - in a privacy-preserving way, by taking advantage of several techniques that have been recently developed in an area broadly referred to as secure computing, which address the problem of allowing a collection of individuals to compute some output that depends on all their inputs, without having to reveal their individual inputs to each other. The core of this proposal focuses on the application of secure computing to two specific problems in personal genomics: The first is the problem of identification of relatives from genetic variation information while preserving privacy of genetic material. The second, is the identification of disease causing variants without sacrificing individual patient's genetic privacy.<br/><br/>The development of the techniques presented in this proposal will have a profound impact on personal genomics and the field of genetics in general for several reasons. First, the easing of privacy fears will drop a major barrier to participation in personal genomics likely increasing the utilization of recent advances in genetic and genomic technologies for the public. This increased utilization will accelerate the medical benefits of these technologies. Second, the current thinking is that it is impossible to protect privacy in personal genomics and the results of this project will surprise many in the field, leading to a rethinking of the how to handle privacy in genetic studies. Finally, this research direction will likely lead to new problems and research directions for the cryptography research community and foster new collaborations between genetics researchers, cryptographers and mathematicians.<br/><br/>This project also contributes to training the next generation of interdisciplinary scientists. The investigators all teach advanced undergraduate courses in both genetics and cryptography and it is likely that the topics developed in this proposal will be included in the curriculum of the courses. In addition, the graduate students involved in this proposal will obtain interdisciplinary training in both genetics and computer science theory."
"1065618","RI: Medium: Approximation Algorithms for Probabilistic Graphical Models with Constraints","IIS","ROBUST INTELLIGENCE","03/15/2011","01/03/2012","Rina Dechter","CA","University of California-Irvine","Continuing grant","James Donlon","02/28/2015","$1,089,282.00","Alexander Ihler","dechter@ics.uci.edu","5171 California Avenue, Ste 150","IRVINE","CA","926977600","9498244768","CSE","7495","7924","$0.00","The goal of this project is to create the next generation of approximate inference techniques and algorithms for probabilistic graphical models. Probabilistic graphical models are employed throughout science and engineering to solve difficult problems, including automated reasoning and decision making, computational biology and genetics, computer vision, data mining, and social network analysis. However, these real-world problems are now of such considerable size that most existing techniques are uneven in their performance in that they typically work well on some problems and not others, and often require sets of choices and customizations that must be made with little guidance or automation.<br/><br/>This project brings together separate but complementary streams of research to develop new algorithms to manage models containing mixtures of probabilistic and deterministic relations and mixtures of graph-based and context-sensitive relationships. This project aims to advance the state of the art of probabilistic reasoning in the presence of deterministic constraints by developing new approximate inference techniques for graphical models, for instance, by exploiting the rich structure of graphical models that is largely neglected by most sampling techniques. This project aims to create improved frameworks for probabilistic graphical models by improving both sampling and message-passing algorithms for approximate inference and developing hybrid approaches that exploit the advantages of each. The frameworks will be used to provide automated guidance for selecting parameters to optimize the inherent tradeoffs between complexity and accuracy as well as provide meaningful bounds on results and accuracy. This project will use the fruits of its research to improve education, both at the undergraduate and graduate level, for instance by developing a new undergraduate course in graphical models, and by posting course materials online. In addition, the project will post open source code on the web."
"1049974","EAGER: Interaction History Management Systems and their Application to Evidence-Based Practice of Healthcare","IIS","INFO INTEGRATION & INFORMATICS","09/01/2010","08/24/2010","Olga Papaemmanouil","MA","Brandeis University","Standard Grant","Frank Olken","08/31/2014","$149,770.00","Stanley Zdonik, Mitch Cherniack, Ugur Cetintemel","olga@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024549110","7817362121","CSE","7364","7916","$0.00","Interactive systems are software systems that incorporate ""human-in-the-loop"" in achieving complex tasks. This proposal introduces Interaction History Management Systems (IHMSs): systems that capture and manage sequences of user interactions that determine the behavior of an interactive system. The interactions managed by an IHMS may be system- and domain-specific and can include SQL queries, search keywords, annotations of results and applied processing algorithms. By managing the histories of such interactions, it becomes possible to optimize and add additional functionality (e.g., versioning, time travel, use analysis) to the underlying interactive system.<br/><br/>This project explores the design and optimization of IHMSs to support the formulation of ""systematic reviews"": human-accumulated evidence that provide empirical data for the effectiveness of treatment strategies of a given patient's diagnosed disease or disorder. The project leverages research in several computer science areas such as query and workflow management, query recommendations and query provenance while it explores new interdisciplinary research domains. It also has high impacts in the domain of healthcare: it leads to the next generation of collaborative, streamlined systematic reviewing systems and therefore improves the effectiveness of evidence-based healthcare practice. Computer science students will be trained in healthcare applications and interdisciplinary research. Further information on the project can be found on the project web page: http://www.cs.brandeis.edu/~olga/IHMS.html"
"0953723","CAREER: Explanation, Decision Making, and Learning in Graphical Models","IIS","EXP PROG TO STIM COMP RES, ROBUST INTELLIGENCE, COLLABORATIVE RESEARCH","08/15/2010","12/13/2011","Changhe Yuan","MS","Mississippi State University","Standard Grant","Todd Leen","07/31/2015","$480,233.00","","changhe.yuan@qc.cuny.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","9150, 7495, 7298","1045, 9215, HPCC, 5955, 5979, 7495, 1187, 9150","$0.00","Graphical models, such as Bayesian networks and influence diagrams, provide principled approaches to solving reasoning and decision making under uncertainty problems. However, the adaptability and scalability of existing methods for these graphical models are often limited. This project aims to address some of these limitations by developing new and improved approaches to explanation, decision making, and learning in graphical models. It includes the following specific objectives: (1) developing new approaches to finding explanations that only contain the most relevant variables for given observations in Bayesian networks, (2) developing heuristic search-based methods and algorithms to solve influence diagrams more efficiently, (3) developing new algorithms for learning optimal Bayesian networks guided by domain-specific heuristic information so that only a small fraction of the solution space need to be explored, and (4) applying the methods developed in this project to real-world applications including multiple-fault diagnosis, supply chain risk management, and online collaborative learning. <br/><br/>This project can lead to significantly better approaches to reasoning and decision making under uncertainty in many disciplines where graphical models have found successful applications, including medicine, security, planning, business, economics, education, and many others. This project can also lead to the development of new and enhanced courses and curricula, the involvement of students from underrepresented groups in the research, and a wide dissemination of the research outcomes through free software, publications, and presentations."
"1054631","CAREER: Algorithms and Applications for Next Generation High-Throughput Sequencing Technologies","IIS","ADVANCES IN BIO INFORMATICS, INFO INTEGRATION & INFORMATICS, EXP PROG TO STIM COMP RES","04/15/2011","04/06/2011","Jinze Liu","KY","University of Kentucky Research Foundation","Standard Grant","Sylvia J. Spengler","03/31/2016","$503,509.00","","liuj@cs.uky.edu","109 Kinkead Hall","Lexington","KY","405060057","8592579420","CSE","1165, 7364, 9150","1045, 7364, 1165, 9150","$0.00","Originally thought to be a relatively uncommon phenomenon, alternative splicing is now appreciated to be a widespread and primary mechanism by which eukaryotes have expanded the structural and functional diversity of their encoded proteome. The new generation of ultra-high throughput sequencers has opened up new ways to study the cell?s alternative splicing and its variation in response to environmental conditions. Accurate characterization of the transcriptome from the hundreds of millions of random short sequences sampled from messenger RNA samples, however, is still an unsolved problem. The PI proposes a research plan involving a set of novel computational approaches to address the issue. It includes: (1) a maximum likelihood approach to achieve highly sensitive and accurate identification of both novel and known splicing and fusion events; (2) a genome-wide transcriptome comparison method to detect statistically significant differential alternative splicing patterns across biological samples; and (3) data mining algorithms to reconstruct co-regulated splicing networks carrying out specific biological functions. <br/><br/>The successful implementation of this research plan will produce a suite of computational and statistical methods implemented as open source software to meet the immediate demand from the biology community for the analysis of high throughput RNA-seq datasets. These tools will enable individual scientists to assess the mRNA transcriptome in a matter of days using samples from any organisms with a reference genome. <br/><br/>The integrated educational program aims to increase the awareness of bioinformatics as a critical interdisciplinary research area among both undergraduate and graduate students from biology, computer science, and engineering at the University of Kentucky (UKy). The PI is committed to enrich the undergraduate curriculum with a new introductory bioinformatics course and to improve cross-disciplinary research training opportunities for graduate and undergraduate students through the Bioinformatics Certificate Program and a newly established Biomedical Informatics Department at UKy. In addition, the PI will emphasize recruitment and retention of under-represented groups including female students and students from the Appalachian region through the NSF funded AMSTEMM program at UKy."
"0937070","FODAVA: Collaborative Research: Foundations of Comparative Analytics for Uncertainty in Graphs","CCF","INFO INTEGRATION & INFORMATICS, GRAPHICS & VISUALIZATION, MSPA-INTERDISCIPLINARY, FOUNDATIONS VISUAL ANALYTICS","09/15/2009","08/26/2011","Lisa Singh","DC","Georgetown University","Standard Grant","Maria Zemankova","08/31/2014","$199,308.00","","singh@cs.georgetown.edu","37th & O St N W","Washington","DC","200571789","2026250100","CSE","7364, 7453, 7454, 7703","9218, 7364, 7703, HPCC","$0.00","This is a collaborative research effort bringing together expertise of Lise Getoor, University of Maryland College Park (0937094), Alex Pang, University of California-Santa Cruz (0937073) and Lisa Singh, Georgetown University (0937070).<br/><br/>In today's linked world, graphs and networks abound. There are communication networks, social networks, financial transaction networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks and more. Observational data describing these networks can often times be obtained; unfortunately, this graph data is usually noisy and uncertain. In this research, we propose a formalism which allows us to capture and reason about the inherent uncertainty and imprecision in an underlying graph. We begin by proposing probabilistic similarity logic (PSL), a simple, yet powerful, language for describing problems which require probabilistic reasoning about similarity in networked data. We also introduce the notion of visual comparative analysis of PSL models derived using different evidence and assumptions, and illustrate its utility for the analysis of graphs and networks. <br/><br/>Dealing with noise and uncertainty in complex domains, and conducting comparative analytics are core capabilities required for the Foundations on Data Analysis and Visual Analytics (FODAVA) mission. This research focuses on integrating representation, comparative analysis and visualizations methods into an open source toolkit that supports the representation, comparison and visualization of PSL models. In addition to producing the toolkit, the research team is working with researchers in a variety of interdisciplinary domains to validate the utility of our approach, and also developing tutorial and training materials for the tools. <br/><br/>The key broader impact of the work is that the methods for reasoning about sources of noise and uncertainty in graphs, and understanding their impact on results are general and fundamental to the intelligent analysis of today's rich information sources. Results, including open source software will be distributed via the project Web site ( http://www.cs.umd.edu/projects/linqs/fodava/ )."
"1054057","CAREER: Statistical Models and Classification of Time-Varying Shape","IIS","ROBUST INTELLIGENCE, EXP PROG TO STIM COMP RES","06/01/2011","04/16/2012","Preston Thomas Fletcher","UT","University of Utah","Standard Grant","Jie Yang","05/31/2016","$412,961.00","","fletcher@sci.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7495, 9150","9251, 9150, 1045, 1187, 7495","$0.00","This project develops nonlinear statistical models and classification procedures for time-varying shape and investigates their application to biomedical image analysis problems. In biology and medicine it is often critical to understand processes that change the shape of anatomy. For example, a neuroscientist studying the development of the infant brain would be interested in how neurodevelopment is different in healthy children versus those with Autism. An evolutionary biologist studying how a species has evolved to adapt to its environment would be interested in studying changes in the shape of bones found in the fossil record. The challenge in this modeling problem is that shape and shape variations are highly nonlinear and high-dimensional, and standard linear statistics cannot be applied. Therefore, the ability to model and understand changes in shape depends on the development of new regression models for data in nonlinear spaces. The research activities of this project include: (1) developing statistical models for dealing with time-varying shape using least-squares principles in shape manifolds, (2) investigating new classification methods for shape sequences, and (3) validating the methodology using synthetic data and testing its efficacy for neuroimaging applications in Alzheimer's disease and Autism. In addition to the significant impact to computer vision, biology, and medicine, this project is combining differential geometry, statistics, and computing within the undergraduate and graduate computer science curriculum."
